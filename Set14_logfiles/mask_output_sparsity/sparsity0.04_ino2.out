(3, 512, 512)
Noisy PSNR is '20.436753992218335'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/2/sparsity/det/0.04/1e-09
epoch:  0 quantization_loss:  0.10812225937843323
p mean is: tensor(-0.0005, device='cuda:5')
epoch:  1000 quantization_loss:  0.08186157792806625
p mean is: tensor(-0.0207, device='cuda:5')
epoch:  2000 quantization_loss:  0.08262820541858673
p mean is: tensor(-0.0341, device='cuda:5')
epoch:  3000 quantization_loss:  0.08042535185813904
p mean is: tensor(-0.0467, device='cuda:5')
epoch:  4000 quantization_loss:  0.07915037125349045
p mean is: tensor(-0.0587, device='cuda:5')
epoch:  5000 quantization_loss:  0.07522314786911011
p mean is: tensor(-0.0710, device='cuda:5')
epoch:  6000 quantization_loss:  0.0731036365032196
p mean is: tensor(-0.0852, device='cuda:5')
epoch:  7000 quantization_loss:  0.06922788172960281
p mean is: tensor(-0.1048, device='cuda:5')
epoch:  8000 quantization_loss:  0.06135781109333038
p mean is: tensor(-0.1301, device='cuda:5')
epoch:  9000 quantization_loss:  0.0580933652818203
p mean is: tensor(-0.1635, device='cuda:5')
epoch:  10000 quantization_loss:  0.05584503710269928
p mean is: tensor(-0.2072, device='cuda:5')
epoch:  11000 quantization_loss:  0.05238376930356026
p mean is: tensor(-0.2648, device='cuda:5')
epoch:  12000 quantization_loss:  0.04911995306611061
p mean is: tensor(-0.3392, device='cuda:5')
epoch:  13000 quantization_loss:  0.047844380140304565
p mean is: tensor(-0.4320, device='cuda:5')
epoch:  14000 quantization_loss:  0.047125861048698425
p mean is: tensor(-0.5438, device='cuda:5')
epoch:  15000 quantization_loss:  0.046125270426273346
p mean is: tensor(-0.6733, device='cuda:5')
epoch:  16000 quantization_loss:  0.044956061989068985
p mean is: tensor(-0.8165, device='cuda:5')
epoch:  17000 quantization_loss:  0.04423457011580467
p mean is: tensor(-0.9673, device='cuda:5')
epoch:  18000 quantization_loss:  0.04381312057375908
p mean is: tensor(-1.1183, device='cuda:5')
epoch:  19000 quantization_loss:  0.04313955083489418
p mean is: tensor(-1.2630, device='cuda:5')
epoch:  20000 quantization_loss:  0.04274601861834526
p mean is: tensor(-1.3976, device='cuda:5')
epoch:  21000 quantization_loss:  0.0424923300743103
p mean is: tensor(-1.5202, device='cuda:5')
epoch:  22000 quantization_loss:  0.04207545146346092
p mean is: tensor(-1.6313, device='cuda:5')
epoch:  23000 quantization_loss:  0.04189838841557503
p mean is: tensor(-1.7316, device='cuda:5')
epoch:  24000 quantization_loss:  0.04054805263876915
p mean is: tensor(-1.8218, device='cuda:5')
epoch:  25000 quantization_loss:  0.04006953164935112
p mean is: tensor(-1.9029, device='cuda:5')
epoch:  26000 quantization_loss:  0.03965453803539276
p mean is: tensor(-1.9754, device='cuda:5')
epoch:  27000 quantization_loss:  0.03954603523015976
p mean is: tensor(-2.0413, device='cuda:5')
epoch:  28000 quantization_loss:  0.03911929577589035
p mean is: tensor(-2.1015, device='cuda:5')
epoch:  29000 quantization_loss:  0.03845444321632385
p mean is: tensor(-2.1560, device='cuda:5')
epoch:  30000 quantization_loss:  0.0380915105342865
p mean is: tensor(-2.2058, device='cuda:5')
epoch:  31000 quantization_loss:  0.0379532128572464
p mean is: tensor(-2.2518, device='cuda:5')
epoch:  32000 quantization_loss:  0.03772612661123276
p mean is: tensor(-2.2946, device='cuda:5')
epoch:  33000 quantization_loss:  0.037616878747940063
p mean is: tensor(-2.3346, device='cuda:5')
epoch:  34000 quantization_loss:  0.03746006265282631
p mean is: tensor(-2.3719, device='cuda:5')
epoch:  35000 quantization_loss:  0.03735297545790672
p mean is: tensor(-2.4069, device='cuda:5')
epoch:  36000 quantization_loss:  0.03730938211083412
p mean is: tensor(-2.4398, device='cuda:5')
epoch:  37000 quantization_loss:  0.03721289709210396
p mean is: tensor(-2.4707, device='cuda:5')
epoch:  38000 quantization_loss:  0.03719653934240341
p mean is: tensor(-2.4999, device='cuda:5')
epoch:  39000 quantization_loss:  0.037091903388500214
p mean is: tensor(-2.5274, device='cuda:5')
epoch:  40000 quantization_loss:  0.03707225248217583
p mean is: tensor(-2.5534, device='cuda:5')
epoch:  41000 quantization_loss:  0.03698824718594551
p mean is: tensor(-2.5780, device='cuda:5')
epoch:  42000 quantization_loss:  0.03696751222014427
p mean is: tensor(-2.6013, device='cuda:5')
epoch:  43000 quantization_loss:  0.0369238406419754
p mean is: tensor(-2.6235, device='cuda:5')
epoch:  44000 quantization_loss:  0.036876048892736435
p mean is: tensor(-2.6445, device='cuda:5')
epoch:  45000 quantization_loss:  0.03685462847352028
p mean is: tensor(-2.6644, device='cuda:5')
epoch:  46000 quantization_loss:  0.03680824115872383
p mean is: tensor(-2.6834, device='cuda:5')
epoch:  47000 quantization_loss:  0.036781858652830124
p mean is: tensor(-2.7015, device='cuda:5')
epoch:  48000 quantization_loss:  0.036786120384931564
p mean is: tensor(-2.7187, device='cuda:5')
epoch:  49000 quantization_loss:  0.036745764315128326
p mean is: tensor(-2.7352, device='cuda:5')
epoch:  50000 quantization_loss:  0.036750130355358124
p mean is: tensor(-2.7508, device='cuda:5')
epoch:  51000 quantization_loss:  0.03672108054161072
p mean is: tensor(-2.7658, device='cuda:5')
epoch:  52000 quantization_loss:  0.036678314208984375
p mean is: tensor(-2.7802, device='cuda:5')
epoch:  53000 quantization_loss:  0.03668651729822159
p mean is: tensor(-2.7939, device='cuda:5')
epoch:  54000 quantization_loss:  0.03665890917181969
p mean is: tensor(-2.8071, device='cuda:5')
epoch:  55000 quantization_loss:  0.036641716957092285
p mean is: tensor(-2.8197, device='cuda:5')
epoch:  56000 quantization_loss:  0.0366375707089901
p mean is: tensor(-2.8318, device='cuda:5')
epoch:  57000 quantization_loss:  0.03662526234984398
p mean is: tensor(-2.8434, device='cuda:5')
epoch:  58000 quantization_loss:  0.03661205992102623
p mean is: tensor(-2.8545, device='cuda:5')
epoch:  59000 quantization_loss:  0.03660551458597183
p mean is: tensor(-2.8653, device='cuda:5')
epoch:  60000 quantization_loss:  0.03658644109964371
p mean is: tensor(-2.8756, device='cuda:5')
epoch:  61000 quantization_loss:  0.036594245582818985
p mean is: tensor(-2.8855, device='cuda:5')
epoch:  62000 quantization_loss:  0.03657927364110947
p mean is: tensor(-2.8951, device='cuda:5')
epoch:  63000 quantization_loss:  0.0365695059299469
p mean is: tensor(-2.9044, device='cuda:5')
epoch:  64000 quantization_loss:  0.03656994551420212
p mean is: tensor(-2.9132, device='cuda:5')
epoch:  65000 quantization_loss:  0.03655528649687767
p mean is: tensor(-2.9218, device='cuda:5')
epoch:  66000 quantization_loss:  0.036552004516124725
p mean is: tensor(-2.9301, device='cuda:5')
epoch:  67000 quantization_loss:  0.03662726283073425
p mean is: tensor(-2.9380, device='cuda:5')
epoch:  68000 quantization_loss:  0.03652895614504814
p mean is: tensor(-2.9457, device='cuda:5')
epoch:  69000 quantization_loss:  0.036527119576931
p mean is: tensor(-2.9532, device='cuda:5')
epoch:  70000 quantization_loss:  0.03654153272509575
p mean is: tensor(-2.9604, device='cuda:5')
epoch:  71000 quantization_loss:  0.03651620075106621
p mean is: tensor(-2.9674, device='cuda:5')
epoch:  72000 quantization_loss:  0.03651838004589081
p mean is: tensor(-2.9742, device='cuda:5')
epoch:  73000 quantization_loss:  0.03651018068194389
p mean is: tensor(-2.9807, device='cuda:5')
epoch:  74000 quantization_loss:  0.036508914083242416
p mean is: tensor(-2.9870, device='cuda:5')
epoch:  75000 quantization_loss:  0.03650302812457085
p mean is: tensor(-2.9931, device='cuda:5')
epoch:  76000 quantization_loss:  0.03649571165442467
p mean is: tensor(-2.9990, device='cuda:5')
epoch:  77000 quantization_loss:  0.03650035336613655
p mean is: tensor(-3.0047, device='cuda:5')
epoch:  78000 quantization_loss:  0.03649222105741501
p mean is: tensor(-3.0103, device='cuda:5')
epoch:  79000 quantization_loss:  0.03648900240659714
p mean is: tensor(-3.0157, device='cuda:5')
Number of elements to keep: 120354
Threshold value: -1.1830261945724487
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.03999977400131013
Number of elements to keep: 120354
Threshold value: -1.1830261945724487
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.03999977400131013
1.1.1.weight         | nonzeros =     589 /   12800             (  4.60%) | total_pruned =   12211 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =      84 /    6400             (  1.31%) | total_pruned =    6316 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      53 /   12800             (  0.41%) | total_pruned =   12747 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      10 /      32             ( 31.25%) | total_pruned =      22 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     109 /   25600             (  0.43%) | total_pruned =   25491 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =       7 /      32             ( 21.88%) | total_pruned =      25 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     158 /   51200             (  0.31%) | total_pruned =   51042 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     297 /  102400             (  0.29%) | total_pruned =  102103 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     281 /  204800             (  0.14%) | total_pruned =  204519 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     588 /  409600             (  0.14%) | total_pruned =  409012 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     687 /  409600             (  0.17%) | total_pruned =  408913 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    2126 /  409600             (  0.52%) | total_pruned =  407474 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    5757 /  409600             (  1.41%) | total_pruned =  403843 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   19043 /  409600             (  4.65%) | total_pruned =  390557 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   26874 /  147456             ( 18.23%) | total_pruned =  120582 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   27211 /  147456             ( 18.45%) | total_pruned =  120245 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   20976 /  147456             ( 14.23%) | total_pruned =  126480 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   10583 /   73728             ( 14.35%) | total_pruned =   63145 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2613 /   18432             ( 14.18%) | total_pruned =   15819 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1049 /    4608             ( 22.76%) | total_pruned =    3559 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      28 /      48             ( 58.33%) | total_pruned =      20 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 120354, pruned : 2888513, total: 3008867, Compression rate :      25.00x  ( 96.00% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  15.374820202623408
Experiment done
