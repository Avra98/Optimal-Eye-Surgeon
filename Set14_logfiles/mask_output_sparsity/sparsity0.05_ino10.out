(3, 512, 512)
Noisy PSNR is '20.183303821340218'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/10/sparsity/det/0.05/1e-09
epoch:  0 quantization_loss:  0.059403251856565475
p mean is: tensor(-0.0005, device='cuda:5')
epoch:  1000 quantization_loss:  0.058085519820451736
p mean is: tensor(-0.0208, device='cuda:5')
epoch:  2000 quantization_loss:  0.05806745961308479
p mean is: tensor(-0.0382, device='cuda:5')
epoch:  3000 quantization_loss:  0.0576503612101078
p mean is: tensor(-0.0561, device='cuda:5')
epoch:  4000 quantization_loss:  0.05788024514913559
p mean is: tensor(-0.0740, device='cuda:5')
epoch:  5000 quantization_loss:  0.05664534121751785
p mean is: tensor(-0.0918, device='cuda:5')
epoch:  6000 quantization_loss:  0.05683430656790733
p mean is: tensor(-0.1096, device='cuda:5')
epoch:  7000 quantization_loss:  0.049512431025505066
p mean is: tensor(-0.1272, device='cuda:5')
epoch:  8000 quantization_loss:  0.04344353824853897
p mean is: tensor(-0.1480, device='cuda:5')
epoch:  9000 quantization_loss:  0.03998654708266258
p mean is: tensor(-0.1756, device='cuda:5')
epoch:  10000 quantization_loss:  0.03328552469611168
p mean is: tensor(-0.2129, device='cuda:5')
epoch:  11000 quantization_loss:  0.03009207360446453
p mean is: tensor(-0.2616, device='cuda:5')
epoch:  12000 quantization_loss:  0.027698848396539688
p mean is: tensor(-0.3241, device='cuda:5')
epoch:  13000 quantization_loss:  0.02666267193853855
p mean is: tensor(-0.4031, device='cuda:5')
epoch:  14000 quantization_loss:  0.02571343258023262
p mean is: tensor(-0.5004, device='cuda:5')
epoch:  15000 quantization_loss:  0.023148715496063232
p mean is: tensor(-0.6145, device='cuda:5')
epoch:  16000 quantization_loss:  0.022381950169801712
p mean is: tensor(-0.7421, device='cuda:5')
epoch:  17000 quantization_loss:  0.021627603098750114
p mean is: tensor(-0.8786, device='cuda:5')
epoch:  18000 quantization_loss:  0.02070526033639908
p mean is: tensor(-1.0178, device='cuda:5')
epoch:  19000 quantization_loss:  0.020672917366027832
p mean is: tensor(-1.1535, device='cuda:5')
epoch:  20000 quantization_loss:  0.019133996218442917
p mean is: tensor(-1.2813, device='cuda:5')
epoch:  21000 quantization_loss:  0.018757561221718788
p mean is: tensor(-1.3987, device='cuda:5')
epoch:  22000 quantization_loss:  0.018495112657546997
p mean is: tensor(-1.5053, device='cuda:5')
epoch:  23000 quantization_loss:  0.018150607123970985
p mean is: tensor(-1.6017, device='cuda:5')
epoch:  24000 quantization_loss:  0.017976054921746254
p mean is: tensor(-1.6890, device='cuda:5')
epoch:  25000 quantization_loss:  0.017726223915815353
p mean is: tensor(-1.7682, device='cuda:5')
epoch:  26000 quantization_loss:  0.017556704580783844
p mean is: tensor(-1.8400, device='cuda:5')
epoch:  27000 quantization_loss:  0.017353154718875885
p mean is: tensor(-1.9052, device='cuda:5')
epoch:  28000 quantization_loss:  0.01728781871497631
p mean is: tensor(-1.9649, device='cuda:5')
epoch:  29000 quantization_loss:  0.017110362648963928
p mean is: tensor(-2.0195, device='cuda:5')
epoch:  30000 quantization_loss:  0.016891829669475555
p mean is: tensor(-2.0696, device='cuda:5')
epoch:  31000 quantization_loss:  0.016906023025512695
p mean is: tensor(-2.1156, device='cuda:5')
epoch:  32000 quantization_loss:  0.016735518351197243
p mean is: tensor(-2.1581, device='cuda:5')
epoch:  33000 quantization_loss:  0.016679691150784492
p mean is: tensor(-2.1974, device='cuda:5')
epoch:  34000 quantization_loss:  0.016682565212249756
p mean is: tensor(-2.2338, device='cuda:5')
epoch:  35000 quantization_loss:  0.01649058796465397
p mean is: tensor(-2.2677, device='cuda:5')
epoch:  36000 quantization_loss:  0.016447417438030243
p mean is: tensor(-2.2993, device='cuda:5')
epoch:  37000 quantization_loss:  0.016380274668335915
p mean is: tensor(-2.3289, device='cuda:5')
epoch:  38000 quantization_loss:  0.016312342137098312
p mean is: tensor(-2.3566, device='cuda:5')
epoch:  39000 quantization_loss:  0.01625821366906166
p mean is: tensor(-2.3826, device='cuda:5')
epoch:  40000 quantization_loss:  0.016206515952944756
p mean is: tensor(-2.4071, device='cuda:5')
epoch:  41000 quantization_loss:  0.016136372461915016
p mean is: tensor(-2.4300, device='cuda:5')
epoch:  42000 quantization_loss:  0.016102945432066917
p mean is: tensor(-2.4517, device='cuda:5')
epoch:  43000 quantization_loss:  0.016072764992713928
p mean is: tensor(-2.4721, device='cuda:5')
epoch:  44000 quantization_loss:  0.0160866379737854
p mean is: tensor(-2.4915, device='cuda:5')
epoch:  45000 quantization_loss:  0.01601433753967285
p mean is: tensor(-2.5097, device='cuda:5')
epoch:  46000 quantization_loss:  0.01597311906516552
p mean is: tensor(-2.5271, device='cuda:5')
epoch:  47000 quantization_loss:  0.015949616208672523
p mean is: tensor(-2.5437, device='cuda:5')
epoch:  48000 quantization_loss:  0.015934541821479797
p mean is: tensor(-2.5594, device='cuda:5')
epoch:  49000 quantization_loss:  0.01589309610426426
p mean is: tensor(-2.5743, device='cuda:5')
epoch:  50000 quantization_loss:  0.015887927263975143
p mean is: tensor(-2.5885, device='cuda:5')
epoch:  51000 quantization_loss:  0.015861596912145615
p mean is: tensor(-2.6021, device='cuda:5')
epoch:  52000 quantization_loss:  0.015874715521931648
p mean is: tensor(-2.6151, device='cuda:5')
epoch:  53000 quantization_loss:  0.015832655131816864
p mean is: tensor(-2.6275, device='cuda:5')
epoch:  54000 quantization_loss:  0.015820592641830444
p mean is: tensor(-2.6393, device='cuda:5')
epoch:  55000 quantization_loss:  0.015803847461938858
p mean is: tensor(-2.6507, device='cuda:5')
epoch:  56000 quantization_loss:  0.01579826883971691
p mean is: tensor(-2.6615, device='cuda:5')
epoch:  57000 quantization_loss:  0.015811793506145477
p mean is: tensor(-2.6719, device='cuda:5')
epoch:  58000 quantization_loss:  0.01577850431203842
p mean is: tensor(-2.6819, device='cuda:5')
epoch:  59000 quantization_loss:  0.015766577795147896
p mean is: tensor(-2.6915, device='cuda:5')
epoch:  60000 quantization_loss:  0.015746133401989937
p mean is: tensor(-2.7006, device='cuda:5')
epoch:  61000 quantization_loss:  0.01569860428571701
p mean is: tensor(-2.7094, device='cuda:5')
epoch:  62000 quantization_loss:  0.015749430283904076
p mean is: tensor(-2.7179, device='cuda:5')
epoch:  63000 quantization_loss:  0.01573845185339451
p mean is: tensor(-2.7261, device='cuda:5')
epoch:  64000 quantization_loss:  0.015734994783997536
p mean is: tensor(-2.7340, device='cuda:5')
epoch:  65000 quantization_loss:  0.015710467472672462
p mean is: tensor(-2.7416, device='cuda:5')
epoch:  66000 quantization_loss:  0.01570519432425499
p mean is: tensor(-2.7489, device='cuda:5')
epoch:  67000 quantization_loss:  0.015680205076932907
p mean is: tensor(-2.7560, device='cuda:5')
epoch:  68000 quantization_loss:  0.01569206826388836
p mean is: tensor(-2.7627, device='cuda:5')
epoch:  69000 quantization_loss:  0.015681376680731773
p mean is: tensor(-2.7693, device='cuda:5')
epoch:  70000 quantization_loss:  0.01570526510477066
p mean is: tensor(-2.7756, device='cuda:5')
epoch:  71000 quantization_loss:  0.015661444514989853
p mean is: tensor(-2.7818, device='cuda:5')
epoch:  72000 quantization_loss:  0.01566087268292904
p mean is: tensor(-2.7878, device='cuda:5')
epoch:  73000 quantization_loss:  0.015655631199479103
p mean is: tensor(-2.7936, device='cuda:5')
epoch:  74000 quantization_loss:  0.015652529895305634
p mean is: tensor(-2.7991, device='cuda:5')
epoch:  75000 quantization_loss:  0.015641851350665092
p mean is: tensor(-2.8046, device='cuda:5')
epoch:  76000 quantization_loss:  0.015633489936590195
p mean is: tensor(-2.8098, device='cuda:5')
epoch:  77000 quantization_loss:  0.015628980472683907
p mean is: tensor(-2.8150, device='cuda:5')
epoch:  78000 quantization_loss:  0.015713347122073174
p mean is: tensor(-2.8199, device='cuda:5')
epoch:  79000 quantization_loss:  0.0156247578561306
p mean is: tensor(-2.8247, device='cuda:5')
Number of elements to keep: 150443
Threshold value: -1.7164067029953003
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
Number of elements to keep: 150443
Threshold value: -1.7164067029953003
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
1.1.1.weight         | nonzeros =     990 /   12800             (  7.73%) | total_pruned =   11810 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     119 /    6400             (  1.86%) | total_pruned =    6281 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       5 /      16             ( 31.25%) | total_pruned =      11 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     191 /   12800             (  1.49%) | total_pruned =   12609 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      13 /      32             ( 40.62%) | total_pruned =      19 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     518 /   25600             (  2.02%) | total_pruned =   25082 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      12 /      32             ( 37.50%) | total_pruned =      20 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     649 /   51200             (  1.27%) | total_pruned =   50551 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =    1086 /  102400             (  1.06%) | total_pruned =  101314 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =    1584 /  204800             (  0.77%) | total_pruned =  203216 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =    2443 /  409600             (  0.60%) | total_pruned =  407157 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    3418 /  409600             (  0.83%) | total_pruned =  406182 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    6775 /  409600             (  1.65%) | total_pruned =  402825 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   13701 /  409600             (  3.34%) | total_pruned =  395899 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   27840 /  409600             (  6.80%) | total_pruned =  381760 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   27539 /  147456             ( 18.68%) | total_pruned =  119917 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   25405 /  147456             ( 17.23%) | total_pruned =  122051 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   20835 /  147456             ( 14.13%) | total_pruned =  126621 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   11983 /   73728             ( 16.25%) | total_pruned =   61745 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    3032 /   18432             ( 16.45%) | total_pruned =   15400 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1030 /    4608             ( 22.35%) | total_pruned =    3578 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      29 /      48             ( 60.42%) | total_pruned =      19 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 150443, pruned : 2858424, total: 3008867, Compression rate :      20.00x  ( 95.00% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  22.025781634337847
Experiment done
