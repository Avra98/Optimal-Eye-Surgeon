(3, 512, 512)
Noisy PSNR is '20.432108171608448'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/2/sparsity/det/0.035/1e-09
epoch:  0 quantization_loss:  0.0938435047864914
p mean is: tensor(-0.0005, device='cuda:0')
epoch:  1000 quantization_loss:  0.08038579672574997
p mean is: tensor(-0.0200, device='cuda:0')
epoch:  2000 quantization_loss:  0.07659708708524704
p mean is: tensor(-0.0345, device='cuda:0')
epoch:  3000 quantization_loss:  0.07604648172855377
p mean is: tensor(-0.0482, device='cuda:0')
epoch:  4000 quantization_loss:  0.07613559812307358
p mean is: tensor(-0.0620, device='cuda:0')
epoch:  5000 quantization_loss:  0.07482756674289703
p mean is: tensor(-0.0765, device='cuda:0')
epoch:  6000 quantization_loss:  0.07558103650808334
p mean is: tensor(-0.0911, device='cuda:0')
epoch:  7000 quantization_loss:  0.07173669338226318
p mean is: tensor(-0.1066, device='cuda:0')
epoch:  8000 quantization_loss:  0.06685046851634979
p mean is: tensor(-0.1243, device='cuda:0')
epoch:  9000 quantization_loss:  0.05938658490777016
p mean is: tensor(-0.1474, device='cuda:0')
epoch:  10000 quantization_loss:  0.05476006865501404
p mean is: tensor(-0.1776, device='cuda:0')
epoch:  11000 quantization_loss:  0.04890848696231842
p mean is: tensor(-0.2174, device='cuda:0')
epoch:  12000 quantization_loss:  0.0460808202624321
p mean is: tensor(-0.2693, device='cuda:0')
epoch:  13000 quantization_loss:  0.0422813855111599
p mean is: tensor(-0.3371, device='cuda:0')
epoch:  14000 quantization_loss:  0.040059302002191544
p mean is: tensor(-0.4228, device='cuda:0')
epoch:  15000 quantization_loss:  0.03838403895497322
p mean is: tensor(-0.5278, device='cuda:0')
epoch:  16000 quantization_loss:  0.037595197558403015
p mean is: tensor(-0.6520, device='cuda:0')
epoch:  17000 quantization_loss:  0.036239370703697205
p mean is: tensor(-0.7924, device='cuda:0')
epoch:  18000 quantization_loss:  0.03557634726166725
p mean is: tensor(-0.9428, device='cuda:0')
epoch:  19000 quantization_loss:  0.03484266251325607
p mean is: tensor(-1.0957, device='cuda:0')
epoch:  20000 quantization_loss:  0.0344034843146801
p mean is: tensor(-1.2442, device='cuda:0')
epoch:  21000 quantization_loss:  0.03383183479309082
p mean is: tensor(-1.3836, device='cuda:0')
epoch:  22000 quantization_loss:  0.033467285335063934
p mean is: tensor(-1.5113, device='cuda:0')
epoch:  23000 quantization_loss:  0.033214349299669266
p mean is: tensor(-1.6268, device='cuda:0')
epoch:  24000 quantization_loss:  0.0325690321624279
p mean is: tensor(-1.7307, device='cuda:0')
epoch:  25000 quantization_loss:  0.03235163912177086
p mean is: tensor(-1.8241, device='cuda:0')
epoch:  26000 quantization_loss:  0.0321345329284668
p mean is: tensor(-1.9082, device='cuda:0')
epoch:  27000 quantization_loss:  0.03200213983654976
p mean is: tensor(-1.9846, device='cuda:0')
epoch:  28000 quantization_loss:  0.031710218638181686
p mean is: tensor(-2.0543, device='cuda:0')
epoch:  29000 quantization_loss:  0.03165598586201668
p mean is: tensor(-2.1181, device='cuda:0')
epoch:  30000 quantization_loss:  0.03141085058450699
p mean is: tensor(-2.1768, device='cuda:0')
epoch:  31000 quantization_loss:  0.031323712319135666
p mean is: tensor(-2.2309, device='cuda:0')
epoch:  32000 quantization_loss:  0.031225742772221565
p mean is: tensor(-2.2809, device='cuda:0')
epoch:  33000 quantization_loss:  0.031098218634724617
p mean is: tensor(-2.3272, device='cuda:0')
epoch:  34000 quantization_loss:  0.031032443046569824
p mean is: tensor(-2.3703, device='cuda:0')
epoch:  35000 quantization_loss:  0.03096427209675312
p mean is: tensor(-2.4106, device='cuda:0')
epoch:  36000 quantization_loss:  0.030878718942403793
p mean is: tensor(-2.4482, device='cuda:0')
epoch:  37000 quantization_loss:  0.03083263337612152
p mean is: tensor(-2.4836, device='cuda:0')
epoch:  38000 quantization_loss:  0.030747119337320328
p mean is: tensor(-2.5167, device='cuda:0')
epoch:  39000 quantization_loss:  0.030717438086867332
p mean is: tensor(-2.5479, device='cuda:0')
epoch:  40000 quantization_loss:  0.030647505074739456
p mean is: tensor(-2.5774, device='cuda:0')
epoch:  41000 quantization_loss:  0.030590340495109558
p mean is: tensor(-2.6052, device='cuda:0')
epoch:  42000 quantization_loss:  0.030580367892980576
p mean is: tensor(-2.6316, device='cuda:0')
epoch:  43000 quantization_loss:  0.030543340370059013
p mean is: tensor(-2.6566, device='cuda:0')
epoch:  44000 quantization_loss:  0.030506661161780357
p mean is: tensor(-2.6802, device='cuda:0')
epoch:  45000 quantization_loss:  0.030468497425317764
p mean is: tensor(-2.7027, device='cuda:0')
epoch:  46000 quantization_loss:  0.030428973957896233
p mean is: tensor(-2.7241, device='cuda:0')
epoch:  47000 quantization_loss:  0.03040895238518715
p mean is: tensor(-2.7445, device='cuda:0')
epoch:  48000 quantization_loss:  0.030381929129362106
p mean is: tensor(-2.7639, device='cuda:0')
epoch:  49000 quantization_loss:  0.03036186844110489
p mean is: tensor(-2.7824, device='cuda:0')
epoch:  50000 quantization_loss:  0.030347790569067
p mean is: tensor(-2.8001, device='cuda:0')
epoch:  51000 quantization_loss:  0.030325371772050858
p mean is: tensor(-2.8170, device='cuda:0')
epoch:  52000 quantization_loss:  0.03030126914381981
p mean is: tensor(-2.8332, device='cuda:0')
epoch:  53000 quantization_loss:  0.0303291454911232
p mean is: tensor(-2.8487, device='cuda:0')
epoch:  54000 quantization_loss:  0.03026047721505165
p mean is: tensor(-2.8635, device='cuda:0')
epoch:  55000 quantization_loss:  0.030356939882040024
p mean is: tensor(-2.8778, device='cuda:0')
epoch:  56000 quantization_loss:  0.03024759143590927
p mean is: tensor(-2.8915, device='cuda:0')
epoch:  57000 quantization_loss:  0.030218761414289474
p mean is: tensor(-2.9046, device='cuda:0')
epoch:  58000 quantization_loss:  0.03022710233926773
p mean is: tensor(-2.9172, device='cuda:0')
epoch:  59000 quantization_loss:  0.030227741226553917
p mean is: tensor(-2.9294, device='cuda:0')
epoch:  60000 quantization_loss:  0.030225491151213646
p mean is: tensor(-2.9411, device='cuda:0')
epoch:  61000 quantization_loss:  0.030190834775567055
p mean is: tensor(-2.9524, device='cuda:0')
epoch:  62000 quantization_loss:  0.030184198170900345
p mean is: tensor(-2.9634, device='cuda:0')
epoch:  63000 quantization_loss:  0.03017946146428585
p mean is: tensor(-2.9739, device='cuda:0')
epoch:  64000 quantization_loss:  0.030168961733579636
p mean is: tensor(-2.9840, device='cuda:0')
epoch:  65000 quantization_loss:  0.030154366046190262
p mean is: tensor(-2.9938, device='cuda:0')
epoch:  66000 quantization_loss:  0.030153637751936913
p mean is: tensor(-3.0033, device='cuda:0')
epoch:  67000 quantization_loss:  0.030154922977089882
p mean is: tensor(-3.0124, device='cuda:0')
epoch:  68000 quantization_loss:  0.030138619244098663
p mean is: tensor(-3.0212, device='cuda:0')
epoch:  69000 quantization_loss:  0.03013458289206028
p mean is: tensor(-3.0298, device='cuda:0')
epoch:  70000 quantization_loss:  0.03013860434293747
p mean is: tensor(-3.0380, device='cuda:0')
epoch:  71000 quantization_loss:  0.030130205675959587
p mean is: tensor(-3.0461, device='cuda:0')
epoch:  72000 quantization_loss:  0.030119087547063828
p mean is: tensor(-3.0538, device='cuda:0')
epoch:  73000 quantization_loss:  0.030118079856038094
p mean is: tensor(-3.0613, device='cuda:0')
epoch:  74000 quantization_loss:  0.03011053241789341
p mean is: tensor(-3.0685, device='cuda:0')
epoch:  75000 quantization_loss:  0.030100686475634575
p mean is: tensor(-3.0756, device='cuda:0')
epoch:  76000 quantization_loss:  0.030102629214525223
p mean is: tensor(-3.0824, device='cuda:0')
epoch:  77000 quantization_loss:  0.03010120615363121
p mean is: tensor(-3.0890, device='cuda:0')
epoch:  78000 quantization_loss:  0.030098024755716324
p mean is: tensor(-3.0955, device='cuda:0')
epoch:  79000 quantization_loss:  0.03009386546909809
p mean is: tensor(-3.1018, device='cuda:0')
Number of elements to keep: 105310
Threshold value: 3.6389851570129395
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.03499988533889999
Number of elements to keep: 105310
Threshold value: 3.6389851570129395
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.03499988533889999
1.1.1.weight         | nonzeros =     464 /   12800             (  3.62%) | total_pruned =   12336 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =      25 /    6400             (  0.39%) | total_pruned =    6375 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       3 /      16             ( 18.75%) | total_pruned =      13 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =       4 /   12800             (  0.03%) | total_pruned =   12796 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =       7 /      32             ( 21.88%) | total_pruned =      25 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =       4 /   25600             (  0.02%) | total_pruned =   25596 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =       6 /      32             ( 18.75%) | total_pruned =      26 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =       1 /   51200             (  0.00%) | total_pruned =   51199 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =       1 /  102400             (  0.00%) | total_pruned =  102399 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =       0 /  204800             (  0.00%) | total_pruned =  204800 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =       0 /  409600             (  0.00%) | total_pruned =  409600 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =       0 /  409600             (  0.00%) | total_pruned =  409600 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =      36 /  409600             (  0.01%) | total_pruned =  409564 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    1089 /  409600             (  0.27%) | total_pruned =  408511 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   11734 /  409600             (  2.86%) | total_pruned =  397866 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   26363 /  147456             ( 17.88%) | total_pruned =  121093 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   26366 /  147456             ( 17.88%) | total_pruned =  121090 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   22721 /  147456             ( 15.41%) | total_pruned =  124735 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   11400 /   73728             ( 15.46%) | total_pruned =   62328 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2781 /   18432             ( 15.09%) | total_pruned =   15651 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1031 /    4608             ( 22.37%) | total_pruned =    3577 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      15 /      16             ( 93.75%) | total_pruned =       1 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      31 /      48             ( 64.58%) | total_pruned =      17 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       3 /       3             (100.00%) | total_pruned =       0 | shape = torch.Size([3])
alive: 105310, pruned : 2903557, total: 3008867, Compression rate :      28.57x  ( 96.50% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  11.119421344617086
Experiment done
