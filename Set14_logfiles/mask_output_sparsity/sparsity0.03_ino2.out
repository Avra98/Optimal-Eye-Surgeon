(3, 512, 512)
Noisy PSNR is '20.432593594605596'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/2/sparsity/det/0.03/1e-09
epoch:  0 quantization_loss:  0.1047295331954956
p mean is: tensor(-0.0006, device='cuda:3')
epoch:  1000 quantization_loss:  0.08074270933866501
p mean is: tensor(-0.0184, device='cuda:3')
epoch:  2000 quantization_loss:  0.0771511122584343
p mean is: tensor(-0.0300, device='cuda:3')
epoch:  3000 quantization_loss:  0.07623333483934402
p mean is: tensor(-0.0415, device='cuda:3')
epoch:  4000 quantization_loss:  0.07675035297870636
p mean is: tensor(-0.0529, device='cuda:3')
epoch:  5000 quantization_loss:  0.07002139836549759
p mean is: tensor(-0.0654, device='cuda:3')
epoch:  6000 quantization_loss:  0.0654352456331253
p mean is: tensor(-0.0812, device='cuda:3')
epoch:  7000 quantization_loss:  0.06380683928728104
p mean is: tensor(-0.1030, device='cuda:3')
epoch:  8000 quantization_loss:  0.0601147785782814
p mean is: tensor(-0.1338, device='cuda:3')
epoch:  9000 quantization_loss:  0.05192101001739502
p mean is: tensor(-0.1736, device='cuda:3')
epoch:  10000 quantization_loss:  0.04728317633271217
p mean is: tensor(-0.2234, device='cuda:3')
epoch:  11000 quantization_loss:  0.041827455163002014
p mean is: tensor(-0.2868, device='cuda:3')
epoch:  12000 quantization_loss:  0.039820197969675064
p mean is: tensor(-0.3656, device='cuda:3')
epoch:  13000 quantization_loss:  0.03856993466615677
p mean is: tensor(-0.4628, device='cuda:3')
epoch:  14000 quantization_loss:  0.03687563166022301
p mean is: tensor(-0.5789, device='cuda:3')
epoch:  15000 quantization_loss:  0.03512490168213844
p mean is: tensor(-0.7121, device='cuda:3')
epoch:  16000 quantization_loss:  0.03438572958111763
p mean is: tensor(-0.8570, device='cuda:3')
epoch:  17000 quantization_loss:  0.03362298011779785
p mean is: tensor(-1.0075, device='cuda:3')
epoch:  18000 quantization_loss:  0.032838400453329086
p mean is: tensor(-1.1568, device='cuda:3')
epoch:  19000 quantization_loss:  0.03233567997813225
p mean is: tensor(-1.2998, device='cuda:3')
epoch:  20000 quantization_loss:  0.031547319144010544
p mean is: tensor(-1.4334, device='cuda:3')
epoch:  21000 quantization_loss:  0.03130074962973595
p mean is: tensor(-1.5563, device='cuda:3')
epoch:  22000 quantization_loss:  0.0309591181576252
p mean is: tensor(-1.6684, device='cuda:3')
epoch:  23000 quantization_loss:  0.030487749725580215
p mean is: tensor(-1.7701, device='cuda:3')
epoch:  24000 quantization_loss:  0.03034307062625885
p mean is: tensor(-1.8626, device='cuda:3')
epoch:  25000 quantization_loss:  0.030150411650538445
p mean is: tensor(-1.9469, device='cuda:3')
epoch:  26000 quantization_loss:  0.029783809557557106
p mean is: tensor(-2.0238, device='cuda:3')
epoch:  27000 quantization_loss:  0.03004974126815796
p mean is: tensor(-2.0944, device='cuda:3')
epoch:  28000 quantization_loss:  0.029393060132861137
p mean is: tensor(-2.1591, device='cuda:3')
epoch:  29000 quantization_loss:  0.029237201437354088
p mean is: tensor(-2.2188, device='cuda:3')
epoch:  30000 quantization_loss:  0.029030799865722656
p mean is: tensor(-2.2740, device='cuda:3')
epoch:  31000 quantization_loss:  0.028925884515047073
p mean is: tensor(-2.3253, device='cuda:3')
epoch:  32000 quantization_loss:  0.028772396966814995
p mean is: tensor(-2.3730, device='cuda:3')
epoch:  33000 quantization_loss:  0.02872774377465248
p mean is: tensor(-2.4178, device='cuda:3')
epoch:  34000 quantization_loss:  0.02860528789460659
p mean is: tensor(-2.4596, device='cuda:3')
epoch:  35000 quantization_loss:  0.02853950299322605
p mean is: tensor(-2.4990, device='cuda:3')
epoch:  36000 quantization_loss:  0.028498543426394463
p mean is: tensor(-2.5359, device='cuda:3')
epoch:  37000 quantization_loss:  0.028369097039103508
p mean is: tensor(-2.5705, device='cuda:3')
epoch:  38000 quantization_loss:  0.028332551941275597
p mean is: tensor(-2.6033, device='cuda:3')
epoch:  39000 quantization_loss:  0.028234925121068954
p mean is: tensor(-2.6343, device='cuda:3')
epoch:  40000 quantization_loss:  0.028205936774611473
p mean is: tensor(-2.6636, device='cuda:3')
epoch:  41000 quantization_loss:  0.028247501701116562
p mean is: tensor(-2.6914, device='cuda:3')
epoch:  42000 quantization_loss:  0.02808951959013939
p mean is: tensor(-2.7177, device='cuda:3')
epoch:  43000 quantization_loss:  0.028084242716431618
p mean is: tensor(-2.7428, device='cuda:3')
epoch:  44000 quantization_loss:  0.0280164685100317
p mean is: tensor(-2.7668, device='cuda:3')
epoch:  45000 quantization_loss:  0.027978019788861275
p mean is: tensor(-2.7896, device='cuda:3')
epoch:  46000 quantization_loss:  0.027951106429100037
p mean is: tensor(-2.8112, device='cuda:3')
epoch:  47000 quantization_loss:  0.02792983315885067
p mean is: tensor(-2.8320, device='cuda:3')
epoch:  48000 quantization_loss:  0.02791447937488556
p mean is: tensor(-2.8518, device='cuda:3')
epoch:  49000 quantization_loss:  0.027877286076545715
p mean is: tensor(-2.8708, device='cuda:3')
epoch:  50000 quantization_loss:  0.027840446680784225
p mean is: tensor(-2.8889, device='cuda:3')
epoch:  51000 quantization_loss:  0.027824562042951584
p mean is: tensor(-2.9064, device='cuda:3')
epoch:  52000 quantization_loss:  0.02798912301659584
p mean is: tensor(-2.9232, device='cuda:3')
epoch:  53000 quantization_loss:  0.027783764526247978
p mean is: tensor(-2.9392, device='cuda:3')
epoch:  54000 quantization_loss:  0.027766721323132515
p mean is: tensor(-2.9547, device='cuda:3')
epoch:  55000 quantization_loss:  0.027748987078666687
p mean is: tensor(-2.9696, device='cuda:3')
epoch:  56000 quantization_loss:  0.027729040011763573
p mean is: tensor(-2.9838, device='cuda:3')
epoch:  57000 quantization_loss:  0.02772073820233345
p mean is: tensor(-2.9976, device='cuda:3')
epoch:  58000 quantization_loss:  0.027704259380698204
p mean is: tensor(-3.0109, device='cuda:3')
epoch:  59000 quantization_loss:  0.02768944576382637
p mean is: tensor(-3.0237, device='cuda:3')
epoch:  60000 quantization_loss:  0.02768496796488762
p mean is: tensor(-3.0361, device='cuda:3')
epoch:  61000 quantization_loss:  0.02767881751060486
p mean is: tensor(-3.0480, device='cuda:3')
epoch:  62000 quantization_loss:  0.027669042348861694
p mean is: tensor(-3.0595, device='cuda:3')
epoch:  63000 quantization_loss:  0.027655091136693954
p mean is: tensor(-3.0707, device='cuda:3')
epoch:  64000 quantization_loss:  0.027643874287605286
p mean is: tensor(-3.0815, device='cuda:3')
epoch:  65000 quantization_loss:  0.027642453089356422
p mean is: tensor(-3.0919, device='cuda:3')
epoch:  66000 quantization_loss:  0.027631938457489014
p mean is: tensor(-3.1020, device='cuda:3')
epoch:  67000 quantization_loss:  0.027620211243629456
p mean is: tensor(-3.1118, device='cuda:3')
epoch:  68000 quantization_loss:  0.02767309732735157
p mean is: tensor(-3.1213, device='cuda:3')
epoch:  69000 quantization_loss:  0.027617719024419785
p mean is: tensor(-3.1305, device='cuda:3')
epoch:  70000 quantization_loss:  0.02760523371398449
p mean is: tensor(-3.1394, device='cuda:3')
epoch:  71000 quantization_loss:  0.027609679847955704
p mean is: tensor(-3.1480, device='cuda:3')
epoch:  72000 quantization_loss:  0.027682501822710037
p mean is: tensor(-3.1564, device='cuda:3')
epoch:  73000 quantization_loss:  0.027583913877606392
p mean is: tensor(-3.1645, device='cuda:3')
epoch:  74000 quantization_loss:  0.027587013319134712
p mean is: tensor(-3.1723, device='cuda:3')
epoch:  75000 quantization_loss:  0.027584217488765717
p mean is: tensor(-3.1800, device='cuda:3')
epoch:  76000 quantization_loss:  0.02756970189511776
p mean is: tensor(-3.1874, device='cuda:3')
epoch:  77000 quantization_loss:  0.02757652848958969
p mean is: tensor(-3.1946, device='cuda:3')
epoch:  78000 quantization_loss:  0.02756541036069393
p mean is: tensor(-3.2017, device='cuda:3')
epoch:  79000 quantization_loss:  0.027562154456973076
p mean is: tensor(-3.2086, device='cuda:3')
Number of elements to keep: 90266
Threshold value: 5.482963562011719
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.029999996676489855
Number of elements to keep: 90266
Threshold value: 5.482963562011719
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.029999996676489855
1.1.1.weight         | nonzeros =     192 /   12800             (  1.50%) | total_pruned =   12608 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       5 /      16             ( 31.25%) | total_pruned =      11 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =      13 /    6400             (  0.20%) | total_pruned =    6387 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       4 /      16             ( 25.00%) | total_pruned =      12 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =       0 /   12800             (  0.00%) | total_pruned =   12800 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =       3 /      32             (  9.38%) | total_pruned =      29 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =       0 /   25600             (  0.00%) | total_pruned =   25600 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =       9 /      32             ( 28.12%) | total_pruned =      23 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =       0 /   51200             (  0.00%) | total_pruned =   51200 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =       0 /  102400             (  0.00%) | total_pruned =  102400 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =       0 /  204800             (  0.00%) | total_pruned =  204800 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =       0 /  409600             (  0.00%) | total_pruned =  409600 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      37 /     128             ( 28.91%) | total_pruned =      91 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =       0 /  409600             (  0.00%) | total_pruned =  409600 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =       4 /  409600             (  0.00%) | total_pruned =  409596 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     157 /  409600             (  0.04%) | total_pruned =  409443 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    4466 /  409600             (  1.09%) | total_pruned =  405134 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   24775 /  147456             ( 16.80%) | total_pruned =  122681 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   25598 /  147456             ( 17.36%) | total_pruned =  121858 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   19951 /  147456             ( 13.53%) | total_pruned =  127505 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    9358 /   73728             ( 12.69%) | total_pruned =   64370 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    3083 /   18432             ( 16.73%) | total_pruned =   15349 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1425 /    4608             ( 30.92%) | total_pruned =    3183 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      32 /      48             ( 66.67%) | total_pruned =      16 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 90266, pruned : 2918601, total: 3008867, Compression rate :      33.33x  ( 97.00% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  10.739304585760634
Experiment done
