(3, 256, 256)
Noisy PSNR is '20.304556142754176'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/3/sparsity/det/0.035/1e-09
epoch:  0 quantization_loss:  0.08104062080383301
p mean is: tensor(-0.0005, device='cuda:2')
epoch:  1000 quantization_loss:  0.07343800365924835
p mean is: tensor(-0.0178, device='cuda:2')
epoch:  2000 quantization_loss:  0.07327114790678024
p mean is: tensor(-0.0305, device='cuda:2')
epoch:  3000 quantization_loss:  0.07227469980716705
p mean is: tensor(-0.0431, device='cuda:2')
epoch:  4000 quantization_loss:  0.07189109176397324
p mean is: tensor(-0.0555, device='cuda:2')
epoch:  5000 quantization_loss:  0.0711691603064537
p mean is: tensor(-0.0681, device='cuda:2')
epoch:  6000 quantization_loss:  0.07202108204364777
p mean is: tensor(-0.0811, device='cuda:2')
epoch:  7000 quantization_loss:  0.07122071087360382
p mean is: tensor(-0.0942, device='cuda:2')
epoch:  8000 quantization_loss:  0.07067563384771347
p mean is: tensor(-0.1074, device='cuda:2')
epoch:  9000 quantization_loss:  0.0718066543340683
p mean is: tensor(-0.1210, device='cuda:2')
epoch:  10000 quantization_loss:  0.07099360227584839
p mean is: tensor(-0.1349, device='cuda:2')
epoch:  11000 quantization_loss:  0.07158931344747543
p mean is: tensor(-0.1494, device='cuda:2')
epoch:  12000 quantization_loss:  0.07092516124248505
p mean is: tensor(-0.1642, device='cuda:2')
epoch:  13000 quantization_loss:  0.07127843052148819
p mean is: tensor(-0.1798, device='cuda:2')
epoch:  14000 quantization_loss:  0.07139378786087036
p mean is: tensor(-0.1959, device='cuda:2')
epoch:  15000 quantization_loss:  0.07062304019927979
p mean is: tensor(-0.2126, device='cuda:2')
epoch:  16000 quantization_loss:  0.07158894091844559
p mean is: tensor(-0.2300, device='cuda:2')
epoch:  17000 quantization_loss:  0.07125791907310486
p mean is: tensor(-0.2480, device='cuda:2')
epoch:  18000 quantization_loss:  0.07031838595867157
p mean is: tensor(-0.2660, device='cuda:2')
epoch:  19000 quantization_loss:  0.07143034785985947
p mean is: tensor(-0.2844, device='cuda:2')
epoch:  20000 quantization_loss:  0.06735040992498398
p mean is: tensor(-0.3028, device='cuda:2')
epoch:  21000 quantization_loss:  0.06320449709892273
p mean is: tensor(-0.3251, device='cuda:2')
epoch:  22000 quantization_loss:  0.05308721214532852
p mean is: tensor(-0.3540, device='cuda:2')
epoch:  23000 quantization_loss:  0.04871372506022453
p mean is: tensor(-0.3920, device='cuda:2')
epoch:  24000 quantization_loss:  0.047443293035030365
p mean is: tensor(-0.4429, device='cuda:2')
epoch:  25000 quantization_loss:  0.04584916681051254
p mean is: tensor(-0.5103, device='cuda:2')
epoch:  26000 quantization_loss:  0.04500884935259819
p mean is: tensor(-0.5973, device='cuda:2')
epoch:  27000 quantization_loss:  0.04299814626574516
p mean is: tensor(-0.7057, device='cuda:2')
epoch:  28000 quantization_loss:  0.04115545377135277
p mean is: tensor(-0.8345, device='cuda:2')
epoch:  29000 quantization_loss:  0.03967204689979553
p mean is: tensor(-0.9794, device='cuda:2')
epoch:  30000 quantization_loss:  0.03904436528682709
p mean is: tensor(-1.1340, device='cuda:2')
epoch:  31000 quantization_loss:  0.03780621290206909
p mean is: tensor(-1.2899, device='cuda:2')
epoch:  32000 quantization_loss:  0.036863453686237335
p mean is: tensor(-1.4398, device='cuda:2')
epoch:  33000 quantization_loss:  0.036213021725416183
p mean is: tensor(-1.5786, device='cuda:2')
epoch:  34000 quantization_loss:  0.035728320479393005
p mean is: tensor(-1.7043, device='cuda:2')
epoch:  35000 quantization_loss:  0.03526958450675011
p mean is: tensor(-1.8163, device='cuda:2')
epoch:  36000 quantization_loss:  0.03501980006694794
p mean is: tensor(-1.9163, device='cuda:2')
epoch:  37000 quantization_loss:  0.0346941277384758
p mean is: tensor(-2.0056, device='cuda:2')
epoch:  38000 quantization_loss:  0.03439580276608467
p mean is: tensor(-2.0859, device='cuda:2')
epoch:  39000 quantization_loss:  0.034177087247371674
p mean is: tensor(-2.1580, device='cuda:2')
epoch:  40000 quantization_loss:  0.034052565693855286
p mean is: tensor(-2.2229, device='cuda:2')
epoch:  41000 quantization_loss:  0.03354940190911293
p mean is: tensor(-2.2818, device='cuda:2')
epoch:  42000 quantization_loss:  0.03340642526745796
p mean is: tensor(-2.3354, device='cuda:2')
epoch:  43000 quantization_loss:  0.0325818695127964
p mean is: tensor(-2.3844, device='cuda:2')
epoch:  44000 quantization_loss:  0.03239155560731888
p mean is: tensor(-2.4291, device='cuda:2')
epoch:  45000 quantization_loss:  0.032262761145830154
p mean is: tensor(-2.4703, device='cuda:2')
epoch:  46000 quantization_loss:  0.03217508643865585
p mean is: tensor(-2.5086, device='cuda:2')
epoch:  47000 quantization_loss:  0.032078128308057785
p mean is: tensor(-2.5440, device='cuda:2')
epoch:  48000 quantization_loss:  0.031954504549503326
p mean is: tensor(-2.5770, device='cuda:2')
epoch:  49000 quantization_loss:  0.0318288616836071
p mean is: tensor(-2.6077, device='cuda:2')
epoch:  50000 quantization_loss:  0.03182334080338478
p mean is: tensor(-2.6365, device='cuda:2')
epoch:  51000 quantization_loss:  0.031685855239629745
p mean is: tensor(-2.6634, device='cuda:2')
epoch:  52000 quantization_loss:  0.0316445454955101
p mean is: tensor(-2.6887, device='cuda:2')
epoch:  53000 quantization_loss:  0.03157586604356766
p mean is: tensor(-2.7125, device='cuda:2')
epoch:  54000 quantization_loss:  0.03159501403570175
p mean is: tensor(-2.7349, device='cuda:2')
epoch:  55000 quantization_loss:  0.03168519586324692
p mean is: tensor(-2.7559, device='cuda:2')
epoch:  56000 quantization_loss:  0.03143252432346344
p mean is: tensor(-2.7757, device='cuda:2')
epoch:  57000 quantization_loss:  0.03141250088810921
p mean is: tensor(-2.7944, device='cuda:2')
epoch:  58000 quantization_loss:  0.03135489672422409
p mean is: tensor(-2.8122, device='cuda:2')
epoch:  59000 quantization_loss:  0.03133342042565346
p mean is: tensor(-2.8290, device='cuda:2')
epoch:  60000 quantization_loss:  0.03129607439041138
p mean is: tensor(-2.8450, device='cuda:2')
epoch:  61000 quantization_loss:  0.03127727657556534
p mean is: tensor(-2.8602, device='cuda:2')
epoch:  62000 quantization_loss:  0.03125596418976784
p mean is: tensor(-2.8746, device='cuda:2')
epoch:  63000 quantization_loss:  0.03123246133327484
p mean is: tensor(-2.8884, device='cuda:2')
epoch:  64000 quantization_loss:  0.031215844675898552
p mean is: tensor(-2.9015, device='cuda:2')
epoch:  65000 quantization_loss:  0.03118276037275791
p mean is: tensor(-2.9139, device='cuda:2')
epoch:  66000 quantization_loss:  0.031183743849396706
p mean is: tensor(-2.9258, device='cuda:2')
epoch:  67000 quantization_loss:  0.03116486966609955
p mean is: tensor(-2.9371, device='cuda:2')
epoch:  68000 quantization_loss:  0.031135929748415947
p mean is: tensor(-2.9479, device='cuda:2')
epoch:  69000 quantization_loss:  0.03113194741308689
p mean is: tensor(-2.9583, device='cuda:2')
epoch:  70000 quantization_loss:  0.031109752133488655
p mean is: tensor(-2.9682, device='cuda:2')
epoch:  71000 quantization_loss:  0.031102119013667107
p mean is: tensor(-2.9777, device='cuda:2')
epoch:  72000 quantization_loss:  0.031092839315533638
p mean is: tensor(-2.9869, device='cuda:2')
epoch:  73000 quantization_loss:  0.03107936680316925
p mean is: tensor(-2.9956, device='cuda:2')
epoch:  74000 quantization_loss:  0.031068110838532448
p mean is: tensor(-3.0040, device='cuda:2')
epoch:  75000 quantization_loss:  0.03106837347149849
p mean is: tensor(-3.0120, device='cuda:2')
epoch:  76000 quantization_loss:  0.031049493700265884
p mean is: tensor(-3.0198, device='cuda:2')
epoch:  77000 quantization_loss:  0.031047943979501724
p mean is: tensor(-3.0272, device='cuda:2')
epoch:  78000 quantization_loss:  0.031037846580147743
p mean is: tensor(-3.0343, device='cuda:2')
epoch:  79000 quantization_loss:  0.031035274267196655
p mean is: tensor(-3.0412, device='cuda:2')
Number of elements to keep: 105310
Threshold value: -2.028942584991455
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.03499988533889999
Number of elements to keep: 105310
Threshold value: -2.028942584991455
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.03499988533889999
1.1.1.weight         | nonzeros =     246 /   12800             (  1.92%) | total_pruned =   12554 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       4 /      16             ( 25.00%) | total_pruned =      12 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =      38 /    6400             (  0.59%) | total_pruned =    6362 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       5 /      16             ( 31.25%) | total_pruned =      11 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      80 /   12800             (  0.62%) | total_pruned =   12720 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     131 /   25600             (  0.51%) | total_pruned =   25469 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     208 /   51200             (  0.41%) | total_pruned =   50992 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     336 /  102400             (  0.33%) | total_pruned =  102064 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     426 /  204800             (  0.21%) | total_pruned =  204374 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     711 /  409600             (  0.17%) | total_pruned =  408889 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    1555 /  409600             (  0.38%) | total_pruned =  408045 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    3405 /  409600             (  0.83%) | total_pruned =  406195 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    7714 /  409600             (  1.88%) | total_pruned =  401886 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   13139 /  409600             (  3.21%) | total_pruned =  396461 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   16904 /  147456             ( 11.46%) | total_pruned =  130552 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   21669 /  147456             ( 14.70%) | total_pruned =  125787 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   23759 /  147456             ( 16.11%) | total_pruned =  123697 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   10079 /   73728             ( 13.67%) | total_pruned =   63649 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2656 /   18432             ( 14.41%) | total_pruned =   15776 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1154 /    4608             ( 25.04%) | total_pruned =    3454 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      15 /      16             ( 93.75%) | total_pruned =       1 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      25 /      48             ( 52.08%) | total_pruned =      23 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       3 /       3             (100.00%) | total_pruned =       0 | shape = torch.Size([3])
alive: 105310, pruned : 2903557, total: 3008867, Compression rate :      28.57x  ( 96.50% pruned)
(3, 256, 256) (3, 256, 256) (3, 256, 256)
PSNR of output image is:  16.305158859516602
Experiment done
