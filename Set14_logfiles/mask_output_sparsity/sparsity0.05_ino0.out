(3, 512, 512)
Noisy PSNR is '20.30480925574432'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/0/sparsity/det/0.05/1e-09
epoch:  0 quantization_loss:  0.07784423232078552
p mean is: tensor(-0.0005, device='cuda:0')
epoch:  1000 quantization_loss:  0.07323812693357468
p mean is: tensor(-0.0218, device='cuda:0')
epoch:  2000 quantization_loss:  0.06770429760217667
p mean is: tensor(-0.0398, device='cuda:0')
epoch:  3000 quantization_loss:  0.06729681044816971
p mean is: tensor(-0.0589, device='cuda:0')
epoch:  4000 quantization_loss:  0.0681227594614029
p mean is: tensor(-0.0791, device='cuda:0')
epoch:  5000 quantization_loss:  0.06688911467790604
p mean is: tensor(-0.1007, device='cuda:0')
epoch:  6000 quantization_loss:  0.06554014980792999
p mean is: tensor(-0.1238, device='cuda:0')
epoch:  7000 quantization_loss:  0.06555736809968948
p mean is: tensor(-0.1480, device='cuda:0')
epoch:  8000 quantization_loss:  0.06404837220907211
p mean is: tensor(-0.1764, device='cuda:0')
epoch:  9000 quantization_loss:  0.06112784519791603
p mean is: tensor(-0.2130, device='cuda:0')
epoch:  10000 quantization_loss:  0.055045709013938904
p mean is: tensor(-0.2584, device='cuda:0')
epoch:  11000 quantization_loss:  0.04935324564576149
p mean is: tensor(-0.3134, device='cuda:0')
epoch:  12000 quantization_loss:  0.04699496924877167
p mean is: tensor(-0.3779, device='cuda:0')
epoch:  13000 quantization_loss:  0.04257144778966904
p mean is: tensor(-0.4553, device='cuda:0')
epoch:  14000 quantization_loss:  0.0411485955119133
p mean is: tensor(-0.5483, device='cuda:0')
epoch:  15000 quantization_loss:  0.03918492794036865
p mean is: tensor(-0.6556, device='cuda:0')
epoch:  16000 quantization_loss:  0.03657365217804909
p mean is: tensor(-0.7745, device='cuda:0')
epoch:  17000 quantization_loss:  0.035322465002536774
p mean is: tensor(-0.9019, device='cuda:0')
epoch:  18000 quantization_loss:  0.034240834414958954
p mean is: tensor(-1.0331, device='cuda:0')
epoch:  19000 quantization_loss:  0.033833812922239304
p mean is: tensor(-1.1629, device='cuda:0')
epoch:  20000 quantization_loss:  0.03355030342936516
p mean is: tensor(-1.2870, device='cuda:0')
epoch:  21000 quantization_loss:  0.033228930085897446
p mean is: tensor(-1.4033, device='cuda:0')
epoch:  22000 quantization_loss:  0.03295304253697395
p mean is: tensor(-1.5105, device='cuda:0')
epoch:  23000 quantization_loss:  0.03274121508002281
p mean is: tensor(-1.6088, device='cuda:0')
epoch:  24000 quantization_loss:  0.03265424817800522
p mean is: tensor(-1.6982, device='cuda:0')
epoch:  25000 quantization_loss:  0.03231535106897354
p mean is: tensor(-1.7793, device='cuda:0')
epoch:  26000 quantization_loss:  0.032192207872867584
p mean is: tensor(-1.8531, device='cuda:0')
epoch:  27000 quantization_loss:  0.03203528746962547
p mean is: tensor(-1.9203, device='cuda:0')
epoch:  28000 quantization_loss:  0.02982085943222046
p mean is: tensor(-1.9814, device='cuda:0')
epoch:  29000 quantization_loss:  0.02954004518687725
p mean is: tensor(-2.0373, device='cuda:0')
epoch:  30000 quantization_loss:  0.029516829177737236
p mean is: tensor(-2.0881, device='cuda:0')
epoch:  31000 quantization_loss:  0.02931733801960945
p mean is: tensor(-2.1347, device='cuda:0')
epoch:  32000 quantization_loss:  0.02936800755560398
p mean is: tensor(-2.1779, device='cuda:0')
epoch:  33000 quantization_loss:  0.02925754338502884
p mean is: tensor(-2.2178, device='cuda:0')
epoch:  34000 quantization_loss:  0.029180562123656273
p mean is: tensor(-2.2550, device='cuda:0')
epoch:  35000 quantization_loss:  0.029132718220353127
p mean is: tensor(-2.2895, device='cuda:0')
epoch:  36000 quantization_loss:  0.02908914163708687
p mean is: tensor(-2.3218, device='cuda:0')
epoch:  37000 quantization_loss:  0.029034242033958435
p mean is: tensor(-2.3520, device='cuda:0')
epoch:  38000 quantization_loss:  0.02900160662829876
p mean is: tensor(-2.3802, device='cuda:0')
epoch:  39000 quantization_loss:  0.029006557539105415
p mean is: tensor(-2.4067, device='cuda:0')
epoch:  40000 quantization_loss:  0.028907375410199165
p mean is: tensor(-2.4315, device='cuda:0')
epoch:  41000 quantization_loss:  0.028868647292256355
p mean is: tensor(-2.4549, device='cuda:0')
epoch:  42000 quantization_loss:  0.028849905356764793
p mean is: tensor(-2.4768, device='cuda:0')
epoch:  43000 quantization_loss:  0.0288137998431921
p mean is: tensor(-2.4976, device='cuda:0')
epoch:  44000 quantization_loss:  0.028795728459954262
p mean is: tensor(-2.5171, device='cuda:0')
epoch:  45000 quantization_loss:  0.028813108801841736
p mean is: tensor(-2.5356, device='cuda:0')
epoch:  46000 quantization_loss:  0.028756029903888702
p mean is: tensor(-2.5532, device='cuda:0')
epoch:  47000 quantization_loss:  0.028807977214455605
p mean is: tensor(-2.5699, device='cuda:0')
epoch:  48000 quantization_loss:  0.028721055015921593
p mean is: tensor(-2.5857, device='cuda:0')
epoch:  49000 quantization_loss:  0.02869304269552231
p mean is: tensor(-2.6007, device='cuda:0')
epoch:  50000 quantization_loss:  0.02868553437292576
p mean is: tensor(-2.6151, device='cuda:0')
epoch:  51000 quantization_loss:  0.02858732081949711
p mean is: tensor(-2.6287, device='cuda:0')
epoch:  52000 quantization_loss:  0.028652820736169815
p mean is: tensor(-2.6417, device='cuda:0')
epoch:  53000 quantization_loss:  0.02865125797688961
p mean is: tensor(-2.6540, device='cuda:0')
epoch:  54000 quantization_loss:  0.02865641564130783
p mean is: tensor(-2.6658, device='cuda:0')
epoch:  55000 quantization_loss:  0.02864006720483303
p mean is: tensor(-2.6770, device='cuda:0')
epoch:  56000 quantization_loss:  0.028602752834558487
p mean is: tensor(-2.6878, device='cuda:0')
epoch:  57000 quantization_loss:  0.028626948595046997
p mean is: tensor(-2.6980, device='cuda:0')
epoch:  58000 quantization_loss:  0.028522798791527748
p mean is: tensor(-2.7078, device='cuda:0')
epoch:  59000 quantization_loss:  0.028614338487386703
p mean is: tensor(-2.7172, device='cuda:0')
epoch:  60000 quantization_loss:  0.02858060970902443
p mean is: tensor(-2.7261, device='cuda:0')
epoch:  61000 quantization_loss:  0.028580518439412117
p mean is: tensor(-2.7346, device='cuda:0')
epoch:  62000 quantization_loss:  0.028577985242009163
p mean is: tensor(-2.7428, device='cuda:0')
epoch:  63000 quantization_loss:  0.028572071343660355
p mean is: tensor(-2.7507, device='cuda:0')
epoch:  64000 quantization_loss:  0.02855207957327366
p mean is: tensor(-2.7582, device='cuda:0')
epoch:  65000 quantization_loss:  0.028553849086165428
p mean is: tensor(-2.7655, device='cuda:0')
epoch:  66000 quantization_loss:  0.02856340818107128
p mean is: tensor(-2.7724, device='cuda:0')
epoch:  67000 quantization_loss:  0.028542473912239075
p mean is: tensor(-2.7791, device='cuda:0')
epoch:  68000 quantization_loss:  0.028550537303090096
p mean is: tensor(-2.7856, device='cuda:0')
epoch:  69000 quantization_loss:  0.028549477458000183
p mean is: tensor(-2.7918, device='cuda:0')
epoch:  70000 quantization_loss:  0.02853100746870041
p mean is: tensor(-2.7977, device='cuda:0')
epoch:  71000 quantization_loss:  0.02854612097144127
p mean is: tensor(-2.8035, device='cuda:0')
epoch:  72000 quantization_loss:  0.02852703630924225
p mean is: tensor(-2.8091, device='cuda:0')
epoch:  73000 quantization_loss:  0.02850833721458912
p mean is: tensor(-2.8144, device='cuda:0')
epoch:  74000 quantization_loss:  0.028537586331367493
p mean is: tensor(-2.8196, device='cuda:0')
epoch:  75000 quantization_loss:  0.028510289266705513
p mean is: tensor(-2.8246, device='cuda:0')
epoch:  76000 quantization_loss:  0.028463909402489662
p mean is: tensor(-2.8294, device='cuda:0')
epoch:  77000 quantization_loss:  0.028513537719845772
p mean is: tensor(-2.8340, device='cuda:0')
epoch:  78000 quantization_loss:  0.028503062203526497
p mean is: tensor(-2.8385, device='cuda:0')
epoch:  79000 quantization_loss:  0.028498224914073944
p mean is: tensor(-2.8428, device='cuda:0')
Number of elements to keep: 150443
Threshold value: -2.1615381240844727
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
Number of elements to keep: 150443
Threshold value: -2.1615381240844727
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
1.1.1.weight         | nonzeros =     868 /   12800             (  6.78%) | total_pruned =   11932 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     134 /    6400             (  2.09%) | total_pruned =    6266 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     331 /   12800             (  2.59%) | total_pruned =   12469 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      13 /      32             ( 40.62%) | total_pruned =      19 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     561 /   25600             (  2.19%) | total_pruned =   25039 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     827 /   51200             (  1.62%) | total_pruned =   50373 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =    1225 /  102400             (  1.20%) | total_pruned =  101175 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =    2165 /  204800             (  1.06%) | total_pruned =  202635 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =    3978 /  409600             (  0.97%) | total_pruned =  405622 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    6845 /  409600             (  1.67%) | total_pruned =  402755 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   11025 /  409600             (  2.69%) | total_pruned =  398575 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   19029 /  409600             (  4.65%) | total_pruned =  390571 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   26521 /  409600             (  6.47%) | total_pruned =  383079 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   25405 /  147456             ( 17.23%) | total_pruned =  122051 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   22328 /  147456             ( 15.14%) | total_pruned =  125128 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   17083 /  147456             ( 11.59%) | total_pruned =  130373 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    7495 /   73728             ( 10.17%) | total_pruned =   66233 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2202 /   18432             ( 11.95%) | total_pruned =   16230 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1190 /    4608             ( 25.82%) | total_pruned =    3418 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      28 /      48             ( 58.33%) | total_pruned =      20 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 150443, pruned : 2858424, total: 3008867, Compression rate :      20.00x  ( 95.00% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  16.85359984344729
Experiment done
