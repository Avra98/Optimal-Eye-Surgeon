(3, 512, 512)
Noisy PSNR is '20.211969347025303'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/4/sparsity/det/0.05/1e-09
epoch:  0 quantization_loss:  0.06925861537456512
p mean is: tensor(-0.0005, device='cuda:5')
epoch:  1000 quantization_loss:  0.053943932056427
p mean is: tensor(-0.0274, device='cuda:5')
epoch:  2000 quantization_loss:  0.05211178958415985
p mean is: tensor(-0.0496, device='cuda:5')
epoch:  3000 quantization_loss:  0.05136512219905853
p mean is: tensor(-0.0722, device='cuda:5')
epoch:  4000 quantization_loss:  0.05252881348133087
p mean is: tensor(-0.0964, device='cuda:5')
epoch:  5000 quantization_loss:  0.050640374422073364
p mean is: tensor(-0.1222, device='cuda:5')
epoch:  6000 quantization_loss:  0.049389541149139404
p mean is: tensor(-0.1497, device='cuda:5')
epoch:  7000 quantization_loss:  0.045093804597854614
p mean is: tensor(-0.1802, device='cuda:5')
epoch:  8000 quantization_loss:  0.04288683459162712
p mean is: tensor(-0.2186, device='cuda:5')
epoch:  9000 quantization_loss:  0.03987542539834976
p mean is: tensor(-0.2665, device='cuda:5')
epoch:  10000 quantization_loss:  0.03632359951734543
p mean is: tensor(-0.3230, device='cuda:5')
epoch:  11000 quantization_loss:  0.034128330647945404
p mean is: tensor(-0.3908, device='cuda:5')
epoch:  12000 quantization_loss:  0.03255860507488251
p mean is: tensor(-0.4740, device='cuda:5')
epoch:  13000 quantization_loss:  0.031409215182065964
p mean is: tensor(-0.5742, device='cuda:5')
epoch:  14000 quantization_loss:  0.03081122413277626
p mean is: tensor(-0.6906, device='cuda:5')
epoch:  15000 quantization_loss:  0.029974574223160744
p mean is: tensor(-0.8206, device='cuda:5')
epoch:  16000 quantization_loss:  0.028897859156131744
p mean is: tensor(-0.9582, device='cuda:5')
epoch:  17000 quantization_loss:  0.028050895780324936
p mean is: tensor(-1.0962, device='cuda:5')
epoch:  18000 quantization_loss:  0.027682166546583176
p mean is: tensor(-1.2297, device='cuda:5')
epoch:  19000 quantization_loss:  0.027288304641842842
p mean is: tensor(-1.3544, device='cuda:5')
epoch:  20000 quantization_loss:  0.027177250012755394
p mean is: tensor(-1.4690, device='cuda:5')
epoch:  21000 quantization_loss:  0.027086246758699417
p mean is: tensor(-1.5737, device='cuda:5')
epoch:  22000 quantization_loss:  0.026616545394062996
p mean is: tensor(-1.6687, device='cuda:5')
epoch:  23000 quantization_loss:  0.026443572714924812
p mean is: tensor(-1.7545, device='cuda:5')
epoch:  24000 quantization_loss:  0.02631664276123047
p mean is: tensor(-1.8320, device='cuda:5')
epoch:  25000 quantization_loss:  0.0261326152831316
p mean is: tensor(-1.9024, device='cuda:5')
epoch:  26000 quantization_loss:  0.02613278664648533
p mean is: tensor(-1.9667, device='cuda:5')
epoch:  27000 quantization_loss:  0.02599644474685192
p mean is: tensor(-2.0255, device='cuda:5')
epoch:  28000 quantization_loss:  0.02588614635169506
p mean is: tensor(-2.0792, device='cuda:5')
epoch:  29000 quantization_loss:  0.025877976790070534
p mean is: tensor(-2.1285, device='cuda:5')
epoch:  30000 quantization_loss:  0.025742247700691223
p mean is: tensor(-2.1739, device='cuda:5')
epoch:  31000 quantization_loss:  0.02569318562746048
p mean is: tensor(-2.2159, device='cuda:5')
epoch:  32000 quantization_loss:  0.025763919577002525
p mean is: tensor(-2.2548, device='cuda:5')
epoch:  33000 quantization_loss:  0.02560744248330593
p mean is: tensor(-2.2908, device='cuda:5')
epoch:  34000 quantization_loss:  0.025614134967327118
p mean is: tensor(-2.3243, device='cuda:5')
epoch:  35000 quantization_loss:  0.02555074542760849
p mean is: tensor(-2.3557, device='cuda:5')
epoch:  36000 quantization_loss:  0.0255061537027359
p mean is: tensor(-2.3848, device='cuda:5')
epoch:  37000 quantization_loss:  0.025516781955957413
p mean is: tensor(-2.4122, device='cuda:5')
epoch:  38000 quantization_loss:  0.025475792586803436
p mean is: tensor(-2.4378, device='cuda:5')
epoch:  39000 quantization_loss:  0.025444695726037025
p mean is: tensor(-2.4620, device='cuda:5')
epoch:  40000 quantization_loss:  0.025386039167642593
p mean is: tensor(-2.4847, device='cuda:5')
epoch:  41000 quantization_loss:  0.025363599881529808
p mean is: tensor(-2.5061, device='cuda:5')
epoch:  42000 quantization_loss:  0.025355806574225426
p mean is: tensor(-2.5263, device='cuda:5')
epoch:  43000 quantization_loss:  0.025345657020807266
p mean is: tensor(-2.5454, device='cuda:5')
epoch:  44000 quantization_loss:  0.02533409371972084
p mean is: tensor(-2.5634, device='cuda:5')
epoch:  45000 quantization_loss:  0.025307679548859596
p mean is: tensor(-2.5806, device='cuda:5')
epoch:  46000 quantization_loss:  0.025266166776418686
p mean is: tensor(-2.5967, device='cuda:5')
epoch:  47000 quantization_loss:  0.025269048288464546
p mean is: tensor(-2.6121, device='cuda:5')
epoch:  48000 quantization_loss:  0.025291290134191513
p mean is: tensor(-2.6267, device='cuda:5')
epoch:  49000 quantization_loss:  0.025238117203116417
p mean is: tensor(-2.6406, device='cuda:5')
epoch:  50000 quantization_loss:  0.02524181641638279
p mean is: tensor(-2.6537, device='cuda:5')
epoch:  51000 quantization_loss:  0.02523730881512165
p mean is: tensor(-2.6664, device='cuda:5')
epoch:  52000 quantization_loss:  0.025215450674295425
p mean is: tensor(-2.6784, device='cuda:5')
epoch:  53000 quantization_loss:  0.025207947939634323
p mean is: tensor(-2.6899, device='cuda:5')
epoch:  54000 quantization_loss:  0.025198401883244514
p mean is: tensor(-2.7008, device='cuda:5')
epoch:  55000 quantization_loss:  0.025180932134389877
p mean is: tensor(-2.7112, device='cuda:5')
epoch:  56000 quantization_loss:  0.025185132399201393
p mean is: tensor(-2.7212, device='cuda:5')
epoch:  57000 quantization_loss:  0.025196416303515434
p mean is: tensor(-2.7307, device='cuda:5')
epoch:  58000 quantization_loss:  0.025171702727675438
p mean is: tensor(-2.7400, device='cuda:5')
epoch:  59000 quantization_loss:  0.02515621855854988
p mean is: tensor(-2.7487, device='cuda:5')
epoch:  60000 quantization_loss:  0.025155186653137207
p mean is: tensor(-2.7571, device='cuda:5')
epoch:  61000 quantization_loss:  0.025154350325465202
p mean is: tensor(-2.7652, device='cuda:5')
epoch:  62000 quantization_loss:  0.02514501102268696
p mean is: tensor(-2.7730, device='cuda:5')
epoch:  63000 quantization_loss:  0.02514316327869892
p mean is: tensor(-2.7805, device='cuda:5')
epoch:  64000 quantization_loss:  0.02514343336224556
p mean is: tensor(-2.7877, device='cuda:5')
epoch:  65000 quantization_loss:  0.025135507807135582
p mean is: tensor(-2.7946, device='cuda:5')
epoch:  66000 quantization_loss:  0.026755867525935173
p mean is: tensor(-2.8013, device='cuda:5')
epoch:  67000 quantization_loss:  0.025126641616225243
p mean is: tensor(-2.8077, device='cuda:5')
epoch:  68000 quantization_loss:  0.025121867656707764
p mean is: tensor(-2.8138, device='cuda:5')
epoch:  69000 quantization_loss:  0.02512025088071823
p mean is: tensor(-2.8198, device='cuda:5')
epoch:  70000 quantization_loss:  0.0251154862344265
p mean is: tensor(-2.8255, device='cuda:5')
epoch:  71000 quantization_loss:  0.02511756494641304
p mean is: tensor(-2.8310, device='cuda:5')
epoch:  72000 quantization_loss:  0.025116564705967903
p mean is: tensor(-2.8362, device='cuda:5')
epoch:  73000 quantization_loss:  0.025107182562351227
p mean is: tensor(-2.8414, device='cuda:5')
epoch:  74000 quantization_loss:  0.02510361559689045
p mean is: tensor(-2.8464, device='cuda:5')
epoch:  75000 quantization_loss:  0.02510484866797924
p mean is: tensor(-2.8512, device='cuda:5')
epoch:  76000 quantization_loss:  0.025100063532590866
p mean is: tensor(-2.8559, device='cuda:5')
epoch:  77000 quantization_loss:  0.025093158707022667
p mean is: tensor(-2.8603, device='cuda:5')
epoch:  78000 quantization_loss:  0.02509746327996254
p mean is: tensor(-2.8647, device='cuda:5')
epoch:  79000 quantization_loss:  0.025049231946468353
p mean is: tensor(-2.8689, device='cuda:5')
Number of elements to keep: 150443
Threshold value: -2.1973323822021484
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
Number of elements to keep: 150443
Threshold value: -2.1973323822021484
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
1.1.1.weight         | nonzeros =     848 /   12800             (  6.62%) | total_pruned =   11952 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     118 /    6400             (  1.84%) | total_pruned =    6282 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       5 /      16             ( 31.25%) | total_pruned =      11 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     253 /   12800             (  1.98%) | total_pruned =   12547 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     539 /   25600             (  2.11%) | total_pruned =   25061 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     606 /   51200             (  1.18%) | total_pruned =   50594 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =    1075 /  102400             (  1.05%) | total_pruned =  101325 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =    2410 /  204800             (  1.18%) | total_pruned =  202390 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      49 /     128             ( 38.28%) | total_pruned =      79 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =    4128 /  409600             (  1.01%) | total_pruned =  405472 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    6776 /  409600             (  1.65%) | total_pruned =  402824 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   12578 /  409600             (  3.07%) | total_pruned =  397022 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   22383 /  409600             (  5.46%) | total_pruned =  387217 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   26590 /  409600             (  6.49%) | total_pruned =  383010 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   22609 /  147456             ( 15.33%) | total_pruned =  124847 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   18201 /  147456             ( 12.34%) | total_pruned =  129255 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   16585 /  147456             ( 11.25%) | total_pruned =  130871 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    9964 /   73728             ( 13.51%) | total_pruned =   63764 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2555 /   18432             ( 13.86%) | total_pruned =   15877 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =     964 /    4608             ( 20.92%) | total_pruned =    3644 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      14 /      16             ( 87.50%) | total_pruned =       2 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      27 /      48             ( 56.25%) | total_pruned =      21 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 150443, pruned : 2858424, total: 3008867, Compression rate :      20.00x  ( 95.00% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  17.93846098796341
Experiment done
