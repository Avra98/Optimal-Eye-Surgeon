(3, 512, 512)
Noisy PSNR is '21.647368657753006'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/8/sparsity/det/0.03/1e-09
epoch:  0 quantization_loss:  0.16046562790870667
p mean is: tensor(-0.0006, device='cuda:3')
epoch:  1000 quantization_loss:  0.1338708996772766
p mean is: tensor(-0.0182, device='cuda:3')
epoch:  2000 quantization_loss:  0.1315803825855255
p mean is: tensor(-0.0289, device='cuda:3')
epoch:  3000 quantization_loss:  0.12795233726501465
p mean is: tensor(-0.0390, device='cuda:3')
epoch:  4000 quantization_loss:  0.12831290066242218
p mean is: tensor(-0.0490, device='cuda:3')
epoch:  5000 quantization_loss:  0.12836214900016785
p mean is: tensor(-0.0590, device='cuda:3')
epoch:  6000 quantization_loss:  0.12534917891025543
p mean is: tensor(-0.0697, device='cuda:3')
epoch:  7000 quantization_loss:  0.12702764570713043
p mean is: tensor(-0.0808, device='cuda:3')
epoch:  8000 quantization_loss:  0.11245807260274887
p mean is: tensor(-0.0925, device='cuda:3')
epoch:  9000 quantization_loss:  0.0950636938214302
p mean is: tensor(-0.1062, device='cuda:3')
epoch:  10000 quantization_loss:  0.0919574648141861
p mean is: tensor(-0.1245, device='cuda:3')
epoch:  11000 quantization_loss:  0.08864115923643112
p mean is: tensor(-0.1506, device='cuda:3')
epoch:  12000 quantization_loss:  0.08726343512535095
p mean is: tensor(-0.1865, device='cuda:3')
epoch:  13000 quantization_loss:  0.08540795743465424
p mean is: tensor(-0.2359, device='cuda:3')
epoch:  14000 quantization_loss:  0.08330158144235611
p mean is: tensor(-0.3016, device='cuda:3')
epoch:  15000 quantization_loss:  0.0802297294139862
p mean is: tensor(-0.3868, device='cuda:3')
epoch:  16000 quantization_loss:  0.07892479747533798
p mean is: tensor(-0.4938, device='cuda:3')
epoch:  17000 quantization_loss:  0.07786022126674652
p mean is: tensor(-0.6231, device='cuda:3')
epoch:  18000 quantization_loss:  0.07730218768119812
p mean is: tensor(-0.7722, device='cuda:3')
epoch:  19000 quantization_loss:  0.07633546739816666
p mean is: tensor(-0.9349, device='cuda:3')
epoch:  20000 quantization_loss:  0.07562610507011414
p mean is: tensor(-1.1026, device='cuda:3')
epoch:  21000 quantization_loss:  0.07511182129383087
p mean is: tensor(-1.2671, device='cuda:3')
epoch:  22000 quantization_loss:  0.07453057914972305
p mean is: tensor(-1.4216, device='cuda:3')
epoch:  23000 quantization_loss:  0.07425348460674286
p mean is: tensor(-1.5633, device='cuda:3')
epoch:  24000 quantization_loss:  0.07386413961648941
p mean is: tensor(-1.6908, device='cuda:3')
epoch:  25000 quantization_loss:  0.07364414632320404
p mean is: tensor(-1.8049, device='cuda:3')
epoch:  26000 quantization_loss:  0.07331938296556473
p mean is: tensor(-1.9068, device='cuda:3')
epoch:  27000 quantization_loss:  0.07324601709842682
p mean is: tensor(-1.9985, device='cuda:3')
epoch:  28000 quantization_loss:  0.07304874062538147
p mean is: tensor(-2.0809, device='cuda:3')
epoch:  29000 quantization_loss:  0.07275671511888504
p mean is: tensor(-2.1558, device='cuda:3')
epoch:  30000 quantization_loss:  0.07263341546058655
p mean is: tensor(-2.2239, device='cuda:3')
epoch:  31000 quantization_loss:  0.07246945798397064
p mean is: tensor(-2.2863, device='cuda:3')
epoch:  32000 quantization_loss:  0.07233457267284393
p mean is: tensor(-2.3434, device='cuda:3')
epoch:  33000 quantization_loss:  0.07238519936800003
p mean is: tensor(-2.3960, device='cuda:3')
epoch:  34000 quantization_loss:  0.07219668477773666
p mean is: tensor(-2.4447, device='cuda:3')
epoch:  35000 quantization_loss:  0.07210037112236023
p mean is: tensor(-2.4898, device='cuda:3')
epoch:  36000 quantization_loss:  0.07205164432525635
p mean is: tensor(-2.5319, device='cuda:3')
epoch:  37000 quantization_loss:  0.0719284936785698
p mean is: tensor(-2.5712, device='cuda:3')
epoch:  38000 quantization_loss:  0.07187299430370331
p mean is: tensor(-2.6079, device='cuda:3')
epoch:  39000 quantization_loss:  0.0717715322971344
p mean is: tensor(-2.6423, device='cuda:3')
epoch:  40000 quantization_loss:  0.07173464447259903
p mean is: tensor(-2.6747, device='cuda:3')
epoch:  41000 quantization_loss:  0.07168987393379211
p mean is: tensor(-2.7051, device='cuda:3')
epoch:  42000 quantization_loss:  0.07166130840778351
p mean is: tensor(-2.7339, device='cuda:3')
epoch:  43000 quantization_loss:  0.07161809504032135
p mean is: tensor(-2.7610, device='cuda:3')
epoch:  44000 quantization_loss:  0.07158859074115753
p mean is: tensor(-2.7867, device='cuda:3')
epoch:  45000 quantization_loss:  0.07155745476484299
p mean is: tensor(-2.8111, device='cuda:3')
epoch:  46000 quantization_loss:  0.0715266615152359
p mean is: tensor(-2.8342, device='cuda:3')
epoch:  47000 quantization_loss:  0.07150177657604218
p mean is: tensor(-2.8561, device='cuda:3')
epoch:  48000 quantization_loss:  0.07145985215902328
p mean is: tensor(-2.8769, device='cuda:3')
epoch:  49000 quantization_loss:  0.07142428308725357
p mean is: tensor(-2.8965, device='cuda:3')
epoch:  50000 quantization_loss:  0.07107524573802948
p mean is: tensor(-2.9144, device='cuda:3')
epoch:  51000 quantization_loss:  0.07101545482873917
p mean is: tensor(-2.9316, device='cuda:3')
epoch:  52000 quantization_loss:  0.07098812609910965
p mean is: tensor(-2.9483, device='cuda:3')
epoch:  53000 quantization_loss:  0.07096806913614273
p mean is: tensor(-2.9644, device='cuda:3')
epoch:  54000 quantization_loss:  0.07094807922840118
p mean is: tensor(-2.9800, device='cuda:3')
epoch:  55000 quantization_loss:  0.07094083726406097
p mean is: tensor(-2.9950, device='cuda:3')
epoch:  56000 quantization_loss:  0.07091370224952698
p mean is: tensor(-3.0096, device='cuda:3')
epoch:  57000 quantization_loss:  0.0708998441696167
p mean is: tensor(-3.0236, device='cuda:3')
epoch:  58000 quantization_loss:  0.0708736851811409
p mean is: tensor(-3.0371, device='cuda:3')
epoch:  59000 quantization_loss:  0.07085246592760086
p mean is: tensor(-3.0500, device='cuda:3')
epoch:  60000 quantization_loss:  0.0708426907658577
p mean is: tensor(-3.0624, device='cuda:3')
epoch:  61000 quantization_loss:  0.07083484530448914
p mean is: tensor(-3.0744, device='cuda:3')
epoch:  62000 quantization_loss:  0.07081808894872665
p mean is: tensor(-3.0860, device='cuda:3')
epoch:  63000 quantization_loss:  0.07081407308578491
p mean is: tensor(-3.0971, device='cuda:3')
epoch:  64000 quantization_loss:  0.0708036944270134
p mean is: tensor(-3.1078, device='cuda:3')
epoch:  65000 quantization_loss:  0.07079005986452103
p mean is: tensor(-3.1182, device='cuda:3')
epoch:  66000 quantization_loss:  0.070786252617836
p mean is: tensor(-3.1283, device='cuda:3')
epoch:  67000 quantization_loss:  0.07077421993017197
p mean is: tensor(-3.1380, device='cuda:3')
epoch:  68000 quantization_loss:  0.07077646255493164
p mean is: tensor(-3.1474, device='cuda:3')
epoch:  69000 quantization_loss:  0.07076626271009445
p mean is: tensor(-3.1565, device='cuda:3')
epoch:  70000 quantization_loss:  0.07076530903577805
p mean is: tensor(-3.1652, device='cuda:3')
epoch:  71000 quantization_loss:  0.07076232880353928
p mean is: tensor(-3.1737, device='cuda:3')
epoch:  72000 quantization_loss:  0.07076355814933777
p mean is: tensor(-3.1819, device='cuda:3')
epoch:  73000 quantization_loss:  0.0707462951540947
p mean is: tensor(-3.1899, device='cuda:3')
epoch:  74000 quantization_loss:  0.07075074315071106
p mean is: tensor(-3.1976, device='cuda:3')
epoch:  75000 quantization_loss:  0.07073955237865448
p mean is: tensor(-3.2050, device='cuda:3')
epoch:  76000 quantization_loss:  0.07073717564344406
p mean is: tensor(-3.2123, device='cuda:3')
epoch:  77000 quantization_loss:  0.07073137164115906
p mean is: tensor(-3.2194, device='cuda:3')
epoch:  78000 quantization_loss:  0.0707286074757576
p mean is: tensor(-3.2262, device='cuda:3')
epoch:  79000 quantization_loss:  0.07073187828063965
p mean is: tensor(-3.2328, device='cuda:3')
Number of elements to keep: 90266
Threshold value: 1.1465967893600464
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.029999996676489855
Number of elements to keep: 90266
Threshold value: 1.1465967893600464
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.029999996676489855
1.1.1.weight         | nonzeros =     399 /   12800             (  3.12%) | total_pruned =   12401 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =      40 /    6400             (  0.62%) | total_pruned =    6360 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       4 /      16             ( 25.00%) | total_pruned =      12 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      20 /   12800             (  0.16%) | total_pruned =   12780 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =       4 /      32             ( 12.50%) | total_pruned =      28 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =      26 /   25600             (  0.10%) | total_pruned =   25574 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =       7 /      32             ( 21.88%) | total_pruned =      25 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =      17 /   51200             (  0.03%) | total_pruned =   51183 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =      18 /  102400             (  0.02%) | total_pruned =  102382 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =       0 /  204800             (  0.00%) | total_pruned =  204800 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =       2 /  409600             (  0.00%) | total_pruned =  409598 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =       2 /  409600             (  0.00%) | total_pruned =  409598 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =     438 /  409600             (  0.11%) | total_pruned =  409162 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    2330 /  409600             (  0.57%) | total_pruned =  407270 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   14915 /  409600             (  3.64%) | total_pruned =  394685 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   21604 /  147456             ( 14.65%) | total_pruned =  125852 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   20988 /  147456             ( 14.23%) | total_pruned =  126468 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   17498 /  147456             ( 11.87%) | total_pruned =  129958 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    8157 /   73728             ( 11.06%) | total_pruned =   65571 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    1854 /   18432             ( 10.06%) | total_pruned =   16578 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =     836 /    4608             ( 18.14%) | total_pruned =    3772 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      15 /      16             ( 93.75%) | total_pruned =       1 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      27 /      48             ( 56.25%) | total_pruned =      21 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 90266, pruned : 2918601, total: 3008867, Compression rate :      33.33x  ( 97.00% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  7.832045506173553
Experiment done
