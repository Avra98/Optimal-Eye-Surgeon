(3, 512, 512)
Noisy PSNR is '20.313455495249357'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/0/sparsity/det/0.0333/1e-09
epoch:  0 quantization_loss:  0.08612838387489319
p mean is: tensor(-0.0006, device='cuda:0')
epoch:  1000 quantization_loss:  0.07254774868488312
p mean is: tensor(-0.0247, device='cuda:0')
epoch:  2000 quantization_loss:  0.07024860382080078
p mean is: tensor(-0.0440, device='cuda:0')
epoch:  3000 quantization_loss:  0.06968224048614502
p mean is: tensor(-0.0628, device='cuda:0')
epoch:  4000 quantization_loss:  0.07051270455121994
p mean is: tensor(-0.0819, device='cuda:0')
epoch:  5000 quantization_loss:  0.06906117498874664
p mean is: tensor(-0.1017, device='cuda:0')
epoch:  6000 quantization_loss:  0.06936221569776535
p mean is: tensor(-0.1228, device='cuda:0')
epoch:  7000 quantization_loss:  0.06828715652227402
p mean is: tensor(-0.1457, device='cuda:0')
epoch:  8000 quantization_loss:  0.06687086820602417
p mean is: tensor(-0.1713, device='cuda:0')
epoch:  9000 quantization_loss:  0.06073516979813576
p mean is: tensor(-0.2032, device='cuda:0')
epoch:  10000 quantization_loss:  0.0558728389441967
p mean is: tensor(-0.2413, device='cuda:0')
epoch:  11000 quantization_loss:  0.05187499523162842
p mean is: tensor(-0.2889, device='cuda:0')
epoch:  12000 quantization_loss:  0.045066941529512405
p mean is: tensor(-0.3478, device='cuda:0')
epoch:  13000 quantization_loss:  0.04229477792978287
p mean is: tensor(-0.4211, device='cuda:0')
epoch:  14000 quantization_loss:  0.03846043348312378
p mean is: tensor(-0.5117, device='cuda:0')
epoch:  15000 quantization_loss:  0.03745488077402115
p mean is: tensor(-0.6201, device='cuda:0')
epoch:  16000 quantization_loss:  0.03628615289926529
p mean is: tensor(-0.7457, device='cuda:0')
epoch:  17000 quantization_loss:  0.034857138991355896
p mean is: tensor(-0.8848, device='cuda:0')
epoch:  18000 quantization_loss:  0.03430546820163727
p mean is: tensor(-1.0311, device='cuda:0')
epoch:  19000 quantization_loss:  0.033719390630722046
p mean is: tensor(-1.1773, device='cuda:0')
epoch:  20000 quantization_loss:  0.033196792006492615
p mean is: tensor(-1.3182, device='cuda:0')
epoch:  21000 quantization_loss:  0.03291286155581474
p mean is: tensor(-1.4501, device='cuda:0')
epoch:  22000 quantization_loss:  0.0324704684317112
p mean is: tensor(-1.5716, device='cuda:0')
epoch:  23000 quantization_loss:  0.032398562878370285
p mean is: tensor(-1.6825, device='cuda:0')
epoch:  24000 quantization_loss:  0.03221139311790466
p mean is: tensor(-1.7833, device='cuda:0')
epoch:  25000 quantization_loss:  0.030713854357600212
p mean is: tensor(-1.8746, device='cuda:0')
epoch:  26000 quantization_loss:  0.03067101538181305
p mean is: tensor(-1.9566, device='cuda:0')
epoch:  27000 quantization_loss:  0.030512100085616112
p mean is: tensor(-2.0313, device='cuda:0')
epoch:  28000 quantization_loss:  0.03020937740802765
p mean is: tensor(-2.0998, device='cuda:0')
epoch:  29000 quantization_loss:  0.03008611686527729
p mean is: tensor(-2.1628, device='cuda:0')
epoch:  30000 quantization_loss:  0.030018379911780357
p mean is: tensor(-2.2209, device='cuda:0')
epoch:  31000 quantization_loss:  0.02994362637400627
p mean is: tensor(-2.2746, device='cuda:0')
epoch:  32000 quantization_loss:  0.02985302172601223
p mean is: tensor(-2.3243, device='cuda:0')
epoch:  33000 quantization_loss:  0.029768940061330795
p mean is: tensor(-2.3707, device='cuda:0')
epoch:  34000 quantization_loss:  0.029752230271697044
p mean is: tensor(-2.4140, device='cuda:0')
epoch:  35000 quantization_loss:  0.0296707134693861
p mean is: tensor(-2.4545, device='cuda:0')
epoch:  36000 quantization_loss:  0.029576895758509636
p mean is: tensor(-2.4924, device='cuda:0')
epoch:  37000 quantization_loss:  0.02954084612429142
p mean is: tensor(-2.5280, device='cuda:0')
epoch:  38000 quantization_loss:  0.02950293757021427
p mean is: tensor(-2.5615, device='cuda:0')
epoch:  39000 quantization_loss:  0.029478656128048897
p mean is: tensor(-2.5929, device='cuda:0')
epoch:  40000 quantization_loss:  0.029426105320453644
p mean is: tensor(-2.6227, device='cuda:0')
epoch:  41000 quantization_loss:  0.029385076835751534
p mean is: tensor(-2.6508, device='cuda:0')
epoch:  42000 quantization_loss:  0.029390737414360046
p mean is: tensor(-2.6775, device='cuda:0')
epoch:  43000 quantization_loss:  0.029310889542102814
p mean is: tensor(-2.7028, device='cuda:0')
epoch:  44000 quantization_loss:  0.02929133176803589
p mean is: tensor(-2.7267, device='cuda:0')
epoch:  45000 quantization_loss:  0.029260767623782158
p mean is: tensor(-2.7495, device='cuda:0')
epoch:  46000 quantization_loss:  0.029231412336230278
p mean is: tensor(-2.7712, device='cuda:0')
epoch:  47000 quantization_loss:  0.029226668179035187
p mean is: tensor(-2.7919, device='cuda:0')
epoch:  48000 quantization_loss:  0.029195636510849
p mean is: tensor(-2.8116, device='cuda:0')
epoch:  49000 quantization_loss:  0.029178576543927193
p mean is: tensor(-2.8305, device='cuda:0')
epoch:  50000 quantization_loss:  0.029157457873225212
p mean is: tensor(-2.8486, device='cuda:0')
epoch:  51000 quantization_loss:  0.029148999601602554
p mean is: tensor(-2.8658, device='cuda:0')
epoch:  52000 quantization_loss:  0.029134083539247513
p mean is: tensor(-2.8824, device='cuda:0')
epoch:  53000 quantization_loss:  0.02911551296710968
p mean is: tensor(-2.8983, device='cuda:0')
epoch:  54000 quantization_loss:  0.02910599485039711
p mean is: tensor(-2.9136, device='cuda:0')
epoch:  55000 quantization_loss:  0.029077166691422462
p mean is: tensor(-2.9283, device='cuda:0')
epoch:  56000 quantization_loss:  0.0291151013225317
p mean is: tensor(-2.9423, device='cuda:0')
epoch:  57000 quantization_loss:  0.029169579967856407
p mean is: tensor(-2.9558, device='cuda:0')
epoch:  58000 quantization_loss:  0.029070695862174034
p mean is: tensor(-2.9689, device='cuda:0')
epoch:  59000 quantization_loss:  0.02904284931719303
p mean is: tensor(-2.9814, device='cuda:0')
epoch:  60000 quantization_loss:  0.02903536520898342
p mean is: tensor(-2.9935, device='cuda:0')
epoch:  61000 quantization_loss:  0.029030630365014076
p mean is: tensor(-3.0051, device='cuda:0')
epoch:  62000 quantization_loss:  0.02902020886540413
p mean is: tensor(-3.0162, device='cuda:0')
epoch:  63000 quantization_loss:  0.02901577390730381
p mean is: tensor(-3.0271, device='cuda:0')
epoch:  64000 quantization_loss:  0.029003987088799477
p mean is: tensor(-3.0375, device='cuda:0')
epoch:  65000 quantization_loss:  0.02900451421737671
p mean is: tensor(-3.0476, device='cuda:0')
epoch:  66000 quantization_loss:  0.028990641236305237
p mean is: tensor(-3.0574, device='cuda:0')
epoch:  67000 quantization_loss:  0.028985071927309036
p mean is: tensor(-3.0669, device='cuda:0')
epoch:  68000 quantization_loss:  0.02897852100431919
p mean is: tensor(-3.0761, device='cuda:0')
epoch:  69000 quantization_loss:  0.02896977588534355
p mean is: tensor(-3.0850, device='cuda:0')
epoch:  70000 quantization_loss:  0.02897472307085991
p mean is: tensor(-3.0935, device='cuda:0')
epoch:  71000 quantization_loss:  0.02896130643785
p mean is: tensor(-3.1017, device='cuda:0')
epoch:  72000 quantization_loss:  0.028961554169654846
p mean is: tensor(-3.1097, device='cuda:0')
epoch:  73000 quantization_loss:  0.02896268106997013
p mean is: tensor(-3.1175, device='cuda:0')
epoch:  74000 quantization_loss:  0.028952397406101227
p mean is: tensor(-3.1251, device='cuda:0')
epoch:  75000 quantization_loss:  0.028951894491910934
p mean is: tensor(-3.1324, device='cuda:0')
epoch:  76000 quantization_loss:  0.028949502855539322
p mean is: tensor(-3.1395, device='cuda:0')
epoch:  77000 quantization_loss:  0.028938516974449158
p mean is: tensor(-3.1464, device='cuda:0')
epoch:  78000 quantization_loss:  0.02893616072833538
p mean is: tensor(-3.1531, device='cuda:0')
epoch:  79000 quantization_loss:  0.028933756053447723
p mean is: tensor(-3.1596, device='cuda:0')
Number of elements to keep: 100195
Threshold value: 0.4514271914958954
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.03329990989963996
Number of elements to keep: 100195
Threshold value: 0.4514271914958954
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.03329990989963996
1.1.1.weight         | nonzeros =     582 /   12800             (  4.55%) | total_pruned =   12218 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =      55 /    6400             (  0.86%) | total_pruned =    6345 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      25 /   12800             (  0.20%) | total_pruned =   12775 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =       8 /      32             ( 25.00%) | total_pruned =      24 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =      42 /   25600             (  0.16%) | total_pruned =   25558 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      10 /      32             ( 31.25%) | total_pruned =      22 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =      33 /   51200             (  0.06%) | total_pruned =   51167 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =      18 /  102400             (  0.02%) | total_pruned =  102382 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =       2 /  204800             (  0.00%) | total_pruned =  204798 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =       0 /  409600             (  0.00%) | total_pruned =  409600 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =       9 /  409600             (  0.00%) | total_pruned =  409591 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =     515 /  409600             (  0.13%) | total_pruned =  409085 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    2483 /  409600             (  0.61%) | total_pruned =  407117 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   13700 /  409600             (  3.34%) | total_pruned =  395900 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   24551 /  147456             ( 16.65%) | total_pruned =  122905 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   25232 /  147456             ( 17.11%) | total_pruned =  122224 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   19800 /  147456             ( 13.43%) | total_pruned =  127656 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    8426 /   73728             ( 11.43%) | total_pruned =   65302 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2305 /   18432             ( 12.51%) | total_pruned =   16127 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1139 /    4608             ( 24.72%) | total_pruned =    3469 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      30 /      48             ( 62.50%) | total_pruned =      18 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 100195, pruned : 2908672, total: 3008867, Compression rate :      30.03x  ( 96.67% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  11.58071434343465
Experiment done
