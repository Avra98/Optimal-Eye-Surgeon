(3, 512, 512)
Noisy PSNR is '21.648246450290767'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/8/sparsity/det/0.035/1e-09
epoch:  0 quantization_loss:  0.1572769284248352
p mean is: tensor(-0.0005, device='cuda:0')
epoch:  1000 quantization_loss:  0.13660208880901337
p mean is: tensor(-0.0188, device='cuda:0')
epoch:  2000 quantization_loss:  0.13277359306812286
p mean is: tensor(-0.0307, device='cuda:0')
epoch:  3000 quantization_loss:  0.1296083629131317
p mean is: tensor(-0.0418, device='cuda:0')
epoch:  4000 quantization_loss:  0.12817800045013428
p mean is: tensor(-0.0527, device='cuda:0')
epoch:  5000 quantization_loss:  0.12876343727111816
p mean is: tensor(-0.0637, device='cuda:0')
epoch:  6000 quantization_loss:  0.1282462626695633
p mean is: tensor(-0.0751, device='cuda:0')
epoch:  7000 quantization_loss:  0.12719079852104187
p mean is: tensor(-0.0866, device='cuda:0')
epoch:  8000 quantization_loss:  0.12428633123636246
p mean is: tensor(-0.0981, device='cuda:0')
epoch:  9000 quantization_loss:  0.1031307801604271
p mean is: tensor(-0.1115, device='cuda:0')
epoch:  10000 quantization_loss:  0.0979163721203804
p mean is: tensor(-0.1288, device='cuda:0')
epoch:  11000 quantization_loss:  0.09618829190731049
p mean is: tensor(-0.1521, device='cuda:0')
epoch:  12000 quantization_loss:  0.09427853673696518
p mean is: tensor(-0.1841, device='cuda:0')
epoch:  13000 quantization_loss:  0.09344126284122467
p mean is: tensor(-0.2276, device='cuda:0')
epoch:  14000 quantization_loss:  0.09254791587591171
p mean is: tensor(-0.2858, device='cuda:0')
epoch:  15000 quantization_loss:  0.088774673640728
p mean is: tensor(-0.3614, device='cuda:0')
epoch:  16000 quantization_loss:  0.08768107742071152
p mean is: tensor(-0.4562, device='cuda:0')
epoch:  17000 quantization_loss:  0.08640004694461823
p mean is: tensor(-0.5714, device='cuda:0')
epoch:  18000 quantization_loss:  0.08558519184589386
p mean is: tensor(-0.7055, device='cuda:0')
epoch:  19000 quantization_loss:  0.08515041321516037
p mean is: tensor(-0.8553, device='cuda:0')
epoch:  20000 quantization_loss:  0.07938047498464584
p mean is: tensor(-1.0125, device='cuda:0')
epoch:  21000 quantization_loss:  0.07677458226680756
p mean is: tensor(-1.1657, device='cuda:0')
epoch:  22000 quantization_loss:  0.07609764486551285
p mean is: tensor(-1.3099, device='cuda:0')
epoch:  23000 quantization_loss:  0.07529186457395554
p mean is: tensor(-1.4437, device='cuda:0')
epoch:  24000 quantization_loss:  0.07508612424135208
p mean is: tensor(-1.5664, device='cuda:0')
epoch:  25000 quantization_loss:  0.07490028440952301
p mean is: tensor(-1.6784, device='cuda:0')
epoch:  26000 quantization_loss:  0.07445430755615234
p mean is: tensor(-1.7803, device='cuda:0')
epoch:  27000 quantization_loss:  0.07421361654996872
p mean is: tensor(-1.8728, device='cuda:0')
epoch:  28000 quantization_loss:  0.07386121898889542
p mean is: tensor(-1.9571, device='cuda:0')
epoch:  29000 quantization_loss:  0.07370896637439728
p mean is: tensor(-2.0338, device='cuda:0')
epoch:  30000 quantization_loss:  0.0734846442937851
p mean is: tensor(-2.1040, device='cuda:0')
epoch:  31000 quantization_loss:  0.07342211157083511
p mean is: tensor(-2.1682, device='cuda:0')
epoch:  32000 quantization_loss:  0.07331612706184387
p mean is: tensor(-2.2270, device='cuda:0')
epoch:  33000 quantization_loss:  0.07313993573188782
p mean is: tensor(-2.2812, device='cuda:0')
epoch:  34000 quantization_loss:  0.07305534183979034
p mean is: tensor(-2.3313, device='cuda:0')
epoch:  35000 quantization_loss:  0.07295162230730057
p mean is: tensor(-2.3776, device='cuda:0')
epoch:  36000 quantization_loss:  0.07289951294660568
p mean is: tensor(-2.4207, device='cuda:0')
epoch:  37000 quantization_loss:  0.0727836862206459
p mean is: tensor(-2.4605, device='cuda:0')
epoch:  38000 quantization_loss:  0.07271625101566315
p mean is: tensor(-2.4978, device='cuda:0')
epoch:  39000 quantization_loss:  0.07266994565725327
p mean is: tensor(-2.5326, device='cuda:0')
epoch:  40000 quantization_loss:  0.0726209357380867
p mean is: tensor(-2.5652, device='cuda:0')
epoch:  41000 quantization_loss:  0.07256801426410675
p mean is: tensor(-2.5958, device='cuda:0')
epoch:  42000 quantization_loss:  0.07251862436532974
p mean is: tensor(-2.6247, device='cuda:0')
epoch:  43000 quantization_loss:  0.07246319949626923
p mean is: tensor(-2.6519, device='cuda:0')
epoch:  44000 quantization_loss:  0.07246753573417664
p mean is: tensor(-2.6775, device='cuda:0')
epoch:  45000 quantization_loss:  0.07239659875631332
p mean is: tensor(-2.7017, device='cuda:0')
epoch:  46000 quantization_loss:  0.07323142141103745
p mean is: tensor(-2.7246, device='cuda:0')
epoch:  47000 quantization_loss:  0.07232843339443207
p mean is: tensor(-2.7463, device='cuda:0')
epoch:  48000 quantization_loss:  0.07232089340686798
p mean is: tensor(-2.7669, device='cuda:0')
epoch:  49000 quantization_loss:  0.07229512929916382
p mean is: tensor(-2.7865, device='cuda:0')
epoch:  50000 quantization_loss:  0.07227395474910736
p mean is: tensor(-2.8051, device='cuda:0')
epoch:  51000 quantization_loss:  0.07224574685096741
p mean is: tensor(-2.8229, device='cuda:0')
epoch:  52000 quantization_loss:  0.07222466915845871
p mean is: tensor(-2.8397, device='cuda:0')
epoch:  53000 quantization_loss:  0.07220492511987686
p mean is: tensor(-2.8559, device='cuda:0')
epoch:  54000 quantization_loss:  0.07219628989696503
p mean is: tensor(-2.8714, device='cuda:0')
epoch:  55000 quantization_loss:  0.07218143343925476
p mean is: tensor(-2.8862, device='cuda:0')
epoch:  56000 quantization_loss:  0.07217168062925339
p mean is: tensor(-2.9002, device='cuda:0')
epoch:  57000 quantization_loss:  0.07215891778469086
p mean is: tensor(-2.9138, device='cuda:0')
epoch:  58000 quantization_loss:  0.07214751094579697
p mean is: tensor(-2.9268, device='cuda:0')
epoch:  59000 quantization_loss:  0.07213848829269409
p mean is: tensor(-2.9393, device='cuda:0')
epoch:  60000 quantization_loss:  0.07212863862514496
p mean is: tensor(-2.9513, device='cuda:0')
epoch:  61000 quantization_loss:  0.0721176415681839
p mean is: tensor(-2.9628, device='cuda:0')
epoch:  62000 quantization_loss:  0.07210975140333176
p mean is: tensor(-2.9738, device='cuda:0')
epoch:  63000 quantization_loss:  0.07209792733192444
p mean is: tensor(-2.9845, device='cuda:0')
epoch:  64000 quantization_loss:  0.07209974527359009
p mean is: tensor(-2.9948, device='cuda:0')
epoch:  65000 quantization_loss:  0.07209072262048721
p mean is: tensor(-3.0046, device='cuda:0')
epoch:  66000 quantization_loss:  0.07207397371530533
p mean is: tensor(-3.0142, device='cuda:0')
epoch:  67000 quantization_loss:  0.07207389920949936
p mean is: tensor(-3.0234, device='cuda:0')
epoch:  68000 quantization_loss:  0.07207214087247849
p mean is: tensor(-3.0322, device='cuda:0')
epoch:  69000 quantization_loss:  0.07206404209136963
p mean is: tensor(-3.0408, device='cuda:0')
epoch:  70000 quantization_loss:  0.07206321507692337
p mean is: tensor(-3.0490, device='cuda:0')
epoch:  71000 quantization_loss:  0.07204960286617279
p mean is: tensor(-3.0570, device='cuda:0')
epoch:  72000 quantization_loss:  0.07204549759626389
p mean is: tensor(-3.0647, device='cuda:0')
epoch:  73000 quantization_loss:  0.07207874953746796
p mean is: tensor(-3.0721, device='cuda:0')
epoch:  74000 quantization_loss:  0.07204031944274902
p mean is: tensor(-3.0793, device='cuda:0')
epoch:  75000 quantization_loss:  0.07204286754131317
p mean is: tensor(-3.0863, device='cuda:0')
epoch:  76000 quantization_loss:  0.07202699035406113
p mean is: tensor(-3.0931, device='cuda:0')
epoch:  77000 quantization_loss:  0.07212235033512115
p mean is: tensor(-3.0996, device='cuda:0')
epoch:  78000 quantization_loss:  0.07201840728521347
p mean is: tensor(-3.1059, device='cuda:0')
epoch:  79000 quantization_loss:  0.07202310115098953
p mean is: tensor(-3.1121, device='cuda:0')
Number of elements to keep: 105310
Threshold value: -1.4319688081741333
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.03499988533889999
Number of elements to keep: 105310
Threshold value: -1.4319688081741333
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.03499988533889999
1.1.1.weight         | nonzeros =     841 /   12800             (  6.57%) | total_pruned =   11959 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =      84 /    6400             (  1.31%) | total_pruned =    6316 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      79 /   12800             (  0.62%) | total_pruned =   12721 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      10 /      32             ( 31.25%) | total_pruned =      22 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     128 /   25600             (  0.50%) | total_pruned =   25472 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     177 /   51200             (  0.35%) | total_pruned =   51023 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     415 /  102400             (  0.41%) | total_pruned =  101985 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     412 /  204800             (  0.20%) | total_pruned =  204388 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     832 /  409600             (  0.20%) | total_pruned =  408768 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    1096 /  409600             (  0.27%) | total_pruned =  408504 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    2921 /  409600             (  0.71%) | total_pruned =  406679 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    6866 /  409600             (  1.68%) | total_pruned =  402734 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   19391 /  409600             (  4.73%) | total_pruned =  390209 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   22314 /  147456             ( 15.13%) | total_pruned =  125142 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   22971 /  147456             ( 15.58%) | total_pruned =  124485 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   16428 /  147456             ( 11.14%) | total_pruned =  131028 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    6333 /   73728             (  8.59%) | total_pruned =   67395 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    1867 /   18432             ( 10.13%) | total_pruned =   16565 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =     995 /    4608             ( 21.59%) | total_pruned =    3613 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      26 /      48             ( 54.17%) | total_pruned =      22 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 105310, pruned : 2903557, total: 3008867, Compression rate :      28.57x  ( 96.50% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  11.027985967856894
Experiment done
