(3, 256, 256)
Noisy PSNR is '20.832948109098556'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/12/sparsity_skip/det/0.02/1e-09
epoch:  0 quantization_loss:  0.11994557827711105
p mean is: tensor(-0.0006, device='cuda:5')
epoch:  1000 quantization_loss:  0.07676274329423904
p mean is: tensor(-0.0122, device='cuda:5')
epoch:  2000 quantization_loss:  0.07493574172258377
p mean is: tensor(-0.0189, device='cuda:5')
epoch:  3000 quantization_loss:  0.07390813529491425
p mean is: tensor(-0.0251, device='cuda:5')
epoch:  4000 quantization_loss:  0.07392992824316025
p mean is: tensor(-0.0312, device='cuda:5')
epoch:  5000 quantization_loss:  0.0751938670873642
p mean is: tensor(-0.0367, device='cuda:5')
epoch:  6000 quantization_loss:  0.07354284077882767
p mean is: tensor(-0.0421, device='cuda:5')
epoch:  7000 quantization_loss:  0.07409285753965378
p mean is: tensor(-0.0479, device='cuda:5')
epoch:  8000 quantization_loss:  0.07318226993083954
p mean is: tensor(-0.0538, device='cuda:5')
epoch:  9000 quantization_loss:  0.07575896382331848
p mean is: tensor(-0.0592, device='cuda:5')
epoch:  10000 quantization_loss:  0.07039525359869003
p mean is: tensor(-0.0648, device='cuda:5')
epoch:  11000 quantization_loss:  0.0650736540555954
p mean is: tensor(-0.0701, device='cuda:5')
epoch:  12000 quantization_loss:  0.05244070664048195
p mean is: tensor(-0.0758, device='cuda:5')
epoch:  13000 quantization_loss:  0.02753523178398609
p mean is: tensor(-0.0821, device='cuda:5')
epoch:  14000 quantization_loss:  0.024097291752696037
p mean is: tensor(-0.0910, device='cuda:5')
epoch:  15000 quantization_loss:  0.02221314050257206
p mean is: tensor(-0.1034, device='cuda:5')
epoch:  16000 quantization_loss:  0.021522749215364456
p mean is: tensor(-0.1209, device='cuda:5')
epoch:  17000 quantization_loss:  0.01998854987323284
p mean is: tensor(-0.1455, device='cuda:5')
epoch:  18000 quantization_loss:  0.019339127466082573
p mean is: tensor(-0.1794, device='cuda:5')
epoch:  19000 quantization_loss:  0.018590474501252174
p mean is: tensor(-0.2247, device='cuda:5')
epoch:  20000 quantization_loss:  0.01796879991889
p mean is: tensor(-0.2836, device='cuda:5')
epoch:  21000 quantization_loss:  0.017240967601537704
p mean is: tensor(-0.3557, device='cuda:5')
epoch:  22000 quantization_loss:  0.016114113852381706
p mean is: tensor(-0.4419, device='cuda:5')
epoch:  23000 quantization_loss:  0.015266968868672848
p mean is: tensor(-0.5418, device='cuda:5')
epoch:  24000 quantization_loss:  0.014760274440050125
p mean is: tensor(-0.6547, device='cuda:5')
epoch:  25000 quantization_loss:  0.014420170336961746
p mean is: tensor(-0.7801, device='cuda:5')
epoch:  26000 quantization_loss:  0.01381796132773161
p mean is: tensor(-0.9137, device='cuda:5')
epoch:  27000 quantization_loss:  0.013730443082749844
p mean is: tensor(-1.0507, device='cuda:5')
epoch:  28000 quantization_loss:  0.013203553855419159
p mean is: tensor(-1.1876, device='cuda:5')
epoch:  29000 quantization_loss:  0.012955591082572937
p mean is: tensor(-1.3211, device='cuda:5')
epoch:  30000 quantization_loss:  0.0126658258959651
p mean is: tensor(-1.4483, device='cuda:5')
epoch:  31000 quantization_loss:  0.012523938901722431
p mean is: tensor(-1.5676, device='cuda:5')
epoch:  32000 quantization_loss:  0.01230567879974842
p mean is: tensor(-1.6793, device='cuda:5')
epoch:  33000 quantization_loss:  0.0121337054297328
p mean is: tensor(-1.7828, device='cuda:5')
epoch:  34000 quantization_loss:  0.011961998417973518
p mean is: tensor(-1.8786, device='cuda:5')
epoch:  35000 quantization_loss:  0.01187245361506939
p mean is: tensor(-1.9673, device='cuda:5')
epoch:  36000 quantization_loss:  0.011760622262954712
p mean is: tensor(-2.0495, device='cuda:5')
epoch:  37000 quantization_loss:  0.011728954501450062
p mean is: tensor(-2.1255, device='cuda:5')
epoch:  38000 quantization_loss:  0.011678008362650871
p mean is: tensor(-2.1961, device='cuda:5')
epoch:  39000 quantization_loss:  0.011462916620075703
p mean is: tensor(-2.2620, device='cuda:5')
epoch:  40000 quantization_loss:  0.011426586657762527
p mean is: tensor(-2.3235, device='cuda:5')
epoch:  41000 quantization_loss:  0.01140696369111538
p mean is: tensor(-2.3810, device='cuda:5')
epoch:  42000 quantization_loss:  0.011332958936691284
p mean is: tensor(-2.4349, device='cuda:5')
epoch:  43000 quantization_loss:  0.011250334791839123
p mean is: tensor(-2.4856, device='cuda:5')
epoch:  44000 quantization_loss:  0.01123348530381918
p mean is: tensor(-2.5335, device='cuda:5')
epoch:  45000 quantization_loss:  0.011188090778887272
p mean is: tensor(-2.5787, device='cuda:5')
epoch:  46000 quantization_loss:  0.0111495116725564
p mean is: tensor(-2.6213, device='cuda:5')
epoch:  47000 quantization_loss:  0.011116648092865944
p mean is: tensor(-2.6615, device='cuda:5')
epoch:  48000 quantization_loss:  0.011126400902867317
p mean is: tensor(-2.6996, device='cuda:5')
epoch:  49000 quantization_loss:  0.011104024946689606
p mean is: tensor(-2.7356, device='cuda:5')
epoch:  50000 quantization_loss:  0.011078664101660252
p mean is: tensor(-2.7701, device='cuda:5')
epoch:  51000 quantization_loss:  0.010987789370119572
p mean is: tensor(-2.8027, device='cuda:5')
epoch:  52000 quantization_loss:  0.010968365706503391
p mean is: tensor(-2.8340, device='cuda:5')
epoch:  53000 quantization_loss:  0.010928831063210964
p mean is: tensor(-2.8638, device='cuda:5')
epoch:  54000 quantization_loss:  0.01091586984694004
p mean is: tensor(-2.8923, device='cuda:5')
epoch:  55000 quantization_loss:  0.010911060497164726
p mean is: tensor(-2.9195, device='cuda:5')
epoch:  56000 quantization_loss:  0.010884871706366539
p mean is: tensor(-2.9457, device='cuda:5')
epoch:  57000 quantization_loss:  0.010858532972633839
p mean is: tensor(-2.9708, device='cuda:5')
epoch:  58000 quantization_loss:  0.010819402523338795
p mean is: tensor(-2.9949, device='cuda:5')
epoch:  59000 quantization_loss:  0.01081584021449089
p mean is: tensor(-3.0180, device='cuda:5')
Number of elements to keep: 44356
Threshold value: 4.483617782592773
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.01999972044759046
Number of elements to keep: 44356
Threshold value: 4.483617782592773
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.01999972044759046
1.0.1.1.weight       | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =   11303 /   36864             ( 30.66%) | total_pruned =   25561 | shape = torch.Size([128, 32, 3, 3])
1.1.1.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.2.weight         | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
1.1.2.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.4.1.weight       | nonzeros =   17005 /  147456             ( 11.53%) | total_pruned =  130451 | shape = torch.Size([128, 128, 3, 3])
1.1.4.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.5.weight         | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
1.1.5.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.0.1.1.weight | nonzeros =     159 /     512             ( 31.05%) | total_pruned =     353 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =    1056 /  147456             (  0.72%) | total_pruned =  146400 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.2.weight   | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.1.7.1.1.2.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.4.1.weight | nonzeros =     550 /  147456             (  0.37%) | total_pruned =  146906 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.5.weight   | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.1.7.1.1.5.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     131 /     512             ( 25.59%) | total_pruned =     381 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =       7 /  147456             (  0.00%) | total_pruned =  147449 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =       3 /  147456             (  0.00%) | total_pruned =  147453 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      53 /     512             ( 10.35%) | total_pruned =     459 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =       1 /  147456             (  0.00%) | total_pruned =  147455 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =      13 /  147456             (  0.01%) | total_pruned =  147443 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      16 /     512             (  3.12%) | total_pruned =     496 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =       8 /  147456             (  0.01%) | total_pruned =  147448 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =      49 /  147456             (  0.03%) | total_pruned =  147407 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      42 /     132             ( 31.82%) | total_pruned =      90 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =      98 /  152064             (  0.06%) | total_pruned =  151966 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =     127 /   16384             (  0.78%) | total_pruned =   16257 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      39 /     132             ( 29.55%) | total_pruned =      93 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =     250 /  152064             (  0.16%) | total_pruned =  151814 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =     181 /   16384             (  1.10%) | total_pruned =   16203 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      27 /     132             ( 20.45%) | total_pruned =     105 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =    1193 /  152064             (  0.78%) | total_pruned =  150871 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.4.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.6.1.weight | nonzeros =     543 /   16384             (  3.31%) | total_pruned =   15841 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.7.weight | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
1.1.7.1.1.7.7.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.2.weight       | nonzeros =      55 /     132             ( 41.67%) | total_pruned =      77 | shape = torch.Size([132])
1.1.7.2.bias         | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.3.1.weight     | nonzeros =    2062 /  152064             (  1.36%) | total_pruned =  150002 | shape = torch.Size([128, 132, 3, 3])
1.1.7.3.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.4.weight       | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.1.7.4.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.6.1.weight     | nonzeros =    1318 /   16384             (  8.04%) | total_pruned =   15066 | shape = torch.Size([128, 128, 1, 1])
1.1.7.6.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.7.weight       | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.1.7.7.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
2.weight             | nonzeros =      77 /     132             ( 58.33%) | total_pruned =      55 | shape = torch.Size([132])
2.bias               | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
3.1.weight           | nonzeros =    2734 /  152064             (  1.80%) | total_pruned =  149330 | shape = torch.Size([128, 132, 3, 3])
3.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
4.weight             | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
6.1.weight           | nonzeros =    3633 /   16384             ( 22.17%) | total_pruned =   12751 | shape = torch.Size([128, 128, 1, 1])
6.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
7.weight             | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
7.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =     196 /     384             ( 51.04%) | total_pruned =     188 | shape = torch.Size([3, 128, 1, 1])
9.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 44356, pruned : 2173475, total: 2217831, Compression rate :      50.00x  ( 98.00% pruned)
(3, 256, 256) (3, 256, 256) (3, 256, 256)
PSNR of output image is:  10.70908288367974
Experiment done
