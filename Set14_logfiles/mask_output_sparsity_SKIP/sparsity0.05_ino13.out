(3, 512, 512)
Noisy PSNR is '20.489148216920945'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/13/sparsity_skip/det/0.05/1e-09
(3, 512, 512)
Noisy PSNR is '20.497323514677063'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/13/sparsity_skip/det/0.05/1e-09
epoch:  0 quantization_loss:  0.08003484457731247
p mean is: tensor(-0.0005, device='cuda:6')
epoch:  1000 quantization_loss:  0.05897970870137215
p mean is: tensor(-0.0161, device='cuda:6')
epoch:  2000 quantization_loss:  0.0599571168422699
p mean is: tensor(-0.0261, device='cuda:6')
epoch:  3000 quantization_loss:  0.06017133221030235
p mean is: tensor(-0.0358, device='cuda:6')
epoch:  4000 quantization_loss:  0.06043844297528267
p mean is: tensor(-0.0454, device='cuda:6')
epoch:  5000 quantization_loss:  0.058710843324661255
p mean is: tensor(-0.0550, device='cuda:6')
epoch:  6000 quantization_loss:  0.06047957390546799
p mean is: tensor(-0.0643, device='cuda:6')
epoch:  7000 quantization_loss:  0.058946263045072556
p mean is: tensor(-0.0737, device='cuda:6')
epoch:  8000 quantization_loss:  0.058443982154130936
p mean is: tensor(-0.0834, device='cuda:6')
epoch:  9000 quantization_loss:  0.058493051677942276
p mean is: tensor(-0.0932, device='cuda:6')
epoch:  10000 quantization_loss:  0.05923698469996452
p mean is: tensor(-0.1034, device='cuda:6')
epoch:  11000 quantization_loss:  0.05896860733628273
p mean is: tensor(-0.1134, device='cuda:6')
epoch:  12000 quantization_loss:  0.05866850167512894
p mean is: tensor(-0.1235, device='cuda:6')
epoch:  13000 quantization_loss:  0.059064462780952454
p mean is: tensor(-0.1338, device='cuda:6')
epoch:  14000 quantization_loss:  0.058251235634088516
p mean is: tensor(-0.1444, device='cuda:6')
epoch:  15000 quantization_loss:  0.05949504300951958
p mean is: tensor(-0.1553, device='cuda:6')
epoch:  16000 quantization_loss:  0.05851898342370987
p mean is: tensor(-0.1661, device='cuda:6')
epoch:  17000 quantization_loss:  0.05825159326195717
p mean is: tensor(-0.1774, device='cuda:6')
epoch:  18000 quantization_loss:  0.05892021954059601
p mean is: tensor(-0.1886, device='cuda:6')
epoch:  19000 quantization_loss:  0.05817001685500145
p mean is: tensor(-0.2006, device='cuda:6')
epoch:  20000 quantization_loss:  0.05459614843130112
p mean is: tensor(-0.2122, device='cuda:6')
epoch:  21000 quantization_loss:  0.03789055347442627
p mean is: tensor(-0.2230, device='cuda:6')
epoch:  22000 quantization_loss:  0.03090430423617363
p mean is: tensor(-0.2363, device='cuda:6')
epoch:  23000 quantization_loss:  0.028278805315494537
p mean is: tensor(-0.2537, device='cuda:6')
epoch:  24000 quantization_loss:  0.026656704023480415
p mean is: tensor(-0.2764, device='cuda:6')
epoch:  25000 quantization_loss:  0.02327602356672287
p mean is: tensor(-0.3066, device='cuda:6')
epoch:  26000 quantization_loss:  0.021979624405503273
p mean is: tensor(-0.3460, device='cuda:6')
epoch:  27000 quantization_loss:  0.01973038539290428
p mean is: tensor(-0.3958, device='cuda:6')
epoch:  28000 quantization_loss:  0.01849658414721489
p mean is: tensor(-0.4576, device='cuda:6')
epoch:  29000 quantization_loss:  0.01770762726664543
p mean is: tensor(-0.5318, device='cuda:6')
epoch:  30000 quantization_loss:  0.01688358001410961
p mean is: tensor(-0.6183, device='cuda:6')
epoch:  31000 quantization_loss:  0.01637301966547966
p mean is: tensor(-0.7152, device='cuda:6')
epoch:  32000 quantization_loss:  0.01572796143591404
p mean is: tensor(-0.8200, device='cuda:6')
epoch:  33000 quantization_loss:  0.01536246296018362
p mean is: tensor(-0.9288, device='cuda:6')
epoch:  34000 quantization_loss:  0.014774511568248272
p mean is: tensor(-1.0378, device='cuda:6')
epoch:  35000 quantization_loss:  0.014281235635280609
p mean is: tensor(-1.1438, device='cuda:6')
epoch:  36000 quantization_loss:  0.013887700624763966
p mean is: tensor(-1.2453, device='cuda:6')
epoch:  37000 quantization_loss:  0.01360431406646967
p mean is: tensor(-1.3406, device='cuda:6')
epoch:  38000 quantization_loss:  0.01346934400498867
p mean is: tensor(-1.4291, device='cuda:6')
epoch:  39000 quantization_loss:  0.013143653981387615
p mean is: tensor(-1.5108, device='cuda:6')
epoch:  40000 quantization_loss:  0.013036361895501614
p mean is: tensor(-1.5860, device='cuda:6')
epoch:  41000 quantization_loss:  0.012790536507964134
p mean is: tensor(-1.6549, device='cuda:6')
epoch:  42000 quantization_loss:  0.0126018226146698
p mean is: tensor(-1.7183, device='cuda:6')
epoch:  43000 quantization_loss:  0.01259064394980669
p mean is: tensor(-1.7766, device='cuda:6')
epoch:  44000 quantization_loss:  0.012380694039165974
p mean is: tensor(-1.8304, device='cuda:6')
epoch:  45000 quantization_loss:  0.012351886369287968
p mean is: tensor(-1.8800, device='cuda:6')
epoch:  46000 quantization_loss:  0.012258990667760372
p mean is: tensor(-1.9256, device='cuda:6')
epoch:  47000 quantization_loss:  0.01211128756403923
p mean is: tensor(-1.9680, device='cuda:6')
epoch:  48000 quantization_loss:  0.012116597965359688
p mean is: tensor(-2.0074, device='cuda:6')
epoch:  49000 quantization_loss:  0.012043101713061333
p mean is: tensor(-2.0438, device='cuda:6')
epoch:  50000 quantization_loss:  0.01191475335508585
p mean is: tensor(-2.0780, device='cuda:6')
epoch:  51000 quantization_loss:  0.011935457587242126
p mean is: tensor(-2.1100, device='cuda:6')
epoch:  52000 quantization_loss:  0.01186329498887062
p mean is: tensor(-2.1401, device='cuda:6')
epoch:  53000 quantization_loss:  0.011851157993078232
p mean is: tensor(-2.1680, device='cuda:6')
epoch:  54000 quantization_loss:  0.011766663752496243
p mean is: tensor(-2.1944, device='cuda:6')
epoch:  55000 quantization_loss:  0.011724867857992649
p mean is: tensor(-2.2191, device='cuda:6')
epoch:  56000 quantization_loss:  0.011723148636519909
p mean is: tensor(-2.2424, device='cuda:6')
epoch:  57000 quantization_loss:  0.01164055336266756
p mean is: tensor(-2.2645, device='cuda:6')
epoch:  58000 quantization_loss:  0.011651012115180492
p mean is: tensor(-2.2854, device='cuda:6')
epoch:  59000 quantization_loss:  0.011673067696392536
p mean is: tensor(-2.3051, device='cuda:6')
Number of elements to keep: 110891
Threshold value: 3.4411401748657227
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999975200995928
Number of elements to keep: 110891
Threshold value: 3.4411401748657227
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999975200995928
1.0.1.1.weight       | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =   13178 /   36864             ( 35.75%) | total_pruned =   23686 | shape = torch.Size([128, 32, 3, 3])
1.1.1.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.2.weight         | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
1.1.2.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.4.1.weight       | nonzeros =   32220 /  147456             ( 21.85%) | total_pruned =  115236 | shape = torch.Size([128, 128, 3, 3])
1.1.4.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.5.weight         | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.1.5.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.0.1.1.weight | nonzeros =     103 /     512             ( 20.12%) | total_pruned =     409 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =   27458 /  147456             ( 18.62%) | total_pruned =  119998 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.2.weight   | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.1.7.1.1.2.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.4.1.weight | nonzeros =   17083 /  147456             ( 11.59%) | total_pruned =  130373 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.5.weight   | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.1.7.1.1.5.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     169 /     512             ( 33.01%) | total_pruned =     343 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =     676 /  147456             (  0.46%) | total_pruned =  146780 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =     446 /  147456             (  0.30%) | total_pruned =  147010 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     110 /     512             ( 21.48%) | total_pruned =     402 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =       8 /  147456             (  0.01%) | total_pruned =  147448 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =      23 /  147456             (  0.02%) | total_pruned =  147433 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      19 /     512             (  3.71%) | total_pruned =     493 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =      34 /  147456             (  0.02%) | total_pruned =  147422 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =     251 /  147456             (  0.17%) | total_pruned =  147205 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      61 /     132             ( 46.21%) | total_pruned =      71 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =     287 /  152064             (  0.19%) | total_pruned =  151777 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =     331 /   16384             (  2.02%) | total_pruned =   16053 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      38 /     132             ( 28.79%) | total_pruned =      94 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =    1169 /  152064             (  0.77%) | total_pruned =  150895 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =     550 /   16384             (  3.36%) | total_pruned =   15834 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      40 /     132             ( 30.30%) | total_pruned =      92 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =    2827 /  152064             (  1.86%) | total_pruned =  149237 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.4.weight | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.6.1.weight | nonzeros =    1579 /   16384             (  9.64%) | total_pruned =   14805 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.7.weight | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
1.1.7.1.1.7.7.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.2.weight       | nonzeros =      72 /     132             ( 54.55%) | total_pruned =      60 | shape = torch.Size([132])
1.1.7.2.bias         | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.3.1.weight     | nonzeros =    4246 /  152064             (  2.79%) | total_pruned =  147818 | shape = torch.Size([128, 132, 3, 3])
1.1.7.3.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.4.weight       | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.1.7.4.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.6.1.weight     | nonzeros =    1126 /   16384             (  6.87%) | total_pruned =   15258 | shape = torch.Size([128, 128, 1, 1])
1.1.7.6.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.7.weight       | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
1.1.7.7.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
2.weight             | nonzeros =      58 /     132             ( 43.94%) | total_pruned =      74 | shape = torch.Size([132])
2.bias               | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
3.1.weight           | nonzeros =    2828 /  152064             (  1.86%) | total_pruned =  149236 | shape = torch.Size([128, 132, 3, 3])
3.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
4.weight             | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
6.1.weight           | nonzeros =    2157 /   16384             ( 13.17%) | total_pruned =   14227 | shape = torch.Size([128, 128, 1, 1])
6.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
7.weight             | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
7.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =     177 /     384             ( 46.09%) | total_pruned =     207 | shape = torch.Size([3, 128, 1, 1])
9.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 110891, pruned : 2106940, total: 2217831, Compression rate :      20.00x  ( 95.00% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  17.934663232843036
Experiment done
