(3, 512, 512)
Noisy PSNR is '21.6502271493057'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/8/sparsity_skip/det/0.069/1e-09
(3, 512, 512)
Noisy PSNR is '21.665910899714827'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/8/sparsity_skip/det/0.069/1e-09
epoch:  0 quantization_loss:  0.1629457324743271
p mean is: tensor(-0.0004, device='cuda:1')
epoch:  1000 quantization_loss:  0.11423777043819427
p mean is: tensor(-0.0115, device='cuda:1')
epoch:  2000 quantization_loss:  0.10988029837608337
p mean is: tensor(-0.0185, device='cuda:1')
epoch:  3000 quantization_loss:  0.10750237107276917
p mean is: tensor(-0.0253, device='cuda:1')
epoch:  4000 quantization_loss:  0.10942809283733368
p mean is: tensor(-0.0321, device='cuda:1')
epoch:  5000 quantization_loss:  0.10760301351547241
p mean is: tensor(-0.0384, device='cuda:1')
epoch:  6000 quantization_loss:  0.10834047198295593
p mean is: tensor(-0.0448, device='cuda:1')
epoch:  7000 quantization_loss:  0.1077551320195198
p mean is: tensor(-0.0512, device='cuda:1')
epoch:  8000 quantization_loss:  0.10741753876209259
p mean is: tensor(-0.0578, device='cuda:1')
epoch:  9000 quantization_loss:  0.10849840939044952
p mean is: tensor(-0.0642, device='cuda:1')
epoch:  10000 quantization_loss:  0.1086205244064331
p mean is: tensor(-0.0714, device='cuda:1')
epoch:  11000 quantization_loss:  0.10752546042203903
p mean is: tensor(-0.0783, device='cuda:1')
epoch:  12000 quantization_loss:  0.10766297578811646
p mean is: tensor(-0.0854, device='cuda:1')
epoch:  13000 quantization_loss:  0.10747124254703522
p mean is: tensor(-0.0927, device='cuda:1')
epoch:  14000 quantization_loss:  0.1078130453824997
p mean is: tensor(-0.1003, device='cuda:1')
epoch:  15000 quantization_loss:  0.10717280209064484
p mean is: tensor(-0.1081, device='cuda:1')
epoch:  16000 quantization_loss:  0.10741731524467468
p mean is: tensor(-0.1155, device='cuda:1')
epoch:  17000 quantization_loss:  0.10622569173574448
p mean is: tensor(-0.1237, device='cuda:1')
epoch:  18000 quantization_loss:  0.10547075420618057
p mean is: tensor(-0.1318, device='cuda:1')
epoch:  19000 quantization_loss:  0.10324738919734955
p mean is: tensor(-0.1396, device='cuda:1')
epoch:  20000 quantization_loss:  0.1019565686583519
p mean is: tensor(-0.1477, device='cuda:1')
epoch:  21000 quantization_loss:  0.09702381491661072
p mean is: tensor(-0.1568, device='cuda:1')
epoch:  22000 quantization_loss:  0.0894533172249794
p mean is: tensor(-0.1661, device='cuda:1')
epoch:  23000 quantization_loss:  0.07899311929941177
p mean is: tensor(-0.1765, device='cuda:1')
epoch:  24000 quantization_loss:  0.06757911294698715
p mean is: tensor(-0.1893, device='cuda:1')
epoch:  25000 quantization_loss:  0.06260673701763153
p mean is: tensor(-0.2056, device='cuda:1')
epoch:  26000 quantization_loss:  0.0476003959774971
p mean is: tensor(-0.2260, device='cuda:1')
epoch:  27000 quantization_loss:  0.04332834482192993
p mean is: tensor(-0.2511, device='cuda:1')
epoch:  28000 quantization_loss:  0.03823978081345558
p mean is: tensor(-0.2822, device='cuda:1')
epoch:  29000 quantization_loss:  0.03641463816165924
p mean is: tensor(-0.3216, device='cuda:1')
epoch:  30000 quantization_loss:  0.0342220664024353
p mean is: tensor(-0.3701, device='cuda:1')
epoch:  31000 quantization_loss:  0.03259658440947533
p mean is: tensor(-0.4284, device='cuda:1')
epoch:  32000 quantization_loss:  0.030861757695674896
p mean is: tensor(-0.4958, device='cuda:1')
epoch:  33000 quantization_loss:  0.029239490628242493
p mean is: tensor(-0.5714, device='cuda:1')
epoch:  34000 quantization_loss:  0.027593184262514114
p mean is: tensor(-0.6532, device='cuda:1')
epoch:  35000 quantization_loss:  0.025879129767417908
p mean is: tensor(-0.7386, device='cuda:1')
epoch:  36000 quantization_loss:  0.024753544479608536
p mean is: tensor(-0.8269, device='cuda:1')
epoch:  37000 quantization_loss:  0.02350505255162716
p mean is: tensor(-0.9165, device='cuda:1')
epoch:  38000 quantization_loss:  0.022625336423516273
p mean is: tensor(-1.0054, device='cuda:1')
epoch:  39000 quantization_loss:  0.022188682109117508
p mean is: tensor(-1.0919, device='cuda:1')
epoch:  40000 quantization_loss:  0.021536963060498238
p mean is: tensor(-1.1751, device='cuda:1')
epoch:  41000 quantization_loss:  0.020783929154276848
p mean is: tensor(-1.2538, device='cuda:1')
epoch:  42000 quantization_loss:  0.02045469544827938
p mean is: tensor(-1.3273, device='cuda:1')
epoch:  43000 quantization_loss:  0.019991574808955193
p mean is: tensor(-1.3958, device='cuda:1')
epoch:  44000 quantization_loss:  0.0195426307618618
p mean is: tensor(-1.4592, device='cuda:1')
epoch:  45000 quantization_loss:  0.019194956868886948
p mean is: tensor(-1.5177, device='cuda:1')
epoch:  46000 quantization_loss:  0.018676526844501495
p mean is: tensor(-1.5717, device='cuda:1')
epoch:  47000 quantization_loss:  0.018863413482904434
p mean is: tensor(-1.6218, device='cuda:1')
epoch:  48000 quantization_loss:  0.018385756760835648
p mean is: tensor(-1.6680, device='cuda:1')
epoch:  49000 quantization_loss:  0.018279192969202995
p mean is: tensor(-1.7109, device='cuda:1')
epoch:  50000 quantization_loss:  0.01792195998132229
p mean is: tensor(-1.7507, device='cuda:1')
epoch:  51000 quantization_loss:  0.017808813601732254
p mean is: tensor(-1.7875, device='cuda:1')
epoch:  52000 quantization_loss:  0.017599398270249367
p mean is: tensor(-1.8215, device='cuda:1')
epoch:  53000 quantization_loss:  0.017791669815778732
p mean is: tensor(-1.8531, device='cuda:1')
epoch:  54000 quantization_loss:  0.01753067411482334
p mean is: tensor(-1.8825, device='cuda:1')
epoch:  55000 quantization_loss:  0.017387954518198967
p mean is: tensor(-1.9099, device='cuda:1')
epoch:  56000 quantization_loss:  0.017077194526791573
p mean is: tensor(-1.9354, device='cuda:1')
epoch:  57000 quantization_loss:  0.017169272527098656
p mean is: tensor(-1.9592, device='cuda:1')
epoch:  58000 quantization_loss:  0.01694367080926895
p mean is: tensor(-1.9814, device='cuda:1')
epoch:  59000 quantization_loss:  0.016847088932991028
p mean is: tensor(-2.0022, device='cuda:1')
Number of elements to keep: 153030
Threshold value: 1.896182656288147
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.06899984714795672
Number of elements to keep: 153030
Threshold value: 1.896182656288147
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.06899984714795672
1.0.1.1.weight       | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =   13634 /   36864             ( 36.98%) | total_pruned =   23230 | shape = torch.Size([128, 32, 3, 3])
1.1.1.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.2.weight         | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.1.2.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.4.1.weight       | nonzeros =   35277 /  147456             ( 23.92%) | total_pruned =  112179 | shape = torch.Size([128, 128, 3, 3])
1.1.4.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.5.weight         | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.1.5.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.0.1.1.weight | nonzeros =     150 /     512             ( 29.30%) | total_pruned =     362 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =   28723 /  147456             ( 19.48%) | total_pruned =  118733 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.2.weight   | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.1.7.1.1.2.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.4.1.weight | nonzeros =   17436 /  147456             ( 11.82%) | total_pruned =  130020 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.5.weight   | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.1.7.1.1.5.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     136 /     512             ( 26.56%) | total_pruned =     376 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    2555 /  147456             (  1.73%) | total_pruned =  144901 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    1661 /  147456             (  1.13%) | total_pruned =  145795 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     131 /     512             ( 25.59%) | total_pruned =     381 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =     535 /  147456             (  0.36%) | total_pruned =  146921 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    1212 /  147456             (  0.82%) | total_pruned =  146244 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     105 /     512             ( 20.51%) | total_pruned =     407 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    1937 /  147456             (  1.31%) | total_pruned =  145519 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    3475 /  147456             (  2.36%) | total_pruned =  143981 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      60 /     132             ( 45.45%) | total_pruned =      72 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =    3396 /  152064             (  2.23%) | total_pruned =  148668 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =     806 /   16384             (  4.92%) | total_pruned =   15578 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      31 /     128             ( 24.22%) | total_pruned =      97 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      36 /     132             ( 27.27%) | total_pruned =      96 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =    3844 /  152064             (  2.53%) | total_pruned =  148220 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =     978 /   16384             (  5.97%) | total_pruned =   15406 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      27 /     128             ( 21.09%) | total_pruned =     101 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      32 /     132             ( 24.24%) | total_pruned =     100 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =    6843 /  152064             (  4.50%) | total_pruned =  145221 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.4.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.6.1.weight | nonzeros =     390 /   16384             (  2.38%) | total_pruned =   15994 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.7.weight | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
1.1.7.1.1.7.7.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.2.weight       | nonzeros =      12 /     132             (  9.09%) | total_pruned =     120 | shape = torch.Size([132])
1.1.7.2.bias         | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.3.1.weight     | nonzeros =    4455 /  152064             (  2.93%) | total_pruned =  147609 | shape = torch.Size([128, 132, 3, 3])
1.1.7.3.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.4.weight       | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
1.1.7.4.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.6.1.weight     | nonzeros =    2111 /   16384             ( 12.88%) | total_pruned =   14273 | shape = torch.Size([128, 128, 1, 1])
1.1.7.6.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.7.weight       | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
1.1.7.7.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
2.weight             | nonzeros =      47 /     132             ( 35.61%) | total_pruned =      85 | shape = torch.Size([132])
2.bias               | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
3.1.weight           | nonzeros =   15141 /  152064             (  9.96%) | total_pruned =  136923 | shape = torch.Size([128, 132, 3, 3])
3.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
4.weight             | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
6.1.weight           | nonzeros =    6113 /   16384             ( 37.31%) | total_pruned =   10271 | shape = torch.Size([128, 128, 1, 1])
6.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
7.weight             | nonzeros =     117 /     128             ( 91.41%) | total_pruned =      11 | shape = torch.Size([128])
7.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =     210 /     384             ( 54.69%) | total_pruned =     174 | shape = torch.Size([3, 128, 1, 1])
9.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 153030, pruned : 2064801, total: 2217831, Compression rate :      14.49x  ( 93.10% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  17.901787456694713
Experiment done
