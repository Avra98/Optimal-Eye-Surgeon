(3, 512, 512)
Noisy PSNR is '20.20575079212554'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/4/sparsity_skip/det/0.069/1e-09
(3, 512, 512)
Noisy PSNR is '20.219464511789006'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/4/sparsity_skip/det/0.069/1e-09
epoch:  0 quantization_loss:  0.07269563525915146
p mean is: tensor(-0.0004, device='cuda:4')
epoch:  1000 quantization_loss:  0.04539532586932182
p mean is: tensor(-0.0178, device='cuda:4')
epoch:  2000 quantization_loss:  0.04499403014779091
p mean is: tensor(-0.0316, device='cuda:4')
epoch:  3000 quantization_loss:  0.04471074417233467
p mean is: tensor(-0.0455, device='cuda:4')
epoch:  4000 quantization_loss:  0.04398013651371002
p mean is: tensor(-0.0598, device='cuda:4')
epoch:  5000 quantization_loss:  0.04375896230340004
p mean is: tensor(-0.0746, device='cuda:4')
epoch:  6000 quantization_loss:  0.044276412576436996
p mean is: tensor(-0.0900, device='cuda:4')
epoch:  7000 quantization_loss:  0.0439973883330822
p mean is: tensor(-0.1059, device='cuda:4')
epoch:  8000 quantization_loss:  0.04402907192707062
p mean is: tensor(-0.1225, device='cuda:4')
epoch:  9000 quantization_loss:  0.043658770620822906
p mean is: tensor(-0.1398, device='cuda:4')
epoch:  10000 quantization_loss:  0.0436740443110466
p mean is: tensor(-0.1575, device='cuda:4')
epoch:  11000 quantization_loss:  0.04330974444746971
p mean is: tensor(-0.1758, device='cuda:4')
epoch:  12000 quantization_loss:  0.043285708874464035
p mean is: tensor(-0.1951, device='cuda:4')
epoch:  13000 quantization_loss:  0.04345645755529404
p mean is: tensor(-0.2160, device='cuda:4')
epoch:  14000 quantization_loss:  0.04335758462548256
p mean is: tensor(-0.2386, device='cuda:4')
epoch:  15000 quantization_loss:  0.04325254634022713
p mean is: tensor(-0.2639, device='cuda:4')
epoch:  16000 quantization_loss:  0.0430028960108757
p mean is: tensor(-0.2913, device='cuda:4')
epoch:  17000 quantization_loss:  0.043042656034231186
p mean is: tensor(-0.3210, device='cuda:4')
epoch:  18000 quantization_loss:  0.0430377796292305
p mean is: tensor(-0.3522, device='cuda:4')
epoch:  19000 quantization_loss:  0.04289219155907631
p mean is: tensor(-0.3847, device='cuda:4')
epoch:  20000 quantization_loss:  0.04285677522420883
p mean is: tensor(-0.4181, device='cuda:4')
epoch:  21000 quantization_loss:  0.0428047701716423
p mean is: tensor(-0.4532, device='cuda:4')
epoch:  22000 quantization_loss:  0.0428212508559227
p mean is: tensor(-0.4894, device='cuda:4')
epoch:  23000 quantization_loss:  0.04295890033245087
p mean is: tensor(-0.5261, device='cuda:4')
epoch:  24000 quantization_loss:  0.042777225375175476
p mean is: tensor(-0.5620, device='cuda:4')
epoch:  25000 quantization_loss:  0.042305730283260345
p mean is: tensor(-0.5972, device='cuda:4')
epoch:  26000 quantization_loss:  0.029756873846054077
p mean is: tensor(-0.6247, device='cuda:4')
epoch:  27000 quantization_loss:  0.02478627674281597
p mean is: tensor(-0.6494, device='cuda:4')
epoch:  28000 quantization_loss:  0.02269083634018898
p mean is: tensor(-0.6772, device='cuda:4')
epoch:  29000 quantization_loss:  0.020636221393942833
p mean is: tensor(-0.7089, device='cuda:4')
epoch:  30000 quantization_loss:  0.019143760204315186
p mean is: tensor(-0.7455, device='cuda:4')
epoch:  31000 quantization_loss:  0.017723198980093002
p mean is: tensor(-0.7876, device='cuda:4')
epoch:  32000 quantization_loss:  0.016237588599324226
p mean is: tensor(-0.8355, device='cuda:4')
epoch:  33000 quantization_loss:  0.01591443456709385
p mean is: tensor(-0.8889, device='cuda:4')
epoch:  34000 quantization_loss:  0.01526721566915512
p mean is: tensor(-0.9474, device='cuda:4')
epoch:  35000 quantization_loss:  0.014753865078091621
p mean is: tensor(-1.0102, device='cuda:4')
epoch:  36000 quantization_loss:  0.014151573181152344
p mean is: tensor(-1.0758, device='cuda:4')
epoch:  37000 quantization_loss:  0.013947763480246067
p mean is: tensor(-1.1431, device='cuda:4')
epoch:  38000 quantization_loss:  0.01371573656797409
p mean is: tensor(-1.2104, device='cuda:4')
epoch:  39000 quantization_loss:  0.013359567150473595
p mean is: tensor(-1.2770, device='cuda:4')
epoch:  40000 quantization_loss:  0.013201219961047173
p mean is: tensor(-1.3417, device='cuda:4')
epoch:  41000 quantization_loss:  0.013039262033998966
p mean is: tensor(-1.4040, device='cuda:4')
epoch:  42000 quantization_loss:  0.012879269197583199
p mean is: tensor(-1.4631, device='cuda:4')
epoch:  43000 quantization_loss:  0.012805494479835033
p mean is: tensor(-1.5188, device='cuda:4')
epoch:  44000 quantization_loss:  0.012777642346918583
p mean is: tensor(-1.5710, device='cuda:4')
epoch:  45000 quantization_loss:  0.012636717408895493
p mean is: tensor(-1.6200, device='cuda:4')
epoch:  46000 quantization_loss:  0.012436732649803162
p mean is: tensor(-1.6659, device='cuda:4')
epoch:  47000 quantization_loss:  0.012456831522285938
p mean is: tensor(-1.7088, device='cuda:4')
epoch:  48000 quantization_loss:  0.012410747818648815
p mean is: tensor(-1.7490, device='cuda:4')
epoch:  49000 quantization_loss:  0.012257956899702549
p mean is: tensor(-1.7869, device='cuda:4')
epoch:  50000 quantization_loss:  0.012180933728814125
p mean is: tensor(-1.8225, device='cuda:4')
epoch:  51000 quantization_loss:  0.012195262126624584
p mean is: tensor(-1.8559, device='cuda:4')
epoch:  52000 quantization_loss:  0.012219943106174469
p mean is: tensor(-1.8874, device='cuda:4')
epoch:  53000 quantization_loss:  0.012131813913583755
p mean is: tensor(-1.9170, device='cuda:4')
epoch:  54000 quantization_loss:  0.011983295902609825
p mean is: tensor(-1.9451, device='cuda:4')
epoch:  55000 quantization_loss:  0.011953383684158325
p mean is: tensor(-1.9715, device='cuda:4')
epoch:  56000 quantization_loss:  0.012005331926047802
p mean is: tensor(-1.9965, device='cuda:4')
epoch:  57000 quantization_loss:  0.011921493336558342
p mean is: tensor(-2.0202, device='cuda:4')
epoch:  58000 quantization_loss:  0.011857524514198303
p mean is: tensor(-2.0425, device='cuda:4')
epoch:  59000 quantization_loss:  0.011815005913376808
p mean is: tensor(-2.0637, device='cuda:4')
Number of elements to keep: 153030
Threshold value: 1.254802942276001
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.06899984714795672
Number of elements to keep: 153030
Threshold value: 1.254802942276001
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.06899984714795672
1.0.1.1.weight       | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =   12674 /   36864             ( 34.38%) | total_pruned =   24190 | shape = torch.Size([128, 32, 3, 3])
1.1.1.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.2.weight         | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.1.2.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.4.1.weight       | nonzeros =   26857 /  147456             ( 18.21%) | total_pruned =  120599 | shape = torch.Size([128, 128, 3, 3])
1.1.4.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.5.weight         | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.1.5.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.0.1.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =   21452 /  147456             ( 14.55%) | total_pruned =  126004 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.2.weight   | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.1.7.1.1.2.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.4.1.weight | nonzeros =   12518 /  147456             (  8.49%) | total_pruned =  134938 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.5.weight   | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.1.7.1.1.5.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      34 /     512             (  6.64%) | total_pruned =     478 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    6366 /  147456             (  4.32%) | total_pruned =  141090 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    5639 /  147456             (  3.82%) | total_pruned =  141817 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     127 /     512             ( 24.80%) | total_pruned =     385 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    1073 /  147456             (  0.73%) | total_pruned =  146383 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    2254 /  147456             (  1.53%) | total_pruned =  145202 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      94 /     512             ( 18.36%) | total_pruned =     418 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    3954 /  147456             (  2.68%) | total_pruned =  143502 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    7709 /  147456             (  5.23%) | total_pruned =  139747 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      78 /     132             ( 59.09%) | total_pruned =      54 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =    7847 /  152064             (  5.16%) | total_pruned =  144217 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =    1870 /   16384             ( 11.41%) | total_pruned =   14514 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      63 /     132             ( 47.73%) | total_pruned =      69 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =    7106 /  152064             (  4.67%) | total_pruned =  144958 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =    1874 /   16384             ( 11.44%) | total_pruned =   14510 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      59 /     132             ( 44.70%) | total_pruned =      73 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =    7454 /  152064             (  4.90%) | total_pruned =  144610 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.4.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.6.1.weight | nonzeros =    2237 /   16384             ( 13.65%) | total_pruned =   14147 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.7.weight | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
1.1.7.1.1.7.7.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.2.weight       | nonzeros =      65 /     132             ( 49.24%) | total_pruned =      67 | shape = torch.Size([132])
1.1.7.2.bias         | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.3.1.weight     | nonzeros =    7354 /  152064             (  4.84%) | total_pruned =  144710 | shape = torch.Size([128, 132, 3, 3])
1.1.7.3.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.4.weight       | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.1.7.4.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.6.1.weight     | nonzeros =    1743 /   16384             ( 10.64%) | total_pruned =   14641 | shape = torch.Size([128, 128, 1, 1])
1.1.7.6.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.7.weight       | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
1.1.7.7.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
2.weight             | nonzeros =      63 /     132             ( 47.73%) | total_pruned =      69 | shape = torch.Size([132])
2.bias               | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
3.1.weight           | nonzeros =    8947 /  152064             (  5.88%) | total_pruned =  143117 | shape = torch.Size([128, 132, 3, 3])
3.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
4.weight             | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
6.1.weight           | nonzeros =    3658 /   16384             ( 22.33%) | total_pruned =   12726 | shape = torch.Size([128, 128, 1, 1])
6.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
7.weight             | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
7.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =     166 /     384             ( 43.23%) | total_pruned =     218 | shape = torch.Size([3, 128, 1, 1])
9.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 153030, pruned : 2064801, total: 2217831, Compression rate :      14.49x  ( 93.10% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  26.214498274699977
Experiment done
