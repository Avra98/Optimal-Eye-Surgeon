(3, 512, 512)
Noisy PSNR is '20.20400400633793'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/4/sparsity_skip/det/0.05/1e-09
(3, 512, 512)
Noisy PSNR is '20.20432070093104'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/4/sparsity_skip/det/0.05/1e-09
epoch:  0 quantization_loss:  0.06683284044265747
p mean is: tensor(-0.0005, device='cuda:4')
epoch:  1000 quantization_loss:  0.04656626656651497
p mean is: tensor(-0.0199, device='cuda:4')
epoch:  2000 quantization_loss:  0.045460477471351624
p mean is: tensor(-0.0355, device='cuda:4')
epoch:  3000 quantization_loss:  0.04496551677584648
p mean is: tensor(-0.0512, device='cuda:4')
epoch:  4000 quantization_loss:  0.04477144405245781
p mean is: tensor(-0.0674, device='cuda:4')
epoch:  5000 quantization_loss:  0.043878160417079926
p mean is: tensor(-0.0835, device='cuda:4')
epoch:  6000 quantization_loss:  0.04428975656628609
p mean is: tensor(-0.1002, device='cuda:4')
epoch:  7000 quantization_loss:  0.04425552114844322
p mean is: tensor(-0.1171, device='cuda:4')
epoch:  8000 quantization_loss:  0.04416915401816368
p mean is: tensor(-0.1347, device='cuda:4')
epoch:  9000 quantization_loss:  0.04375076666474342
p mean is: tensor(-0.1525, device='cuda:4')
epoch:  10000 quantization_loss:  0.04375844448804855
p mean is: tensor(-0.1711, device='cuda:4')
epoch:  11000 quantization_loss:  0.04358936473727226
p mean is: tensor(-0.1904, device='cuda:4')
epoch:  12000 quantization_loss:  0.04406721144914627
p mean is: tensor(-0.2105, device='cuda:4')
epoch:  13000 quantization_loss:  0.04364481940865517
p mean is: tensor(-0.2315, device='cuda:4')
epoch:  14000 quantization_loss:  0.0434238500893116
p mean is: tensor(-0.2530, device='cuda:4')
epoch:  15000 quantization_loss:  0.04347710311412811
p mean is: tensor(-0.2754, device='cuda:4')
epoch:  16000 quantization_loss:  0.043424639850854874
p mean is: tensor(-0.2986, device='cuda:4')
epoch:  17000 quantization_loss:  0.04338144510984421
p mean is: tensor(-0.3230, device='cuda:4')
epoch:  18000 quantization_loss:  0.043338749557733536
p mean is: tensor(-0.3488, device='cuda:4')
epoch:  19000 quantization_loss:  0.043269310146570206
p mean is: tensor(-0.3760, device='cuda:4')
epoch:  20000 quantization_loss:  0.04357466846704483
p mean is: tensor(-0.4045, device='cuda:4')
epoch:  21000 quantization_loss:  0.043022483587265015
p mean is: tensor(-0.4341, device='cuda:4')
epoch:  22000 quantization_loss:  0.04339296370744705
p mean is: tensor(-0.4648, device='cuda:4')
epoch:  23000 quantization_loss:  0.04324207827448845
p mean is: tensor(-0.4964, device='cuda:4')
epoch:  24000 quantization_loss:  0.043058764189481735
p mean is: tensor(-0.5289, device='cuda:4')
epoch:  25000 quantization_loss:  0.042929451912641525
p mean is: tensor(-0.5620, device='cuda:4')
epoch:  26000 quantization_loss:  0.04290038347244263
p mean is: tensor(-0.5961, device='cuda:4')
epoch:  27000 quantization_loss:  0.04313134774565697
p mean is: tensor(-0.6302, device='cuda:4')
epoch:  28000 quantization_loss:  0.042978622019290924
p mean is: tensor(-0.6642, device='cuda:4')
epoch:  29000 quantization_loss:  0.04319557547569275
p mean is: tensor(-0.6983, device='cuda:4')
epoch:  30000 quantization_loss:  0.042664166539907455
p mean is: tensor(-0.7315, device='cuda:4')
epoch:  31000 quantization_loss:  0.036019217222929
p mean is: tensor(-0.7631, device='cuda:4')
epoch:  32000 quantization_loss:  0.027582697570323944
p mean is: tensor(-0.7857, device='cuda:4')
epoch:  33000 quantization_loss:  0.022934425622224808
p mean is: tensor(-0.8091, device='cuda:4')
epoch:  34000 quantization_loss:  0.020988930016756058
p mean is: tensor(-0.8359, device='cuda:4')
epoch:  35000 quantization_loss:  0.01968185417354107
p mean is: tensor(-0.8678, device='cuda:4')
epoch:  36000 quantization_loss:  0.018476877361536026
p mean is: tensor(-0.9064, device='cuda:4')
epoch:  37000 quantization_loss:  0.017069902271032333
p mean is: tensor(-0.9516, device='cuda:4')
epoch:  38000 quantization_loss:  0.01599361188709736
p mean is: tensor(-1.0037, device='cuda:4')
epoch:  39000 quantization_loss:  0.015202121809124947
p mean is: tensor(-1.0619, device='cuda:4')
epoch:  40000 quantization_loss:  0.014916479587554932
p mean is: tensor(-1.1253, device='cuda:4')
epoch:  41000 quantization_loss:  0.014513189904391766
p mean is: tensor(-1.1933, device='cuda:4')
epoch:  42000 quantization_loss:  0.013884947635233402
p mean is: tensor(-1.2641, device='cuda:4')
epoch:  43000 quantization_loss:  0.013543241657316685
p mean is: tensor(-1.3365, device='cuda:4')
epoch:  44000 quantization_loss:  0.013263226486742496
p mean is: tensor(-1.4087, device='cuda:4')
epoch:  45000 quantization_loss:  0.013135809451341629
p mean is: tensor(-1.4796, device='cuda:4')
epoch:  46000 quantization_loss:  0.012742899358272552
p mean is: tensor(-1.5481, device='cuda:4')
epoch:  47000 quantization_loss:  0.012659513391554356
p mean is: tensor(-1.6141, device='cuda:4')
epoch:  48000 quantization_loss:  0.012513593770563602
p mean is: tensor(-1.6766, device='cuda:4')
epoch:  49000 quantization_loss:  0.012350414879620075
p mean is: tensor(-1.7356, device='cuda:4')
epoch:  50000 quantization_loss:  0.01228917296975851
p mean is: tensor(-1.7907, device='cuda:4')
epoch:  51000 quantization_loss:  0.012257137335836887
p mean is: tensor(-1.8423, device='cuda:4')
epoch:  52000 quantization_loss:  0.01216824445873499
p mean is: tensor(-1.8907, device='cuda:4')
epoch:  53000 quantization_loss:  0.011973795481026173
p mean is: tensor(-1.9359, device='cuda:4')
epoch:  54000 quantization_loss:  0.011959158815443516
p mean is: tensor(-1.9781, device='cuda:4')
epoch:  55000 quantization_loss:  0.011906160973012447
p mean is: tensor(-2.0178, device='cuda:4')
epoch:  56000 quantization_loss:  0.011874654330313206
p mean is: tensor(-2.0553, device='cuda:4')
epoch:  57000 quantization_loss:  0.011803509667515755
p mean is: tensor(-2.0904, device='cuda:4')
epoch:  58000 quantization_loss:  0.011705270037055016
p mean is: tensor(-2.1234, device='cuda:4')
epoch:  59000 quantization_loss:  0.011660509742796421
p mean is: tensor(-2.1546, device='cuda:4')
Number of elements to keep: 110891
Threshold value: 2.427532434463501
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999975200995928
Number of elements to keep: 110891
Threshold value: 2.427532434463501
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999975200995928
1.0.1.1.weight       | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =   11337 /   36864             ( 30.75%) | total_pruned =   25527 | shape = torch.Size([128, 32, 3, 3])
1.1.1.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.2.weight         | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.1.2.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.4.1.weight       | nonzeros =   21500 /  147456             ( 14.58%) | total_pruned =  125956 | shape = torch.Size([128, 128, 3, 3])
1.1.4.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.5.weight         | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.1.5.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.0.1.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =   17783 /  147456             ( 12.06%) | total_pruned =  129673 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.2.weight   | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.1.7.1.1.2.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.4.1.weight | nonzeros =    9608 /  147456             (  6.52%) | total_pruned =  137848 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.5.weight   | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.1.7.1.1.5.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      32 /     512             (  6.25%) | total_pruned =     480 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    4086 /  147456             (  2.77%) | total_pruned =  143370 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    3422 /  147456             (  2.32%) | total_pruned =  144034 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      91 /     512             ( 17.77%) | total_pruned =     421 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =     689 /  147456             (  0.47%) | total_pruned =  146767 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    1365 /  147456             (  0.93%) | total_pruned =  146091 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      61 /     512             ( 11.91%) | total_pruned =     451 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    2231 /  147456             (  1.51%) | total_pruned =  145225 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    4254 /  147456             (  2.88%) | total_pruned =  143202 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      65 /     132             ( 49.24%) | total_pruned =      67 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =    4065 /  152064             (  2.67%) | total_pruned =  147999 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =    1104 /   16384             (  6.74%) | total_pruned =   15280 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      43 /     132             ( 32.58%) | total_pruned =      89 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =    4066 /  152064             (  2.67%) | total_pruned =  147998 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =    1687 /   16384             ( 10.30%) | total_pruned =   14697 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      63 /     132             ( 47.73%) | total_pruned =      69 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =    4926 /  152064             (  3.24%) | total_pruned =  147138 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.4.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.6.1.weight | nonzeros =    1812 /   16384             ( 11.06%) | total_pruned =   14572 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.7.weight | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
1.1.7.1.1.7.7.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.2.weight       | nonzeros =      66 /     132             ( 50.00%) | total_pruned =      66 | shape = torch.Size([132])
1.1.7.2.bias         | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.3.1.weight     | nonzeros =    4441 /  152064             (  2.92%) | total_pruned =  147623 | shape = torch.Size([128, 132, 3, 3])
1.1.7.3.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.4.weight       | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.1.7.4.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.6.1.weight     | nonzeros =    1172 /   16384             (  7.15%) | total_pruned =   15212 | shape = torch.Size([128, 128, 1, 1])
1.1.7.6.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.7.weight       | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
1.1.7.7.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
2.weight             | nonzeros =      50 /     132             ( 37.88%) | total_pruned =      82 | shape = torch.Size([132])
2.bias               | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
3.1.weight           | nonzeros =    5415 /  152064             (  3.56%) | total_pruned =  146649 | shape = torch.Size([128, 132, 3, 3])
3.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
4.weight             | nonzeros =     112 /     128             ( 87.50%) | total_pruned =      16 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
6.1.weight           | nonzeros =    3656 /   16384             ( 22.31%) | total_pruned =   12728 | shape = torch.Size([128, 128, 1, 1])
6.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
7.weight             | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
7.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =     175 /     384             ( 45.57%) | total_pruned =     209 | shape = torch.Size([3, 128, 1, 1])
9.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 110891, pruned : 2106940, total: 2217831, Compression rate :      20.00x  ( 95.00% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  24.966422949142032
Experiment done
