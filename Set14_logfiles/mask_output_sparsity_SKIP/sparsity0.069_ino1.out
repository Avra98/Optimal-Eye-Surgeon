(3, 256, 256)
Noisy PSNR is '20.464277663062013'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/1/sparsity_skip/det/0.069/1e-09
(3, 256, 256)
Noisy PSNR is '20.475539688381215'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/1/sparsity_skip/det/0.069/1e-09
epoch:  0 quantization_loss:  0.09604020416736603
p mean is: tensor(-0.0004, device='cuda:1')
epoch:  1000 quantization_loss:  0.06996431946754456
p mean is: tensor(-0.0097, device='cuda:1')
epoch:  2000 quantization_loss:  0.07085954397916794
p mean is: tensor(-0.0150, device='cuda:1')
epoch:  3000 quantization_loss:  0.06767907738685608
p mean is: tensor(-0.0202, device='cuda:1')
epoch:  4000 quantization_loss:  0.07285499572753906
p mean is: tensor(-0.0249, device='cuda:1')
epoch:  5000 quantization_loss:  0.06881237775087357
p mean is: tensor(-0.0298, device='cuda:1')
epoch:  6000 quantization_loss:  0.06865653395652771
p mean is: tensor(-0.0344, device='cuda:1')
epoch:  7000 quantization_loss:  0.07076677680015564
p mean is: tensor(-0.0392, device='cuda:1')
epoch:  8000 quantization_loss:  0.06984259933233261
p mean is: tensor(-0.0440, device='cuda:1')
epoch:  9000 quantization_loss:  0.06999177485704422
p mean is: tensor(-0.0487, device='cuda:1')
epoch:  10000 quantization_loss:  0.07096460461616516
p mean is: tensor(-0.0537, device='cuda:1')
epoch:  11000 quantization_loss:  0.06740009039640427
p mean is: tensor(-0.0586, device='cuda:1')
epoch:  12000 quantization_loss:  0.06868136674165726
p mean is: tensor(-0.0635, device='cuda:1')
epoch:  13000 quantization_loss:  0.06878987699747086
p mean is: tensor(-0.0682, device='cuda:1')
epoch:  14000 quantization_loss:  0.07772066444158554
p mean is: tensor(-0.0732, device='cuda:1')
epoch:  15000 quantization_loss:  0.04612329229712486
p mean is: tensor(-0.0781, device='cuda:1')
epoch:  16000 quantization_loss:  0.0373602956533432
p mean is: tensor(-0.0835, device='cuda:1')
epoch:  17000 quantization_loss:  0.031103068962693214
p mean is: tensor(-0.0904, device='cuda:1')
epoch:  18000 quantization_loss:  0.02741415798664093
p mean is: tensor(-0.1001, device='cuda:1')
epoch:  19000 quantization_loss:  0.02542896568775177
p mean is: tensor(-0.1135, device='cuda:1')
epoch:  20000 quantization_loss:  0.02338794432580471
p mean is: tensor(-0.1318, device='cuda:1')
epoch:  21000 quantization_loss:  0.019594887271523476
p mean is: tensor(-0.1556, device='cuda:1')
epoch:  22000 quantization_loss:  0.0180889293551445
p mean is: tensor(-0.1861, device='cuda:1')
epoch:  23000 quantization_loss:  0.016346393153071404
p mean is: tensor(-0.2249, device='cuda:1')
epoch:  24000 quantization_loss:  0.015536807477474213
p mean is: tensor(-0.2734, device='cuda:1')
epoch:  25000 quantization_loss:  0.014826773665845394
p mean is: tensor(-0.3332, device='cuda:1')
epoch:  26000 quantization_loss:  0.014226038008928299
p mean is: tensor(-0.4047, device='cuda:1')
epoch:  27000 quantization_loss:  0.01375278364866972
p mean is: tensor(-0.4876, device='cuda:1')
epoch:  28000 quantization_loss:  0.013321931473910809
p mean is: tensor(-0.5798, device='cuda:1')
epoch:  29000 quantization_loss:  0.012689473107457161
p mean is: tensor(-0.6787, device='cuda:1')
epoch:  30000 quantization_loss:  0.0126336719840765
p mean is: tensor(-0.7807, device='cuda:1')
epoch:  31000 quantization_loss:  0.012050675228238106
p mean is: tensor(-0.8838, device='cuda:1')
epoch:  32000 quantization_loss:  0.011598952114582062
p mean is: tensor(-0.9852, device='cuda:1')
epoch:  33000 quantization_loss:  0.011467285454273224
p mean is: tensor(-1.0825, device='cuda:1')
epoch:  34000 quantization_loss:  0.011028836481273174
p mean is: tensor(-1.1749, device='cuda:1')
epoch:  35000 quantization_loss:  0.01088301744312048
p mean is: tensor(-1.2612, device='cuda:1')
epoch:  36000 quantization_loss:  0.010749651119112968
p mean is: tensor(-1.3418, device='cuda:1')
epoch:  37000 quantization_loss:  0.010556133463978767
p mean is: tensor(-1.4166, device='cuda:1')
epoch:  38000 quantization_loss:  0.010391045361757278
p mean is: tensor(-1.4858, device='cuda:1')
epoch:  39000 quantization_loss:  0.010402670130133629
p mean is: tensor(-1.5498, device='cuda:1')
epoch:  40000 quantization_loss:  0.010194533504545689
p mean is: tensor(-1.6091, device='cuda:1')
epoch:  41000 quantization_loss:  0.01033235527575016
p mean is: tensor(-1.6638, device='cuda:1')
epoch:  42000 quantization_loss:  0.010121261700987816
p mean is: tensor(-1.7144, device='cuda:1')
epoch:  43000 quantization_loss:  0.009945599362254143
p mean is: tensor(-1.7612, device='cuda:1')
epoch:  44000 quantization_loss:  0.009993108920753002
p mean is: tensor(-1.8044, device='cuda:1')
epoch:  45000 quantization_loss:  0.009884866885840893
p mean is: tensor(-1.8447, device='cuda:1')
epoch:  46000 quantization_loss:  0.009830310009419918
p mean is: tensor(-1.8822, device='cuda:1')
epoch:  47000 quantization_loss:  0.009809085167944431
p mean is: tensor(-1.9170, device='cuda:1')
epoch:  48000 quantization_loss:  0.009753991849720478
p mean is: tensor(-1.9493, device='cuda:1')
epoch:  49000 quantization_loss:  0.0097549082711339
p mean is: tensor(-1.9796, device='cuda:1')
epoch:  50000 quantization_loss:  0.009719020687043667
p mean is: tensor(-2.0078, device='cuda:1')
epoch:  51000 quantization_loss:  0.009613513946533203
p mean is: tensor(-2.0342, device='cuda:1')
epoch:  52000 quantization_loss:  0.009607826359570026
p mean is: tensor(-2.0590, device='cuda:1')
epoch:  53000 quantization_loss:  0.009579341858625412
p mean is: tensor(-2.0823, device='cuda:1')
epoch:  54000 quantization_loss:  0.009542452171444893
p mean is: tensor(-2.1041, device='cuda:1')
epoch:  55000 quantization_loss:  0.009532132185995579
p mean is: tensor(-2.1246, device='cuda:1')
epoch:  56000 quantization_loss:  0.009461643174290657
p mean is: tensor(-2.1438, device='cuda:1')
epoch:  57000 quantization_loss:  0.009501030668616295
p mean is: tensor(-2.1621, device='cuda:1')
epoch:  58000 quantization_loss:  0.009463409893214703
p mean is: tensor(-2.1793, device='cuda:1')
epoch:  59000 quantization_loss:  0.009418124333024025
p mean is: tensor(-2.1956, device='cuda:1')
Number of elements to keep: 153030
Threshold value: -0.5937293767929077
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.06899984714795672
Number of elements to keep: 153030
Threshold value: -0.5937293767929077
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.06899984714795672
1.0.1.1.weight       | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =   15529 /   36864             ( 42.13%) | total_pruned =   21335 | shape = torch.Size([128, 32, 3, 3])
1.1.1.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.2.weight         | nonzeros =     112 /     128             ( 87.50%) | total_pruned =      16 | shape = torch.Size([128])
1.1.2.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.4.1.weight       | nonzeros =   37730 /  147456             ( 25.59%) | total_pruned =  109726 | shape = torch.Size([128, 128, 3, 3])
1.1.4.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.5.weight         | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
1.1.5.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.0.1.1.weight | nonzeros =     170 /     512             ( 33.20%) | total_pruned =     342 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =   20185 /  147456             ( 13.69%) | total_pruned =  127271 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.2.weight   | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
1.1.7.1.1.2.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.4.1.weight | nonzeros =   12505 /  147456             (  8.48%) | total_pruned =  134951 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.5.weight   | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.1.7.1.1.5.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     130 /     512             ( 25.39%) | total_pruned =     382 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    3639 /  147456             (  2.47%) | total_pruned =  143817 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    2859 /  147456             (  1.94%) | total_pruned =  144597 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     143 /     512             ( 27.93%) | total_pruned =     369 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =     351 /  147456             (  0.24%) | total_pruned =  147105 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =     858 /  147456             (  0.58%) | total_pruned =  146598 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      46 /     512             (  8.98%) | total_pruned =     466 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    1551 /  147456             (  1.05%) | total_pruned =  145905 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    2826 /  147456             (  1.92%) | total_pruned =  144630 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      72 /     132             ( 54.55%) | total_pruned =      60 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =    3369 /  152064             (  2.22%) | total_pruned =  148695 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =     899 /   16384             (  5.49%) | total_pruned =   15485 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      44 /     132             ( 33.33%) | total_pruned =      88 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =    4250 /  152064             (  2.79%) | total_pruned =  147814 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =     882 /   16384             (  5.38%) | total_pruned =   15502 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      31 /     128             ( 24.22%) | total_pruned =      97 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      30 /     132             ( 22.73%) | total_pruned =     102 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =    6994 /  152064             (  4.60%) | total_pruned =  145070 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.4.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.6.1.weight | nonzeros =    1399 /   16384             (  8.54%) | total_pruned =   14985 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.7.weight | nonzeros =      34 /     128             ( 26.56%) | total_pruned =      94 | shape = torch.Size([128])
1.1.7.1.1.7.7.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.2.weight       | nonzeros =      35 /     132             ( 26.52%) | total_pruned =      97 | shape = torch.Size([132])
1.1.7.2.bias         | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.3.1.weight     | nonzeros =   10920 /  152064             (  7.18%) | total_pruned =  141144 | shape = torch.Size([128, 132, 3, 3])
1.1.7.3.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.4.weight       | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.1.7.4.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.6.1.weight     | nonzeros =    2436 /   16384             ( 14.87%) | total_pruned =   13948 | shape = torch.Size([128, 128, 1, 1])
1.1.7.6.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.7.weight       | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
1.1.7.7.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
2.weight             | nonzeros =      58 /     132             ( 43.94%) | total_pruned =      74 | shape = torch.Size([132])
2.bias               | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
3.1.weight           | nonzeros =   16946 /  152064             ( 11.14%) | total_pruned =  135118 | shape = torch.Size([128, 132, 3, 3])
3.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
4.weight             | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
6.1.weight           | nonzeros =    4357 /   16384             ( 26.59%) | total_pruned =   12027 | shape = torch.Size([128, 128, 1, 1])
6.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
7.weight             | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
7.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =     187 /     384             ( 48.70%) | total_pruned =     197 | shape = torch.Size([3, 128, 1, 1])
9.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 153030, pruned : 2064801, total: 2217831, Compression rate :      14.49x  ( 93.10% pruned)
(3, 256, 256) (3, 256, 256) (3, 256, 256)
PSNR of output image is:  28.858769563560458
Experiment done
