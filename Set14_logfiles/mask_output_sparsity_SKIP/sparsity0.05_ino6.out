(3, 512, 512)
Noisy PSNR is '20.134796191316706'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/6/sparsity_skip/det/0.05/1e-09
(3, 512, 512)
Noisy PSNR is '20.134857581939475'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/6/sparsity_skip/det/0.05/1e-09
epoch:  0 quantization_loss:  0.06264925748109818
p mean is: tensor(-0.0005, device='cuda:6')
epoch:  1000 quantization_loss:  0.04472608119249344
p mean is: tensor(-0.0227, device='cuda:6')
epoch:  2000 quantization_loss:  0.04320792108774185
p mean is: tensor(-0.0414, device='cuda:6')
epoch:  3000 quantization_loss:  0.04295004904270172
p mean is: tensor(-0.0600, device='cuda:6')
epoch:  4000 quantization_loss:  0.042547035962343216
p mean is: tensor(-0.0789, device='cuda:6')
epoch:  5000 quantization_loss:  0.042276155203580856
p mean is: tensor(-0.0985, device='cuda:6')
epoch:  6000 quantization_loss:  0.04210888594388962
p mean is: tensor(-0.1182, device='cuda:6')
epoch:  7000 quantization_loss:  0.04241932928562164
p mean is: tensor(-0.1383, device='cuda:6')
epoch:  8000 quantization_loss:  0.04224688559770584
p mean is: tensor(-0.1595, device='cuda:6')
epoch:  9000 quantization_loss:  0.04216843470931053
p mean is: tensor(-0.1811, device='cuda:6')
epoch:  10000 quantization_loss:  0.04178978502750397
p mean is: tensor(-0.2033, device='cuda:6')
epoch:  11000 quantization_loss:  0.04193224385380745
p mean is: tensor(-0.2261, device='cuda:6')
epoch:  12000 quantization_loss:  0.04193282127380371
p mean is: tensor(-0.2500, device='cuda:6')
epoch:  13000 quantization_loss:  0.042181648313999176
p mean is: tensor(-0.2748, device='cuda:6')
epoch:  14000 quantization_loss:  0.0418454073369503
p mean is: tensor(-0.3006, device='cuda:6')
epoch:  15000 quantization_loss:  0.04182513430714607
p mean is: tensor(-0.3278, device='cuda:6')
epoch:  16000 quantization_loss:  0.04171089082956314
p mean is: tensor(-0.3563, device='cuda:6')
epoch:  17000 quantization_loss:  0.04164255037903786
p mean is: tensor(-0.3865, device='cuda:6')
epoch:  18000 quantization_loss:  0.04144284874200821
p mean is: tensor(-0.4181, device='cuda:6')
epoch:  19000 quantization_loss:  0.041574470698833466
p mean is: tensor(-0.4510, device='cuda:6')
epoch:  20000 quantization_loss:  0.04152088239789009
p mean is: tensor(-0.4856, device='cuda:6')
epoch:  21000 quantization_loss:  0.04146678000688553
p mean is: tensor(-0.5212, device='cuda:6')
epoch:  22000 quantization_loss:  0.04145005717873573
p mean is: tensor(-0.5584, device='cuda:6')
epoch:  23000 quantization_loss:  0.04162946343421936
p mean is: tensor(-0.5963, device='cuda:6')
epoch:  24000 quantization_loss:  0.041295375674963
p mean is: tensor(-0.6350, device='cuda:6')
epoch:  25000 quantization_loss:  0.04128733277320862
p mean is: tensor(-0.6738, device='cuda:6')
epoch:  26000 quantization_loss:  0.04144156351685524
p mean is: tensor(-0.7121, device='cuda:6')
epoch:  27000 quantization_loss:  0.04109056293964386
p mean is: tensor(-0.7504, device='cuda:6')
epoch:  28000 quantization_loss:  0.040959957987070084
p mean is: tensor(-0.7878, device='cuda:6')
epoch:  29000 quantization_loss:  0.03629789501428604
p mean is: tensor(-0.8188, device='cuda:6')
epoch:  30000 quantization_loss:  0.0330069363117218
p mean is: tensor(-0.8484, device='cuda:6')
epoch:  31000 quantization_loss:  0.030572928488254547
p mean is: tensor(-0.8837, device='cuda:6')
epoch:  32000 quantization_loss:  0.027488213032484055
p mean is: tensor(-0.9248, device='cuda:6')
epoch:  33000 quantization_loss:  0.02369770221412182
p mean is: tensor(-0.9705, device='cuda:6')
epoch:  34000 quantization_loss:  0.021352048963308334
p mean is: tensor(-1.0210, device='cuda:6')
epoch:  35000 quantization_loss:  0.018867049366235733
p mean is: tensor(-1.0769, device='cuda:6')
epoch:  36000 quantization_loss:  0.01798401027917862
p mean is: tensor(-1.1380, device='cuda:6')
epoch:  37000 quantization_loss:  0.016853399574756622
p mean is: tensor(-1.2035, device='cuda:6')
epoch:  38000 quantization_loss:  0.016099901869893074
p mean is: tensor(-1.2723, device='cuda:6')
epoch:  39000 quantization_loss:  0.015570872463285923
p mean is: tensor(-1.3427, device='cuda:6')
epoch:  40000 quantization_loss:  0.015067698433995247
p mean is: tensor(-1.4138, device='cuda:6')
epoch:  41000 quantization_loss:  0.014488090761005878
p mean is: tensor(-1.4840, device='cuda:6')
epoch:  42000 quantization_loss:  0.014116428792476654
p mean is: tensor(-1.5522, device='cuda:6')
epoch:  43000 quantization_loss:  0.014036632142961025
p mean is: tensor(-1.6176, device='cuda:6')
epoch:  44000 quantization_loss:  0.013770991005003452
p mean is: tensor(-1.6796, device='cuda:6')
epoch:  45000 quantization_loss:  0.013463982380926609
p mean is: tensor(-1.7380, device='cuda:6')
epoch:  46000 quantization_loss:  0.013282381929457188
p mean is: tensor(-1.7925, device='cuda:6')
epoch:  47000 quantization_loss:  0.013139183633029461
p mean is: tensor(-1.8435, device='cuda:6')
epoch:  48000 quantization_loss:  0.012961121276021004
p mean is: tensor(-1.8914, device='cuda:6')
epoch:  49000 quantization_loss:  0.012842422351241112
p mean is: tensor(-1.9363, device='cuda:6')
epoch:  50000 quantization_loss:  0.01277040783315897
p mean is: tensor(-1.9780, device='cuda:6')
epoch:  51000 quantization_loss:  0.012812639586627483
p mean is: tensor(-2.0170, device='cuda:6')
epoch:  52000 quantization_loss:  0.012490766122937202
p mean is: tensor(-2.0536, device='cuda:6')
epoch:  53000 quantization_loss:  0.012532916851341724
p mean is: tensor(-2.0879, device='cuda:6')
epoch:  54000 quantization_loss:  0.012387600727379322
p mean is: tensor(-2.1201, device='cuda:6')
epoch:  55000 quantization_loss:  0.01235117856413126
p mean is: tensor(-2.1502, device='cuda:6')
epoch:  56000 quantization_loss:  0.012285955250263214
p mean is: tensor(-2.1786, device='cuda:6')
epoch:  57000 quantization_loss:  0.012255722656846046
p mean is: tensor(-2.2055, device='cuda:6')
epoch:  58000 quantization_loss:  0.012219585478305817
p mean is: tensor(-2.2309, device='cuda:6')
epoch:  59000 quantization_loss:  0.012110697105526924
p mean is: tensor(-2.2549, device='cuda:6')
Number of elements to keep: 110891
Threshold value: 2.891634702682495
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999975200995928
Number of elements to keep: 110891
Threshold value: 2.891634702682495
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999975200995928
1.0.1.1.weight       | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =   12117 /   36864             ( 32.87%) | total_pruned =   24747 | shape = torch.Size([128, 32, 3, 3])
1.1.1.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.2.weight         | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.1.2.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.4.1.weight       | nonzeros =   28383 /  147456             ( 19.25%) | total_pruned =  119073 | shape = torch.Size([128, 128, 3, 3])
1.1.4.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.5.weight         | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.1.5.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.0.1.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =   21861 /  147456             ( 14.83%) | total_pruned =  125595 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.2.weight   | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.1.7.1.1.2.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.4.1.weight | nonzeros =   12812 /  147456             (  8.69%) | total_pruned =  134644 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.5.weight   | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.1.7.1.1.5.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     104 /     512             ( 20.31%) | total_pruned =     408 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    2398 /  147456             (  1.63%) | total_pruned =  145058 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    1482 /  147456             (  1.01%) | total_pruned =  145974 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      75 /     512             ( 14.65%) | total_pruned =     437 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =     322 /  147456             (  0.22%) | total_pruned =  147134 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =     575 /  147456             (  0.39%) | total_pruned =  146881 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      75 /     512             ( 14.65%) | total_pruned =     437 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =     831 /  147456             (  0.56%) | total_pruned =  146625 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    2019 /  147456             (  1.37%) | total_pruned =  145437 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      67 /     132             ( 50.76%) | total_pruned =      65 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =    1727 /  152064             (  1.14%) | total_pruned =  150337 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =     710 /   16384             (  4.33%) | total_pruned =   15674 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      39 /     132             ( 29.55%) | total_pruned =      93 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =    2228 /  152064             (  1.47%) | total_pruned =  149836 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =     762 /   16384             (  4.65%) | total_pruned =   15622 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      27 /     128             ( 21.09%) | total_pruned =     101 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      32 /     132             ( 24.24%) | total_pruned =     100 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =    2956 /  152064             (  1.94%) | total_pruned =  149108 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.4.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.6.1.weight | nonzeros =    1640 /   16384             ( 10.01%) | total_pruned =   14744 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.7.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.1.7.1.1.7.7.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.2.weight       | nonzeros =      67 /     132             ( 50.76%) | total_pruned =      65 | shape = torch.Size([132])
1.1.7.2.bias         | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.3.1.weight     | nonzeros =    4607 /  152064             (  3.03%) | total_pruned =  147457 | shape = torch.Size([128, 132, 3, 3])
1.1.7.3.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.4.weight       | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.1.7.4.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.6.1.weight     | nonzeros =    1225 /   16384             (  7.48%) | total_pruned =   15159 | shape = torch.Size([128, 128, 1, 1])
1.1.7.6.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.7.weight       | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
1.1.7.7.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
2.weight             | nonzeros =      49 /     132             ( 37.12%) | total_pruned =      83 | shape = torch.Size([132])
2.bias               | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
3.1.weight           | nonzeros =    6050 /  152064             (  3.98%) | total_pruned =  146014 | shape = torch.Size([128, 132, 3, 3])
3.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
4.weight             | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
6.1.weight           | nonzeros =    3944 /   16384             ( 24.07%) | total_pruned =   12440 | shape = torch.Size([128, 128, 1, 1])
6.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
7.weight             | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
7.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =     168 /     384             ( 43.75%) | total_pruned =     216 | shape = torch.Size([3, 128, 1, 1])
9.1.bias             | nonzeros =       3 /       3             (100.00%) | total_pruned =       0 | shape = torch.Size([3])
alive: 110891, pruned : 2106940, total: 2217831, Compression rate :      20.00x  ( 95.00% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  22.473453011763223
Experiment done
