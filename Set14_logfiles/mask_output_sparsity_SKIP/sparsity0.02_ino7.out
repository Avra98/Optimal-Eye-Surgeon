(3, 512, 512)
Noisy PSNR is '20.296710781948796'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/7/sparsity_skip/det/0.02/1e-09
epoch:  0 quantization_loss:  0.08075001090765
p mean is: tensor(-0.0006, device='cuda:0')
epoch:  1000 quantization_loss:  0.06685394793748856
p mean is: tensor(-0.0218, device='cuda:0')
epoch:  2000 quantization_loss:  0.06706660985946655
p mean is: tensor(-0.0376, device='cuda:0')
epoch:  3000 quantization_loss:  0.0669063851237297
p mean is: tensor(-0.0529, device='cuda:0')
epoch:  4000 quantization_loss:  0.06628189980983734
p mean is: tensor(-0.0681, device='cuda:0')
epoch:  5000 quantization_loss:  0.06638317555189133
p mean is: tensor(-0.0833, device='cuda:0')
epoch:  6000 quantization_loss:  0.06609737128019333
p mean is: tensor(-0.0984, device='cuda:0')
epoch:  7000 quantization_loss:  0.06597143411636353
p mean is: tensor(-0.1132, device='cuda:0')
epoch:  8000 quantization_loss:  0.06635177880525589
p mean is: tensor(-0.1286, device='cuda:0')
epoch:  9000 quantization_loss:  0.06541460007429123
p mean is: tensor(-0.1441, device='cuda:0')
epoch:  10000 quantization_loss:  0.06584151089191437
p mean is: tensor(-0.1598, device='cuda:0')
epoch:  11000 quantization_loss:  0.06602068990468979
p mean is: tensor(-0.1757, device='cuda:0')
epoch:  12000 quantization_loss:  0.06597781926393509
p mean is: tensor(-0.1921, device='cuda:0')
epoch:  13000 quantization_loss:  0.061220381408929825
p mean is: tensor(-0.2083, device='cuda:0')
epoch:  14000 quantization_loss:  0.056052468717098236
p mean is: tensor(-0.2244, device='cuda:0')
epoch:  15000 quantization_loss:  0.04900922626256943
p mean is: tensor(-0.2438, device='cuda:0')
epoch:  16000 quantization_loss:  0.03897220641374588
p mean is: tensor(-0.2675, device='cuda:0')
epoch:  17000 quantization_loss:  0.03564395383000374
p mean is: tensor(-0.2960, device='cuda:0')
epoch:  18000 quantization_loss:  0.032582420855760574
p mean is: tensor(-0.3311, device='cuda:0')
epoch:  19000 quantization_loss:  0.0306073147803545
p mean is: tensor(-0.3739, device='cuda:0')
epoch:  20000 quantization_loss:  0.028874851763248444
p mean is: tensor(-0.4253, device='cuda:0')
epoch:  21000 quantization_loss:  0.027663569897413254
p mean is: tensor(-0.4867, device='cuda:0')
epoch:  22000 quantization_loss:  0.026727447286248207
p mean is: tensor(-0.5588, device='cuda:0')
epoch:  23000 quantization_loss:  0.025910157710313797
p mean is: tensor(-0.6407, device='cuda:0')
epoch:  24000 quantization_loss:  0.024729015305638313
p mean is: tensor(-0.7313, device='cuda:0')
epoch:  25000 quantization_loss:  0.023822631686925888
p mean is: tensor(-0.8288, device='cuda:0')
epoch:  26000 quantization_loss:  0.023068619892001152
p mean is: tensor(-0.9308, device='cuda:0')
epoch:  27000 quantization_loss:  0.02255350910127163
p mean is: tensor(-1.0355, device='cuda:0')
epoch:  28000 quantization_loss:  0.02199489064514637
p mean is: tensor(-1.1404, device='cuda:0')
epoch:  29000 quantization_loss:  0.021753830835223198
p mean is: tensor(-1.2436, device='cuda:0')
epoch:  30000 quantization_loss:  0.021146260201931
p mean is: tensor(-1.3428, device='cuda:0')
epoch:  31000 quantization_loss:  0.020809225738048553
p mean is: tensor(-1.4380, device='cuda:0')
epoch:  32000 quantization_loss:  0.020552905276417732
p mean is: tensor(-1.5287, device='cuda:0')
epoch:  33000 quantization_loss:  0.020299799740314484
p mean is: tensor(-1.6144, device='cuda:0')
epoch:  34000 quantization_loss:  0.01999899186193943
p mean is: tensor(-1.6951, device='cuda:0')
epoch:  35000 quantization_loss:  0.019726168364286423
p mean is: tensor(-1.7708, device='cuda:0')
epoch:  36000 quantization_loss:  0.019654888659715652
p mean is: tensor(-1.8418, device='cuda:0')
epoch:  37000 quantization_loss:  0.01931849867105484
p mean is: tensor(-1.9087, device='cuda:0')
epoch:  38000 quantization_loss:  0.019039185717701912
p mean is: tensor(-1.9716, device='cuda:0')
epoch:  39000 quantization_loss:  0.018974952399730682
p mean is: tensor(-2.0309, device='cuda:0')
epoch:  40000 quantization_loss:  0.01893228106200695
p mean is: tensor(-2.0866, device='cuda:0')
epoch:  41000 quantization_loss:  0.018682138994336128
p mean is: tensor(-2.1392, device='cuda:0')
epoch:  42000 quantization_loss:  0.018500616773962975
p mean is: tensor(-2.1890, device='cuda:0')
epoch:  43000 quantization_loss:  0.01837959885597229
p mean is: tensor(-2.2363, device='cuda:0')
epoch:  44000 quantization_loss:  0.018266994506120682
p mean is: tensor(-2.2814, device='cuda:0')
epoch:  45000 quantization_loss:  0.01816398836672306
p mean is: tensor(-2.3239, device='cuda:0')
epoch:  46000 quantization_loss:  0.017990002408623695
p mean is: tensor(-2.3642, device='cuda:0')
epoch:  47000 quantization_loss:  0.017987972125411034
p mean is: tensor(-2.4027, device='cuda:0')
epoch:  48000 quantization_loss:  0.01785668171942234
p mean is: tensor(-2.4395, device='cuda:0')
epoch:  49000 quantization_loss:  0.01796862483024597
p mean is: tensor(-2.4746, device='cuda:0')
epoch:  50000 quantization_loss:  0.017609888687729836
p mean is: tensor(-2.5083, device='cuda:0')
epoch:  51000 quantization_loss:  0.01768019236624241
p mean is: tensor(-2.5407, device='cuda:0')
epoch:  52000 quantization_loss:  0.017543263733386993
p mean is: tensor(-2.5715, device='cuda:0')
epoch:  53000 quantization_loss:  0.0174256581813097
p mean is: tensor(-2.6013, device='cuda:0')
epoch:  54000 quantization_loss:  0.017399633303284645
p mean is: tensor(-2.6298, device='cuda:0')
epoch:  55000 quantization_loss:  0.017316380515694618
p mean is: tensor(-2.6570, device='cuda:0')
epoch:  56000 quantization_loss:  0.01727328449487686
p mean is: tensor(-2.6834, device='cuda:0')
epoch:  57000 quantization_loss:  0.017178909853100777
p mean is: tensor(-2.7088, device='cuda:0')
epoch:  58000 quantization_loss:  0.017159078270196915
p mean is: tensor(-2.7332, device='cuda:0')
epoch:  59000 quantization_loss:  0.017139079049229622
p mean is: tensor(-2.7566, device='cuda:0')
Number of elements to keep: 44356
Threshold value: 6.231019020080566
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.01999972044759046
Number of elements to keep: 44356
Threshold value: 6.231019020080566
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.01999972044759046
1.0.1.1.weight       | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =   11646 /   36864             ( 31.59%) | total_pruned =   25218 | shape = torch.Size([128, 32, 3, 3])
1.1.1.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.2.weight         | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.1.2.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.4.1.weight       | nonzeros =   21911 /  147456             ( 14.86%) | total_pruned =  125545 | shape = torch.Size([128, 128, 3, 3])
1.1.4.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.5.weight         | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
1.1.5.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.0.1.1.weight | nonzeros =     171 /     512             ( 33.40%) | total_pruned =     341 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =    3197 /  147456             (  2.17%) | total_pruned =  144259 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.2.weight   | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.1.7.1.1.2.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.4.1.weight | nonzeros =     992 /  147456             (  0.67%) | total_pruned =  146464 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.5.weight   | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.1.7.1.1.5.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      97 /     512             ( 18.95%) | total_pruned =     415 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =       2 /  147456             (  0.00%) | total_pruned =  147454 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =       4 /  147456             (  0.00%) | total_pruned =  147452 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      63 /     512             ( 12.30%) | total_pruned =     449 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =       4 /  147456             (  0.00%) | total_pruned =  147452 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =      37 /  147456             (  0.03%) | total_pruned =  147419 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      77 /     132             ( 58.33%) | total_pruned =      55 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =      29 /  152064             (  0.02%) | total_pruned =  152035 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =     176 /   16384             (  1.07%) | total_pruned =   16208 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      57 /     132             ( 43.18%) | total_pruned =      75 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =     254 /  152064             (  0.17%) | total_pruned =  151810 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =     210 /   16384             (  1.28%) | total_pruned =   16174 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      50 /     132             ( 37.88%) | total_pruned =      82 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =     686 /  152064             (  0.45%) | total_pruned =  151378 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.4.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.6.1.weight | nonzeros =     352 /   16384             (  2.15%) | total_pruned =   16032 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.7.weight | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
1.1.7.1.1.7.7.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.2.weight       | nonzeros =      53 /     132             ( 40.15%) | total_pruned =      79 | shape = torch.Size([132])
1.1.7.2.bias         | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.3.1.weight     | nonzeros =    1340 /  152064             (  0.88%) | total_pruned =  150724 | shape = torch.Size([128, 132, 3, 3])
1.1.7.3.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.4.weight       | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
1.1.7.4.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.6.1.weight     | nonzeros =     412 /   16384             (  2.51%) | total_pruned =   15972 | shape = torch.Size([128, 128, 1, 1])
1.1.7.6.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.7.weight       | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
1.1.7.7.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
2.weight             | nonzeros =      77 /     132             ( 58.33%) | total_pruned =      55 | shape = torch.Size([132])
2.bias               | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
3.1.weight           | nonzeros =     184 /  152064             (  0.12%) | total_pruned =  151880 | shape = torch.Size([128, 132, 3, 3])
3.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
4.weight             | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
6.1.weight           | nonzeros =     531 /   16384             (  3.24%) | total_pruned =   15853 | shape = torch.Size([128, 128, 1, 1])
6.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
7.weight             | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
7.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =     174 /     384             ( 45.31%) | total_pruned =     210 | shape = torch.Size([3, 128, 1, 1])
9.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 44356, pruned : 2173475, total: 2217831, Compression rate :      50.00x  ( 98.00% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  12.495326133249643
Experiment done
