(3, 512, 512)
Noisy PSNR is '20.176620904747452'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/10/sparsity_skip/det/0.069/1e-09
(3, 512, 512)
Noisy PSNR is '20.171166480623583'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/10/sparsity_skip/det/0.069/1e-09
epoch:  0 quantization_loss:  0.05875546857714653
p mean is: tensor(-0.0004, device='cuda:3')
epoch:  1000 quantization_loss:  0.056873954832553864
p mean is: tensor(-0.0160, device='cuda:3')
epoch:  2000 quantization_loss:  0.05723530054092407
p mean is: tensor(-0.0290, device='cuda:3')
epoch:  3000 quantization_loss:  0.05652174726128578
p mean is: tensor(-0.0425, device='cuda:3')
epoch:  4000 quantization_loss:  0.05685502663254738
p mean is: tensor(-0.0559, device='cuda:3')
epoch:  5000 quantization_loss:  0.056392282247543335
p mean is: tensor(-0.0693, device='cuda:3')
epoch:  6000 quantization_loss:  0.05588925629854202
p mean is: tensor(-0.0826, device='cuda:3')
epoch:  7000 quantization_loss:  0.05637006834149361
p mean is: tensor(-0.0959, device='cuda:3')
epoch:  8000 quantization_loss:  0.055269766598939896
p mean is: tensor(-0.1095, device='cuda:3')
epoch:  9000 quantization_loss:  0.05611617490649223
p mean is: tensor(-0.1239, device='cuda:3')
epoch:  10000 quantization_loss:  0.055891845375299454
p mean is: tensor(-0.1381, device='cuda:3')
epoch:  11000 quantization_loss:  0.05638568475842476
p mean is: tensor(-0.1524, device='cuda:3')
epoch:  12000 quantization_loss:  0.0557234063744545
p mean is: tensor(-0.1673, device='cuda:3')
epoch:  13000 quantization_loss:  0.055244456976652145
p mean is: tensor(-0.1821, device='cuda:3')
epoch:  14000 quantization_loss:  0.05449775606393814
p mean is: tensor(-0.1967, device='cuda:3')
epoch:  15000 quantization_loss:  0.03739302605390549
p mean is: tensor(-0.2110, device='cuda:3')
epoch:  16000 quantization_loss:  0.03127997741103172
p mean is: tensor(-0.2277, device='cuda:3')
epoch:  17000 quantization_loss:  0.028165360912680626
p mean is: tensor(-0.2495, device='cuda:3')
epoch:  18000 quantization_loss:  0.02671969309449196
p mean is: tensor(-0.2783, device='cuda:3')
epoch:  19000 quantization_loss:  0.025587501004338264
p mean is: tensor(-0.3156, device='cuda:3')
epoch:  20000 quantization_loss:  0.023869449272751808
p mean is: tensor(-0.3629, device='cuda:3')
epoch:  21000 quantization_loss:  0.022253602743148804
p mean is: tensor(-0.4207, device='cuda:3')
epoch:  22000 quantization_loss:  0.020848678424954414
p mean is: tensor(-0.4891, device='cuda:3')
epoch:  23000 quantization_loss:  0.020063631236553192
p mean is: tensor(-0.5672, device='cuda:3')
epoch:  24000 quantization_loss:  0.01911098137497902
p mean is: tensor(-0.6531, device='cuda:3')
epoch:  25000 quantization_loss:  0.01841968297958374
p mean is: tensor(-0.7441, device='cuda:3')
epoch:  26000 quantization_loss:  0.0178634375333786
p mean is: tensor(-0.8380, device='cuda:3')
epoch:  27000 quantization_loss:  0.017249755561351776
p mean is: tensor(-0.9317, device='cuda:3')
epoch:  28000 quantization_loss:  0.016965746879577637
p mean is: tensor(-1.0229, device='cuda:3')
epoch:  29000 quantization_loss:  0.016514314338564873
p mean is: tensor(-1.1101, device='cuda:3')
epoch:  30000 quantization_loss:  0.01635614037513733
p mean is: tensor(-1.1927, device='cuda:3')
epoch:  31000 quantization_loss:  0.01586008258163929
p mean is: tensor(-1.2702, device='cuda:3')
epoch:  32000 quantization_loss:  0.0157240591943264
p mean is: tensor(-1.3426, device='cuda:3')
epoch:  33000 quantization_loss:  0.015392836183309555
p mean is: tensor(-1.4102, device='cuda:3')
epoch:  34000 quantization_loss:  0.015284701250493526
p mean is: tensor(-1.4733, device='cuda:3')
epoch:  35000 quantization_loss:  0.015050319954752922
p mean is: tensor(-1.5316, device='cuda:3')
epoch:  36000 quantization_loss:  0.014772034250199795
p mean is: tensor(-1.5855, device='cuda:3')
epoch:  37000 quantization_loss:  0.014686010777950287
p mean is: tensor(-1.6356, device='cuda:3')
epoch:  38000 quantization_loss:  0.014635593630373478
p mean is: tensor(-1.6822, device='cuda:3')
epoch:  39000 quantization_loss:  0.01435337495058775
p mean is: tensor(-1.7256, device='cuda:3')
epoch:  40000 quantization_loss:  0.014499306678771973
p mean is: tensor(-1.7662, device='cuda:3')
epoch:  41000 quantization_loss:  0.014212070032954216
p mean is: tensor(-1.8039, device='cuda:3')
epoch:  42000 quantization_loss:  0.0141217689961195
p mean is: tensor(-1.8391, device='cuda:3')
epoch:  43000 quantization_loss:  0.014119677245616913
p mean is: tensor(-1.8717, device='cuda:3')
epoch:  44000 quantization_loss:  0.014002795331180096
p mean is: tensor(-1.9022, device='cuda:3')
epoch:  45000 quantization_loss:  0.013915129005908966
p mean is: tensor(-1.9306, device='cuda:3')
epoch:  46000 quantization_loss:  0.013956415466964245
p mean is: tensor(-1.9572, device='cuda:3')
epoch:  47000 quantization_loss:  0.013836844824254513
p mean is: tensor(-1.9821, device='cuda:3')
epoch:  48000 quantization_loss:  0.01387827005237341
p mean is: tensor(-2.0055, device='cuda:3')
epoch:  49000 quantization_loss:  0.013802662491798401
p mean is: tensor(-2.0273, device='cuda:3')
epoch:  50000 quantization_loss:  0.013807384297251701
p mean is: tensor(-2.0477, device='cuda:3')
epoch:  51000 quantization_loss:  0.01376990508288145
p mean is: tensor(-2.0669, device='cuda:3')
epoch:  52000 quantization_loss:  0.013694682158529758
p mean is: tensor(-2.0849, device='cuda:3')
epoch:  53000 quantization_loss:  0.013622264377772808
p mean is: tensor(-2.1019, device='cuda:3')
epoch:  54000 quantization_loss:  0.01359520759433508
p mean is: tensor(-2.1179, device='cuda:3')
epoch:  55000 quantization_loss:  0.013587277382612228
p mean is: tensor(-2.1329, device='cuda:3')
epoch:  56000 quantization_loss:  0.013638087548315525
p mean is: tensor(-2.1473, device='cuda:3')
epoch:  57000 quantization_loss:  0.013572130352258682
p mean is: tensor(-2.1608, device='cuda:3')
epoch:  58000 quantization_loss:  0.013514109887182713
p mean is: tensor(-2.1735, device='cuda:3')
epoch:  59000 quantization_loss:  0.013489545322954655
p mean is: tensor(-2.1858, device='cuda:3')
Number of elements to keep: 153030
Threshold value: 0.9869469404220581
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.06899984714795672
Number of elements to keep: 153030
Threshold value: 0.9869469404220581
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.06899984714795672
1.0.1.1.weight       | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =   15639 /   36864             ( 42.42%) | total_pruned =   21225 | shape = torch.Size([128, 32, 3, 3])
1.1.1.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.2.weight         | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
1.1.2.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.4.1.weight       | nonzeros =   40349 /  147456             ( 27.36%) | total_pruned =  107107 | shape = torch.Size([128, 128, 3, 3])
1.1.4.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.5.weight         | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.1.5.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.0.1.1.weight | nonzeros =     163 /     512             ( 31.84%) | total_pruned =     349 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =   30401 /  147456             ( 20.62%) | total_pruned =  117055 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.2.weight   | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.1.7.1.1.2.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.4.1.weight | nonzeros =   19550 /  147456             ( 13.26%) | total_pruned =  127906 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.5.weight   | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.1.7.1.1.5.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     152 /     512             ( 29.69%) | total_pruned =     360 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    2958 /  147456             (  2.01%) | total_pruned =  144498 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    1904 /  147456             (  1.29%) | total_pruned =  145552 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     145 /     512             ( 28.32%) | total_pruned =     367 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =     193 /  147456             (  0.13%) | total_pruned =  147263 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =     574 /  147456             (  0.39%) | total_pruned =  146882 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      97 /     512             ( 18.95%) | total_pruned =     415 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =     800 /  147456             (  0.54%) | total_pruned =  146656 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    2118 /  147456             (  1.44%) | total_pruned =  145338 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      58 /     132             ( 43.94%) | total_pruned =      74 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =    1984 /  152064             (  1.30%) | total_pruned =  150080 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =     628 /   16384             (  3.83%) | total_pruned =   15756 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      28 /     132             ( 21.21%) | total_pruned =     104 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =    3493 /  152064             (  2.30%) | total_pruned =  148571 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =     719 /   16384             (  4.39%) | total_pruned =   15665 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      23 /     132             ( 17.42%) | total_pruned =     109 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =    4996 /  152064             (  3.29%) | total_pruned =  147068 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.4.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.6.1.weight | nonzeros =    1604 /   16384             (  9.79%) | total_pruned =   14780 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.7.weight | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
1.1.7.1.1.7.7.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.2.weight       | nonzeros =      46 /     132             ( 34.85%) | total_pruned =      86 | shape = torch.Size([132])
1.1.7.2.bias         | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.3.1.weight     | nonzeros =    9793 /  152064             (  6.44%) | total_pruned =  142271 | shape = torch.Size([128, 132, 3, 3])
1.1.7.3.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.4.weight       | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.1.7.4.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.6.1.weight     | nonzeros =    2395 /   16384             ( 14.62%) | total_pruned =   13989 | shape = torch.Size([128, 128, 1, 1])
1.1.7.6.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.7.weight       | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.1.7.7.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
2.weight             | nonzeros =      76 /     132             ( 57.58%) | total_pruned =      56 | shape = torch.Size([132])
2.bias               | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
3.1.weight           | nonzeros =    8502 /  152064             (  5.59%) | total_pruned =  143562 | shape = torch.Size([128, 132, 3, 3])
3.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
4.weight             | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
6.1.weight           | nonzeros =    1879 /   16384             ( 11.47%) | total_pruned =   14505 | shape = torch.Size([128, 128, 1, 1])
6.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
7.weight             | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
7.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =     148 /     384             ( 38.54%) | total_pruned =     236 | shape = torch.Size([3, 128, 1, 1])
9.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 153030, pruned : 2064801, total: 2217831, Compression rate :      14.49x  ( 93.10% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  23.435190988223226
Experiment done
