(3, 256, 256)
Noisy PSNR is '20.180038804994517'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/9/sparsity_skip/det/0.05/1e-09
(3, 256, 256)
Noisy PSNR is '20.220993112544114'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/9/sparsity_skip/det/0.05/1e-09
epoch:  0 quantization_loss:  0.061455074697732925
p mean is: tensor(-0.0004, device='cuda:2')
epoch:  1000 quantization_loss:  0.05780380964279175
p mean is: tensor(-0.0115, device='cuda:2')
epoch:  2000 quantization_loss:  0.058118801563978195
p mean is: tensor(-0.0201, device='cuda:2')
epoch:  3000 quantization_loss:  0.056162722408771515
p mean is: tensor(-0.0289, device='cuda:2')
epoch:  4000 quantization_loss:  0.056545134633779526
p mean is: tensor(-0.0381, device='cuda:2')
epoch:  5000 quantization_loss:  0.05628836527466774
p mean is: tensor(-0.0474, device='cuda:2')
epoch:  6000 quantization_loss:  0.056944817304611206
p mean is: tensor(-0.0567, device='cuda:2')
epoch:  7000 quantization_loss:  0.05817282944917679
p mean is: tensor(-0.0663, device='cuda:2')
epoch:  8000 quantization_loss:  0.057246699929237366
p mean is: tensor(-0.0754, device='cuda:2')
epoch:  9000 quantization_loss:  0.05683121085166931
p mean is: tensor(-0.0847, device='cuda:2')
epoch:  10000 quantization_loss:  0.05519145354628563
p mean is: tensor(-0.0937, device='cuda:2')
epoch:  11000 quantization_loss:  0.049312394112348557
p mean is: tensor(-0.1014, device='cuda:2')
epoch:  12000 quantization_loss:  0.02952421084046364
p mean is: tensor(-0.1094, device='cuda:2')
epoch:  13000 quantization_loss:  0.023165525868535042
p mean is: tensor(-0.1187, device='cuda:2')
epoch:  14000 quantization_loss:  0.021831857040524483
p mean is: tensor(-0.1316, device='cuda:2')
epoch:  15000 quantization_loss:  0.02134719118475914
p mean is: tensor(-0.1490, device='cuda:2')
epoch:  16000 quantization_loss:  0.02012355625629425
p mean is: tensor(-0.1725, device='cuda:2')
epoch:  17000 quantization_loss:  0.019356172531843185
p mean is: tensor(-0.2038, device='cuda:2')
epoch:  18000 quantization_loss:  0.018093500286340714
p mean is: tensor(-0.2444, device='cuda:2')
epoch:  19000 quantization_loss:  0.01731959916651249
p mean is: tensor(-0.2968, device='cuda:2')
epoch:  20000 quantization_loss:  0.01684054546058178
p mean is: tensor(-0.3626, device='cuda:2')
epoch:  21000 quantization_loss:  0.01631098985671997
p mean is: tensor(-0.4432, device='cuda:2')
epoch:  22000 quantization_loss:  0.015488490462303162
p mean is: tensor(-0.5376, device='cuda:2')
epoch:  23000 quantization_loss:  0.014765591360628605
p mean is: tensor(-0.6428, device='cuda:2')
epoch:  24000 quantization_loss:  0.014386260882019997
p mean is: tensor(-0.7556, device='cuda:2')
epoch:  25000 quantization_loss:  0.013629203662276268
p mean is: tensor(-0.8727, device='cuda:2')
epoch:  26000 quantization_loss:  0.01318613812327385
p mean is: tensor(-0.9904, device='cuda:2')
epoch:  27000 quantization_loss:  0.012746560387313366
p mean is: tensor(-1.1051, device='cuda:2')
epoch:  28000 quantization_loss:  0.01246621459722519
p mean is: tensor(-1.2149, device='cuda:2')
epoch:  29000 quantization_loss:  0.012051645666360855
p mean is: tensor(-1.3177, device='cuda:2')
epoch:  30000 quantization_loss:  0.011866612359881401
p mean is: tensor(-1.4139, device='cuda:2')
epoch:  31000 quantization_loss:  0.011778556741774082
p mean is: tensor(-1.5027, device='cuda:2')
epoch:  32000 quantization_loss:  0.01142454519867897
p mean is: tensor(-1.5847, device='cuda:2')
epoch:  33000 quantization_loss:  0.011276472359895706
p mean is: tensor(-1.6599, device='cuda:2')
epoch:  34000 quantization_loss:  0.01115256268531084
p mean is: tensor(-1.7295, device='cuda:2')
epoch:  35000 quantization_loss:  0.011012373492121696
p mean is: tensor(-1.7936, device='cuda:2')
epoch:  36000 quantization_loss:  0.0109111238270998
p mean is: tensor(-1.8528, device='cuda:2')
epoch:  37000 quantization_loss:  0.010898066684603691
p mean is: tensor(-1.9076, device='cuda:2')
epoch:  38000 quantization_loss:  0.010853664018213749
p mean is: tensor(-1.9587, device='cuda:2')
epoch:  39000 quantization_loss:  0.010763436555862427
p mean is: tensor(-2.0063, device='cuda:2')
epoch:  40000 quantization_loss:  0.010655409656465054
p mean is: tensor(-2.0504, device='cuda:2')
epoch:  41000 quantization_loss:  0.01062611024826765
p mean is: tensor(-2.0916, device='cuda:2')
epoch:  42000 quantization_loss:  0.010579157620668411
p mean is: tensor(-2.1300, device='cuda:2')
epoch:  43000 quantization_loss:  0.010667964816093445
p mean is: tensor(-2.1659, device='cuda:2')
epoch:  44000 quantization_loss:  0.01052207313477993
p mean is: tensor(-2.1995, device='cuda:2')
epoch:  45000 quantization_loss:  0.010456845164299011
p mean is: tensor(-2.2309, device='cuda:2')
epoch:  46000 quantization_loss:  0.010431290604174137
p mean is: tensor(-2.2606, device='cuda:2')
epoch:  47000 quantization_loss:  0.010490968823432922
p mean is: tensor(-2.2885, device='cuda:2')
epoch:  48000 quantization_loss:  0.01039395947009325
p mean is: tensor(-2.3149, device='cuda:2')
epoch:  49000 quantization_loss:  0.010370154865086079
p mean is: tensor(-2.3398, device='cuda:2')
epoch:  50000 quantization_loss:  0.010360314510762691
p mean is: tensor(-2.3632, device='cuda:2')
epoch:  51000 quantization_loss:  0.010313105769455433
p mean is: tensor(-2.3853, device='cuda:2')
epoch:  52000 quantization_loss:  0.010325641371309757
p mean is: tensor(-2.4062, device='cuda:2')
epoch:  53000 quantization_loss:  0.010272528976202011
p mean is: tensor(-2.4261, device='cuda:2')
epoch:  54000 quantization_loss:  0.01026119478046894
p mean is: tensor(-2.4449, device='cuda:2')
epoch:  55000 quantization_loss:  0.010267401114106178
p mean is: tensor(-2.4630, device='cuda:2')
epoch:  56000 quantization_loss:  0.010227151215076447
p mean is: tensor(-2.4799, device='cuda:2')
epoch:  57000 quantization_loss:  0.010238531976938248
p mean is: tensor(-2.4961, device='cuda:2')
epoch:  58000 quantization_loss:  0.010188493877649307
p mean is: tensor(-2.5116, device='cuda:2')
epoch:  59000 quantization_loss:  0.010171491652727127
p mean is: tensor(-2.5265, device='cuda:2')
Number of elements to keep: 110891
Threshold value: 0.13372674584388733
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999975200995928
Number of elements to keep: 110891
Threshold value: 0.13372674584388733
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999975200995928
1.0.1.1.weight       | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =   14347 /   36864             ( 38.92%) | total_pruned =   22517 | shape = torch.Size([128, 32, 3, 3])
1.1.1.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.2.weight         | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
1.1.2.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.4.1.weight       | nonzeros =   35058 /  147456             ( 23.78%) | total_pruned =  112398 | shape = torch.Size([128, 128, 3, 3])
1.1.4.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.5.weight         | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
1.1.5.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.0.1.1.weight | nonzeros =     168 /     512             ( 32.81%) | total_pruned =     344 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =   13760 /  147456             (  9.33%) | total_pruned =  133696 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.2.weight   | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.1.7.1.1.2.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.4.1.weight | nonzeros =    7359 /  147456             (  4.99%) | total_pruned =  140097 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.5.weight   | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.1.7.1.1.5.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     148 /     512             ( 28.91%) | total_pruned =     364 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =     293 /  147456             (  0.20%) | total_pruned =  147163 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =     287 /  147456             (  0.19%) | total_pruned =  147169 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     117 /     512             ( 22.85%) | total_pruned =     395 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =      37 /  147456             (  0.03%) | total_pruned =  147419 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =     117 /  147456             (  0.08%) | total_pruned =  147339 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =     310 /  147456             (  0.21%) | total_pruned =  147146 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =     901 /  147456             (  0.61%) | total_pruned =  146555 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      58 /     132             ( 43.94%) | total_pruned =      74 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =    1389 /  152064             (  0.91%) | total_pruned =  150675 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =     697 /   16384             (  4.25%) | total_pruned =   15687 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      40 /     132             ( 30.30%) | total_pruned =      92 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =    1819 /  152064             (  1.20%) | total_pruned =  150245 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =     488 /   16384             (  2.98%) | total_pruned =   15896 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      21 /     132             ( 15.91%) | total_pruned =     111 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =    3656 /  152064             (  2.40%) | total_pruned =  148408 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.4.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.6.1.weight | nonzeros =    1308 /   16384             (  7.98%) | total_pruned =   15076 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.7.weight | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
1.1.7.1.1.7.7.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.2.weight       | nonzeros =      42 /     132             ( 31.82%) | total_pruned =      90 | shape = torch.Size([132])
1.1.7.2.bias         | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.3.1.weight     | nonzeros =    9099 /  152064             (  5.98%) | total_pruned =  142965 | shape = torch.Size([128, 132, 3, 3])
1.1.7.3.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.4.weight       | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.1.7.4.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.6.1.weight     | nonzeros =    2625 /   16384             ( 16.02%) | total_pruned =   13759 | shape = torch.Size([128, 128, 1, 1])
1.1.7.6.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.7.weight       | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.1.7.7.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
2.weight             | nonzeros =      74 /     132             ( 56.06%) | total_pruned =      58 | shape = torch.Size([132])
2.bias               | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
3.1.weight           | nonzeros =   13072 /  152064             (  8.60%) | total_pruned =  138992 | shape = torch.Size([128, 132, 3, 3])
3.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
4.weight             | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
6.1.weight           | nonzeros =    1966 /   16384             ( 12.00%) | total_pruned =   14418 | shape = torch.Size([128, 128, 1, 1])
6.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
7.weight             | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
7.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =     146 /     384             ( 38.02%) | total_pruned =     238 | shape = torch.Size([3, 128, 1, 1])
9.1.bias             | nonzeros =       3 /       3             (100.00%) | total_pruned =       0 | shape = torch.Size([3])
alive: 110891, pruned : 2106940, total: 2217831, Compression rate :      20.00x  ( 95.00% pruned)
(3, 256, 256) (3, 256, 256) (3, 256, 256)
PSNR of output image is:  27.719724040532828
Experiment done
