(3, 512, 512)
Noisy PSNR is '20.14079358040403'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/6/sparsity_skip/det/0.02/1e-09
epoch:  0 quantization_loss:  0.06434401124715805
p mean is: tensor(-0.0006, device='cuda:6')
epoch:  1000 quantization_loss:  0.04399777203798294
p mean is: tensor(-0.0286, device='cuda:6')
epoch:  2000 quantization_loss:  0.04401904344558716
p mean is: tensor(-0.0509, device='cuda:6')
epoch:  3000 quantization_loss:  0.043382469564676285
p mean is: tensor(-0.0735, device='cuda:6')
epoch:  4000 quantization_loss:  0.043569501489400864
p mean is: tensor(-0.0964, device='cuda:6')
epoch:  5000 quantization_loss:  0.04336706921458244
p mean is: tensor(-0.1197, device='cuda:6')
epoch:  6000 quantization_loss:  0.04334648698568344
p mean is: tensor(-0.1438, device='cuda:6')
epoch:  7000 quantization_loss:  0.043028395622968674
p mean is: tensor(-0.1682, device='cuda:6')
epoch:  8000 quantization_loss:  0.04275282099843025
p mean is: tensor(-0.1935, device='cuda:6')
epoch:  9000 quantization_loss:  0.04298611730337143
p mean is: tensor(-0.2195, device='cuda:6')
epoch:  10000 quantization_loss:  0.042876340448856354
p mean is: tensor(-0.2458, device='cuda:6')
epoch:  11000 quantization_loss:  0.04306180030107498
p mean is: tensor(-0.2734, device='cuda:6')
epoch:  12000 quantization_loss:  0.04254801571369171
p mean is: tensor(-0.3022, device='cuda:6')
epoch:  13000 quantization_loss:  0.0424688458442688
p mean is: tensor(-0.3326, device='cuda:6')
epoch:  14000 quantization_loss:  0.04250844568014145
p mean is: tensor(-0.3644, device='cuda:6')
epoch:  15000 quantization_loss:  0.042360711842775345
p mean is: tensor(-0.3979, device='cuda:6')
epoch:  16000 quantization_loss:  0.042251139879226685
p mean is: tensor(-0.4331, device='cuda:6')
epoch:  17000 quantization_loss:  0.042248718440532684
p mean is: tensor(-0.4697, device='cuda:6')
epoch:  18000 quantization_loss:  0.04227292165160179
p mean is: tensor(-0.5084, device='cuda:6')
epoch:  19000 quantization_loss:  0.04224887490272522
p mean is: tensor(-0.5488, device='cuda:6')
epoch:  20000 quantization_loss:  0.04222618043422699
p mean is: tensor(-0.5906, device='cuda:6')
epoch:  21000 quantization_loss:  0.04197152331471443
p mean is: tensor(-0.6336, device='cuda:6')
epoch:  22000 quantization_loss:  0.04196655750274658
p mean is: tensor(-0.6770, device='cuda:6')
epoch:  23000 quantization_loss:  0.041949763894081116
p mean is: tensor(-0.7207, device='cuda:6')
epoch:  24000 quantization_loss:  0.04180288314819336
p mean is: tensor(-0.7647, device='cuda:6')
epoch:  25000 quantization_loss:  0.042238615453243256
p mean is: tensor(-0.8091, device='cuda:6')
epoch:  26000 quantization_loss:  0.04188826307654381
p mean is: tensor(-0.8532, device='cuda:6')
epoch:  27000 quantization_loss:  0.04185910150408745
p mean is: tensor(-0.8969, device='cuda:6')
epoch:  28000 quantization_loss:  0.04167429730296135
p mean is: tensor(-0.9400, device='cuda:6')
epoch:  29000 quantization_loss:  0.0416254848241806
p mean is: tensor(-0.9822, device='cuda:6')
epoch:  30000 quantization_loss:  0.041595444083213806
p mean is: tensor(-1.0236, device='cuda:6')
epoch:  31000 quantization_loss:  0.041637733578681946
p mean is: tensor(-1.0647, device='cuda:6')
epoch:  32000 quantization_loss:  0.041516199707984924
p mean is: tensor(-1.1051, device='cuda:6')
epoch:  33000 quantization_loss:  0.04158105328679085
p mean is: tensor(-1.1438, device='cuda:6')
epoch:  34000 quantization_loss:  0.040982529520988464
p mean is: tensor(-1.1804, device='cuda:6')
epoch:  35000 quantization_loss:  0.035442106425762177
p mean is: tensor(-1.2113, device='cuda:6')
epoch:  36000 quantization_loss:  0.03294115513563156
p mean is: tensor(-1.2435, device='cuda:6')
epoch:  37000 quantization_loss:  0.03063846193253994
p mean is: tensor(-1.2819, device='cuda:6')
epoch:  38000 quantization_loss:  0.0276779904961586
p mean is: tensor(-1.3259, device='cuda:6')
epoch:  39000 quantization_loss:  0.02449166402220726
p mean is: tensor(-1.3763, device='cuda:6')
epoch:  40000 quantization_loss:  0.02208324335515499
p mean is: tensor(-1.4334, device='cuda:6')
epoch:  41000 quantization_loss:  0.02013317681849003
p mean is: tensor(-1.4961, device='cuda:6')
epoch:  42000 quantization_loss:  0.01809953711926937
p mean is: tensor(-1.5639, device='cuda:6')
epoch:  43000 quantization_loss:  0.017139071598649025
p mean is: tensor(-1.6349, device='cuda:6')
epoch:  44000 quantization_loss:  0.016689276322722435
p mean is: tensor(-1.7085, device='cuda:6')
epoch:  45000 quantization_loss:  0.015797367319464684
p mean is: tensor(-1.7829, device='cuda:6')
epoch:  46000 quantization_loss:  0.015243667177855968
p mean is: tensor(-1.8572, device='cuda:6')
epoch:  47000 quantization_loss:  0.01496943924576044
p mean is: tensor(-1.9299, device='cuda:6')
epoch:  48000 quantization_loss:  0.014667061157524586
p mean is: tensor(-2.0004, device='cuda:6')
epoch:  49000 quantization_loss:  0.014170078560709953
p mean is: tensor(-2.0680, device='cuda:6')
epoch:  50000 quantization_loss:  0.01398441568017006
p mean is: tensor(-2.1323, device='cuda:6')
epoch:  51000 quantization_loss:  0.013724870048463345
p mean is: tensor(-2.1931, device='cuda:6')
epoch:  52000 quantization_loss:  0.01368685718625784
p mean is: tensor(-2.2508, device='cuda:6')
epoch:  53000 quantization_loss:  0.013553166761994362
p mean is: tensor(-2.3051, device='cuda:6')
epoch:  54000 quantization_loss:  0.013244133442640305
p mean is: tensor(-2.3562, device='cuda:6')
epoch:  55000 quantization_loss:  0.013111904263496399
p mean is: tensor(-2.4044, device='cuda:6')
epoch:  56000 quantization_loss:  0.01290691364556551
p mean is: tensor(-2.4500, device='cuda:6')
epoch:  57000 quantization_loss:  0.013032916001975536
p mean is: tensor(-2.4932, device='cuda:6')
epoch:  58000 quantization_loss:  0.01277768425643444
p mean is: tensor(-2.5341, device='cuda:6')
epoch:  59000 quantization_loss:  0.012602526694536209
p mean is: tensor(-2.5730, device='cuda:6')
Number of elements to keep: 44356
Threshold value: 5.061326026916504
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.01999972044759046
Number of elements to keep: 44356
Threshold value: 5.061326026916504
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.01999972044759046
1.0.1.1.weight       | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =   10001 /   36864             ( 27.13%) | total_pruned =   26863 | shape = torch.Size([128, 32, 3, 3])
1.1.1.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.2.weight         | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.1.2.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.4.1.weight       | nonzeros =   15520 /  147456             ( 10.53%) | total_pruned =  131936 | shape = torch.Size([128, 128, 3, 3])
1.1.4.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.5.weight         | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.1.5.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.0.1.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =    9527 /  147456             (  6.46%) | total_pruned =  137929 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.2.weight   | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.1.7.1.1.2.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.4.1.weight | nonzeros =    2811 /  147456             (  1.91%) | total_pruned =  144645 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.5.weight   | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.1.7.1.1.5.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      56 /     512             ( 10.94%) | total_pruned =     456 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =     148 /  147456             (  0.10%) | total_pruned =  147308 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =      87 /  147456             (  0.06%) | total_pruned =  147369 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      71 /     512             ( 13.87%) | total_pruned =     441 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =      16 /  147456             (  0.01%) | total_pruned =  147440 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =      16 /  147456             (  0.01%) | total_pruned =  147440 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =      36 /  147456             (  0.02%) | total_pruned =  147420 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =     115 /  147456             (  0.08%) | total_pruned =  147341 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      58 /     132             ( 43.94%) | total_pruned =      74 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =      74 /  152064             (  0.05%) | total_pruned =  151990 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =     131 /   16384             (  0.80%) | total_pruned =   16253 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      30 /     132             ( 22.73%) | total_pruned =     102 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =     388 /  152064             (  0.26%) | total_pruned =  151676 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =     175 /   16384             (  1.07%) | total_pruned =   16209 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      32 /     132             ( 24.24%) | total_pruned =     100 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =     629 /  152064             (  0.41%) | total_pruned =  151435 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.4.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.6.1.weight | nonzeros =     339 /   16384             (  2.07%) | total_pruned =   16045 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.7.weight | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
1.1.7.1.1.7.7.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.2.weight       | nonzeros =      51 /     132             ( 38.64%) | total_pruned =      81 | shape = torch.Size([132])
1.1.7.2.bias         | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.3.1.weight     | nonzeros =     187 /  152064             (  0.12%) | total_pruned =  151877 | shape = torch.Size([128, 132, 3, 3])
1.1.7.3.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.4.weight       | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
1.1.7.4.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.6.1.weight     | nonzeros =     288 /   16384             (  1.76%) | total_pruned =   16096 | shape = torch.Size([128, 128, 1, 1])
1.1.7.6.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.7.weight       | nonzeros =      49 /     128             ( 38.28%) | total_pruned =      79 | shape = torch.Size([128])
1.1.7.7.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
2.weight             | nonzeros =      58 /     132             ( 43.94%) | total_pruned =      74 | shape = torch.Size([132])
2.bias               | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
3.1.weight           | nonzeros =     387 /  152064             (  0.25%) | total_pruned =  151677 | shape = torch.Size([128, 132, 3, 3])
3.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
4.weight             | nonzeros =     117 /     128             ( 91.41%) | total_pruned =      11 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
6.1.weight           | nonzeros =    1619 /   16384             (  9.88%) | total_pruned =   14765 | shape = torch.Size([128, 128, 1, 1])
6.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
7.weight             | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
7.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =     162 /     384             ( 42.19%) | total_pruned =     222 | shape = torch.Size([3, 128, 1, 1])
9.1.bias             | nonzeros =       3 /       3             (100.00%) | total_pruned =       0 | shape = torch.Size([3])
alive: 44356, pruned : 2173475, total: 2217831, Compression rate :      50.00x  ( 98.00% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  15.505109517635189
Experiment done
