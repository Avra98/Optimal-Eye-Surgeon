(3, 512, 512)
Starting vanilla DIP on 4 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '19.74551212981995'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 16, 16])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/4/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-2.0/1e-09
epoch:  0 quantization_loss:  0.06479848921298981
p mean is: tensor(-0.0003, device='cuda:4')
epoch:  1000 quantization_loss:  0.06355553865432739
p mean is: tensor(-0.0139, device='cuda:4')
epoch:  2000 quantization_loss:  0.0567801333963871
p mean is: tensor(-0.0227, device='cuda:4')
epoch:  3000 quantization_loss:  0.04339519143104553
p mean is: tensor(-0.0288, device='cuda:4')
epoch:  4000 quantization_loss:  0.03603098914027214
p mean is: tensor(-0.0389, device='cuda:4')
epoch:  5000 quantization_loss:  0.0344124361872673
p mean is: tensor(-0.0488, device='cuda:4')
epoch:  6000 quantization_loss:  0.03231767937541008
p mean is: tensor(-0.0598, device='cuda:4')
epoch:  7000 quantization_loss:  0.02995213307440281
p mean is: tensor(-0.0742, device='cuda:4')
epoch:  8000 quantization_loss:  0.02879330702126026
p mean is: tensor(-0.0903, device='cuda:4')
epoch:  9000 quantization_loss:  0.027313942089676857
p mean is: tensor(-0.1092, device='cuda:4')
epoch:  10000 quantization_loss:  0.027217762544751167
p mean is: tensor(-0.1311, device='cuda:4')
epoch:  11000 quantization_loss:  0.026223663240671158
p mean is: tensor(-0.1583, device='cuda:4')
epoch:  12000 quantization_loss:  0.025697404518723488
p mean is: tensor(-0.1897, device='cuda:4')
epoch:  13000 quantization_loss:  0.02522614225745201
p mean is: tensor(-0.2260, device='cuda:4')
epoch:  14000 quantization_loss:  0.02470945566892624
p mean is: tensor(-0.2661, device='cuda:4')
epoch:  15000 quantization_loss:  0.024312404915690422
p mean is: tensor(-0.3092, device='cuda:4')
epoch:  16000 quantization_loss:  0.024242127314209938
p mean is: tensor(-0.3536, device='cuda:4')
epoch:  17000 quantization_loss:  0.02359909750521183
p mean is: tensor(-0.3982, device='cuda:4')
epoch:  18000 quantization_loss:  0.023501073941588402
p mean is: tensor(-0.4437, device='cuda:4')
epoch:  19000 quantization_loss:  0.023379601538181305
p mean is: tensor(-0.4863, device='cuda:4')
epoch:  20000 quantization_loss:  0.02310997247695923
p mean is: tensor(-0.5268, device='cuda:4')
epoch:  21000 quantization_loss:  0.022883450612425804
p mean is: tensor(-0.5643, device='cuda:4')
epoch:  22000 quantization_loss:  0.02254713885486126
p mean is: tensor(-0.6012, device='cuda:4')
epoch:  23000 quantization_loss:  0.022543543949723244
p mean is: tensor(-0.6364, device='cuda:4')
epoch:  24000 quantization_loss:  0.02227662317454815
p mean is: tensor(-0.6672, device='cuda:4')
epoch:  25000 quantization_loss:  0.022204957902431488
p mean is: tensor(-0.6971, device='cuda:4')
epoch:  26000 quantization_loss:  0.022142354398965836
p mean is: tensor(-0.7262, device='cuda:4')
epoch:  27000 quantization_loss:  0.022016379982233047
p mean is: tensor(-0.7530, device='cuda:4')
epoch:  28000 quantization_loss:  0.021942676976323128
p mean is: tensor(-0.7765, device='cuda:4')
epoch:  29000 quantization_loss:  0.021914998069405556
p mean is: tensor(-0.7991, device='cuda:4')
epoch:  30000 quantization_loss:  0.021811433136463165
p mean is: tensor(-0.8199, device='cuda:4')
epoch:  31000 quantization_loss:  0.02176092565059662
p mean is: tensor(-0.8384, device='cuda:4')
epoch:  32000 quantization_loss:  0.021717412397265434
p mean is: tensor(-0.8563, device='cuda:4')
epoch:  33000 quantization_loss:  0.02166285179555416
p mean is: tensor(-0.8730, device='cuda:4')
epoch:  34000 quantization_loss:  0.021600402891635895
p mean is: tensor(-0.8884, device='cuda:4')
epoch:  35000 quantization_loss:  0.02160116285085678
p mean is: tensor(-0.9016, device='cuda:4')
epoch:  36000 quantization_loss:  0.021550415083765984
p mean is: tensor(-0.9136, device='cuda:4')
epoch:  37000 quantization_loss:  0.021538037806749344
p mean is: tensor(-0.9238, device='cuda:4')
epoch:  38000 quantization_loss:  0.0214979387819767
p mean is: tensor(-0.9336, device='cuda:4')
epoch:  39000 quantization_loss:  0.02146153151988983
p mean is: tensor(-0.9431, device='cuda:4')
epoch:  40000 quantization_loss:  0.02144952490925789
p mean is: tensor(-0.9519, device='cuda:4')
epoch:  41000 quantization_loss:  0.021441195160150528
p mean is: tensor(-0.9598, device='cuda:4')
epoch:  42000 quantization_loss:  0.021418873220682144
p mean is: tensor(-0.9674, device='cuda:4')
epoch:  43000 quantization_loss:  0.021388009190559387
p mean is: tensor(-0.9745, device='cuda:4')
epoch:  44000 quantization_loss:  0.02146146260201931
p mean is: tensor(-0.9811, device='cuda:4')
epoch:  45000 quantization_loss:  0.02136310189962387
p mean is: tensor(-0.9874, device='cuda:4')
epoch:  46000 quantization_loss:  0.021356631070375443
p mean is: tensor(-0.9931, device='cuda:4')
epoch:  47000 quantization_loss:  0.021443527191877365
p mean is: tensor(-0.9979, device='cuda:4')
epoch:  48000 quantization_loss:  0.02132641151547432
p mean is: tensor(-1.0021, device='cuda:4')
epoch:  49000 quantization_loss:  0.021355118602514267
p mean is: tensor(-1.0058, device='cuda:4')
epoch:  50000 quantization_loss:  0.021336406469345093
p mean is: tensor(-1.0094, device='cuda:4')
epoch:  51000 quantization_loss:  0.021327046677470207
p mean is: tensor(-1.0121, device='cuda:4')
epoch:  52000 quantization_loss:  0.021328285336494446
p mean is: tensor(-1.0148, device='cuda:4')
epoch:  53000 quantization_loss:  0.021287012845277786
p mean is: tensor(-1.0175, device='cuda:4')
epoch:  54000 quantization_loss:  0.0212814062833786
p mean is: tensor(-1.0200, device='cuda:4')
epoch:  55000 quantization_loss:  0.02129608578979969
p mean is: tensor(-1.0228, device='cuda:4')
epoch:  56000 quantization_loss:  0.021277541294693947
p mean is: tensor(-1.0248, device='cuda:4')
epoch:  57000 quantization_loss:  0.02127915993332863
p mean is: tensor(-1.0267, device='cuda:4')
epoch:  58000 quantization_loss:  0.021273380145430565
p mean is: tensor(-1.0281, device='cuda:4')
epoch:  59000 quantization_loss:  0.02128281258046627
p mean is: tensor(-1.0298, device='cuda:4')
epoch:  60000 quantization_loss:  0.021278275176882744
p mean is: tensor(-1.0311, device='cuda:4')
epoch:  61000 quantization_loss:  0.021263377740979195
p mean is: tensor(-1.0326, device='cuda:4')
epoch:  62000 quantization_loss:  0.021251071244478226
p mean is: tensor(-1.0336, device='cuda:4')
epoch:  63000 quantization_loss:  0.021255185827612877
p mean is: tensor(-1.0348, device='cuda:4')
epoch:  64000 quantization_loss:  0.021233687177300453
p mean is: tensor(-1.0357, device='cuda:4')
epoch:  65000 quantization_loss:  0.02121560089290142
p mean is: tensor(-1.0369, device='cuda:4')
epoch:  66000 quantization_loss:  0.021210867911577225
p mean is: tensor(-1.0378, device='cuda:4')
epoch:  67000 quantization_loss:  0.021214233711361885
p mean is: tensor(-1.0386, device='cuda:4')
epoch:  68000 quantization_loss:  0.021230701357126236
p mean is: tensor(-1.0393, device='cuda:4')
epoch:  69000 quantization_loss:  0.02120998315513134
p mean is: tensor(-1.0398, device='cuda:4')
epoch:  70000 quantization_loss:  0.021205615252256393
p mean is: tensor(-1.0402, device='cuda:4')
epoch:  71000 quantization_loss:  0.021344518288969994
p mean is: tensor(-1.0410, device='cuda:4')
epoch:  72000 quantization_loss:  0.021210715174674988
p mean is: tensor(-1.0414, device='cuda:4')
epoch:  73000 quantization_loss:  0.021201837807893753
p mean is: tensor(-1.0416, device='cuda:4')
epoch:  74000 quantization_loss:  0.021195201203227043
p mean is: tensor(-1.0422, device='cuda:4')
epoch:  75000 quantization_loss:  0.021193496882915497
p mean is: tensor(-1.0423, device='cuda:4')
epoch:  76000 quantization_loss:  0.021204575896263123
p mean is: tensor(-1.0428, device='cuda:4')
epoch:  77000 quantization_loss:  0.021188464015722275
p mean is: tensor(-1.0430, device='cuda:4')
epoch:  78000 quantization_loss:  0.021183041855692863
p mean is: tensor(-1.0432, device='cuda:4')
epoch:  79000 quantization_loss:  0.02118881605565548
p mean is: tensor(-1.0433, device='cuda:4')
here
1.1.weight           | nonzeros =    5191 /   16384             ( 31.68%) | total_pruned =   11193 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =    4020 /   16384             ( 24.54%) | total_pruned =   12364 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    4816 /   16384             ( 29.39%) | total_pruned =   11568 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =    3974 /   16384             ( 24.26%) | total_pruned =   12410 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =    3339 /   16384             ( 20.38%) | total_pruned =   13045 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =    3696 /   16384             ( 22.56%) | total_pruned =   12688 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     182 /     384             ( 47.40%) | total_pruned =     202 | shape = torch.Size([3, 128, 1, 1])
alive: 25768, pruned : 74456, total: 100224, Compression rate :       3.89x  ( 74.29% pruned)
PSNR of output image is:  18.73674779121258
Experiment done
