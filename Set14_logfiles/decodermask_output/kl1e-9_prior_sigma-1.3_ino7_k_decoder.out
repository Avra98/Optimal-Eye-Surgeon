(3, 512, 512)
Starting vanilla DIP on 7 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.245832356203543'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 16, 16])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/7/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-1.3/1e-09
epoch:  0 quantization_loss:  0.07975181937217712
p mean is: tensor(-0.0002, device='cuda:3')
epoch:  1000 quantization_loss:  0.07526631653308868
p mean is: tensor(-0.0109, device='cuda:3')
epoch:  2000 quantization_loss:  0.07200147956609726
p mean is: tensor(-0.0185, device='cuda:3')
epoch:  3000 quantization_loss:  0.06419418007135391
p mean is: tensor(-0.0191, device='cuda:3')
epoch:  4000 quantization_loss:  0.0603681355714798
p mean is: tensor(-0.0193, device='cuda:3')
epoch:  5000 quantization_loss:  0.0434347465634346
p mean is: tensor(-0.0224, device='cuda:3')
epoch:  6000 quantization_loss:  0.03880302235484123
p mean is: tensor(-0.0269, device='cuda:3')
epoch:  7000 quantization_loss:  0.035562511533498764
p mean is: tensor(-0.0333, device='cuda:3')
epoch:  8000 quantization_loss:  0.03402572497725487
p mean is: tensor(-0.0394, device='cuda:3')
epoch:  9000 quantization_loss:  0.03218521177768707
p mean is: tensor(-0.0497, device='cuda:3')
epoch:  10000 quantization_loss:  0.03085055574774742
p mean is: tensor(-0.0607, device='cuda:3')
epoch:  11000 quantization_loss:  0.0309003833681345
p mean is: tensor(-0.0760, device='cuda:3')
epoch:  12000 quantization_loss:  0.02991512045264244
p mean is: tensor(-0.0922, device='cuda:3')
epoch:  13000 quantization_loss:  0.02958044596016407
p mean is: tensor(-0.1134, device='cuda:3')
epoch:  14000 quantization_loss:  0.02921949326992035
p mean is: tensor(-0.1367, device='cuda:3')
epoch:  15000 quantization_loss:  0.0288154985755682
p mean is: tensor(-0.1650, device='cuda:3')
epoch:  16000 quantization_loss:  0.028623295947909355
p mean is: tensor(-0.1939, device='cuda:3')
epoch:  17000 quantization_loss:  0.028139248490333557
p mean is: tensor(-0.2238, device='cuda:3')
epoch:  18000 quantization_loss:  0.028088968247175217
p mean is: tensor(-0.2548, device='cuda:3')
epoch:  19000 quantization_loss:  0.02774900384247303
p mean is: tensor(-0.2862, device='cuda:3')
epoch:  20000 quantization_loss:  0.02758762799203396
p mean is: tensor(-0.3168, device='cuda:3')
epoch:  21000 quantization_loss:  0.027493318542838097
p mean is: tensor(-0.3459, device='cuda:3')
epoch:  22000 quantization_loss:  0.027379047125577927
p mean is: tensor(-0.3745, device='cuda:3')
epoch:  23000 quantization_loss:  0.02721482701599598
p mean is: tensor(-0.4006, device='cuda:3')
epoch:  24000 quantization_loss:  0.02718142233788967
p mean is: tensor(-0.4253, device='cuda:3')
epoch:  25000 quantization_loss:  0.027036461979150772
p mean is: tensor(-0.4484, device='cuda:3')
epoch:  26000 quantization_loss:  0.026995057240128517
p mean is: tensor(-0.4702, device='cuda:3')
epoch:  27000 quantization_loss:  0.026928545907139778
p mean is: tensor(-0.4896, device='cuda:3')
epoch:  28000 quantization_loss:  0.026917800307273865
p mean is: tensor(-0.5076, device='cuda:3')
epoch:  29000 quantization_loss:  0.027032291516661644
p mean is: tensor(-0.5222, device='cuda:3')
epoch:  30000 quantization_loss:  0.026703715324401855
p mean is: tensor(-0.5359, device='cuda:3')
epoch:  31000 quantization_loss:  0.026646684855222702
p mean is: tensor(-0.5482, device='cuda:3')
epoch:  32000 quantization_loss:  0.026600230485200882
p mean is: tensor(-0.5581, device='cuda:3')
epoch:  33000 quantization_loss:  0.026603616774082184
p mean is: tensor(-0.5669, device='cuda:3')
epoch:  34000 quantization_loss:  0.02653738483786583
p mean is: tensor(-0.5750, device='cuda:3')
epoch:  35000 quantization_loss:  0.02654470130801201
p mean is: tensor(-0.5812, device='cuda:3')
epoch:  36000 quantization_loss:  0.026508677750825882
p mean is: tensor(-0.5864, device='cuda:3')
epoch:  37000 quantization_loss:  0.026479272171854973
p mean is: tensor(-0.5913, device='cuda:3')
epoch:  38000 quantization_loss:  0.02646864950656891
p mean is: tensor(-0.5948, device='cuda:3')
epoch:  39000 quantization_loss:  0.026477623730897903
p mean is: tensor(-0.5981, device='cuda:3')
epoch:  40000 quantization_loss:  0.026452207937836647
p mean is: tensor(-0.6012, device='cuda:3')
epoch:  41000 quantization_loss:  0.026426859200000763
p mean is: tensor(-0.6033, device='cuda:3')
epoch:  42000 quantization_loss:  0.02638052962720394
p mean is: tensor(-0.6057, device='cuda:3')
epoch:  43000 quantization_loss:  0.026365848258137703
p mean is: tensor(-0.6079, device='cuda:3')
epoch:  44000 quantization_loss:  0.026345739141106606
p mean is: tensor(-0.6089, device='cuda:3')
epoch:  45000 quantization_loss:  0.026335809379816055
p mean is: tensor(-0.6091, device='cuda:3')
epoch:  46000 quantization_loss:  0.026303816586732864
p mean is: tensor(-0.6096, device='cuda:3')
epoch:  47000 quantization_loss:  0.02631678432226181
p mean is: tensor(-0.6098, device='cuda:3')
epoch:  48000 quantization_loss:  0.02637309767305851
p mean is: tensor(-0.6107, device='cuda:3')
epoch:  49000 quantization_loss:  0.026288336142897606
p mean is: tensor(-0.6111, device='cuda:3')
epoch:  50000 quantization_loss:  0.0262819342315197
p mean is: tensor(-0.6112, device='cuda:3')
epoch:  51000 quantization_loss:  0.02627641148865223
p mean is: tensor(-0.6118, device='cuda:3')
epoch:  52000 quantization_loss:  0.026285946369171143
p mean is: tensor(-0.6127, device='cuda:3')
epoch:  53000 quantization_loss:  0.02626180462539196
p mean is: tensor(-0.6125, device='cuda:3')
epoch:  54000 quantization_loss:  0.026266027241945267
p mean is: tensor(-0.6122, device='cuda:3')
epoch:  55000 quantization_loss:  0.02626626007258892
p mean is: tensor(-0.6120, device='cuda:3')
epoch:  56000 quantization_loss:  0.02625293657183647
p mean is: tensor(-0.6116, device='cuda:3')
epoch:  57000 quantization_loss:  0.026251165196299553
p mean is: tensor(-0.6124, device='cuda:3')
epoch:  58000 quantization_loss:  0.026247186586260796
p mean is: tensor(-0.6127, device='cuda:3')
epoch:  59000 quantization_loss:  0.026239022612571716
p mean is: tensor(-0.6121, device='cuda:3')
epoch:  60000 quantization_loss:  0.02625151164829731
p mean is: tensor(-0.6117, device='cuda:3')
epoch:  61000 quantization_loss:  0.02623744308948517
p mean is: tensor(-0.6113, device='cuda:3')
epoch:  62000 quantization_loss:  0.026229185983538628
p mean is: tensor(-0.6108, device='cuda:3')
epoch:  63000 quantization_loss:  0.02623009867966175
p mean is: tensor(-0.6104, device='cuda:3')
epoch:  64000 quantization_loss:  0.026223791763186455
p mean is: tensor(-0.6097, device='cuda:3')
epoch:  65000 quantization_loss:  0.026225270703434944
p mean is: tensor(-0.6093, device='cuda:3')
epoch:  66000 quantization_loss:  0.026231015101075172
p mean is: tensor(-0.6086, device='cuda:3')
epoch:  67000 quantization_loss:  0.026218567043542862
p mean is: tensor(-0.6074, device='cuda:3')
epoch:  68000 quantization_loss:  0.026215804740786552
p mean is: tensor(-0.6065, device='cuda:3')
epoch:  69000 quantization_loss:  0.02625071443617344
p mean is: tensor(-0.6056, device='cuda:3')
epoch:  70000 quantization_loss:  0.02622242271900177
p mean is: tensor(-0.6051, device='cuda:3')
epoch:  71000 quantization_loss:  0.026213958859443665
p mean is: tensor(-0.6047, device='cuda:3')
epoch:  72000 quantization_loss:  0.026213007047772408
p mean is: tensor(-0.6044, device='cuda:3')
epoch:  73000 quantization_loss:  0.02622070536017418
p mean is: tensor(-0.6042, device='cuda:3')
epoch:  74000 quantization_loss:  0.026221539825201035
p mean is: tensor(-0.6041, device='cuda:3')
epoch:  75000 quantization_loss:  0.026210276409983635
p mean is: tensor(-0.6037, device='cuda:3')
epoch:  76000 quantization_loss:  0.026211213320493698
p mean is: tensor(-0.6033, device='cuda:3')
epoch:  77000 quantization_loss:  0.02620598115026951
p mean is: tensor(-0.6035, device='cuda:3')
epoch:  78000 quantization_loss:  0.026211122050881386
p mean is: tensor(-0.6035, device='cuda:3')
epoch:  79000 quantization_loss:  0.02620980329811573
p mean is: tensor(-0.6039, device='cuda:3')
here
1.1.weight           | nonzeros =    5029 /   16384             ( 30.69%) | total_pruned =   11355 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =    4264 /   16384             ( 26.03%) | total_pruned =   12120 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    5342 /   16384             ( 32.60%) | total_pruned =   11042 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =    4231 /   16384             ( 25.82%) | total_pruned =   12153 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =    2268 /   16384             ( 13.84%) | total_pruned =   14116 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =    2637 /   16384             ( 16.09%) | total_pruned =   13747 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     183 /     384             ( 47.66%) | total_pruned =     201 | shape = torch.Size([3, 128, 1, 1])
alive: 24485, pruned : 75739, total: 100224, Compression rate :       4.09x  ( 75.57% pruned)
PSNR of output image is:  17.522123031758195
Experiment done
