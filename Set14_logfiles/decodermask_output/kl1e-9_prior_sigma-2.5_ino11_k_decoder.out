(3, 512, 512)
Starting vanilla DIP on 11 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.310777064859565'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 16, 16])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/11/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-2.5/1e-09
epoch:  0 quantization_loss:  0.06859558075666428
p mean is: tensor(-0.0004, device='cuda:2')
epoch:  1000 quantization_loss:  0.06308651715517044
p mean is: tensor(-0.0181, device='cuda:2')
epoch:  2000 quantization_loss:  0.05359940603375435
p mean is: tensor(-0.0238, device='cuda:2')
epoch:  3000 quantization_loss:  0.04915066063404083
p mean is: tensor(-0.0299, device='cuda:2')
epoch:  4000 quantization_loss:  0.04704316705465317
p mean is: tensor(-0.0391, device='cuda:2')
epoch:  5000 quantization_loss:  0.046017758548259735
p mean is: tensor(-0.0510, device='cuda:2')
epoch:  6000 quantization_loss:  0.04533053934574127
p mean is: tensor(-0.0656, device='cuda:2')
epoch:  7000 quantization_loss:  0.0445389561355114
p mean is: tensor(-0.0825, device='cuda:2')
epoch:  8000 quantization_loss:  0.04361904785037041
p mean is: tensor(-0.1027, device='cuda:2')
epoch:  9000 quantization_loss:  0.04280436411499977
p mean is: tensor(-0.1263, device='cuda:2')
epoch:  10000 quantization_loss:  0.041823141276836395
p mean is: tensor(-0.1537, device='cuda:2')
epoch:  11000 quantization_loss:  0.04093806818127632
p mean is: tensor(-0.1869, device='cuda:2')
epoch:  12000 quantization_loss:  0.03989769518375397
p mean is: tensor(-0.2221, device='cuda:2')
epoch:  13000 quantization_loss:  0.03912628814578056
p mean is: tensor(-0.2601, device='cuda:2')
epoch:  14000 quantization_loss:  0.03853985294699669
p mean is: tensor(-0.3000, device='cuda:2')
epoch:  15000 quantization_loss:  0.038253460079431534
p mean is: tensor(-0.3425, device='cuda:2')
epoch:  16000 quantization_loss:  0.037429213523864746
p mean is: tensor(-0.3828, device='cuda:2')
epoch:  17000 quantization_loss:  0.036548737436532974
p mean is: tensor(-0.4239, device='cuda:2')
epoch:  18000 quantization_loss:  0.03619285300374031
p mean is: tensor(-0.4632, device='cuda:2')
epoch:  19000 quantization_loss:  0.035584211349487305
p mean is: tensor(-0.5017, device='cuda:2')
epoch:  20000 quantization_loss:  0.034752849489450455
p mean is: tensor(-0.5406, device='cuda:2')
epoch:  21000 quantization_loss:  0.034420572221279144
p mean is: tensor(-0.5765, device='cuda:2')
epoch:  22000 quantization_loss:  0.03366227075457573
p mean is: tensor(-0.6112, device='cuda:2')
epoch:  23000 quantization_loss:  0.033493876457214355
p mean is: tensor(-0.6448, device='cuda:2')
epoch:  24000 quantization_loss:  0.03294659033417702
p mean is: tensor(-0.6784, device='cuda:2')
epoch:  25000 quantization_loss:  0.032603904604911804
p mean is: tensor(-0.7092, device='cuda:2')
epoch:  26000 quantization_loss:  0.03212239220738411
p mean is: tensor(-0.7397, device='cuda:2')
epoch:  27000 quantization_loss:  0.03191487118601799
p mean is: tensor(-0.7691, device='cuda:2')
epoch:  28000 quantization_loss:  0.031682174652814865
p mean is: tensor(-0.7956, device='cuda:2')
epoch:  29000 quantization_loss:  0.03144845366477966
p mean is: tensor(-0.8220, device='cuda:2')
epoch:  30000 quantization_loss:  0.031017102301120758
p mean is: tensor(-0.8473, device='cuda:2')
epoch:  31000 quantization_loss:  0.030874110758304596
p mean is: tensor(-0.8715, device='cuda:2')
epoch:  32000 quantization_loss:  0.03082907758653164
p mean is: tensor(-0.8941, device='cuda:2')
epoch:  33000 quantization_loss:  0.030471106991171837
p mean is: tensor(-0.9143, device='cuda:2')
epoch:  34000 quantization_loss:  0.030784720554947853
p mean is: tensor(-0.9331, device='cuda:2')
epoch:  35000 quantization_loss:  0.030354870483279228
p mean is: tensor(-0.9494, device='cuda:2')
epoch:  36000 quantization_loss:  0.030268415808677673
p mean is: tensor(-0.9652, device='cuda:2')
epoch:  37000 quantization_loss:  0.029995743185281754
p mean is: tensor(-0.9798, device='cuda:2')
epoch:  38000 quantization_loss:  0.029890824109315872
p mean is: tensor(-0.9938, device='cuda:2')
epoch:  39000 quantization_loss:  0.0296280849725008
p mean is: tensor(-1.0062, device='cuda:2')
epoch:  40000 quantization_loss:  0.029612239450216293
p mean is: tensor(-1.0184, device='cuda:2')
epoch:  41000 quantization_loss:  0.02949804998934269
p mean is: tensor(-1.0289, device='cuda:2')
epoch:  42000 quantization_loss:  0.029467934742569923
p mean is: tensor(-1.0392, device='cuda:2')
epoch:  43000 quantization_loss:  0.029421022161841393
p mean is: tensor(-1.0478, device='cuda:2')
epoch:  44000 quantization_loss:  0.029425211250782013
p mean is: tensor(-1.0561, device='cuda:2')
epoch:  45000 quantization_loss:  0.029407499358057976
p mean is: tensor(-1.0626, device='cuda:2')
epoch:  46000 quantization_loss:  0.02919839136302471
p mean is: tensor(-1.0693, device='cuda:2')
epoch:  47000 quantization_loss:  0.02911648154258728
p mean is: tensor(-1.0754, device='cuda:2')
epoch:  48000 quantization_loss:  0.029080219566822052
p mean is: tensor(-1.0813, device='cuda:2')
epoch:  49000 quantization_loss:  0.029036613181233406
p mean is: tensor(-1.0869, device='cuda:2')
epoch:  50000 quantization_loss:  0.02907843329012394
p mean is: tensor(-1.0922, device='cuda:2')
epoch:  51000 quantization_loss:  0.028995495289564133
p mean is: tensor(-1.0967, device='cuda:2')
epoch:  52000 quantization_loss:  0.02904742956161499
p mean is: tensor(-1.1007, device='cuda:2')
epoch:  53000 quantization_loss:  0.02898133359849453
p mean is: tensor(-1.1048, device='cuda:2')
epoch:  54000 quantization_loss:  0.028951914981007576
p mean is: tensor(-1.1087, device='cuda:2')
epoch:  55000 quantization_loss:  0.028968272730708122
p mean is: tensor(-1.1120, device='cuda:2')
epoch:  56000 quantization_loss:  0.028960851952433586
p mean is: tensor(-1.1149, device='cuda:2')
epoch:  57000 quantization_loss:  0.028985384851694107
p mean is: tensor(-1.1182, device='cuda:2')
epoch:  58000 quantization_loss:  0.02895362116396427
p mean is: tensor(-1.1209, device='cuda:2')
epoch:  59000 quantization_loss:  0.028929956257343292
p mean is: tensor(-1.1232, device='cuda:2')
epoch:  60000 quantization_loss:  0.028713351115584373
p mean is: tensor(-1.1252, device='cuda:2')
epoch:  61000 quantization_loss:  0.02868814766407013
p mean is: tensor(-1.1273, device='cuda:2')
epoch:  62000 quantization_loss:  0.02866796962916851
p mean is: tensor(-1.1296, device='cuda:2')
epoch:  63000 quantization_loss:  0.028680305927991867
p mean is: tensor(-1.1317, device='cuda:2')
epoch:  64000 quantization_loss:  0.028659634292125702
p mean is: tensor(-1.1340, device='cuda:2')
epoch:  65000 quantization_loss:  0.02866809070110321
p mean is: tensor(-1.1362, device='cuda:2')
epoch:  66000 quantization_loss:  0.029431650415062904
p mean is: tensor(-1.1376, device='cuda:2')
epoch:  67000 quantization_loss:  0.028499308973550797
p mean is: tensor(-1.1387, device='cuda:2')
epoch:  68000 quantization_loss:  0.02852240391075611
p mean is: tensor(-1.1402, device='cuda:2')
epoch:  69000 quantization_loss:  0.028492925688624382
p mean is: tensor(-1.1416, device='cuda:2')
epoch:  70000 quantization_loss:  0.02860967628657818
p mean is: tensor(-1.1427, device='cuda:2')
epoch:  71000 quantization_loss:  0.028478123247623444
p mean is: tensor(-1.1444, device='cuda:2')
epoch:  72000 quantization_loss:  0.028527487069368362
p mean is: tensor(-1.1454, device='cuda:2')
epoch:  73000 quantization_loss:  0.028457898646593094
p mean is: tensor(-1.1464, device='cuda:2')
epoch:  74000 quantization_loss:  0.028318967670202255
p mean is: tensor(-1.1474, device='cuda:2')
epoch:  75000 quantization_loss:  0.02836955338716507
p mean is: tensor(-1.1482, device='cuda:2')
epoch:  76000 quantization_loss:  0.02829669415950775
p mean is: tensor(-1.1496, device='cuda:2')
epoch:  77000 quantization_loss:  0.028311366215348244
p mean is: tensor(-1.1502, device='cuda:2')
epoch:  78000 quantization_loss:  0.02828473411500454
p mean is: tensor(-1.1510, device='cuda:2')
epoch:  79000 quantization_loss:  0.028296465054154396
p mean is: tensor(-1.1515, device='cuda:2')
here
1.1.weight           | nonzeros =    5066 /   16384             ( 30.92%) | total_pruned =   11318 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =    4152 /   16384             ( 25.34%) | total_pruned =   12232 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    6305 /   16384             ( 38.48%) | total_pruned =   10079 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =    5415 /   16384             ( 33.05%) | total_pruned =   10969 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =    3433 /   16384             ( 20.95%) | total_pruned =   12951 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =    2494 /   16384             ( 15.22%) | total_pruned =   13890 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     132 /     384             ( 34.38%) | total_pruned =     252 | shape = torch.Size([3, 128, 1, 1])
alive: 27550, pruned : 72674, total: 100224, Compression rate :       3.64x  ( 72.51% pruned)
PSNR of output image is:  16.875003757143382
Experiment done
