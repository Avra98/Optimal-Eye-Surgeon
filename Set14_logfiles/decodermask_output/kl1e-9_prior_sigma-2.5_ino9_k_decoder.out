(3, 256, 256)
Starting vanilla DIP on 9 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.20972828632406'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 8, 8])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/9/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-2.5/1e-09
epoch:  0 quantization_loss:  0.06175486370921135
p mean is: tensor(-0.0004, device='cuda:4')
epoch:  1000 quantization_loss:  0.058233827352523804
p mean is: tensor(-0.0103, device='cuda:4')
epoch:  2000 quantization_loss:  0.025084910914301872
p mean is: tensor(-0.0136, device='cuda:4')
epoch:  3000 quantization_loss:  0.024246063083410263
p mean is: tensor(-0.0198, device='cuda:4')
epoch:  4000 quantization_loss:  0.023520084097981453
p mean is: tensor(-0.0268, device='cuda:4')
epoch:  5000 quantization_loss:  0.022659657523036003
p mean is: tensor(-0.0346, device='cuda:4')
epoch:  6000 quantization_loss:  0.02258845791220665
p mean is: tensor(-0.0445, device='cuda:4')
epoch:  7000 quantization_loss:  0.021941568702459335
p mean is: tensor(-0.0572, device='cuda:4')
epoch:  8000 quantization_loss:  0.021790655329823494
p mean is: tensor(-0.0729, device='cuda:4')
epoch:  9000 quantization_loss:  0.021266205236315727
p mean is: tensor(-0.0918, device='cuda:4')
epoch:  10000 quantization_loss:  0.021225962787866592
p mean is: tensor(-0.1156, device='cuda:4')
epoch:  11000 quantization_loss:  0.021070508286356926
p mean is: tensor(-0.1442, device='cuda:4')
epoch:  12000 quantization_loss:  0.02031237632036209
p mean is: tensor(-0.1769, device='cuda:4')
epoch:  13000 quantization_loss:  0.02023174613714218
p mean is: tensor(-0.2141, device='cuda:4')
epoch:  14000 quantization_loss:  0.020088212564587593
p mean is: tensor(-0.2546, device='cuda:4')
epoch:  15000 quantization_loss:  0.01939295418560505
p mean is: tensor(-0.3000, device='cuda:4')
epoch:  16000 quantization_loss:  0.019333967939019203
p mean is: tensor(-0.3482, device='cuda:4')
epoch:  17000 quantization_loss:  0.01921364665031433
p mean is: tensor(-0.3966, device='cuda:4')
epoch:  18000 quantization_loss:  0.019362885504961014
p mean is: tensor(-0.4449, device='cuda:4')
epoch:  19000 quantization_loss:  0.01899569109082222
p mean is: tensor(-0.4939, device='cuda:4')
epoch:  20000 quantization_loss:  0.01886211894452572
p mean is: tensor(-0.5404, device='cuda:4')
epoch:  21000 quantization_loss:  0.018755439668893814
p mean is: tensor(-0.5858, device='cuda:4')
epoch:  22000 quantization_loss:  0.018614834174513817
p mean is: tensor(-0.6294, device='cuda:4')
epoch:  23000 quantization_loss:  0.018739784136414528
p mean is: tensor(-0.6706, device='cuda:4')
epoch:  24000 quantization_loss:  0.018595272675156593
p mean is: tensor(-0.7111, device='cuda:4')
epoch:  25000 quantization_loss:  0.018339794129133224
p mean is: tensor(-0.7483, device='cuda:4')
epoch:  26000 quantization_loss:  0.01860111393034458
p mean is: tensor(-0.7849, device='cuda:4')
epoch:  27000 quantization_loss:  0.01866159215569496
p mean is: tensor(-0.8200, device='cuda:4')
epoch:  28000 quantization_loss:  0.018585054203867912
p mean is: tensor(-0.8527, device='cuda:4')
epoch:  29000 quantization_loss:  0.018039438873529434
p mean is: tensor(-0.8830, device='cuda:4')
epoch:  30000 quantization_loss:  0.01788448914885521
p mean is: tensor(-0.9116, device='cuda:4')
epoch:  31000 quantization_loss:  0.017768172547221184
p mean is: tensor(-0.9391, device='cuda:4')
epoch:  32000 quantization_loss:  0.017508631572127342
p mean is: tensor(-0.9662, device='cuda:4')
epoch:  33000 quantization_loss:  0.01747910864651203
p mean is: tensor(-0.9910, device='cuda:4')
epoch:  34000 quantization_loss:  0.017400791868567467
p mean is: tensor(-1.0149, device='cuda:4')
epoch:  35000 quantization_loss:  0.01727902702987194
p mean is: tensor(-1.0393, device='cuda:4')
epoch:  36000 quantization_loss:  0.01712166890501976
p mean is: tensor(-1.0616, device='cuda:4')
epoch:  37000 quantization_loss:  0.01700766757130623
p mean is: tensor(-1.0833, device='cuda:4')
epoch:  38000 quantization_loss:  0.01691083051264286
p mean is: tensor(-1.1052, device='cuda:4')
epoch:  39000 quantization_loss:  0.01686413399875164
p mean is: tensor(-1.1246, device='cuda:4')
epoch:  40000 quantization_loss:  0.01675022952258587
p mean is: tensor(-1.1449, device='cuda:4')
epoch:  41000 quantization_loss:  0.016865046694874763
p mean is: tensor(-1.1642, device='cuda:4')
epoch:  42000 quantization_loss:  0.016709934920072556
p mean is: tensor(-1.1823, device='cuda:4')
epoch:  43000 quantization_loss:  0.016604114323854446
p mean is: tensor(-1.1997, device='cuda:4')
epoch:  44000 quantization_loss:  0.016661930829286575
p mean is: tensor(-1.2160, device='cuda:4')
epoch:  45000 quantization_loss:  0.01678897626698017
p mean is: tensor(-1.2321, device='cuda:4')
epoch:  46000 quantization_loss:  0.016506364569067955
p mean is: tensor(-1.2480, device='cuda:4')
epoch:  47000 quantization_loss:  0.01641237549483776
p mean is: tensor(-1.2631, device='cuda:4')
epoch:  48000 quantization_loss:  0.016752365976572037
p mean is: tensor(-1.2774, device='cuda:4')
epoch:  49000 quantization_loss:  0.016347112134099007
p mean is: tensor(-1.2913, device='cuda:4')
epoch:  50000 quantization_loss:  0.01659863442182541
p mean is: tensor(-1.3048, device='cuda:4')
epoch:  51000 quantization_loss:  0.016259226948022842
p mean is: tensor(-1.3173, device='cuda:4')
epoch:  52000 quantization_loss:  0.016344280913472176
p mean is: tensor(-1.3290, device='cuda:4')
epoch:  53000 quantization_loss:  0.016198592260479927
p mean is: tensor(-1.3417, device='cuda:4')
epoch:  54000 quantization_loss:  0.016347263008356094
p mean is: tensor(-1.3526, device='cuda:4')
epoch:  55000 quantization_loss:  0.01643959805369377
p mean is: tensor(-1.3635, device='cuda:4')
epoch:  56000 quantization_loss:  0.016155412420630455
p mean is: tensor(-1.3732, device='cuda:4')
epoch:  57000 quantization_loss:  0.016202179715037346
p mean is: tensor(-1.3820, device='cuda:4')
epoch:  58000 quantization_loss:  0.016133127734065056
p mean is: tensor(-1.3898, device='cuda:4')
epoch:  59000 quantization_loss:  0.016097698360681534
p mean is: tensor(-1.3972, device='cuda:4')
epoch:  60000 quantization_loss:  0.016202840954065323
p mean is: tensor(-1.4043, device='cuda:4')
epoch:  61000 quantization_loss:  0.016200097277760506
p mean is: tensor(-1.4119, device='cuda:4')
epoch:  62000 quantization_loss:  0.01606665924191475
p mean is: tensor(-1.4186, device='cuda:4')
epoch:  63000 quantization_loss:  0.016105281189084053
p mean is: tensor(-1.4254, device='cuda:4')
epoch:  64000 quantization_loss:  0.016013117507100105
p mean is: tensor(-1.4310, device='cuda:4')
epoch:  65000 quantization_loss:  0.016203273087739944
p mean is: tensor(-1.4369, device='cuda:4')
epoch:  66000 quantization_loss:  0.01606569066643715
p mean is: tensor(-1.4425, device='cuda:4')
epoch:  67000 quantization_loss:  0.015977993607521057
p mean is: tensor(-1.4476, device='cuda:4')
epoch:  68000 quantization_loss:  0.016052590683102608
p mean is: tensor(-1.4524, device='cuda:4')
epoch:  69000 quantization_loss:  0.015963682904839516
p mean is: tensor(-1.4563, device='cuda:4')
epoch:  70000 quantization_loss:  0.01593872159719467
p mean is: tensor(-1.4604, device='cuda:4')
epoch:  71000 quantization_loss:  0.015959274023771286
p mean is: tensor(-1.4642, device='cuda:4')
epoch:  72000 quantization_loss:  0.015950879082083702
p mean is: tensor(-1.4675, device='cuda:4')
epoch:  73000 quantization_loss:  0.015907442197203636
p mean is: tensor(-1.4708, device='cuda:4')
epoch:  74000 quantization_loss:  0.01589648798108101
p mean is: tensor(-1.4742, device='cuda:4')
epoch:  75000 quantization_loss:  0.016028987243771553
p mean is: tensor(-1.4774, device='cuda:4')
epoch:  76000 quantization_loss:  0.01592332124710083
p mean is: tensor(-1.4809, device='cuda:4')
epoch:  77000 quantization_loss:  0.015860868617892265
p mean is: tensor(-1.4834, device='cuda:4')
epoch:  78000 quantization_loss:  0.015867523849010468
p mean is: tensor(-1.4860, device='cuda:4')
epoch:  79000 quantization_loss:  0.015991821885108948
p mean is: tensor(-1.4882, device='cuda:4')
here
1.1.weight           | nonzeros =    4434 /   16384             ( 27.06%) | total_pruned =   11950 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =    3267 /   16384             ( 19.94%) | total_pruned =   13117 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    3995 /   16384             ( 24.38%) | total_pruned =   12389 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =    3695 /   16384             ( 22.55%) | total_pruned =   12689 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =    3499 /   16384             ( 21.36%) | total_pruned =   12885 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =    1533 /   16384             (  9.36%) | total_pruned =   14851 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     100 /     384             ( 26.04%) | total_pruned =     284 | shape = torch.Size([3, 128, 1, 1])
alive: 20995, pruned : 79229, total: 100224, Compression rate :       4.77x  ( 79.05% pruned)
PSNR of output image is:  21.680895714121824
Experiment done
