(3, 512, 512)
Starting vanilla DIP on 5 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.083814179189268'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 16, 16])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/5/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-1.0/1e-09
epoch:  0 quantization_loss:  0.0657811388373375
p mean is: tensor(-0.0002, device='cuda:3')
epoch:  1000 quantization_loss:  0.057922206819057465
p mean is: tensor(-0.0089, device='cuda:3')
epoch:  2000 quantization_loss:  0.048486754298210144
p mean is: tensor(-0.0047, device='cuda:3')
epoch:  3000 quantization_loss:  0.043547194451093674
p mean is: tensor(-0.0016, device='cuda:3')
epoch:  4000 quantization_loss:  0.0404115729033947
p mean is: tensor(-0.0021, device='cuda:3')
epoch:  5000 quantization_loss:  0.03772584721446037
p mean is: tensor(-0.0021, device='cuda:3')
epoch:  6000 quantization_loss:  0.03564494475722313
p mean is: tensor(-0.0027, device='cuda:3')
epoch:  7000 quantization_loss:  0.03382525220513344
p mean is: tensor(-0.0046, device='cuda:3')
epoch:  8000 quantization_loss:  0.03206561878323555
p mean is: tensor(-0.0092, device='cuda:3')
epoch:  9000 quantization_loss:  0.031055232509970665
p mean is: tensor(-0.0162, device='cuda:3')
epoch:  10000 quantization_loss:  0.029512174427509308
p mean is: tensor(-0.0242, device='cuda:3')
epoch:  11000 quantization_loss:  0.02825048938393593
p mean is: tensor(-0.0313, device='cuda:3')
epoch:  12000 quantization_loss:  0.0277098435908556
p mean is: tensor(-0.0396, device='cuda:3')
epoch:  13000 quantization_loss:  0.0266862865537405
p mean is: tensor(-0.0502, device='cuda:3')
epoch:  14000 quantization_loss:  0.026134813204407692
p mean is: tensor(-0.0625, device='cuda:3')
epoch:  15000 quantization_loss:  0.02557562105357647
p mean is: tensor(-0.0758, device='cuda:3')
epoch:  16000 quantization_loss:  0.025092676281929016
p mean is: tensor(-0.0901, device='cuda:3')
epoch:  17000 quantization_loss:  0.02448972500860691
p mean is: tensor(-0.1069, device='cuda:3')
epoch:  18000 quantization_loss:  0.02399277500808239
p mean is: tensor(-0.1228, device='cuda:3')
epoch:  19000 quantization_loss:  0.02380811795592308
p mean is: tensor(-0.1389, device='cuda:3')
epoch:  20000 quantization_loss:  0.023398317396640778
p mean is: tensor(-0.1538, device='cuda:3')
epoch:  21000 quantization_loss:  0.023196956142783165
p mean is: tensor(-0.1688, device='cuda:3')
epoch:  22000 quantization_loss:  0.022904908284544945
p mean is: tensor(-0.1853, device='cuda:3')
epoch:  23000 quantization_loss:  0.022736435756087303
p mean is: tensor(-0.2007, device='cuda:3')
epoch:  24000 quantization_loss:  0.022621871903538704
p mean is: tensor(-0.2149, device='cuda:3')
epoch:  25000 quantization_loss:  0.0224001407623291
p mean is: tensor(-0.2285, device='cuda:3')
epoch:  26000 quantization_loss:  0.022106997668743134
p mean is: tensor(-0.2404, device='cuda:3')
epoch:  27000 quantization_loss:  0.022117771208286285
p mean is: tensor(-0.2508, device='cuda:3')
epoch:  28000 quantization_loss:  0.02189483307301998
p mean is: tensor(-0.2607, device='cuda:3')
epoch:  29000 quantization_loss:  0.02159317396581173
p mean is: tensor(-0.2695, device='cuda:3')
epoch:  30000 quantization_loss:  0.021448345854878426
p mean is: tensor(-0.2770, device='cuda:3')
epoch:  31000 quantization_loss:  0.021418718621134758
p mean is: tensor(-0.2832, device='cuda:3')
epoch:  32000 quantization_loss:  0.021247176453471184
p mean is: tensor(-0.2892, device='cuda:3')
epoch:  33000 quantization_loss:  0.021076200529932976
p mean is: tensor(-0.2934, device='cuda:3')
epoch:  34000 quantization_loss:  0.020995335653424263
p mean is: tensor(-0.2976, device='cuda:3')
epoch:  35000 quantization_loss:  0.02128870226442814
p mean is: tensor(-0.3014, device='cuda:3')
epoch:  36000 quantization_loss:  0.020862650126218796
p mean is: tensor(-0.3055, device='cuda:3')
epoch:  37000 quantization_loss:  0.02080804482102394
p mean is: tensor(-0.3091, device='cuda:3')
epoch:  38000 quantization_loss:  0.020738326013088226
p mean is: tensor(-0.3111, device='cuda:3')
epoch:  39000 quantization_loss:  0.0207382719963789
p mean is: tensor(-0.3127, device='cuda:3')
epoch:  40000 quantization_loss:  0.02068379893898964
p mean is: tensor(-0.3141, device='cuda:3')
epoch:  41000 quantization_loss:  0.020545905455946922
p mean is: tensor(-0.3147, device='cuda:3')
epoch:  42000 quantization_loss:  0.020533982664346695
p mean is: tensor(-0.3158, device='cuda:3')
epoch:  43000 quantization_loss:  0.020472589880228043
p mean is: tensor(-0.3171, device='cuda:3')
epoch:  44000 quantization_loss:  0.0204623993486166
p mean is: tensor(-0.3176, device='cuda:3')
epoch:  45000 quantization_loss:  0.02042524889111519
p mean is: tensor(-0.3191, device='cuda:3')
epoch:  46000 quantization_loss:  0.020461274310946465
p mean is: tensor(-0.3198, device='cuda:3')
epoch:  47000 quantization_loss:  0.02038872241973877
p mean is: tensor(-0.3199, device='cuda:3')
epoch:  48000 quantization_loss:  0.020374754443764687
p mean is: tensor(-0.3200, device='cuda:3')
epoch:  49000 quantization_loss:  0.020384198054671288
p mean is: tensor(-0.3199, device='cuda:3')
epoch:  50000 quantization_loss:  0.020377518609166145
p mean is: tensor(-0.3200, device='cuda:3')
epoch:  51000 quantization_loss:  0.02035340666770935
p mean is: tensor(-0.3192, device='cuda:3')
epoch:  52000 quantization_loss:  0.02035067044198513
p mean is: tensor(-0.3188, device='cuda:3')
epoch:  53000 quantization_loss:  0.020322659984230995
p mean is: tensor(-0.3186, device='cuda:3')
epoch:  54000 quantization_loss:  0.020327381789684296
p mean is: tensor(-0.3184, device='cuda:3')
epoch:  55000 quantization_loss:  0.020315121859312057
p mean is: tensor(-0.3179, device='cuda:3')
epoch:  56000 quantization_loss:  0.020339014008641243
p mean is: tensor(-0.3174, device='cuda:3')
epoch:  57000 quantization_loss:  0.020357904955744743
p mean is: tensor(-0.3176, device='cuda:3')
epoch:  58000 quantization_loss:  0.020316775888204575
p mean is: tensor(-0.3173, device='cuda:3')
epoch:  59000 quantization_loss:  0.02035645954310894
p mean is: tensor(-0.3172, device='cuda:3')
epoch:  60000 quantization_loss:  0.020318128168582916
p mean is: tensor(-0.3176, device='cuda:3')
epoch:  61000 quantization_loss:  0.020284533500671387
p mean is: tensor(-0.3174, device='cuda:3')
epoch:  62000 quantization_loss:  0.02029942162334919
p mean is: tensor(-0.3175, device='cuda:3')
epoch:  63000 quantization_loss:  0.020286722108721733
p mean is: tensor(-0.3172, device='cuda:3')
epoch:  64000 quantization_loss:  0.020313778892159462
p mean is: tensor(-0.3172, device='cuda:3')
epoch:  65000 quantization_loss:  0.020296216011047363
p mean is: tensor(-0.3168, device='cuda:3')
epoch:  66000 quantization_loss:  0.020275814458727837
p mean is: tensor(-0.3169, device='cuda:3')
epoch:  67000 quantization_loss:  0.020295828580856323
p mean is: tensor(-0.3170, device='cuda:3')
epoch:  68000 quantization_loss:  0.020291633903980255
p mean is: tensor(-0.3170, device='cuda:3')
epoch:  69000 quantization_loss:  0.020279962569475174
p mean is: tensor(-0.3170, device='cuda:3')
epoch:  70000 quantization_loss:  0.02026580646634102
p mean is: tensor(-0.3168, device='cuda:3')
epoch:  71000 quantization_loss:  0.020287394523620605
p mean is: tensor(-0.3167, device='cuda:3')
epoch:  72000 quantization_loss:  0.02026117593050003
p mean is: tensor(-0.3167, device='cuda:3')
epoch:  73000 quantization_loss:  0.02030053921043873
p mean is: tensor(-0.3168, device='cuda:3')
epoch:  74000 quantization_loss:  0.020270325243473053
p mean is: tensor(-0.3172, device='cuda:3')
epoch:  75000 quantization_loss:  0.020263392478227615
p mean is: tensor(-0.3176, device='cuda:3')
epoch:  76000 quantization_loss:  0.020251687616109848
p mean is: tensor(-0.3176, device='cuda:3')
epoch:  77000 quantization_loss:  0.02025432139635086
p mean is: tensor(-0.3177, device='cuda:3')
epoch:  78000 quantization_loss:  0.020247679203748703
p mean is: tensor(-0.3176, device='cuda:3')
epoch:  79000 quantization_loss:  0.020253438502550125
p mean is: tensor(-0.3176, device='cuda:3')
here
1.1.weight           | nonzeros =    6494 /   16384             ( 39.64%) | total_pruned =    9890 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =    5854 /   16384             ( 35.73%) | total_pruned =   10530 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    7122 /   16384             ( 43.47%) | total_pruned =    9262 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =    5947 /   16384             ( 36.30%) | total_pruned =   10437 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =    2944 /   16384             ( 17.97%) | total_pruned =   13440 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =    2436 /   16384             ( 14.87%) | total_pruned =   13948 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     177 /     384             ( 46.09%) | total_pruned =     207 | shape = torch.Size([3, 128, 1, 1])
alive: 31567, pruned : 68657, total: 100224, Compression rate :       3.17x  ( 68.50% pruned)
PSNR of output image is:  19.46551392071334
Experiment done
