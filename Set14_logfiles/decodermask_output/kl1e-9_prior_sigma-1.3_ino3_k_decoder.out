(3, 256, 256)
Starting vanilla DIP on 3 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.333320722117772'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 8, 8])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/3/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-1.3/1e-09
epoch:  0 quantization_loss:  0.07597608119249344
p mean is: tensor(-0.0002, device='cuda:1')
epoch:  1000 quantization_loss:  0.07367920130491257
p mean is: tensor(-0.0078, device='cuda:1')
epoch:  2000 quantization_loss:  0.0721183717250824
p mean is: tensor(-0.0123, device='cuda:1')
epoch:  3000 quantization_loss:  0.05729442462325096
p mean is: tensor(-0.0136, device='cuda:1')
epoch:  4000 quantization_loss:  0.05280623957514763
p mean is: tensor(-0.0145, device='cuda:1')
epoch:  5000 quantization_loss:  0.04800713434815407
p mean is: tensor(-0.0160, device='cuda:1')
epoch:  6000 quantization_loss:  0.045566752552986145
p mean is: tensor(-0.0166, device='cuda:1')
epoch:  7000 quantization_loss:  0.04328690096735954
p mean is: tensor(-0.0164, device='cuda:1')
epoch:  8000 quantization_loss:  0.0432928092777729
p mean is: tensor(-0.0182, device='cuda:1')
epoch:  9000 quantization_loss:  0.03936255723237991
p mean is: tensor(-0.0213, device='cuda:1')
epoch:  10000 quantization_loss:  0.03918154910206795
p mean is: tensor(-0.0240, device='cuda:1')
epoch:  11000 quantization_loss:  0.03704458475112915
p mean is: tensor(-0.0299, device='cuda:1')
epoch:  12000 quantization_loss:  0.036308977752923965
p mean is: tensor(-0.0377, device='cuda:1')
epoch:  13000 quantization_loss:  0.035959918051958084
p mean is: tensor(-0.0472, device='cuda:1')
epoch:  14000 quantization_loss:  0.03536124527454376
p mean is: tensor(-0.0590, device='cuda:1')
epoch:  15000 quantization_loss:  0.03439437970519066
p mean is: tensor(-0.0726, device='cuda:1')
epoch:  16000 quantization_loss:  0.033854831010103226
p mean is: tensor(-0.0890, device='cuda:1')
epoch:  17000 quantization_loss:  0.03309866040945053
p mean is: tensor(-0.1075, device='cuda:1')
epoch:  18000 quantization_loss:  0.032661668956279755
p mean is: tensor(-0.1268, device='cuda:1')
epoch:  19000 quantization_loss:  0.03261483088135719
p mean is: tensor(-0.1466, device='cuda:1')
epoch:  20000 quantization_loss:  0.03192867338657379
p mean is: tensor(-0.1676, device='cuda:1')
epoch:  21000 quantization_loss:  0.031765129417181015
p mean is: tensor(-0.1878, device='cuda:1')
epoch:  22000 quantization_loss:  0.031141938641667366
p mean is: tensor(-0.2099, device='cuda:1')
epoch:  23000 quantization_loss:  0.030619923025369644
p mean is: tensor(-0.2295, device='cuda:1')
epoch:  24000 quantization_loss:  0.03042471408843994
p mean is: tensor(-0.2513, device='cuda:1')
epoch:  25000 quantization_loss:  0.030209137126803398
p mean is: tensor(-0.2710, device='cuda:1')
epoch:  26000 quantization_loss:  0.029993543401360512
p mean is: tensor(-0.2916, device='cuda:1')
epoch:  27000 quantization_loss:  0.02959052473306656
p mean is: tensor(-0.3105, device='cuda:1')
epoch:  28000 quantization_loss:  0.02923920936882496
p mean is: tensor(-0.3306, device='cuda:1')
epoch:  29000 quantization_loss:  0.029052840545773506
p mean is: tensor(-0.3502, device='cuda:1')
epoch:  30000 quantization_loss:  0.02870875783264637
p mean is: tensor(-0.3682, device='cuda:1')
epoch:  31000 quantization_loss:  0.028618544340133667
p mean is: tensor(-0.3841, device='cuda:1')
epoch:  32000 quantization_loss:  0.028385501354932785
p mean is: tensor(-0.3997, device='cuda:1')
epoch:  33000 quantization_loss:  0.028297001495957375
p mean is: tensor(-0.4141, device='cuda:1')
epoch:  34000 quantization_loss:  0.028126806020736694
p mean is: tensor(-0.4274, device='cuda:1')
epoch:  35000 quantization_loss:  0.028069498017430305
p mean is: tensor(-0.4399, device='cuda:1')
epoch:  36000 quantization_loss:  0.02803000807762146
p mean is: tensor(-0.4516, device='cuda:1')
epoch:  37000 quantization_loss:  0.027849100530147552
p mean is: tensor(-0.4621, device='cuda:1')
epoch:  38000 quantization_loss:  0.027682924643158913
p mean is: tensor(-0.4706, device='cuda:1')
epoch:  39000 quantization_loss:  0.027697967365384102
p mean is: tensor(-0.4790, device='cuda:1')
epoch:  40000 quantization_loss:  0.027640948072075844
p mean is: tensor(-0.4863, device='cuda:1')
epoch:  41000 quantization_loss:  0.02750353142619133
p mean is: tensor(-0.4931, device='cuda:1')
epoch:  42000 quantization_loss:  0.02743363194167614
p mean is: tensor(-0.4989, device='cuda:1')
epoch:  43000 quantization_loss:  0.02732986956834793
p mean is: tensor(-0.5038, device='cuda:1')
epoch:  44000 quantization_loss:  0.027282238006591797
p mean is: tensor(-0.5080, device='cuda:1')
epoch:  45000 quantization_loss:  0.027217840775847435
p mean is: tensor(-0.5115, device='cuda:1')
epoch:  46000 quantization_loss:  0.02731291577219963
p mean is: tensor(-0.5143, device='cuda:1')
epoch:  47000 quantization_loss:  0.027160707861185074
p mean is: tensor(-0.5170, device='cuda:1')
epoch:  48000 quantization_loss:  0.02715999446809292
p mean is: tensor(-0.5203, device='cuda:1')
epoch:  49000 quantization_loss:  0.027115263044834137
p mean is: tensor(-0.5218, device='cuda:1')
epoch:  50000 quantization_loss:  0.027083419263362885
p mean is: tensor(-0.5238, device='cuda:1')
epoch:  51000 quantization_loss:  0.027047373354434967
p mean is: tensor(-0.5248, device='cuda:1')
epoch:  52000 quantization_loss:  0.02705785259604454
p mean is: tensor(-0.5254, device='cuda:1')
epoch:  53000 quantization_loss:  0.026996249333024025
p mean is: tensor(-0.5254, device='cuda:1')
epoch:  54000 quantization_loss:  0.027044691145420074
p mean is: tensor(-0.5253, device='cuda:1')
epoch:  55000 quantization_loss:  0.026962723582983017
p mean is: tensor(-0.5256, device='cuda:1')
epoch:  56000 quantization_loss:  0.02698993869125843
p mean is: tensor(-0.5260, device='cuda:1')
epoch:  57000 quantization_loss:  0.02693859674036503
p mean is: tensor(-0.5262, device='cuda:1')
epoch:  58000 quantization_loss:  0.02693462371826172
p mean is: tensor(-0.5258, device='cuda:1')
epoch:  59000 quantization_loss:  0.026921026408672333
p mean is: tensor(-0.5251, device='cuda:1')
epoch:  60000 quantization_loss:  0.02689805068075657
p mean is: tensor(-0.5251, device='cuda:1')
epoch:  61000 quantization_loss:  0.026927417144179344
p mean is: tensor(-0.5249, device='cuda:1')
epoch:  62000 quantization_loss:  0.026880327612161636
p mean is: tensor(-0.5246, device='cuda:1')
epoch:  63000 quantization_loss:  0.02695043385028839
p mean is: tensor(-0.5243, device='cuda:1')
epoch:  64000 quantization_loss:  0.02691672556102276
p mean is: tensor(-0.5243, device='cuda:1')
epoch:  65000 quantization_loss:  0.026846466585993767
p mean is: tensor(-0.5250, device='cuda:1')
epoch:  66000 quantization_loss:  0.027171170338988304
p mean is: tensor(-0.5257, device='cuda:1')
epoch:  67000 quantization_loss:  0.02685822919011116
p mean is: tensor(-0.5250, device='cuda:1')
epoch:  68000 quantization_loss:  0.026830561459064484
p mean is: tensor(-0.5251, device='cuda:1')
epoch:  69000 quantization_loss:  0.026828590780496597
p mean is: tensor(-0.5251, device='cuda:1')
epoch:  70000 quantization_loss:  0.026838630437850952
p mean is: tensor(-0.5255, device='cuda:1')
epoch:  71000 quantization_loss:  0.026808375492691994
p mean is: tensor(-0.5257, device='cuda:1')
epoch:  72000 quantization_loss:  0.026808399707078934
p mean is: tensor(-0.5257, device='cuda:1')
epoch:  73000 quantization_loss:  0.026813827455043793
p mean is: tensor(-0.5254, device='cuda:1')
epoch:  74000 quantization_loss:  0.02688436023890972
p mean is: tensor(-0.5255, device='cuda:1')
epoch:  75000 quantization_loss:  0.02678646892309189
p mean is: tensor(-0.5256, device='cuda:1')
epoch:  76000 quantization_loss:  0.02679191716015339
p mean is: tensor(-0.5255, device='cuda:1')
epoch:  77000 quantization_loss:  0.02676989696919918
p mean is: tensor(-0.5250, device='cuda:1')
epoch:  78000 quantization_loss:  0.026779726147651672
p mean is: tensor(-0.5251, device='cuda:1')
epoch:  79000 quantization_loss:  0.026788022369146347
p mean is: tensor(-0.5253, device='cuda:1')
here
1.1.weight           | nonzeros =    4873 /   16384             ( 29.74%) | total_pruned =   11511 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =    3703 /   16384             ( 22.60%) | total_pruned =   12681 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    4806 /   16384             ( 29.33%) | total_pruned =   11578 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =    4719 /   16384             ( 28.80%) | total_pruned =   11665 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =    4092 /   16384             ( 24.98%) | total_pruned =   12292 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =    3774 /   16384             ( 23.03%) | total_pruned =   12610 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     188 /     384             ( 48.96%) | total_pruned =     196 | shape = torch.Size([3, 128, 1, 1])
alive: 26696, pruned : 73528, total: 100224, Compression rate :       3.75x  ( 73.36% pruned)
PSNR of output image is:  17.275061562650794
Experiment done
