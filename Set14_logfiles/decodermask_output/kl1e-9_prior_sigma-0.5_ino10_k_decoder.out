(3, 512, 512)
Starting vanilla DIP on 10 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.18252384799153'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 16, 16])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/10/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-0.5/1e-09
epoch:  0 quantization_loss:  0.06133294105529785
p mean is: tensor(-7.9735e-05, device='cuda:3')
epoch:  1000 quantization_loss:  0.05757102742791176
p mean is: tensor(-0.0075, device='cuda:3')
epoch:  2000 quantization_loss:  0.04746227338910103
p mean is: tensor(-0.0078, device='cuda:3')
epoch:  3000 quantization_loss:  0.033047839999198914
p mean is: tensor(-0.0014, device='cuda:3')
epoch:  4000 quantization_loss:  0.03020847588777542
p mean is: tensor(-0.0013, device='cuda:3')
epoch:  5000 quantization_loss:  0.02849104441702366
p mean is: tensor(-0.0007, device='cuda:3')
epoch:  6000 quantization_loss:  0.026974383741617203
p mean is: tensor(-0.0005, device='cuda:3')
epoch:  7000 quantization_loss:  0.025739746168255806
p mean is: tensor(0.0005, device='cuda:3')
epoch:  8000 quantization_loss:  0.02575037255883217
p mean is: tensor(-8.8864e-05, device='cuda:3')
epoch:  9000 quantization_loss:  0.02504214085638523
p mean is: tensor(-0.0015, device='cuda:3')
epoch:  10000 quantization_loss:  0.024424953386187553
p mean is: tensor(-0.0030, device='cuda:3')
epoch:  11000 quantization_loss:  0.023782875388860703
p mean is: tensor(-0.0066, device='cuda:3')
epoch:  12000 quantization_loss:  0.023324310779571533
p mean is: tensor(-0.0121, device='cuda:3')
epoch:  13000 quantization_loss:  0.022887954488396645
p mean is: tensor(-0.0202, device='cuda:3')
epoch:  14000 quantization_loss:  0.022401584312319756
p mean is: tensor(-0.0291, device='cuda:3')
epoch:  15000 quantization_loss:  0.022208241745829582
p mean is: tensor(-0.0387, device='cuda:3')
epoch:  16000 quantization_loss:  0.021965468302369118
p mean is: tensor(-0.0485, device='cuda:3')
epoch:  17000 quantization_loss:  0.021551258862018585
p mean is: tensor(-0.0580, device='cuda:3')
epoch:  18000 quantization_loss:  0.02132469043135643
p mean is: tensor(-0.0678, device='cuda:3')
epoch:  19000 quantization_loss:  0.021076718345284462
p mean is: tensor(-0.0761, device='cuda:3')
epoch:  20000 quantization_loss:  0.02095176838338375
p mean is: tensor(-0.0849, device='cuda:3')
epoch:  21000 quantization_loss:  0.020677898079156876
p mean is: tensor(-0.0937, device='cuda:3')
epoch:  22000 quantization_loss:  0.020606065168976784
p mean is: tensor(-0.1014, device='cuda:3')
epoch:  23000 quantization_loss:  0.020462267100811005
p mean is: tensor(-0.1085, device='cuda:3')
epoch:  24000 quantization_loss:  0.020298058167099953
p mean is: tensor(-0.1155, device='cuda:3')
epoch:  25000 quantization_loss:  0.020223166793584824
p mean is: tensor(-0.1220, device='cuda:3')
epoch:  26000 quantization_loss:  0.020044874399900436
p mean is: tensor(-0.1271, device='cuda:3')
epoch:  27000 quantization_loss:  0.019942941144108772
p mean is: tensor(-0.1335, device='cuda:3')
epoch:  28000 quantization_loss:  0.019839715212583542
p mean is: tensor(-0.1386, device='cuda:3')
epoch:  29000 quantization_loss:  0.01972942426800728
p mean is: tensor(-0.1419, device='cuda:3')
epoch:  30000 quantization_loss:  0.01973515935242176
p mean is: tensor(-0.1451, device='cuda:3')
epoch:  31000 quantization_loss:  0.01956549659371376
p mean is: tensor(-0.1476, device='cuda:3')
epoch:  32000 quantization_loss:  0.019684923812747
p mean is: tensor(-0.1500, device='cuda:3')
epoch:  33000 quantization_loss:  0.019457576796412468
p mean is: tensor(-0.1512, device='cuda:3')
epoch:  34000 quantization_loss:  0.019451595842838287
p mean is: tensor(-0.1532, device='cuda:3')
epoch:  35000 quantization_loss:  0.01937285251915455
p mean is: tensor(-0.1534, device='cuda:3')
epoch:  36000 quantization_loss:  0.01933808997273445
p mean is: tensor(-0.1536, device='cuda:3')
epoch:  37000 quantization_loss:  0.019374633207917213
p mean is: tensor(-0.1540, device='cuda:3')
epoch:  38000 quantization_loss:  0.019278354942798615
p mean is: tensor(-0.1538, device='cuda:3')
epoch:  39000 quantization_loss:  0.019248347729444504
p mean is: tensor(-0.1545, device='cuda:3')
epoch:  40000 quantization_loss:  0.019202744588255882
p mean is: tensor(-0.1545, device='cuda:3')
epoch:  41000 quantization_loss:  0.0191671010106802
p mean is: tensor(-0.1536, device='cuda:3')
epoch:  42000 quantization_loss:  0.01913200318813324
p mean is: tensor(-0.1524, device='cuda:3')
epoch:  43000 quantization_loss:  0.019146820530295372
p mean is: tensor(-0.1527, device='cuda:3')
epoch:  44000 quantization_loss:  0.01909596100449562
p mean is: tensor(-0.1516, device='cuda:3')
epoch:  45000 quantization_loss:  0.01906248927116394
p mean is: tensor(-0.1510, device='cuda:3')
epoch:  46000 quantization_loss:  0.019085967913269997
p mean is: tensor(-0.1500, device='cuda:3')
epoch:  47000 quantization_loss:  0.019065605476498604
p mean is: tensor(-0.1496, device='cuda:3')
epoch:  48000 quantization_loss:  0.01903216913342476
p mean is: tensor(-0.1483, device='cuda:3')
epoch:  49000 quantization_loss:  0.019033940508961678
p mean is: tensor(-0.1478, device='cuda:3')
epoch:  50000 quantization_loss:  0.01903780922293663
p mean is: tensor(-0.1463, device='cuda:3')
epoch:  51000 quantization_loss:  0.019021006301045418
p mean is: tensor(-0.1451, device='cuda:3')
epoch:  52000 quantization_loss:  0.01904316246509552
p mean is: tensor(-0.1435, device='cuda:3')
epoch:  53000 quantization_loss:  0.01900160126388073
p mean is: tensor(-0.1422, device='cuda:3')
epoch:  54000 quantization_loss:  0.018996478989720345
p mean is: tensor(-0.1406, device='cuda:3')
epoch:  55000 quantization_loss:  0.01897541433572769
p mean is: tensor(-0.1392, device='cuda:3')
epoch:  56000 quantization_loss:  0.018961967900395393
p mean is: tensor(-0.1388, device='cuda:3')
epoch:  57000 quantization_loss:  0.01895216852426529
p mean is: tensor(-0.1378, device='cuda:3')
epoch:  58000 quantization_loss:  0.018939156085252762
p mean is: tensor(-0.1367, device='cuda:3')
epoch:  59000 quantization_loss:  0.018934305757284164
p mean is: tensor(-0.1357, device='cuda:3')
epoch:  60000 quantization_loss:  0.01893327571451664
p mean is: tensor(-0.1349, device='cuda:3')
epoch:  61000 quantization_loss:  0.018949337303638458
p mean is: tensor(-0.1335, device='cuda:3')
epoch:  62000 quantization_loss:  0.018920471891760826
p mean is: tensor(-0.1321, device='cuda:3')
epoch:  63000 quantization_loss:  0.01892942190170288
p mean is: tensor(-0.1313, device='cuda:3')
epoch:  64000 quantization_loss:  0.019369158893823624
p mean is: tensor(-0.1302, device='cuda:3')
epoch:  65000 quantization_loss:  0.018916722387075424
p mean is: tensor(-0.1293, device='cuda:3')
epoch:  66000 quantization_loss:  0.01890391856431961
p mean is: tensor(-0.1289, device='cuda:3')
epoch:  67000 quantization_loss:  0.018907148391008377
p mean is: tensor(-0.1280, device='cuda:3')
epoch:  68000 quantization_loss:  0.018908288329839706
p mean is: tensor(-0.1270, device='cuda:3')
epoch:  69000 quantization_loss:  0.01890709437429905
p mean is: tensor(-0.1263, device='cuda:3')
epoch:  70000 quantization_loss:  0.018899651244282722
p mean is: tensor(-0.1258, device='cuda:3')
epoch:  71000 quantization_loss:  0.018897660076618195
p mean is: tensor(-0.1249, device='cuda:3')
epoch:  72000 quantization_loss:  0.01889672689139843
p mean is: tensor(-0.1244, device='cuda:3')
epoch:  73000 quantization_loss:  0.018888939172029495
p mean is: tensor(-0.1238, device='cuda:3')
epoch:  74000 quantization_loss:  0.018960721790790558
p mean is: tensor(-0.1232, device='cuda:3')
epoch:  75000 quantization_loss:  0.01890593022108078
p mean is: tensor(-0.1229, device='cuda:3')
epoch:  76000 quantization_loss:  0.0188873540610075
p mean is: tensor(-0.1229, device='cuda:3')
epoch:  77000 quantization_loss:  0.018875587731599808
p mean is: tensor(-0.1224, device='cuda:3')
epoch:  78000 quantization_loss:  0.018889494240283966
p mean is: tensor(-0.1222, device='cuda:3')
epoch:  79000 quantization_loss:  0.018867215141654015
p mean is: tensor(-0.1220, device='cuda:3')
here
1.1.weight           | nonzeros =    6065 /   16384             ( 37.02%) | total_pruned =   10319 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =    4769 /   16384             ( 29.11%) | total_pruned =   11615 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    5724 /   16384             ( 34.94%) | total_pruned =   10660 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =    4817 /   16384             ( 29.40%) | total_pruned =   11567 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =    1886 /   16384             ( 11.51%) | total_pruned =   14498 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =    1313 /   16384             (  8.01%) | total_pruned =   15071 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     151 /     384             ( 39.32%) | total_pruned =     233 | shape = torch.Size([3, 128, 1, 1])
alive: 25221, pruned : 75003, total: 100224, Compression rate :       3.97x  ( 74.84% pruned)
PSNR of output image is:  20.190229065430394
Experiment done
