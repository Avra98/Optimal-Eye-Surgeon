(3, 512, 512)
Starting vanilla DIP on 13 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.49278166410428'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 16, 16])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/13/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/0.0/1e-09
epoch:  0 quantization_loss:  0.08127474039793015
p mean is: tensor(3.1870e-06, device='cuda:3')
epoch:  1000 quantization_loss:  0.07804051786661148
p mean is: tensor(-0.0040, device='cuda:3')
epoch:  2000 quantization_loss:  0.07729531824588776
p mean is: tensor(-0.0062, device='cuda:3')
epoch:  3000 quantization_loss:  0.07702863961458206
p mean is: tensor(-0.0059, device='cuda:3')
epoch:  4000 quantization_loss:  0.05437510460615158
p mean is: tensor(-0.0020, device='cuda:3')
epoch:  5000 quantization_loss:  0.04859629645943642
p mean is: tensor(0.0010, device='cuda:3')
epoch:  6000 quantization_loss:  0.04069548100233078
p mean is: tensor(0.0051, device='cuda:3')
epoch:  7000 quantization_loss:  0.035776637494564056
p mean is: tensor(0.0075, device='cuda:3')
epoch:  8000 quantization_loss:  0.032881055027246475
p mean is: tensor(0.0094, device='cuda:3')
epoch:  9000 quantization_loss:  0.031540658324956894
p mean is: tensor(0.0118, device='cuda:3')
epoch:  10000 quantization_loss:  0.03068830631673336
p mean is: tensor(0.0130, device='cuda:3')
epoch:  11000 quantization_loss:  0.029823457822203636
p mean is: tensor(0.0130, device='cuda:3')
epoch:  12000 quantization_loss:  0.02854025550186634
p mean is: tensor(0.0130, device='cuda:3')
epoch:  13000 quantization_loss:  0.02798694372177124
p mean is: tensor(0.0123, device='cuda:3')
epoch:  14000 quantization_loss:  0.027061400935053825
p mean is: tensor(0.0127, device='cuda:3')
epoch:  15000 quantization_loss:  0.026596693322062492
p mean is: tensor(0.0115, device='cuda:3')
epoch:  16000 quantization_loss:  0.02614939771592617
p mean is: tensor(0.0085, device='cuda:3')
epoch:  17000 quantization_loss:  0.025510549545288086
p mean is: tensor(0.0072, device='cuda:3')
epoch:  18000 quantization_loss:  0.025178201496601105
p mean is: tensor(0.0067, device='cuda:3')
epoch:  19000 quantization_loss:  0.024772195145487785
p mean is: tensor(0.0052, device='cuda:3')
epoch:  20000 quantization_loss:  0.02454899623990059
p mean is: tensor(0.0041, device='cuda:3')
epoch:  21000 quantization_loss:  0.024680564180016518
p mean is: tensor(0.0027, device='cuda:3')
epoch:  22000 quantization_loss:  0.024193773046135902
p mean is: tensor(0.0015, device='cuda:3')
epoch:  23000 quantization_loss:  0.02381676249206066
p mean is: tensor(0.0019, device='cuda:3')
epoch:  24000 quantization_loss:  0.023693187162280083
p mean is: tensor(0.0018, device='cuda:3')
epoch:  25000 quantization_loss:  0.023493485525250435
p mean is: tensor(0.0014, device='cuda:3')
epoch:  26000 quantization_loss:  0.02339685894548893
p mean is: tensor(0.0022, device='cuda:3')
epoch:  27000 quantization_loss:  0.02320426143705845
p mean is: tensor(0.0024, device='cuda:3')
epoch:  28000 quantization_loss:  0.023149888962507248
p mean is: tensor(0.0030, device='cuda:3')
epoch:  29000 quantization_loss:  0.02294386923313141
p mean is: tensor(0.0041, device='cuda:3')
epoch:  30000 quantization_loss:  0.022863049060106277
p mean is: tensor(0.0060, device='cuda:3')
epoch:  31000 quantization_loss:  0.02281562238931656
p mean is: tensor(0.0075, device='cuda:3')
epoch:  32000 quantization_loss:  0.022717487066984177
p mean is: tensor(0.0099, device='cuda:3')
epoch:  33000 quantization_loss:  0.022674202919006348
p mean is: tensor(0.0113, device='cuda:3')
epoch:  34000 quantization_loss:  0.022535203024744987
p mean is: tensor(0.0140, device='cuda:3')
epoch:  35000 quantization_loss:  0.022502794861793518
p mean is: tensor(0.0165, device='cuda:3')
epoch:  36000 quantization_loss:  0.022340165451169014
p mean is: tensor(0.0183, device='cuda:3')
epoch:  37000 quantization_loss:  0.0223071426153183
p mean is: tensor(0.0207, device='cuda:3')
epoch:  38000 quantization_loss:  0.022257588803768158
p mean is: tensor(0.0231, device='cuda:3')
epoch:  39000 quantization_loss:  0.022215478122234344
p mean is: tensor(0.0248, device='cuda:3')
epoch:  40000 quantization_loss:  0.022163309156894684
p mean is: tensor(0.0269, device='cuda:3')
epoch:  41000 quantization_loss:  0.022150250151753426
p mean is: tensor(0.0287, device='cuda:3')
epoch:  42000 quantization_loss:  0.02210431918501854
p mean is: tensor(0.0300, device='cuda:3')
epoch:  43000 quantization_loss:  0.022328590974211693
p mean is: tensor(0.0312, device='cuda:3')
epoch:  44000 quantization_loss:  0.022059882059693336
p mean is: tensor(0.0323, device='cuda:3')
epoch:  45000 quantization_loss:  0.021993892267346382
p mean is: tensor(0.0334, device='cuda:3')
epoch:  46000 quantization_loss:  0.0219988115131855
p mean is: tensor(0.0340, device='cuda:3')
epoch:  47000 quantization_loss:  0.021962756291031837
p mean is: tensor(0.0354, device='cuda:3')
epoch:  48000 quantization_loss:  0.021954460069537163
p mean is: tensor(0.0367, device='cuda:3')
epoch:  49000 quantization_loss:  0.021955285221338272
p mean is: tensor(0.0376, device='cuda:3')
epoch:  50000 quantization_loss:  0.02194773405790329
p mean is: tensor(0.0382, device='cuda:3')
epoch:  51000 quantization_loss:  0.02198861539363861
p mean is: tensor(0.0379, device='cuda:3')
epoch:  52000 quantization_loss:  0.021906111389398575
p mean is: tensor(0.0383, device='cuda:3')
epoch:  53000 quantization_loss:  0.0218616034835577
p mean is: tensor(0.0389, device='cuda:3')
epoch:  54000 quantization_loss:  0.02195233479142189
p mean is: tensor(0.0392, device='cuda:3')
epoch:  55000 quantization_loss:  0.02184748277068138
p mean is: tensor(0.0396, device='cuda:3')
epoch:  56000 quantization_loss:  0.02189239300787449
p mean is: tensor(0.0402, device='cuda:3')
epoch:  57000 quantization_loss:  0.021817632019519806
p mean is: tensor(0.0406, device='cuda:3')
epoch:  58000 quantization_loss:  0.02171892672777176
p mean is: tensor(0.0415, device='cuda:3')
epoch:  59000 quantization_loss:  0.02169494517147541
p mean is: tensor(0.0422, device='cuda:3')
epoch:  60000 quantization_loss:  0.021711766719818115
p mean is: tensor(0.0430, device='cuda:3')
epoch:  61000 quantization_loss:  0.021681228652596474
p mean is: tensor(0.0434, device='cuda:3')
epoch:  62000 quantization_loss:  0.021742386743426323
p mean is: tensor(0.0436, device='cuda:3')
epoch:  63000 quantization_loss:  0.021685028448700905
p mean is: tensor(0.0436, device='cuda:3')
epoch:  64000 quantization_loss:  0.021804839372634888
p mean is: tensor(0.0433, device='cuda:3')
epoch:  65000 quantization_loss:  0.02167382277548313
p mean is: tensor(0.0432, device='cuda:3')
epoch:  66000 quantization_loss:  0.02165459282696247
p mean is: tensor(0.0430, device='cuda:3')
epoch:  67000 quantization_loss:  0.02167438343167305
p mean is: tensor(0.0428, device='cuda:3')
epoch:  68000 quantization_loss:  0.02166282758116722
p mean is: tensor(0.0426, device='cuda:3')
epoch:  69000 quantization_loss:  0.02164497785270214
p mean is: tensor(0.0421, device='cuda:3')
epoch:  70000 quantization_loss:  0.02165648154914379
p mean is: tensor(0.0419, device='cuda:3')
epoch:  71000 quantization_loss:  0.02167903445661068
p mean is: tensor(0.0421, device='cuda:3')
epoch:  72000 quantization_loss:  0.02165241539478302
p mean is: tensor(0.0425, device='cuda:3')
epoch:  73000 quantization_loss:  0.021648503839969635
p mean is: tensor(0.0427, device='cuda:3')
epoch:  74000 quantization_loss:  0.021676162257790565
p mean is: tensor(0.0425, device='cuda:3')
epoch:  75000 quantization_loss:  0.021648410707712173
p mean is: tensor(0.0424, device='cuda:3')
epoch:  76000 quantization_loss:  0.02163209393620491
p mean is: tensor(0.0424, device='cuda:3')
epoch:  77000 quantization_loss:  0.021629109978675842
p mean is: tensor(0.0429, device='cuda:3')
epoch:  78000 quantization_loss:  0.021644406020641327
p mean is: tensor(0.0431, device='cuda:3')
epoch:  79000 quantization_loss:  0.021569227799773216
p mean is: tensor(0.0434, device='cuda:3')
here
1.1.weight           | nonzeros =    8582 /   16384             ( 52.38%) | total_pruned =    7802 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =    7301 /   16384             ( 44.56%) | total_pruned =    9083 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    7563 /   16384             ( 46.16%) | total_pruned =    8821 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =    7071 /   16384             ( 43.16%) | total_pruned =    9313 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =    6358 /   16384             ( 38.81%) | total_pruned =   10026 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =    6604 /   16384             ( 40.31%) | total_pruned =    9780 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     225 /     384             ( 58.59%) | total_pruned =     159 | shape = torch.Size([3, 128, 1, 1])
alive: 44227, pruned : 55997, total: 100224, Compression rate :       2.27x  ( 55.87% pruned)
PSNR of output image is:  18.444713053735498
Experiment done
