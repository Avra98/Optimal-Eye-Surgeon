(3, 512, 512)
Starting vanilla DIP on 5 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.09319053653868'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 16, 16])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/5/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-0.5/1e-09
epoch:  0 quantization_loss:  0.06528671830892563
p mean is: tensor(-9.2007e-05, device='cuda:2')
epoch:  1000 quantization_loss:  0.059568554162979126
p mean is: tensor(-0.0079, device='cuda:2')
epoch:  2000 quantization_loss:  0.049348026514053345
p mean is: tensor(-0.0068, device='cuda:2')
epoch:  3000 quantization_loss:  0.04425393417477608
p mean is: tensor(-0.0012, device='cuda:2')
epoch:  4000 quantization_loss:  0.042307719588279724
p mean is: tensor(-0.0009, device='cuda:2')
epoch:  5000 quantization_loss:  0.040014538913965225
p mean is: tensor(-0.0003, device='cuda:2')
epoch:  6000 quantization_loss:  0.037388674914836884
p mean is: tensor(0.0039, device='cuda:2')
epoch:  7000 quantization_loss:  0.03581111133098602
p mean is: tensor(0.0079, device='cuda:2')
epoch:  8000 quantization_loss:  0.03322172909975052
p mean is: tensor(0.0091, device='cuda:2')
epoch:  9000 quantization_loss:  0.03175733610987663
p mean is: tensor(0.0099, device='cuda:2')
epoch:  10000 quantization_loss:  0.02993161976337433
p mean is: tensor(0.0097, device='cuda:2')
epoch:  11000 quantization_loss:  0.02920812927186489
p mean is: tensor(0.0083, device='cuda:2')
epoch:  12000 quantization_loss:  0.02864324301481247
p mean is: tensor(0.0060, device='cuda:2')
epoch:  13000 quantization_loss:  0.02742699719965458
p mean is: tensor(0.0006, device='cuda:2')
epoch:  14000 quantization_loss:  0.026445789262652397
p mean is: tensor(-0.0041, device='cuda:2')
epoch:  15000 quantization_loss:  0.02563433349132538
p mean is: tensor(-0.0112, device='cuda:2')
epoch:  16000 quantization_loss:  0.02505061961710453
p mean is: tensor(-0.0180, device='cuda:2')
epoch:  17000 quantization_loss:  0.024520255625247955
p mean is: tensor(-0.0254, device='cuda:2')
epoch:  18000 quantization_loss:  0.023982249200344086
p mean is: tensor(-0.0320, device='cuda:2')
epoch:  19000 quantization_loss:  0.0234677754342556
p mean is: tensor(-0.0404, device='cuda:2')
epoch:  20000 quantization_loss:  0.023224474862217903
p mean is: tensor(-0.0477, device='cuda:2')
epoch:  21000 quantization_loss:  0.02262701466679573
p mean is: tensor(-0.0549, device='cuda:2')
epoch:  22000 quantization_loss:  0.02225986309349537
p mean is: tensor(-0.0634, device='cuda:2')
epoch:  23000 quantization_loss:  0.022130213677883148
p mean is: tensor(-0.0705, device='cuda:2')
epoch:  24000 quantization_loss:  0.02179437130689621
p mean is: tensor(-0.0778, device='cuda:2')
epoch:  25000 quantization_loss:  0.021460222080349922
p mean is: tensor(-0.0839, device='cuda:2')
epoch:  26000 quantization_loss:  0.02138802409172058
p mean is: tensor(-0.0890, device='cuda:2')
epoch:  27000 quantization_loss:  0.02129209414124489
p mean is: tensor(-0.0940, device='cuda:2')
epoch:  28000 quantization_loss:  0.021110905334353447
p mean is: tensor(-0.0991, device='cuda:2')
epoch:  29000 quantization_loss:  0.021065877750515938
p mean is: tensor(-0.1035, device='cuda:2')
epoch:  30000 quantization_loss:  0.02102246694266796
p mean is: tensor(-0.1075, device='cuda:2')
epoch:  31000 quantization_loss:  0.020763572305440903
p mean is: tensor(-0.1106, device='cuda:2')
epoch:  32000 quantization_loss:  0.02071181870996952
p mean is: tensor(-0.1134, device='cuda:2')
epoch:  33000 quantization_loss:  0.020534304901957512
p mean is: tensor(-0.1156, device='cuda:2')
epoch:  34000 quantization_loss:  0.02068173699080944
p mean is: tensor(-0.1164, device='cuda:2')
epoch:  35000 quantization_loss:  0.021007288247346878
p mean is: tensor(-0.1178, device='cuda:2')
epoch:  36000 quantization_loss:  0.020322047173976898
p mean is: tensor(-0.1187, device='cuda:2')
epoch:  37000 quantization_loss:  0.02027837559580803
p mean is: tensor(-0.1201, device='cuda:2')
epoch:  38000 quantization_loss:  0.020317168906331062
p mean is: tensor(-0.1206, device='cuda:2')
epoch:  39000 quantization_loss:  0.020625606179237366
p mean is: tensor(-0.1212, device='cuda:2')
epoch:  40000 quantization_loss:  0.020212257280945778
p mean is: tensor(-0.1214, device='cuda:2')
epoch:  41000 quantization_loss:  0.02017730101943016
p mean is: tensor(-0.1213, device='cuda:2')
epoch:  42000 quantization_loss:  0.0202132947742939
p mean is: tensor(-0.1212, device='cuda:2')
epoch:  43000 quantization_loss:  0.020546631887555122
p mean is: tensor(-0.1215, device='cuda:2')
epoch:  44000 quantization_loss:  0.020068524405360222
p mean is: tensor(-0.1212, device='cuda:2')
epoch:  45000 quantization_loss:  0.02010009065270424
p mean is: tensor(-0.1215, device='cuda:2')
epoch:  46000 quantization_loss:  0.020066579803824425
p mean is: tensor(-0.1218, device='cuda:2')
epoch:  47000 quantization_loss:  0.02003508247435093
p mean is: tensor(-0.1222, device='cuda:2')
epoch:  48000 quantization_loss:  0.02002996765077114
p mean is: tensor(-0.1226, device='cuda:2')
epoch:  49000 quantization_loss:  0.020032649859786034
p mean is: tensor(-0.1226, device='cuda:2')
epoch:  50000 quantization_loss:  0.020163731649518013
p mean is: tensor(-0.1234, device='cuda:2')
epoch:  51000 quantization_loss:  0.020028473809361458
p mean is: tensor(-0.1235, device='cuda:2')
epoch:  52000 quantization_loss:  0.020001843571662903
p mean is: tensor(-0.1232, device='cuda:2')
epoch:  53000 quantization_loss:  0.01998654007911682
p mean is: tensor(-0.1233, device='cuda:2')
epoch:  54000 quantization_loss:  0.019971251487731934
p mean is: tensor(-0.1228, device='cuda:2')
epoch:  55000 quantization_loss:  0.019996197894215584
p mean is: tensor(-0.1228, device='cuda:2')
epoch:  56000 quantization_loss:  0.019952265545725822
p mean is: tensor(-0.1231, device='cuda:2')
epoch:  57000 quantization_loss:  0.01996026746928692
p mean is: tensor(-0.1225, device='cuda:2')
epoch:  58000 quantization_loss:  0.019946862012147903
p mean is: tensor(-0.1218, device='cuda:2')
epoch:  59000 quantization_loss:  0.019990423694252968
p mean is: tensor(-0.1218, device='cuda:2')
epoch:  60000 quantization_loss:  0.019957002252340317
p mean is: tensor(-0.1217, device='cuda:2')
epoch:  61000 quantization_loss:  0.019912239164114
p mean is: tensor(-0.1222, device='cuda:2')
epoch:  62000 quantization_loss:  0.019913392141461372
p mean is: tensor(-0.1229, device='cuda:2')
epoch:  63000 quantization_loss:  0.019925571978092194
p mean is: tensor(-0.1236, device='cuda:2')
epoch:  64000 quantization_loss:  0.019903510808944702
p mean is: tensor(-0.1235, device='cuda:2')
epoch:  65000 quantization_loss:  0.019914347678422928
p mean is: tensor(-0.1229, device='cuda:2')
epoch:  66000 quantization_loss:  0.01991005428135395
p mean is: tensor(-0.1224, device='cuda:2')
epoch:  67000 quantization_loss:  0.019929664209485054
p mean is: tensor(-0.1223, device='cuda:2')
epoch:  68000 quantization_loss:  0.019889550283551216
p mean is: tensor(-0.1221, device='cuda:2')
epoch:  69000 quantization_loss:  0.019900964573025703
p mean is: tensor(-0.1222, device='cuda:2')
epoch:  70000 quantization_loss:  0.019974395632743835
p mean is: tensor(-0.1223, device='cuda:2')
epoch:  71000 quantization_loss:  0.019876373931765556
p mean is: tensor(-0.1223, device='cuda:2')
epoch:  72000 quantization_loss:  0.019929412752389908
p mean is: tensor(-0.1224, device='cuda:2')
epoch:  73000 quantization_loss:  0.019870532676577568
p mean is: tensor(-0.1219, device='cuda:2')
epoch:  74000 quantization_loss:  0.019971322268247604
p mean is: tensor(-0.1218, device='cuda:2')
epoch:  75000 quantization_loss:  0.019862860441207886
p mean is: tensor(-0.1220, device='cuda:2')
epoch:  76000 quantization_loss:  0.019858775660395622
p mean is: tensor(-0.1225, device='cuda:2')
epoch:  77000 quantization_loss:  0.019859058782458305
p mean is: tensor(-0.1225, device='cuda:2')
epoch:  78000 quantization_loss:  0.020082151517271996
p mean is: tensor(-0.1222, device='cuda:2')
epoch:  79000 quantization_loss:  0.019892798736691475
p mean is: tensor(-0.1218, device='cuda:2')
here
1.1.weight           | nonzeros =    6751 /   16384             ( 41.20%) | total_pruned =    9633 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =    5268 /   16384             ( 32.15%) | total_pruned =   11116 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =     114 /     128             ( 89.06%) | total_pruned =      14 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    6393 /   16384             ( 39.02%) | total_pruned =    9991 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =    5874 /   16384             ( 35.85%) | total_pruned =   10510 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =    3664 /   16384             ( 22.36%) | total_pruned =   12720 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =    3095 /   16384             ( 18.89%) | total_pruned =   13289 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     184 /     384             ( 47.92%) | total_pruned =     200 | shape = torch.Size([3, 128, 1, 1])
alive: 31824, pruned : 68400, total: 100224, Compression rate :       3.15x  ( 68.25% pruned)
PSNR of output image is:  19.63716158950755
Experiment done
