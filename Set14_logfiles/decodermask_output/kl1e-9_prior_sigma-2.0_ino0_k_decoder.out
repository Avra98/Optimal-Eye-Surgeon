(3, 512, 512)
Starting vanilla DIP on 0 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '19.673738397056745'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 16, 16])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/0/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-2.0/1e-09
epoch:  0 quantization_loss:  0.0797685757279396
p mean is: tensor(-0.0003, device='cuda:3')
epoch:  1000 quantization_loss:  0.07864230126142502
p mean is: tensor(-0.0110, device='cuda:3')
epoch:  2000 quantization_loss:  0.07272172719240189
p mean is: tensor(-0.0185, device='cuda:3')
epoch:  3000 quantization_loss:  0.055368803441524506
p mean is: tensor(-0.0213, device='cuda:3')
epoch:  4000 quantization_loss:  0.04767559468746185
p mean is: tensor(-0.0296, device='cuda:3')
epoch:  5000 quantization_loss:  0.045760735869407654
p mean is: tensor(-0.0382, device='cuda:3')
epoch:  6000 quantization_loss:  0.04316923767328262
p mean is: tensor(-0.0472, device='cuda:3')
epoch:  7000 quantization_loss:  0.04000601917505264
p mean is: tensor(-0.0571, device='cuda:3')
epoch:  8000 quantization_loss:  0.0352182611823082
p mean is: tensor(-0.0687, device='cuda:3')
epoch:  9000 quantization_loss:  0.03237239271402359
p mean is: tensor(-0.0825, device='cuda:3')
epoch:  10000 quantization_loss:  0.03149469569325447
p mean is: tensor(-0.0993, device='cuda:3')
epoch:  11000 quantization_loss:  0.031281955540180206
p mean is: tensor(-0.1187, device='cuda:3')
epoch:  12000 quantization_loss:  0.02995213121175766
p mean is: tensor(-0.1425, device='cuda:3')
epoch:  13000 quantization_loss:  0.029042048379778862
p mean is: tensor(-0.1714, device='cuda:3')
epoch:  14000 quantization_loss:  0.028891492635011673
p mean is: tensor(-0.2040, device='cuda:3')
epoch:  15000 quantization_loss:  0.028016120195388794
p mean is: tensor(-0.2366, device='cuda:3')
epoch:  16000 quantization_loss:  0.027470555156469345
p mean is: tensor(-0.2713, device='cuda:3')
epoch:  17000 quantization_loss:  0.026963310316205025
p mean is: tensor(-0.3058, device='cuda:3')
epoch:  18000 quantization_loss:  0.02661546692252159
p mean is: tensor(-0.3413, device='cuda:3')
epoch:  19000 quantization_loss:  0.026609566062688828
p mean is: tensor(-0.3758, device='cuda:3')
epoch:  20000 quantization_loss:  0.026116201654076576
p mean is: tensor(-0.4094, device='cuda:3')
epoch:  21000 quantization_loss:  0.025629930198192596
p mean is: tensor(-0.4418, device='cuda:3')
epoch:  22000 quantization_loss:  0.025592420250177383
p mean is: tensor(-0.4733, device='cuda:3')
epoch:  23000 quantization_loss:  0.025341609492897987
p mean is: tensor(-0.5031, device='cuda:3')
epoch:  24000 quantization_loss:  0.025112973526120186
p mean is: tensor(-0.5308, device='cuda:3')
epoch:  25000 quantization_loss:  0.025041457265615463
p mean is: tensor(-0.5576, device='cuda:3')
epoch:  26000 quantization_loss:  0.024589724838733673
p mean is: tensor(-0.5836, device='cuda:3')
epoch:  27000 quantization_loss:  0.024519795551896095
p mean is: tensor(-0.6071, device='cuda:3')
epoch:  28000 quantization_loss:  0.02431982196867466
p mean is: tensor(-0.6273, device='cuda:3')
epoch:  29000 quantization_loss:  0.02395113743841648
p mean is: tensor(-0.6473, device='cuda:3')
epoch:  30000 quantization_loss:  0.023911530151963234
p mean is: tensor(-0.6657, device='cuda:3')
epoch:  31000 quantization_loss:  0.023840630427002907
p mean is: tensor(-0.6840, device='cuda:3')
epoch:  32000 quantization_loss:  0.023913336917757988
p mean is: tensor(-0.6998, device='cuda:3')
epoch:  33000 quantization_loss:  0.02383984439074993
p mean is: tensor(-0.7150, device='cuda:3')
epoch:  34000 quantization_loss:  0.023693162947893143
p mean is: tensor(-0.7287, device='cuda:3')
epoch:  35000 quantization_loss:  0.02351740561425686
p mean is: tensor(-0.7405, device='cuda:3')
epoch:  36000 quantization_loss:  0.023409634828567505
p mean is: tensor(-0.7515, device='cuda:3')
epoch:  37000 quantization_loss:  0.023435737937688828
p mean is: tensor(-0.7613, device='cuda:3')
epoch:  38000 quantization_loss:  0.02330256998538971
p mean is: tensor(-0.7707, device='cuda:3')
epoch:  39000 quantization_loss:  0.023252498358488083
p mean is: tensor(-0.7801, device='cuda:3')
epoch:  40000 quantization_loss:  0.023549603298306465
p mean is: tensor(-0.7880, device='cuda:3')
epoch:  41000 quantization_loss:  0.023014279082417488
p mean is: tensor(-0.7949, device='cuda:3')
epoch:  42000 quantization_loss:  0.022966742515563965
p mean is: tensor(-0.8012, device='cuda:3')
epoch:  43000 quantization_loss:  0.022960606962442398
p mean is: tensor(-0.8064, device='cuda:3')
epoch:  44000 quantization_loss:  0.02296075038611889
p mean is: tensor(-0.8112, device='cuda:3')
epoch:  45000 quantization_loss:  0.02298096753656864
p mean is: tensor(-0.8156, device='cuda:3')
epoch:  46000 quantization_loss:  0.022911779582500458
p mean is: tensor(-0.8200, device='cuda:3')
epoch:  47000 quantization_loss:  0.02295716665685177
p mean is: tensor(-0.8242, device='cuda:3')
epoch:  48000 quantization_loss:  0.022883234545588493
p mean is: tensor(-0.8288, device='cuda:3')
epoch:  49000 quantization_loss:  0.02284177578985691
p mean is: tensor(-0.8324, device='cuda:3')
epoch:  50000 quantization_loss:  0.022809874266386032
p mean is: tensor(-0.8356, device='cuda:3')
epoch:  51000 quantization_loss:  0.022548802196979523
p mean is: tensor(-0.8385, device='cuda:3')
epoch:  52000 quantization_loss:  0.022497160360217094
p mean is: tensor(-0.8415, device='cuda:3')
epoch:  53000 quantization_loss:  0.022555796429514885
p mean is: tensor(-0.8446, device='cuda:3')
epoch:  54000 quantization_loss:  0.022411804646253586
p mean is: tensor(-0.8478, device='cuda:3')
epoch:  55000 quantization_loss:  0.022357899695634842
p mean is: tensor(-0.8512, device='cuda:3')
epoch:  56000 quantization_loss:  0.022350233048200607
p mean is: tensor(-0.8531, device='cuda:3')
epoch:  57000 quantization_loss:  0.02241109311580658
p mean is: tensor(-0.8552, device='cuda:3')
epoch:  58000 quantization_loss:  0.02230175957083702
p mean is: tensor(-0.8573, device='cuda:3')
epoch:  59000 quantization_loss:  0.02226480469107628
p mean is: tensor(-0.8589, device='cuda:3')
epoch:  60000 quantization_loss:  0.02226688526570797
p mean is: tensor(-0.8611, device='cuda:3')
epoch:  61000 quantization_loss:  0.022255148738622665
p mean is: tensor(-0.8627, device='cuda:3')
epoch:  62000 quantization_loss:  0.02229565568268299
p mean is: tensor(-0.8645, device='cuda:3')
epoch:  63000 quantization_loss:  0.022227369248867035
p mean is: tensor(-0.8654, device='cuda:3')
epoch:  64000 quantization_loss:  0.0222266037017107
p mean is: tensor(-0.8661, device='cuda:3')
epoch:  65000 quantization_loss:  0.022213494405150414
p mean is: tensor(-0.8670, device='cuda:3')
epoch:  66000 quantization_loss:  0.02221890166401863
p mean is: tensor(-0.8680, device='cuda:3')
epoch:  67000 quantization_loss:  0.022196728736162186
p mean is: tensor(-0.8690, device='cuda:3')
epoch:  68000 quantization_loss:  0.022210650146007538
p mean is: tensor(-0.8697, device='cuda:3')
epoch:  69000 quantization_loss:  0.022184744477272034
p mean is: tensor(-0.8704, device='cuda:3')
epoch:  70000 quantization_loss:  0.022177191451191902
p mean is: tensor(-0.8715, device='cuda:3')
epoch:  71000 quantization_loss:  0.022153133526444435
p mean is: tensor(-0.8725, device='cuda:3')
epoch:  72000 quantization_loss:  0.02216927334666252
p mean is: tensor(-0.8733, device='cuda:3')
epoch:  73000 quantization_loss:  0.02216285467147827
p mean is: tensor(-0.8745, device='cuda:3')
epoch:  74000 quantization_loss:  0.022147951647639275
p mean is: tensor(-0.8752, device='cuda:3')
epoch:  75000 quantization_loss:  0.022134549915790558
p mean is: tensor(-0.8753, device='cuda:3')
epoch:  76000 quantization_loss:  0.02214622311294079
p mean is: tensor(-0.8760, device='cuda:3')
epoch:  77000 quantization_loss:  0.02212096005678177
p mean is: tensor(-0.8765, device='cuda:3')
epoch:  78000 quantization_loss:  0.022117311134934425
p mean is: tensor(-0.8770, device='cuda:3')
epoch:  79000 quantization_loss:  0.022128811106085777
p mean is: tensor(-0.8778, device='cuda:3')
here
1.1.weight           | nonzeros =    5712 /   16384             ( 34.86%) | total_pruned =   10672 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =    4776 /   16384             ( 29.15%) | total_pruned =   11608 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    5608 /   16384             ( 34.23%) | total_pruned =   10776 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =    4793 /   16384             ( 29.25%) | total_pruned =   11591 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =    3898 /   16384             ( 23.79%) | total_pruned =   12486 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =    4634 /   16384             ( 28.28%) | total_pruned =   11750 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     212 /     384             ( 55.21%) | total_pruned =     172 | shape = torch.Size([3, 128, 1, 1])
alive: 30235, pruned : 69989, total: 100224, Compression rate :       3.31x  ( 69.83% pruned)
PSNR of output image is:  18.026501454872395
Experiment done
