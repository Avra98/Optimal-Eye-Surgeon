(3, 256, 256)
Starting vanilla DIP on 1 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.48535273602451'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 8, 8])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/1/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-0.5/1e-09
epoch:  0 quantization_loss:  0.09322693198919296
p mean is: tensor(-7.9173e-05, device='cuda:4')
epoch:  1000 quantization_loss:  0.08984285593032837
p mean is: tensor(-0.0035, device='cuda:4')
epoch:  2000 quantization_loss:  0.05817553400993347
p mean is: tensor(0.0018, device='cuda:4')
epoch:  3000 quantization_loss:  0.048921044915914536
p mean is: tensor(0.0016, device='cuda:4')
epoch:  4000 quantization_loss:  0.04660061374306679
p mean is: tensor(0.0005, device='cuda:4')
epoch:  5000 quantization_loss:  0.04238840565085411
p mean is: tensor(-0.0035, device='cuda:4')
epoch:  6000 quantization_loss:  0.039410777390003204
p mean is: tensor(-0.0081, device='cuda:4')
epoch:  7000 quantization_loss:  0.03672930598258972
p mean is: tensor(-0.0113, device='cuda:4')
epoch:  8000 quantization_loss:  0.035558976233005524
p mean is: tensor(-0.0153, device='cuda:4')
epoch:  9000 quantization_loss:  0.033627744764089584
p mean is: tensor(-0.0179, device='cuda:4')
epoch:  10000 quantization_loss:  0.03410108759999275
p mean is: tensor(-0.0203, device='cuda:4')
epoch:  11000 quantization_loss:  0.03213636577129364
p mean is: tensor(-0.0221, device='cuda:4')
epoch:  12000 quantization_loss:  0.0314091257750988
p mean is: tensor(-0.0249, device='cuda:4')
epoch:  13000 quantization_loss:  0.030621904879808426
p mean is: tensor(-0.0275, device='cuda:4')
epoch:  14000 quantization_loss:  0.030023017898201942
p mean is: tensor(-0.0304, device='cuda:4')
epoch:  15000 quantization_loss:  0.02932175248861313
p mean is: tensor(-0.0348, device='cuda:4')
epoch:  16000 quantization_loss:  0.02878699079155922
p mean is: tensor(-0.0402, device='cuda:4')
epoch:  17000 quantization_loss:  0.028555400669574738
p mean is: tensor(-0.0463, device='cuda:4')
epoch:  18000 quantization_loss:  0.028101826086640358
p mean is: tensor(-0.0518, device='cuda:4')
epoch:  19000 quantization_loss:  0.027540158480405807
p mean is: tensor(-0.0579, device='cuda:4')
epoch:  20000 quantization_loss:  0.02716163545846939
p mean is: tensor(-0.0654, device='cuda:4')
epoch:  21000 quantization_loss:  0.027017338201403618
p mean is: tensor(-0.0729, device='cuda:4')
epoch:  22000 quantization_loss:  0.0265360027551651
p mean is: tensor(-0.0809, device='cuda:4')
epoch:  23000 quantization_loss:  0.026252049952745438
p mean is: tensor(-0.0883, device='cuda:4')
epoch:  24000 quantization_loss:  0.026094060391187668
p mean is: tensor(-0.0952, device='cuda:4')
epoch:  25000 quantization_loss:  0.025896744802594185
p mean is: tensor(-0.1028, device='cuda:4')
epoch:  26000 quantization_loss:  0.02644863910973072
p mean is: tensor(-0.1096, device='cuda:4')
epoch:  27000 quantization_loss:  0.02550402283668518
p mean is: tensor(-0.1166, device='cuda:4')
epoch:  28000 quantization_loss:  0.025177234783768654
p mean is: tensor(-0.1242, device='cuda:4')
epoch:  29000 quantization_loss:  0.025105170905590057
p mean is: tensor(-0.1303, device='cuda:4')
epoch:  30000 quantization_loss:  0.024944616481661797
p mean is: tensor(-0.1365, device='cuda:4')
epoch:  31000 quantization_loss:  0.025214262306690216
p mean is: tensor(-0.1403, device='cuda:4')
epoch:  32000 quantization_loss:  0.024669131264090538
p mean is: tensor(-0.1450, device='cuda:4')
epoch:  33000 quantization_loss:  0.024312322959303856
p mean is: tensor(-0.1496, device='cuda:4')
epoch:  34000 quantization_loss:  0.024562880396842957
p mean is: tensor(-0.1526, device='cuda:4')
epoch:  35000 quantization_loss:  0.024149952456355095
p mean is: tensor(-0.1573, device='cuda:4')
epoch:  36000 quantization_loss:  0.02380181849002838
p mean is: tensor(-0.1598, device='cuda:4')
epoch:  37000 quantization_loss:  0.023655297234654427
p mean is: tensor(-0.1618, device='cuda:4')
epoch:  38000 quantization_loss:  0.023615311831235886
p mean is: tensor(-0.1647, device='cuda:4')
epoch:  39000 quantization_loss:  0.023561228066682816
p mean is: tensor(-0.1669, device='cuda:4')
epoch:  40000 quantization_loss:  0.02353668212890625
p mean is: tensor(-0.1691, device='cuda:4')
epoch:  41000 quantization_loss:  0.023307010531425476
p mean is: tensor(-0.1697, device='cuda:4')
epoch:  42000 quantization_loss:  0.02337094582617283
p mean is: tensor(-0.1720, device='cuda:4')
epoch:  43000 quantization_loss:  0.023371892049908638
p mean is: tensor(-0.1730, device='cuda:4')
epoch:  44000 quantization_loss:  0.02323690988123417
p mean is: tensor(-0.1754, device='cuda:4')
epoch:  45000 quantization_loss:  0.023203272372484207
p mean is: tensor(-0.1760, device='cuda:4')
epoch:  46000 quantization_loss:  0.023192819207906723
p mean is: tensor(-0.1772, device='cuda:4')
epoch:  47000 quantization_loss:  0.02322939597070217
p mean is: tensor(-0.1783, device='cuda:4')
epoch:  48000 quantization_loss:  0.022962749004364014
p mean is: tensor(-0.1790, device='cuda:4')
epoch:  49000 quantization_loss:  0.022903824225068092
p mean is: tensor(-0.1795, device='cuda:4')
epoch:  50000 quantization_loss:  0.022879615426063538
p mean is: tensor(-0.1793, device='cuda:4')
epoch:  51000 quantization_loss:  0.02275577187538147
p mean is: tensor(-0.1799, device='cuda:4')
epoch:  52000 quantization_loss:  0.02273121476173401
p mean is: tensor(-0.1792, device='cuda:4')
epoch:  53000 quantization_loss:  0.022729165852069855
p mean is: tensor(-0.1798, device='cuda:4')
epoch:  54000 quantization_loss:  0.022674955427646637
p mean is: tensor(-0.1786, device='cuda:4')
epoch:  55000 quantization_loss:  0.02263588458299637
p mean is: tensor(-0.1783, device='cuda:4')
epoch:  56000 quantization_loss:  0.02265366166830063
p mean is: tensor(-0.1783, device='cuda:4')
epoch:  57000 quantization_loss:  0.02260832116007805
p mean is: tensor(-0.1783, device='cuda:4')
epoch:  58000 quantization_loss:  0.022624270990490913
p mean is: tensor(-0.1777, device='cuda:4')
epoch:  59000 quantization_loss:  0.02259344421327114
p mean is: tensor(-0.1781, device='cuda:4')
epoch:  60000 quantization_loss:  0.02264164388179779
p mean is: tensor(-0.1776, device='cuda:4')
epoch:  61000 quantization_loss:  0.022510793060064316
p mean is: tensor(-0.1778, device='cuda:4')
epoch:  62000 quantization_loss:  0.02246716618537903
p mean is: tensor(-0.1778, device='cuda:4')
epoch:  63000 quantization_loss:  0.022515306249260902
p mean is: tensor(-0.1770, device='cuda:4')
epoch:  64000 quantization_loss:  0.02246858738362789
p mean is: tensor(-0.1773, device='cuda:4')
epoch:  65000 quantization_loss:  0.022457489743828773
p mean is: tensor(-0.1769, device='cuda:4')
epoch:  66000 quantization_loss:  0.022418035194277763
p mean is: tensor(-0.1762, device='cuda:4')
epoch:  67000 quantization_loss:  0.0223932396620512
p mean is: tensor(-0.1752, device='cuda:4')
epoch:  68000 quantization_loss:  0.022383008152246475
p mean is: tensor(-0.1749, device='cuda:4')
epoch:  69000 quantization_loss:  0.022404232993721962
p mean is: tensor(-0.1749, device='cuda:4')
epoch:  70000 quantization_loss:  0.022408751770853996
p mean is: tensor(-0.1747, device='cuda:4')
epoch:  71000 quantization_loss:  0.022413838654756546
p mean is: tensor(-0.1742, device='cuda:4')
epoch:  72000 quantization_loss:  0.022457752376794815
p mean is: tensor(-0.1737, device='cuda:4')
epoch:  73000 quantization_loss:  0.0223222803324461
p mean is: tensor(-0.1734, device='cuda:4')
epoch:  74000 quantization_loss:  0.022310426458716393
p mean is: tensor(-0.1730, device='cuda:4')
epoch:  75000 quantization_loss:  0.022358957678079605
p mean is: tensor(-0.1729, device='cuda:4')
epoch:  76000 quantization_loss:  0.022402675822377205
p mean is: tensor(-0.1725, device='cuda:4')
epoch:  77000 quantization_loss:  0.022295143455266953
p mean is: tensor(-0.1716, device='cuda:4')
epoch:  78000 quantization_loss:  0.022301651537418365
p mean is: tensor(-0.1710, device='cuda:4')
epoch:  79000 quantization_loss:  0.022269507870078087
p mean is: tensor(-0.1712, device='cuda:4')
here
1.1.weight           | nonzeros =    6307 /   16384             ( 38.49%) | total_pruned =   10077 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =    4229 /   16384             ( 25.81%) | total_pruned =   12155 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    5009 /   16384             ( 30.57%) | total_pruned =   11375 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =    3989 /   16384             ( 24.35%) | total_pruned =   12395 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =    1777 /   16384             ( 10.85%) | total_pruned =   14607 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =    2416 /   16384             ( 14.75%) | total_pruned =   13968 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     224 /     384             ( 58.33%) | total_pruned =     160 | shape = torch.Size([3, 128, 1, 1])
alive: 24472, pruned : 75752, total: 100224, Compression rate :       4.10x  ( 75.58% pruned)
PSNR of output image is:  18.338586946957832
Experiment done
