(3, 512, 512)
Starting vanilla DIP on 11 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.314445995331578'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 16, 16])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/11/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-1.3/1e-09
epoch:  0 quantization_loss:  0.0671437531709671
p mean is: tensor(-0.0002, device='cuda:3')
epoch:  1000 quantization_loss:  0.06378977000713348
p mean is: tensor(-0.0120, device='cuda:3')
epoch:  2000 quantization_loss:  0.05538277328014374
p mean is: tensor(-0.0138, device='cuda:3')
epoch:  3000 quantization_loss:  0.04935256391763687
p mean is: tensor(-0.0131, device='cuda:3')
epoch:  4000 quantization_loss:  0.04724540561437607
p mean is: tensor(-0.0169, device='cuda:3')
epoch:  5000 quantization_loss:  0.046510666608810425
p mean is: tensor(-0.0207, device='cuda:3')
epoch:  6000 quantization_loss:  0.04494135454297066
p mean is: tensor(-0.0239, device='cuda:3')
epoch:  7000 quantization_loss:  0.04399760067462921
p mean is: tensor(-0.0300, device='cuda:3')
epoch:  8000 quantization_loss:  0.04231710731983185
p mean is: tensor(-0.0385, device='cuda:3')
epoch:  9000 quantization_loss:  0.04123572260141373
p mean is: tensor(-0.0488, device='cuda:3')
epoch:  10000 quantization_loss:  0.04074612259864807
p mean is: tensor(-0.0635, device='cuda:3')
epoch:  11000 quantization_loss:  0.0396280512213707
p mean is: tensor(-0.0804, device='cuda:3')
epoch:  12000 quantization_loss:  0.039718788117170334
p mean is: tensor(-0.1007, device='cuda:3')
epoch:  13000 quantization_loss:  0.03879205882549286
p mean is: tensor(-0.1239, device='cuda:3')
epoch:  14000 quantization_loss:  0.038473330438137054
p mean is: tensor(-0.1491, device='cuda:3')
epoch:  15000 quantization_loss:  0.037596896290779114
p mean is: tensor(-0.1750, device='cuda:3')
epoch:  16000 quantization_loss:  0.03707335889339447
p mean is: tensor(-0.2031, device='cuda:3')
epoch:  17000 quantization_loss:  0.036192234605550766
p mean is: tensor(-0.2298, device='cuda:3')
epoch:  18000 quantization_loss:  0.03551118075847626
p mean is: tensor(-0.2565, device='cuda:3')
epoch:  19000 quantization_loss:  0.03476085141301155
p mean is: tensor(-0.2835, device='cuda:3')
epoch:  20000 quantization_loss:  0.03430943563580513
p mean is: tensor(-0.3107, device='cuda:3')
epoch:  21000 quantization_loss:  0.033487603068351746
p mean is: tensor(-0.3348, device='cuda:3')
epoch:  22000 quantization_loss:  0.033239975571632385
p mean is: tensor(-0.3590, device='cuda:3')
epoch:  23000 quantization_loss:  0.03263917192816734
p mean is: tensor(-0.3812, device='cuda:3')
epoch:  24000 quantization_loss:  0.03214952349662781
p mean is: tensor(-0.4012, device='cuda:3')
epoch:  25000 quantization_loss:  0.03171230107545853
p mean is: tensor(-0.4206, device='cuda:3')
epoch:  26000 quantization_loss:  0.03161407262086868
p mean is: tensor(-0.4382, device='cuda:3')
epoch:  27000 quantization_loss:  0.0315595380961895
p mean is: tensor(-0.4549, device='cuda:3')
epoch:  28000 quantization_loss:  0.03107534721493721
p mean is: tensor(-0.4700, device='cuda:3')
epoch:  29000 quantization_loss:  0.031063714995980263
p mean is: tensor(-0.4834, device='cuda:3')
epoch:  30000 quantization_loss:  0.031031940132379532
p mean is: tensor(-0.4960, device='cuda:3')
epoch:  31000 quantization_loss:  0.030920252203941345
p mean is: tensor(-0.5073, device='cuda:3')
epoch:  32000 quantization_loss:  0.03073286823928356
p mean is: tensor(-0.5185, device='cuda:3')
epoch:  33000 quantization_loss:  0.0306474007666111
p mean is: tensor(-0.5283, device='cuda:3')
epoch:  34000 quantization_loss:  0.03054645098745823
p mean is: tensor(-0.5379, device='cuda:3')
epoch:  35000 quantization_loss:  0.03054782748222351
p mean is: tensor(-0.5455, device='cuda:3')
epoch:  36000 quantization_loss:  0.030448680743575096
p mean is: tensor(-0.5526, device='cuda:3')
epoch:  37000 quantization_loss:  0.03038386069238186
p mean is: tensor(-0.5591, device='cuda:3')
epoch:  38000 quantization_loss:  0.02991359494626522
p mean is: tensor(-0.5652, device='cuda:3')
epoch:  39000 quantization_loss:  0.02976410463452339
p mean is: tensor(-0.5699, device='cuda:3')
epoch:  40000 quantization_loss:  0.029782524332404137
p mean is: tensor(-0.5741, device='cuda:3')
epoch:  41000 quantization_loss:  0.029689349234104156
p mean is: tensor(-0.5781, device='cuda:3')
epoch:  42000 quantization_loss:  0.029697347432374954
p mean is: tensor(-0.5807, device='cuda:3')
epoch:  43000 quantization_loss:  0.029531531035900116
p mean is: tensor(-0.5834, device='cuda:3')
epoch:  44000 quantization_loss:  0.02950393781065941
p mean is: tensor(-0.5854, device='cuda:3')
epoch:  45000 quantization_loss:  0.029530778527259827
p mean is: tensor(-0.5868, device='cuda:3')
epoch:  46000 quantization_loss:  0.029466357082128525
p mean is: tensor(-0.5886, device='cuda:3')
epoch:  47000 quantization_loss:  0.029440684244036674
p mean is: tensor(-0.5901, device='cuda:3')
epoch:  48000 quantization_loss:  0.029412362724542618
p mean is: tensor(-0.5912, device='cuda:3')
epoch:  49000 quantization_loss:  0.029501119628548622
p mean is: tensor(-0.5928, device='cuda:3')
epoch:  50000 quantization_loss:  0.02936769463121891
p mean is: tensor(-0.5930, device='cuda:3')
epoch:  51000 quantization_loss:  0.029354678466916084
p mean is: tensor(-0.5932, device='cuda:3')
epoch:  52000 quantization_loss:  0.029443759471178055
p mean is: tensor(-0.5939, device='cuda:3')
epoch:  53000 quantization_loss:  0.029328931123018265
p mean is: tensor(-0.5946, device='cuda:3')
epoch:  54000 quantization_loss:  0.029394472017884254
p mean is: tensor(-0.5952, device='cuda:3')
epoch:  55000 quantization_loss:  0.029276438057422638
p mean is: tensor(-0.5960, device='cuda:3')
epoch:  56000 quantization_loss:  0.029607348144054413
p mean is: tensor(-0.5962, device='cuda:3')
epoch:  57000 quantization_loss:  0.029268451035022736
p mean is: tensor(-0.5963, device='cuda:3')
epoch:  58000 quantization_loss:  0.029291564598679543
p mean is: tensor(-0.5961, device='cuda:3')
epoch:  59000 quantization_loss:  0.029246758669614792
p mean is: tensor(-0.5961, device='cuda:3')
epoch:  60000 quantization_loss:  0.029228443279862404
p mean is: tensor(-0.5969, device='cuda:3')
epoch:  61000 quantization_loss:  0.029291946440935135
p mean is: tensor(-0.5967, device='cuda:3')
epoch:  62000 quantization_loss:  0.02920250967144966
p mean is: tensor(-0.5969, device='cuda:3')
epoch:  63000 quantization_loss:  0.029198789969086647
p mean is: tensor(-0.5966, device='cuda:3')
epoch:  64000 quantization_loss:  0.029211295768618584
p mean is: tensor(-0.5962, device='cuda:3')
epoch:  65000 quantization_loss:  0.02921031229197979
p mean is: tensor(-0.5957, device='cuda:3')
epoch:  66000 quantization_loss:  0.029168568551540375
p mean is: tensor(-0.5950, device='cuda:3')
epoch:  67000 quantization_loss:  0.02918390743434429
p mean is: tensor(-0.5943, device='cuda:3')
epoch:  68000 quantization_loss:  0.029148433357477188
p mean is: tensor(-0.5943, device='cuda:3')
epoch:  69000 quantization_loss:  0.029210112988948822
p mean is: tensor(-0.5941, device='cuda:3')
epoch:  70000 quantization_loss:  0.029139898717403412
p mean is: tensor(-0.5940, device='cuda:3')
epoch:  71000 quantization_loss:  0.029113469645380974
p mean is: tensor(-0.5937, device='cuda:3')
epoch:  72000 quantization_loss:  0.029141582548618317
p mean is: tensor(-0.5931, device='cuda:3')
epoch:  73000 quantization_loss:  0.02910660207271576
p mean is: tensor(-0.5928, device='cuda:3')
epoch:  74000 quantization_loss:  0.029102833941578865
p mean is: tensor(-0.5925, device='cuda:3')
epoch:  75000 quantization_loss:  0.029103880748152733
p mean is: tensor(-0.5923, device='cuda:3')
epoch:  76000 quantization_loss:  0.029173074290156364
p mean is: tensor(-0.5918, device='cuda:3')
epoch:  77000 quantization_loss:  0.029085084795951843
p mean is: tensor(-0.5915, device='cuda:3')
epoch:  78000 quantization_loss:  0.029071200639009476
p mean is: tensor(-0.5912, device='cuda:3')
epoch:  79000 quantization_loss:  0.0290693249553442
p mean is: tensor(-0.5907, device='cuda:3')
here
1.1.weight           | nonzeros =    4866 /   16384             ( 29.70%) | total_pruned =   11518 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =    4130 /   16384             ( 25.21%) | total_pruned =   12254 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    6342 /   16384             ( 38.71%) | total_pruned =   10042 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =    5315 /   16384             ( 32.44%) | total_pruned =   11069 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =    2413 /   16384             ( 14.73%) | total_pruned =   13971 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =    1710 /   16384             ( 10.44%) | total_pruned =   14674 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     135 /     384             ( 35.16%) | total_pruned =     249 | shape = torch.Size([3, 128, 1, 1])
alive: 25433, pruned : 74791, total: 100224, Compression rate :       3.94x  ( 74.62% pruned)
PSNR of output image is:  16.69202964323307
Experiment done
