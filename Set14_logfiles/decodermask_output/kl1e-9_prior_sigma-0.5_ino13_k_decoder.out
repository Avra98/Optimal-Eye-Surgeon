(3, 512, 512)
Starting vanilla DIP on 13 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.488850820400568'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 16, 16])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/13/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-0.5/1e-09
epoch:  0 quantization_loss:  0.0824728012084961
p mean is: tensor(-9.3364e-05, device='cuda:2')
epoch:  1000 quantization_loss:  0.0773431807756424
p mean is: tensor(-0.0066, device='cuda:2')
epoch:  2000 quantization_loss:  0.07767058908939362
p mean is: tensor(-0.0106, device='cuda:2')
epoch:  3000 quantization_loss:  0.07146566361188889
p mean is: tensor(-0.0099, device='cuda:2')
epoch:  4000 quantization_loss:  0.05032454803586006
p mean is: tensor(-0.0050, device='cuda:2')
epoch:  5000 quantization_loss:  0.04267653077840805
p mean is: tensor(-0.0025, device='cuda:2')
epoch:  6000 quantization_loss:  0.03723723068833351
p mean is: tensor(0.0001, device='cuda:2')
epoch:  7000 quantization_loss:  0.03262864798307419
p mean is: tensor(0.0015, device='cuda:2')
epoch:  8000 quantization_loss:  0.03147519752383232
p mean is: tensor(0.0017, device='cuda:2')
epoch:  9000 quantization_loss:  0.03026564046740532
p mean is: tensor(-0.0003, device='cuda:2')
epoch:  10000 quantization_loss:  0.028979014605283737
p mean is: tensor(-0.0039, device='cuda:2')
epoch:  11000 quantization_loss:  0.0279327854514122
p mean is: tensor(-0.0082, device='cuda:2')
epoch:  12000 quantization_loss:  0.027362709864974022
p mean is: tensor(-0.0152, device='cuda:2')
epoch:  13000 quantization_loss:  0.026560112833976746
p mean is: tensor(-0.0213, device='cuda:2')
epoch:  14000 quantization_loss:  0.026583917438983917
p mean is: tensor(-0.0295, device='cuda:2')
epoch:  15000 quantization_loss:  0.025391651317477226
p mean is: tensor(-0.0383, device='cuda:2')
epoch:  16000 quantization_loss:  0.025066545233130455
p mean is: tensor(-0.0475, device='cuda:2')
epoch:  17000 quantization_loss:  0.02456606552004814
p mean is: tensor(-0.0569, device='cuda:2')
epoch:  18000 quantization_loss:  0.02417956106364727
p mean is: tensor(-0.0672, device='cuda:2')
epoch:  19000 quantization_loss:  0.02403223142027855
p mean is: tensor(-0.0768, device='cuda:2')
epoch:  20000 quantization_loss:  0.023783447220921516
p mean is: tensor(-0.0874, device='cuda:2')
epoch:  21000 quantization_loss:  0.02352837845683098
p mean is: tensor(-0.0962, device='cuda:2')
epoch:  22000 quantization_loss:  0.023351073265075684
p mean is: tensor(-0.1055, device='cuda:2')
epoch:  23000 quantization_loss:  0.023084959015250206
p mean is: tensor(-0.1124, device='cuda:2')
epoch:  24000 quantization_loss:  0.02278967760503292
p mean is: tensor(-0.1196, device='cuda:2')
epoch:  25000 quantization_loss:  0.022728389129042625
p mean is: tensor(-0.1259, device='cuda:2')
epoch:  26000 quantization_loss:  0.02264450676739216
p mean is: tensor(-0.1327, device='cuda:2')
epoch:  27000 quantization_loss:  0.022544775158166885
p mean is: tensor(-0.1378, device='cuda:2')
epoch:  28000 quantization_loss:  0.022363869473338127
p mean is: tensor(-0.1425, device='cuda:2')
epoch:  29000 quantization_loss:  0.022329000756144524
p mean is: tensor(-0.1473, device='cuda:2')
epoch:  30000 quantization_loss:  0.02248298190534115
p mean is: tensor(-0.1510, device='cuda:2')
epoch:  31000 quantization_loss:  0.022209806367754936
p mean is: tensor(-0.1536, device='cuda:2')
epoch:  32000 quantization_loss:  0.022095073014497757
p mean is: tensor(-0.1570, device='cuda:2')
epoch:  33000 quantization_loss:  0.022034192457795143
p mean is: tensor(-0.1599, device='cuda:2')
epoch:  34000 quantization_loss:  0.021954229101538658
p mean is: tensor(-0.1622, device='cuda:2')
epoch:  35000 quantization_loss:  0.021955866366624832
p mean is: tensor(-0.1633, device='cuda:2')
epoch:  36000 quantization_loss:  0.02188432775437832
p mean is: tensor(-0.1647, device='cuda:2')
epoch:  37000 quantization_loss:  0.021985173225402832
p mean is: tensor(-0.1668, device='cuda:2')
epoch:  38000 quantization_loss:  0.021869808435440063
p mean is: tensor(-0.1681, device='cuda:2')
epoch:  39000 quantization_loss:  0.02178281731903553
p mean is: tensor(-0.1681, device='cuda:2')
epoch:  40000 quantization_loss:  0.02173018269240856
p mean is: tensor(-0.1677, device='cuda:2')
epoch:  41000 quantization_loss:  0.02172832377254963
p mean is: tensor(-0.1672, device='cuda:2')
epoch:  42000 quantization_loss:  0.021702056750655174
p mean is: tensor(-0.1674, device='cuda:2')
epoch:  43000 quantization_loss:  0.021631896495819092
p mean is: tensor(-0.1674, device='cuda:2')
epoch:  44000 quantization_loss:  0.021600978448987007
p mean is: tensor(-0.1669, device='cuda:2')
epoch:  45000 quantization_loss:  0.021604448556900024
p mean is: tensor(-0.1669, device='cuda:2')
epoch:  46000 quantization_loss:  0.021594900637865067
p mean is: tensor(-0.1661, device='cuda:2')
epoch:  47000 quantization_loss:  0.02186322584748268
p mean is: tensor(-0.1654, device='cuda:2')
epoch:  48000 quantization_loss:  0.021569982171058655
p mean is: tensor(-0.1652, device='cuda:2')
epoch:  49000 quantization_loss:  0.02150607667863369
p mean is: tensor(-0.1654, device='cuda:2')
epoch:  50000 quantization_loss:  0.02148042991757393
p mean is: tensor(-0.1651, device='cuda:2')
epoch:  51000 quantization_loss:  0.021497508510947227
p mean is: tensor(-0.1641, device='cuda:2')
epoch:  52000 quantization_loss:  0.021445685997605324
p mean is: tensor(-0.1639, device='cuda:2')
epoch:  53000 quantization_loss:  0.021499400958418846
p mean is: tensor(-0.1630, device='cuda:2')
epoch:  54000 quantization_loss:  0.02142794243991375
p mean is: tensor(-0.1632, device='cuda:2')
epoch:  55000 quantization_loss:  0.021398169919848442
p mean is: tensor(-0.1629, device='cuda:2')
epoch:  56000 quantization_loss:  0.02141224965453148
p mean is: tensor(-0.1633, device='cuda:2')
epoch:  57000 quantization_loss:  0.021421296522021294
p mean is: tensor(-0.1640, device='cuda:2')
epoch:  58000 quantization_loss:  0.021391725167632103
p mean is: tensor(-0.1643, device='cuda:2')
epoch:  59000 quantization_loss:  0.02143886685371399
p mean is: tensor(-0.1644, device='cuda:2')
epoch:  60000 quantization_loss:  0.021354855969548225
p mean is: tensor(-0.1649, device='cuda:2')
epoch:  61000 quantization_loss:  0.021242007613182068
p mean is: tensor(-0.1645, device='cuda:2')
epoch:  62000 quantization_loss:  0.02125909924507141
p mean is: tensor(-0.1647, device='cuda:2')
epoch:  63000 quantization_loss:  0.021250037476420403
p mean is: tensor(-0.1643, device='cuda:2')
epoch:  64000 quantization_loss:  0.02124837040901184
p mean is: tensor(-0.1642, device='cuda:2')
epoch:  65000 quantization_loss:  0.02125594951212406
p mean is: tensor(-0.1640, device='cuda:2')
epoch:  66000 quantization_loss:  0.021205613389611244
p mean is: tensor(-0.1632, device='cuda:2')
epoch:  67000 quantization_loss:  0.02118219994008541
p mean is: tensor(-0.1635, device='cuda:2')
epoch:  68000 quantization_loss:  0.02117936499416828
p mean is: tensor(-0.1637, device='cuda:2')
epoch:  69000 quantization_loss:  0.021193375810980797
p mean is: tensor(-0.1638, device='cuda:2')
epoch:  70000 quantization_loss:  0.0211852565407753
p mean is: tensor(-0.1636, device='cuda:2')
epoch:  71000 quantization_loss:  0.02123378776013851
p mean is: tensor(-0.1633, device='cuda:2')
epoch:  72000 quantization_loss:  0.02117978408932686
p mean is: tensor(-0.1634, device='cuda:2')
epoch:  73000 quantization_loss:  0.021142277866601944
p mean is: tensor(-0.1629, device='cuda:2')
epoch:  74000 quantization_loss:  0.02113829366862774
p mean is: tensor(-0.1630, device='cuda:2')
epoch:  75000 quantization_loss:  0.021174347028136253
p mean is: tensor(-0.1628, device='cuda:2')
epoch:  76000 quantization_loss:  0.021149812266230583
p mean is: tensor(-0.1624, device='cuda:2')
epoch:  77000 quantization_loss:  0.021156199276447296
p mean is: tensor(-0.1622, device='cuda:2')
epoch:  78000 quantization_loss:  0.021127179265022278
p mean is: tensor(-0.1620, device='cuda:2')
epoch:  79000 quantization_loss:  0.021138599142432213
p mean is: tensor(-0.1613, device='cuda:2')
here
1.1.weight           | nonzeros =    6047 /   16384             ( 36.91%) | total_pruned =   10337 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =    4084 /   16384             ( 24.93%) | total_pruned =   12300 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    4766 /   16384             ( 29.09%) | total_pruned =   11618 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =    3973 /   16384             ( 24.25%) | total_pruned =   12411 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =    3233 /   16384             ( 19.73%) | total_pruned =   13151 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =    4063 /   16384             ( 24.80%) | total_pruned =   12321 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =     114 /     128             ( 89.06%) | total_pruned =      14 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     220 /     384             ( 57.29%) | total_pruned =     164 | shape = torch.Size([3, 128, 1, 1])
alive: 26933, pruned : 73291, total: 100224, Compression rate :       3.72x  ( 73.13% pruned)
PSNR of output image is:  18.539555683295532
Experiment done
