(3, 512, 512)
Starting vanilla DIP on 4 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '19.755646761863012'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 16, 16])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/4/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-1.3/1e-09
epoch:  0 quantization_loss:  0.06553412973880768
p mean is: tensor(-0.0002, device='cuda:2')
epoch:  1000 quantization_loss:  0.06287168711423874
p mean is: tensor(-0.0108, device='cuda:2')
epoch:  2000 quantization_loss:  0.06260385364294052
p mean is: tensor(-0.0191, device='cuda:2')
epoch:  3000 quantization_loss:  0.053496185690164566
p mean is: tensor(-0.0250, device='cuda:2')
epoch:  4000 quantization_loss:  0.043215494602918625
p mean is: tensor(-0.0281, device='cuda:2')
epoch:  5000 quantization_loss:  0.036402516067028046
p mean is: tensor(-0.0341, device='cuda:2')
epoch:  6000 quantization_loss:  0.03261955827474594
p mean is: tensor(-0.0406, device='cuda:2')
epoch:  7000 quantization_loss:  0.031248871237039566
p mean is: tensor(-0.0488, device='cuda:2')
epoch:  8000 quantization_loss:  0.02991235814988613
p mean is: tensor(-0.0586, device='cuda:2')
epoch:  9000 quantization_loss:  0.029280047863721848
p mean is: tensor(-0.0721, device='cuda:2')
epoch:  10000 quantization_loss:  0.02793218567967415
p mean is: tensor(-0.0888, device='cuda:2')
epoch:  11000 quantization_loss:  0.027163924649357796
p mean is: tensor(-0.1069, device='cuda:2')
epoch:  12000 quantization_loss:  0.026696333661675453
p mean is: tensor(-0.1282, device='cuda:2')
epoch:  13000 quantization_loss:  0.02587517723441124
p mean is: tensor(-0.1516, device='cuda:2')
epoch:  14000 quantization_loss:  0.02551751397550106
p mean is: tensor(-0.1767, device='cuda:2')
epoch:  15000 quantization_loss:  0.02501240000128746
p mean is: tensor(-0.2041, device='cuda:2')
epoch:  16000 quantization_loss:  0.024745065718889236
p mean is: tensor(-0.2334, device='cuda:2')
epoch:  17000 quantization_loss:  0.02449421025812626
p mean is: tensor(-0.2625, device='cuda:2')
epoch:  18000 quantization_loss:  0.024007150903344154
p mean is: tensor(-0.2896, device='cuda:2')
epoch:  19000 quantization_loss:  0.02418133057653904
p mean is: tensor(-0.3181, device='cuda:2')
epoch:  20000 quantization_loss:  0.023750029504299164
p mean is: tensor(-0.3447, device='cuda:2')
epoch:  21000 quantization_loss:  0.02366883121430874
p mean is: tensor(-0.3700, device='cuda:2')
epoch:  22000 quantization_loss:  0.023369014263153076
p mean is: tensor(-0.3948, device='cuda:2')
epoch:  23000 quantization_loss:  0.02320767380297184
p mean is: tensor(-0.4178, device='cuda:2')
epoch:  24000 quantization_loss:  0.02313113585114479
p mean is: tensor(-0.4388, device='cuda:2')
epoch:  25000 quantization_loss:  0.02303752675652504
p mean is: tensor(-0.4604, device='cuda:2')
epoch:  26000 quantization_loss:  0.02293807454407215
p mean is: tensor(-0.4791, device='cuda:2')
epoch:  27000 quantization_loss:  0.02282235212624073
p mean is: tensor(-0.4961, device='cuda:2')
epoch:  28000 quantization_loss:  0.022768167778849602
p mean is: tensor(-0.5127, device='cuda:2')
epoch:  29000 quantization_loss:  0.022715387865900993
p mean is: tensor(-0.5264, device='cuda:2')
epoch:  30000 quantization_loss:  0.022633185610175133
p mean is: tensor(-0.5396, device='cuda:2')
epoch:  31000 quantization_loss:  0.022587722167372704
p mean is: tensor(-0.5513, device='cuda:2')
epoch:  32000 quantization_loss:  0.022550292313098907
p mean is: tensor(-0.5617, device='cuda:2')
epoch:  33000 quantization_loss:  0.02235652506351471
p mean is: tensor(-0.5712, device='cuda:2')
epoch:  34000 quantization_loss:  0.022287113592028618
p mean is: tensor(-0.5798, device='cuda:2')
epoch:  35000 quantization_loss:  0.022106200456619263
p mean is: tensor(-0.5874, device='cuda:2')
epoch:  36000 quantization_loss:  0.02194015122950077
p mean is: tensor(-0.5938, device='cuda:2')
epoch:  37000 quantization_loss:  0.021940937265753746
p mean is: tensor(-0.5989, device='cuda:2')
epoch:  38000 quantization_loss:  0.02190062403678894
p mean is: tensor(-0.6043, device='cuda:2')
epoch:  39000 quantization_loss:  0.021861577406525612
p mean is: tensor(-0.6090, device='cuda:2')
epoch:  40000 quantization_loss:  0.02183992601931095
p mean is: tensor(-0.6132, device='cuda:2')
epoch:  41000 quantization_loss:  0.021876808255910873
p mean is: tensor(-0.6165, device='cuda:2')
epoch:  42000 quantization_loss:  0.021822292357683182
p mean is: tensor(-0.6195, device='cuda:2')
epoch:  43000 quantization_loss:  0.021771127358078957
p mean is: tensor(-0.6225, device='cuda:2')
epoch:  44000 quantization_loss:  0.021805929020047188
p mean is: tensor(-0.6245, device='cuda:2')
epoch:  45000 quantization_loss:  0.021715473383665085
p mean is: tensor(-0.6261, device='cuda:2')
epoch:  46000 quantization_loss:  0.021697666496038437
p mean is: tensor(-0.6286, device='cuda:2')
epoch:  47000 quantization_loss:  0.021690212190151215
p mean is: tensor(-0.6303, device='cuda:2')
epoch:  48000 quantization_loss:  0.021758761256933212
p mean is: tensor(-0.6321, device='cuda:2')
epoch:  49000 quantization_loss:  0.02168690413236618
p mean is: tensor(-0.6338, device='cuda:2')
epoch:  50000 quantization_loss:  0.021660106256604195
p mean is: tensor(-0.6348, device='cuda:2')
epoch:  51000 quantization_loss:  0.02167331427335739
p mean is: tensor(-0.6360, device='cuda:2')
epoch:  52000 quantization_loss:  0.02164488472044468
p mean is: tensor(-0.6370, device='cuda:2')
epoch:  53000 quantization_loss:  0.02163933776319027
p mean is: tensor(-0.6379, device='cuda:2')
epoch:  54000 quantization_loss:  0.02160084992647171
p mean is: tensor(-0.6388, device='cuda:2')
epoch:  55000 quantization_loss:  0.021657204255461693
p mean is: tensor(-0.6393, device='cuda:2')
epoch:  56000 quantization_loss:  0.021584127098321915
p mean is: tensor(-0.6404, device='cuda:2')
epoch:  57000 quantization_loss:  0.021569332107901573
p mean is: tensor(-0.6413, device='cuda:2')
epoch:  58000 quantization_loss:  0.02155737206339836
p mean is: tensor(-0.6419, device='cuda:2')
epoch:  59000 quantization_loss:  0.021580200642347336
p mean is: tensor(-0.6422, device='cuda:2')
epoch:  60000 quantization_loss:  0.021563299000263214
p mean is: tensor(-0.6424, device='cuda:2')
epoch:  61000 quantization_loss:  0.021537194028496742
p mean is: tensor(-0.6427, device='cuda:2')
epoch:  62000 quantization_loss:  0.021532749757170677
p mean is: tensor(-0.6426, device='cuda:2')
epoch:  63000 quantization_loss:  0.021521924063563347
p mean is: tensor(-0.6420, device='cuda:2')
epoch:  64000 quantization_loss:  0.021505605429410934
p mean is: tensor(-0.6420, device='cuda:2')
epoch:  65000 quantization_loss:  0.0215116236358881
p mean is: tensor(-0.6419, device='cuda:2')
epoch:  66000 quantization_loss:  0.021503683179616928
p mean is: tensor(-0.6422, device='cuda:2')
epoch:  67000 quantization_loss:  0.021498633548617363
p mean is: tensor(-0.6424, device='cuda:2')
epoch:  68000 quantization_loss:  0.021491913124918938
p mean is: tensor(-0.6429, device='cuda:2')
epoch:  69000 quantization_loss:  0.02149958536028862
p mean is: tensor(-0.6434, device='cuda:2')
epoch:  70000 quantization_loss:  0.02149752900004387
p mean is: tensor(-0.6438, device='cuda:2')
epoch:  71000 quantization_loss:  0.021492358297109604
p mean is: tensor(-0.6439, device='cuda:2')
epoch:  72000 quantization_loss:  0.021511493250727654
p mean is: tensor(-0.6441, device='cuda:2')
epoch:  73000 quantization_loss:  0.021490996703505516
p mean is: tensor(-0.6441, device='cuda:2')
epoch:  74000 quantization_loss:  0.021479278802871704
p mean is: tensor(-0.6443, device='cuda:2')
epoch:  75000 quantization_loss:  0.02149404026567936
p mean is: tensor(-0.6444, device='cuda:2')
epoch:  76000 quantization_loss:  0.021478643640875816
p mean is: tensor(-0.6443, device='cuda:2')
epoch:  77000 quantization_loss:  0.021481631323695183
p mean is: tensor(-0.6442, device='cuda:2')
epoch:  78000 quantization_loss:  0.02147796005010605
p mean is: tensor(-0.6443, device='cuda:2')
epoch:  79000 quantization_loss:  0.021471086889505386
p mean is: tensor(-0.6442, device='cuda:2')
here
1.1.weight           | nonzeros =    5379 /   16384             ( 32.83%) | total_pruned =   11005 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =    4074 /   16384             ( 24.87%) | total_pruned =   12310 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    4923 /   16384             ( 30.05%) | total_pruned =   11461 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =    4114 /   16384             ( 25.11%) | total_pruned =   12270 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =    3090 /   16384             ( 18.86%) | total_pruned =   13294 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =    3974 /   16384             ( 24.26%) | total_pruned =   12410 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     210 /     384             ( 54.69%) | total_pruned =     174 | shape = torch.Size([3, 128, 1, 1])
alive: 26321, pruned : 73903, total: 100224, Compression rate :       3.81x  ( 73.74% pruned)
PSNR of output image is:  18.62928860792155
Experiment done
