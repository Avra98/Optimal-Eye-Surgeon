(3, 512, 512)
Starting vanilla DIP on 0 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '19.67215851144453'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 16, 16])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/0/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-0.5/1e-09
epoch:  0 quantization_loss:  0.08332641422748566
p mean is: tensor(-6.8076e-05, device='cuda:4')
epoch:  1000 quantization_loss:  0.0780768096446991
p mean is: tensor(-0.0076, device='cuda:4')
epoch:  2000 quantization_loss:  0.06317196041345596
p mean is: tensor(-0.0077, device='cuda:4')
epoch:  3000 quantization_loss:  0.049028683453798294
p mean is: tensor(-0.0113, device='cuda:4')
epoch:  4000 quantization_loss:  0.044484011828899384
p mean is: tensor(-0.0149, device='cuda:4')
epoch:  5000 quantization_loss:  0.041180167347192764
p mean is: tensor(-0.0162, device='cuda:4')
epoch:  6000 quantization_loss:  0.03636224567890167
p mean is: tensor(-0.0170, device='cuda:4')
epoch:  7000 quantization_loss:  0.03276028484106064
p mean is: tensor(-0.0175, device='cuda:4')
epoch:  8000 quantization_loss:  0.03094889596104622
p mean is: tensor(-0.0192, device='cuda:4')
epoch:  9000 quantization_loss:  0.029679276049137115
p mean is: tensor(-0.0214, device='cuda:4')
epoch:  10000 quantization_loss:  0.02842697687447071
p mean is: tensor(-0.0253, device='cuda:4')
epoch:  11000 quantization_loss:  0.02773965522646904
p mean is: tensor(-0.0297, device='cuda:4')
epoch:  12000 quantization_loss:  0.02679036557674408
p mean is: tensor(-0.0361, device='cuda:4')
epoch:  13000 quantization_loss:  0.02658449485898018
p mean is: tensor(-0.0432, device='cuda:4')
epoch:  14000 quantization_loss:  0.025849489495158195
p mean is: tensor(-0.0505, device='cuda:4')
epoch:  15000 quantization_loss:  0.025752075016498566
p mean is: tensor(-0.0600, device='cuda:4')
epoch:  16000 quantization_loss:  0.025065533816814423
p mean is: tensor(-0.0701, device='cuda:4')
epoch:  17000 quantization_loss:  0.02500678040087223
p mean is: tensor(-0.0811, device='cuda:4')
epoch:  18000 quantization_loss:  0.024904675781726837
p mean is: tensor(-0.0911, device='cuda:4')
epoch:  19000 quantization_loss:  0.024435216560959816
p mean is: tensor(-0.1016, device='cuda:4')
epoch:  20000 quantization_loss:  0.02406229078769684
p mean is: tensor(-0.1118, device='cuda:4')
epoch:  21000 quantization_loss:  0.02400372363626957
p mean is: tensor(-0.1222, device='cuda:4')
epoch:  22000 quantization_loss:  0.023533524945378304
p mean is: tensor(-0.1315, device='cuda:4')
epoch:  23000 quantization_loss:  0.02345964126288891
p mean is: tensor(-0.1404, device='cuda:4')
epoch:  24000 quantization_loss:  0.02325371280312538
p mean is: tensor(-0.1479, device='cuda:4')
epoch:  25000 quantization_loss:  0.022981224581599236
p mean is: tensor(-0.1552, device='cuda:4')
epoch:  26000 quantization_loss:  0.022947289049625397
p mean is: tensor(-0.1624, device='cuda:4')
epoch:  27000 quantization_loss:  0.022885305806994438
p mean is: tensor(-0.1702, device='cuda:4')
epoch:  28000 quantization_loss:  0.022781865671277046
p mean is: tensor(-0.1754, device='cuda:4')
epoch:  29000 quantization_loss:  0.02262091264128685
p mean is: tensor(-0.1809, device='cuda:4')
epoch:  30000 quantization_loss:  0.02250690758228302
p mean is: tensor(-0.1854, device='cuda:4')
epoch:  31000 quantization_loss:  0.02236124500632286
p mean is: tensor(-0.1903, device='cuda:4')
epoch:  32000 quantization_loss:  0.02244187705218792
p mean is: tensor(-0.1940, device='cuda:4')
epoch:  33000 quantization_loss:  0.02219283953309059
p mean is: tensor(-0.1969, device='cuda:4')
epoch:  34000 quantization_loss:  0.022203875705599785
p mean is: tensor(-0.1990, device='cuda:4')
epoch:  35000 quantization_loss:  0.02218291535973549
p mean is: tensor(-0.2009, device='cuda:4')
epoch:  36000 quantization_loss:  0.022100793197751045
p mean is: tensor(-0.2028, device='cuda:4')
epoch:  37000 quantization_loss:  0.02193484827876091
p mean is: tensor(-0.2046, device='cuda:4')
epoch:  38000 quantization_loss:  0.021962277591228485
p mean is: tensor(-0.2067, device='cuda:4')
epoch:  39000 quantization_loss:  0.021923186257481575
p mean is: tensor(-0.2079, device='cuda:4')
epoch:  40000 quantization_loss:  0.02189236879348755
p mean is: tensor(-0.2095, device='cuda:4')
epoch:  41000 quantization_loss:  0.021762000396847725
p mean is: tensor(-0.2104, device='cuda:4')
epoch:  42000 quantization_loss:  0.021760867908596992
p mean is: tensor(-0.2117, device='cuda:4')
epoch:  43000 quantization_loss:  0.021774591878056526
p mean is: tensor(-0.2126, device='cuda:4')
epoch:  44000 quantization_loss:  0.021732594817876816
p mean is: tensor(-0.2132, device='cuda:4')
epoch:  45000 quantization_loss:  0.021691538393497467
p mean is: tensor(-0.2145, device='cuda:4')
epoch:  46000 quantization_loss:  0.021648313850164413
p mean is: tensor(-0.2157, device='cuda:4')
epoch:  47000 quantization_loss:  0.02163098007440567
p mean is: tensor(-0.2159, device='cuda:4')
epoch:  48000 quantization_loss:  0.021596834063529968
p mean is: tensor(-0.2168, device='cuda:4')
epoch:  49000 quantization_loss:  0.021576646715402603
p mean is: tensor(-0.2170, device='cuda:4')
epoch:  50000 quantization_loss:  0.021561991423368454
p mean is: tensor(-0.2171, device='cuda:4')
epoch:  51000 quantization_loss:  0.02155498042702675
p mean is: tensor(-0.2180, device='cuda:4')
epoch:  52000 quantization_loss:  0.02154855988919735
p mean is: tensor(-0.2184, device='cuda:4')
epoch:  53000 quantization_loss:  0.021542368456721306
p mean is: tensor(-0.2190, device='cuda:4')
epoch:  54000 quantization_loss:  0.02160336822271347
p mean is: tensor(-0.2197, device='cuda:4')
epoch:  55000 quantization_loss:  0.021514933556318283
p mean is: tensor(-0.2200, device='cuda:4')
epoch:  56000 quantization_loss:  0.0215009655803442
p mean is: tensor(-0.2209, device='cuda:4')
epoch:  57000 quantization_loss:  0.021525990217924118
p mean is: tensor(-0.2216, device='cuda:4')
epoch:  58000 quantization_loss:  0.02151082456111908
p mean is: tensor(-0.2220, device='cuda:4')
epoch:  59000 quantization_loss:  0.021451834589242935
p mean is: tensor(-0.2225, device='cuda:4')
epoch:  60000 quantization_loss:  0.0214521661400795
p mean is: tensor(-0.2236, device='cuda:4')
epoch:  61000 quantization_loss:  0.021473003551363945
p mean is: tensor(-0.2243, device='cuda:4')
epoch:  62000 quantization_loss:  0.021430274471640587
p mean is: tensor(-0.2248, device='cuda:4')
epoch:  63000 quantization_loss:  0.021490681916475296
p mean is: tensor(-0.2257, device='cuda:4')
epoch:  64000 quantization_loss:  0.02144494280219078
p mean is: tensor(-0.2267, device='cuda:4')
epoch:  65000 quantization_loss:  0.021419323980808258
p mean is: tensor(-0.2275, device='cuda:4')
epoch:  66000 quantization_loss:  0.02140064164996147
p mean is: tensor(-0.2279, device='cuda:4')
epoch:  67000 quantization_loss:  0.02138686180114746
p mean is: tensor(-0.2285, device='cuda:4')
epoch:  68000 quantization_loss:  0.02140655741095543
p mean is: tensor(-0.2286, device='cuda:4')
epoch:  69000 quantization_loss:  0.021417075768113136
p mean is: tensor(-0.2293, device='cuda:4')
epoch:  70000 quantization_loss:  0.021389249712228775
p mean is: tensor(-0.2295, device='cuda:4')
epoch:  71000 quantization_loss:  0.02138073369860649
p mean is: tensor(-0.2299, device='cuda:4')
epoch:  72000 quantization_loss:  0.021381104364991188
p mean is: tensor(-0.2302, device='cuda:4')
epoch:  73000 quantization_loss:  0.021380223333835602
p mean is: tensor(-0.2305, device='cuda:4')
epoch:  74000 quantization_loss:  0.02137068286538124
p mean is: tensor(-0.2309, device='cuda:4')
epoch:  75000 quantization_loss:  0.021399153396487236
p mean is: tensor(-0.2308, device='cuda:4')
epoch:  76000 quantization_loss:  0.02135801501572132
p mean is: tensor(-0.2312, device='cuda:4')
epoch:  77000 quantization_loss:  0.0213874951004982
p mean is: tensor(-0.2311, device='cuda:4')
epoch:  78000 quantization_loss:  0.021352961659431458
p mean is: tensor(-0.2308, device='cuda:4')
epoch:  79000 quantization_loss:  0.021388549357652664
p mean is: tensor(-0.2311, device='cuda:4')
here
1.1.weight           | nonzeros =    5523 /   16384             ( 33.71%) | total_pruned =   10861 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =    4205 /   16384             ( 25.67%) | total_pruned =   12179 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    5619 /   16384             ( 34.30%) | total_pruned =   10765 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =    4678 /   16384             ( 28.55%) | total_pruned =   11706 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =    4451 /   16384             ( 27.17%) | total_pruned =   11933 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =    5228 /   16384             ( 31.91%) | total_pruned =   11156 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =     117 /     128             ( 91.41%) | total_pruned =      11 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     219 /     384             ( 57.03%) | total_pruned =     165 | shape = torch.Size([3, 128, 1, 1])
alive: 30518, pruned : 69706, total: 100224, Compression rate :       3.28x  ( 69.55% pruned)
PSNR of output image is:  18.26272412267389
Experiment done
