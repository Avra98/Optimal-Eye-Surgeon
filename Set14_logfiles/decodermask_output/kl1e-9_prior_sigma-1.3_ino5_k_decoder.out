(3, 512, 512)
Starting vanilla DIP on 5 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.098953276250434'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 16, 16])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/5/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-1.3/1e-09
epoch:  0 quantization_loss:  0.06540859490633011
p mean is: tensor(-0.0002, device='cuda:3')
epoch:  1000 quantization_loss:  0.058057863265275955
p mean is: tensor(-0.0102, device='cuda:3')
epoch:  2000 quantization_loss:  0.04676549881696701
p mean is: tensor(-0.0117, device='cuda:3')
epoch:  3000 quantization_loss:  0.044351428747177124
p mean is: tensor(-0.0109, device='cuda:3')
epoch:  4000 quantization_loss:  0.04117913916707039
p mean is: tensor(-0.0122, device='cuda:3')
epoch:  5000 quantization_loss:  0.039077725261449814
p mean is: tensor(-0.0118, device='cuda:3')
epoch:  6000 quantization_loss:  0.03624647855758667
p mean is: tensor(-0.0116, device='cuda:3')
epoch:  7000 quantization_loss:  0.03477978706359863
p mean is: tensor(-0.0116, device='cuda:3')
epoch:  8000 quantization_loss:  0.03326913341879845
p mean is: tensor(-0.0137, device='cuda:3')
epoch:  9000 quantization_loss:  0.031136367470026016
p mean is: tensor(-0.0190, device='cuda:3')
epoch:  10000 quantization_loss:  0.02973303757607937
p mean is: tensor(-0.0287, device='cuda:3')
epoch:  11000 quantization_loss:  0.028532925993204117
p mean is: tensor(-0.0403, device='cuda:3')
epoch:  12000 quantization_loss:  0.027079498395323753
p mean is: tensor(-0.0535, device='cuda:3')
epoch:  13000 quantization_loss:  0.026211630553007126
p mean is: tensor(-0.0689, device='cuda:3')
epoch:  14000 quantization_loss:  0.026055175811052322
p mean is: tensor(-0.0855, device='cuda:3')
epoch:  15000 quantization_loss:  0.024911794811487198
p mean is: tensor(-0.1042, device='cuda:3')
epoch:  16000 quantization_loss:  0.024362727999687195
p mean is: tensor(-0.1234, device='cuda:3')
epoch:  17000 quantization_loss:  0.023953521624207497
p mean is: tensor(-0.1422, device='cuda:3')
epoch:  18000 quantization_loss:  0.023559510707855225
p mean is: tensor(-0.1626, device='cuda:3')
epoch:  19000 quantization_loss:  0.023243509232997894
p mean is: tensor(-0.1827, device='cuda:3')
epoch:  20000 quantization_loss:  0.023179691284894943
p mean is: tensor(-0.2035, device='cuda:3')
epoch:  21000 quantization_loss:  0.02287030592560768
p mean is: tensor(-0.2237, device='cuda:3')
epoch:  22000 quantization_loss:  0.02241712249815464
p mean is: tensor(-0.2426, device='cuda:3')
epoch:  23000 quantization_loss:  0.022263692691922188
p mean is: tensor(-0.2622, device='cuda:3')
epoch:  24000 quantization_loss:  0.021946260705590248
p mean is: tensor(-0.2810, device='cuda:3')
epoch:  25000 quantization_loss:  0.02173088677227497
p mean is: tensor(-0.2985, device='cuda:3')
epoch:  26000 quantization_loss:  0.02165113389492035
p mean is: tensor(-0.3155, device='cuda:3')
epoch:  27000 quantization_loss:  0.021458961069583893
p mean is: tensor(-0.3317, device='cuda:3')
epoch:  28000 quantization_loss:  0.021305305883288383
p mean is: tensor(-0.3459, device='cuda:3')
epoch:  29000 quantization_loss:  0.021265069022774696
p mean is: tensor(-0.3593, device='cuda:3')
epoch:  30000 quantization_loss:  0.021157579496502876
p mean is: tensor(-0.3714, device='cuda:3')
epoch:  31000 quantization_loss:  0.0210553128272295
p mean is: tensor(-0.3829, device='cuda:3')
epoch:  32000 quantization_loss:  0.020904237404465675
p mean is: tensor(-0.3936, device='cuda:3')
epoch:  33000 quantization_loss:  0.020830921828746796
p mean is: tensor(-0.4025, device='cuda:3')
epoch:  34000 quantization_loss:  0.020764406770467758
p mean is: tensor(-0.4107, device='cuda:3')
epoch:  35000 quantization_loss:  0.020709754899144173
p mean is: tensor(-0.4191, device='cuda:3')
epoch:  36000 quantization_loss:  0.020685294643044472
p mean is: tensor(-0.4263, device='cuda:3')
epoch:  37000 quantization_loss:  0.020644554868340492
p mean is: tensor(-0.4320, device='cuda:3')
epoch:  38000 quantization_loss:  0.02059479057788849
p mean is: tensor(-0.4369, device='cuda:3')
epoch:  39000 quantization_loss:  0.02061600424349308
p mean is: tensor(-0.4414, device='cuda:3')
epoch:  40000 quantization_loss:  0.020549846813082695
p mean is: tensor(-0.4449, device='cuda:3')
epoch:  41000 quantization_loss:  0.020558573305606842
p mean is: tensor(-0.4482, device='cuda:3')
epoch:  42000 quantization_loss:  0.02054951898753643
p mean is: tensor(-0.4514, device='cuda:3')
epoch:  43000 quantization_loss:  0.020508022978901863
p mean is: tensor(-0.4536, device='cuda:3')
epoch:  44000 quantization_loss:  0.02047087997198105
p mean is: tensor(-0.4553, device='cuda:3')
epoch:  45000 quantization_loss:  0.020569542422890663
p mean is: tensor(-0.4570, device='cuda:3')
epoch:  46000 quantization_loss:  0.020459553226828575
p mean is: tensor(-0.4586, device='cuda:3')
epoch:  47000 quantization_loss:  0.020487086847424507
p mean is: tensor(-0.4596, device='cuda:3')
epoch:  48000 quantization_loss:  0.02048627845942974
p mean is: tensor(-0.4600, device='cuda:3')
epoch:  49000 quantization_loss:  0.020419033244252205
p mean is: tensor(-0.4607, device='cuda:3')
epoch:  50000 quantization_loss:  0.0202983058989048
p mean is: tensor(-0.4615, device='cuda:3')
epoch:  51000 quantization_loss:  0.020337361842393875
p mean is: tensor(-0.4619, device='cuda:3')
epoch:  52000 quantization_loss:  0.02028629183769226
p mean is: tensor(-0.4622, device='cuda:3')
epoch:  53000 quantization_loss:  0.020276006311178207
p mean is: tensor(-0.4624, device='cuda:3')
epoch:  54000 quantization_loss:  0.02035045437514782
p mean is: tensor(-0.4626, device='cuda:3')
epoch:  55000 quantization_loss:  0.020296256989240646
p mean is: tensor(-0.4620, device='cuda:3')
epoch:  56000 quantization_loss:  0.02024480514228344
p mean is: tensor(-0.4619, device='cuda:3')
epoch:  57000 quantization_loss:  0.020264679566025734
p mean is: tensor(-0.4618, device='cuda:3')
epoch:  58000 quantization_loss:  0.020300518721342087
p mean is: tensor(-0.4621, device='cuda:3')
epoch:  59000 quantization_loss:  0.02024850994348526
p mean is: tensor(-0.4625, device='cuda:3')
epoch:  60000 quantization_loss:  0.020220186561346054
p mean is: tensor(-0.4627, device='cuda:3')
epoch:  61000 quantization_loss:  0.02022668719291687
p mean is: tensor(-0.4630, device='cuda:3')
epoch:  62000 quantization_loss:  0.02033660188317299
p mean is: tensor(-0.4631, device='cuda:3')
epoch:  63000 quantization_loss:  0.02023140899837017
p mean is: tensor(-0.4640, device='cuda:3')
epoch:  64000 quantization_loss:  0.020247437059879303
p mean is: tensor(-0.4643, device='cuda:3')
epoch:  65000 quantization_loss:  0.02019450254738331
p mean is: tensor(-0.4642, device='cuda:3')
epoch:  66000 quantization_loss:  0.020182564854621887
p mean is: tensor(-0.4642, device='cuda:3')
epoch:  67000 quantization_loss:  0.020198315382003784
p mean is: tensor(-0.4644, device='cuda:3')
epoch:  68000 quantization_loss:  0.020312141627073288
p mean is: tensor(-0.4645, device='cuda:3')
epoch:  69000 quantization_loss:  0.020187754184007645
p mean is: tensor(-0.4642, device='cuda:3')
epoch:  70000 quantization_loss:  0.02018171362578869
p mean is: tensor(-0.4640, device='cuda:3')
epoch:  71000 quantization_loss:  0.02018170990049839
p mean is: tensor(-0.4638, device='cuda:3')
epoch:  72000 quantization_loss:  0.020227137953042984
p mean is: tensor(-0.4638, device='cuda:3')
epoch:  73000 quantization_loss:  0.020076286047697067
p mean is: tensor(-0.4636, device='cuda:3')
epoch:  74000 quantization_loss:  0.020071815699338913
p mean is: tensor(-0.4636, device='cuda:3')
epoch:  75000 quantization_loss:  0.020107978954911232
p mean is: tensor(-0.4638, device='cuda:3')
epoch:  76000 quantization_loss:  0.020065540447831154
p mean is: tensor(-0.4637, device='cuda:3')
epoch:  77000 quantization_loss:  0.020063791424036026
p mean is: tensor(-0.4634, device='cuda:3')
epoch:  78000 quantization_loss:  0.020060060545802116
p mean is: tensor(-0.4634, device='cuda:3')
epoch:  79000 quantization_loss:  0.02005838230252266
p mean is: tensor(-0.4635, device='cuda:3')
here
1.1.weight           | nonzeros =    6008 /   16384             ( 36.67%) | total_pruned =   10376 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =    5671 /   16384             ( 34.61%) | total_pruned =   10713 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    7170 /   16384             ( 43.76%) | total_pruned =    9214 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =    5351 /   16384             ( 32.66%) | total_pruned =   11033 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =    2853 /   16384             ( 17.41%) | total_pruned =   13531 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =    2581 /   16384             ( 15.75%) | total_pruned =   13803 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     179 /     384             ( 46.61%) | total_pruned =     205 | shape = torch.Size([3, 128, 1, 1])
alive: 30394, pruned : 69830, total: 100224, Compression rate :       3.30x  ( 69.67% pruned)
PSNR of output image is:  19.5428985696951
Experiment done
