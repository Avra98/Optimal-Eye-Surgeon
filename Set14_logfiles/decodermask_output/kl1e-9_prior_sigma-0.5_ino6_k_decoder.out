(3, 512, 512)
Starting vanilla DIP on 6 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.13618468996565'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 16, 16])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/6/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-0.5/1e-09
epoch:  0 quantization_loss:  0.06411869078874588
p mean is: tensor(-0.0001, device='cuda:3')
epoch:  1000 quantization_loss:  0.0617249459028244
p mean is: tensor(-0.0092, device='cuda:3')
epoch:  2000 quantization_loss:  0.061045560985803604
p mean is: tensor(-0.0140, device='cuda:3')
epoch:  3000 quantization_loss:  0.056891582906246185
p mean is: tensor(-0.0149, device='cuda:3')
epoch:  4000 quantization_loss:  0.05266496166586876
p mean is: tensor(-0.0109, device='cuda:3')
epoch:  5000 quantization_loss:  0.05073775351047516
p mean is: tensor(-0.0088, device='cuda:3')
epoch:  6000 quantization_loss:  0.04941355064511299
p mean is: tensor(-0.0095, device='cuda:3')
epoch:  7000 quantization_loss:  0.047369152307510376
p mean is: tensor(-0.0099, device='cuda:3')
epoch:  8000 quantization_loss:  0.045006267726421356
p mean is: tensor(-0.0143, device='cuda:3')
epoch:  9000 quantization_loss:  0.04352807253599167
p mean is: tensor(-0.0179, device='cuda:3')
epoch:  10000 quantization_loss:  0.04181980714201927
p mean is: tensor(-0.0226, device='cuda:3')
epoch:  11000 quantization_loss:  0.04061992093920708
p mean is: tensor(-0.0306, device='cuda:3')
epoch:  12000 quantization_loss:  0.039101045578718185
p mean is: tensor(-0.0392, device='cuda:3')
epoch:  13000 quantization_loss:  0.038472730666399
p mean is: tensor(-0.0491, device='cuda:3')
epoch:  14000 quantization_loss:  0.03760348632931709
p mean is: tensor(-0.0595, device='cuda:3')
epoch:  15000 quantization_loss:  0.037272434681653976
p mean is: tensor(-0.0698, device='cuda:3')
epoch:  16000 quantization_loss:  0.03661391884088516
p mean is: tensor(-0.0811, device='cuda:3')
epoch:  17000 quantization_loss:  0.03613642603158951
p mean is: tensor(-0.0918, device='cuda:3')
epoch:  18000 quantization_loss:  0.03564603254199028
p mean is: tensor(-0.1042, device='cuda:3')
epoch:  19000 quantization_loss:  0.03516392037272453
p mean is: tensor(-0.1155, device='cuda:3')
epoch:  20000 quantization_loss:  0.03469293937087059
p mean is: tensor(-0.1268, device='cuda:3')
epoch:  21000 quantization_loss:  0.034364644438028336
p mean is: tensor(-0.1367, device='cuda:3')
epoch:  22000 quantization_loss:  0.033843062818050385
p mean is: tensor(-0.1462, device='cuda:3')
epoch:  23000 quantization_loss:  0.03348790109157562
p mean is: tensor(-0.1545, device='cuda:3')
epoch:  24000 quantization_loss:  0.03327178582549095
p mean is: tensor(-0.1615, device='cuda:3')
epoch:  25000 quantization_loss:  0.033020373433828354
p mean is: tensor(-0.1681, device='cuda:3')
epoch:  26000 quantization_loss:  0.03286168724298477
p mean is: tensor(-0.1739, device='cuda:3')
epoch:  27000 quantization_loss:  0.03270610049366951
p mean is: tensor(-0.1781, device='cuda:3')
epoch:  28000 quantization_loss:  0.032608289271593094
p mean is: tensor(-0.1826, device='cuda:3')
epoch:  29000 quantization_loss:  0.03264705464243889
p mean is: tensor(-0.1852, device='cuda:3')
epoch:  30000 quantization_loss:  0.03228000923991203
p mean is: tensor(-0.1874, device='cuda:3')
epoch:  31000 quantization_loss:  0.03218326345086098
p mean is: tensor(-0.1897, device='cuda:3')
epoch:  32000 quantization_loss:  0.03204795718193054
p mean is: tensor(-0.1914, device='cuda:3')
epoch:  33000 quantization_loss:  0.031939417123794556
p mean is: tensor(-0.1929, device='cuda:3')
epoch:  34000 quantization_loss:  0.03198976442217827
p mean is: tensor(-0.1940, device='cuda:3')
epoch:  35000 quantization_loss:  0.031923823058605194
p mean is: tensor(-0.1940, device='cuda:3')
epoch:  36000 quantization_loss:  0.03181350603699684
p mean is: tensor(-0.1944, device='cuda:3')
epoch:  37000 quantization_loss:  0.031853798776865005
p mean is: tensor(-0.1950, device='cuda:3')
epoch:  38000 quantization_loss:  0.03176123648881912
p mean is: tensor(-0.1955, device='cuda:3')
epoch:  39000 quantization_loss:  0.03191375359892845
p mean is: tensor(-0.1951, device='cuda:3')
epoch:  40000 quantization_loss:  0.0316820964217186
p mean is: tensor(-0.1954, device='cuda:3')
epoch:  41000 quantization_loss:  0.031651705503463745
p mean is: tensor(-0.1945, device='cuda:3')
epoch:  42000 quantization_loss:  0.0316513366997242
p mean is: tensor(-0.1945, device='cuda:3')
epoch:  43000 quantization_loss:  0.03160941228270531
p mean is: tensor(-0.1935, device='cuda:3')
epoch:  44000 quantization_loss:  0.0316549688577652
p mean is: tensor(-0.1928, device='cuda:3')
epoch:  45000 quantization_loss:  0.03167137876152992
p mean is: tensor(-0.1920, device='cuda:3')
epoch:  46000 quantization_loss:  0.03157660365104675
p mean is: tensor(-0.1920, device='cuda:3')
epoch:  47000 quantization_loss:  0.03158719465136528
p mean is: tensor(-0.1919, device='cuda:3')
epoch:  48000 quantization_loss:  0.031497109681367874
p mean is: tensor(-0.1913, device='cuda:3')
epoch:  49000 quantization_loss:  0.03151842951774597
p mean is: tensor(-0.1915, device='cuda:3')
epoch:  50000 quantization_loss:  0.03148335963487625
p mean is: tensor(-0.1914, device='cuda:3')
epoch:  51000 quantization_loss:  0.031471315771341324
p mean is: tensor(-0.1910, device='cuda:3')
epoch:  52000 quantization_loss:  0.031457576900720596
p mean is: tensor(-0.1907, device='cuda:3')
epoch:  53000 quantization_loss:  0.03141988813877106
p mean is: tensor(-0.1902, device='cuda:3')
epoch:  54000 quantization_loss:  0.0314079113304615
p mean is: tensor(-0.1893, device='cuda:3')
epoch:  55000 quantization_loss:  0.03139062225818634
p mean is: tensor(-0.1889, device='cuda:3')
epoch:  56000 quantization_loss:  0.031424444168806076
p mean is: tensor(-0.1880, device='cuda:3')
epoch:  57000 quantization_loss:  0.03150671347975731
p mean is: tensor(-0.1878, device='cuda:3')
epoch:  58000 quantization_loss:  0.031365856528282166
p mean is: tensor(-0.1876, device='cuda:3')
epoch:  59000 quantization_loss:  0.0313430018723011
p mean is: tensor(-0.1874, device='cuda:3')
epoch:  60000 quantization_loss:  0.031338393688201904
p mean is: tensor(-0.1871, device='cuda:3')
epoch:  61000 quantization_loss:  0.03132802993059158
p mean is: tensor(-0.1872, device='cuda:3')
epoch:  62000 quantization_loss:  0.03130818158388138
p mean is: tensor(-0.1872, device='cuda:3')
epoch:  63000 quantization_loss:  0.031315598636865616
p mean is: tensor(-0.1872, device='cuda:3')
epoch:  64000 quantization_loss:  0.031346678733825684
p mean is: tensor(-0.1881, device='cuda:3')
epoch:  65000 quantization_loss:  0.03129992634057999
p mean is: tensor(-0.1880, device='cuda:3')
epoch:  66000 quantization_loss:  0.031320467591285706
p mean is: tensor(-0.1876, device='cuda:3')
epoch:  67000 quantization_loss:  0.031274739652872086
p mean is: tensor(-0.1883, device='cuda:3')
epoch:  68000 quantization_loss:  0.03137008100748062
p mean is: tensor(-0.1882, device='cuda:3')
epoch:  69000 quantization_loss:  0.031280387192964554
p mean is: tensor(-0.1879, device='cuda:3')
epoch:  70000 quantization_loss:  0.03125708922743797
p mean is: tensor(-0.1879, device='cuda:3')
epoch:  71000 quantization_loss:  0.031283628195524216
p mean is: tensor(-0.1882, device='cuda:3')
epoch:  72000 quantization_loss:  0.0311720073223114
p mean is: tensor(-0.1887, device='cuda:3')
epoch:  73000 quantization_loss:  0.031144840642809868
p mean is: tensor(-0.1890, device='cuda:3')
epoch:  74000 quantization_loss:  0.03115340881049633
p mean is: tensor(-0.1897, device='cuda:3')
epoch:  75000 quantization_loss:  0.0311322882771492
p mean is: tensor(-0.1900, device='cuda:3')
epoch:  76000 quantization_loss:  0.031160756945610046
p mean is: tensor(-0.1902, device='cuda:3')
epoch:  77000 quantization_loss:  0.031146926805377007
p mean is: tensor(-0.1903, device='cuda:3')
epoch:  78000 quantization_loss:  0.031149720773100853
p mean is: tensor(-0.1906, device='cuda:3')
epoch:  79000 quantization_loss:  0.03112209215760231
p mean is: tensor(-0.1903, device='cuda:3')
here
1.1.weight           | nonzeros =    6183 /   16384             ( 37.74%) | total_pruned =   10201 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =    4709 /   16384             ( 28.74%) | total_pruned =   11675 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    5736 /   16384             ( 35.01%) | total_pruned =   10648 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =    3952 /   16384             ( 24.12%) | total_pruned =   12432 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =    2006 /   16384             ( 12.24%) | total_pruned =   14378 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =    2473 /   16384             ( 15.09%) | total_pruned =   13911 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     182 /     384             ( 47.40%) | total_pruned =     202 | shape = torch.Size([3, 128, 1, 1])
alive: 25773, pruned : 74451, total: 100224, Compression rate :       3.89x  ( 74.28% pruned)
PSNR of output image is:  16.613604908537233
Experiment done
