(3, 256, 256)
Starting vanilla DIP on 9 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.20795177628723'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 8, 8])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/9/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/0.0/1e-09
epoch:  0 quantization_loss:  0.0619475357234478
p mean is: tensor(-8.7733e-06, device='cuda:3')
epoch:  1000 quantization_loss:  0.0484028197824955
p mean is: tensor(-0.0022, device='cuda:3')
epoch:  2000 quantization_loss:  0.02490353398025036
p mean is: tensor(0.0004, device='cuda:3')
epoch:  3000 quantization_loss:  0.023957509547472
p mean is: tensor(0.0012, device='cuda:3')
epoch:  4000 quantization_loss:  0.023497333750128746
p mean is: tensor(0.0015, device='cuda:3')
epoch:  5000 quantization_loss:  0.022572748363018036
p mean is: tensor(0.0021, device='cuda:3')
epoch:  6000 quantization_loss:  0.022084958851337433
p mean is: tensor(0.0027, device='cuda:3')
epoch:  7000 quantization_loss:  0.022636938840150833
p mean is: tensor(0.0035, device='cuda:3')
epoch:  8000 quantization_loss:  0.021746983751654625
p mean is: tensor(0.0044, device='cuda:3')
epoch:  9000 quantization_loss:  0.020953107625246048
p mean is: tensor(0.0064, device='cuda:3')
epoch:  10000 quantization_loss:  0.021002400666475296
p mean is: tensor(0.0074, device='cuda:3')
epoch:  11000 quantization_loss:  0.02065611071884632
p mean is: tensor(0.0087, device='cuda:3')
epoch:  12000 quantization_loss:  0.020259564742445946
p mean is: tensor(0.0102, device='cuda:3')
epoch:  13000 quantization_loss:  0.020204083994030952
p mean is: tensor(0.0115, device='cuda:3')
epoch:  14000 quantization_loss:  0.019832858815789223
p mean is: tensor(0.0115, device='cuda:3')
epoch:  15000 quantization_loss:  0.019795825704932213
p mean is: tensor(0.0124, device='cuda:3')
epoch:  16000 quantization_loss:  0.019298939034342766
p mean is: tensor(0.0134, device='cuda:3')
epoch:  17000 quantization_loss:  0.019264834001660347
p mean is: tensor(0.0131, device='cuda:3')
epoch:  18000 quantization_loss:  0.019347909837961197
p mean is: tensor(0.0140, device='cuda:3')
epoch:  19000 quantization_loss:  0.01868823543190956
p mean is: tensor(0.0153, device='cuda:3')
epoch:  20000 quantization_loss:  0.01863819733262062
p mean is: tensor(0.0171, device='cuda:3')
epoch:  21000 quantization_loss:  0.018655577674508095
p mean is: tensor(0.0181, device='cuda:3')
epoch:  22000 quantization_loss:  0.01863856241106987
p mean is: tensor(0.0197, device='cuda:3')
epoch:  23000 quantization_loss:  0.01854982227087021
p mean is: tensor(0.0214, device='cuda:3')
epoch:  24000 quantization_loss:  0.018339036032557487
p mean is: tensor(0.0220, device='cuda:3')
epoch:  25000 quantization_loss:  0.01820918545126915
p mean is: tensor(0.0230, device='cuda:3')
epoch:  26000 quantization_loss:  0.018059153109788895
p mean is: tensor(0.0243, device='cuda:3')
epoch:  27000 quantization_loss:  0.018009744584560394
p mean is: tensor(0.0249, device='cuda:3')
epoch:  28000 quantization_loss:  0.01777450554072857
p mean is: tensor(0.0260, device='cuda:3')
epoch:  29000 quantization_loss:  0.018359515815973282
p mean is: tensor(0.0273, device='cuda:3')
epoch:  30000 quantization_loss:  0.017588911578059196
p mean is: tensor(0.0277, device='cuda:3')
epoch:  31000 quantization_loss:  0.01753629930317402
p mean is: tensor(0.0294, device='cuda:3')
epoch:  32000 quantization_loss:  0.017624646425247192
p mean is: tensor(0.0301, device='cuda:3')
epoch:  33000 quantization_loss:  0.01728043146431446
p mean is: tensor(0.0326, device='cuda:3')
epoch:  34000 quantization_loss:  0.01755818910896778
p mean is: tensor(0.0338, device='cuda:3')
epoch:  35000 quantization_loss:  0.017370684072375298
p mean is: tensor(0.0343, device='cuda:3')
epoch:  36000 quantization_loss:  0.016989264637231827
p mean is: tensor(0.0351, device='cuda:3')
epoch:  37000 quantization_loss:  0.016752896830439568
p mean is: tensor(0.0365, device='cuda:3')
epoch:  38000 quantization_loss:  0.01684577576816082
p mean is: tensor(0.0383, device='cuda:3')
epoch:  39000 quantization_loss:  0.016721198335289955
p mean is: tensor(0.0393, device='cuda:3')
epoch:  40000 quantization_loss:  0.0166474599391222
p mean is: tensor(0.0402, device='cuda:3')
epoch:  41000 quantization_loss:  0.016788946464657784
p mean is: tensor(0.0417, device='cuda:3')
epoch:  42000 quantization_loss:  0.01673041842877865
p mean is: tensor(0.0430, device='cuda:3')
epoch:  43000 quantization_loss:  0.016536962240934372
p mean is: tensor(0.0447, device='cuda:3')
epoch:  44000 quantization_loss:  0.016407150775194168
p mean is: tensor(0.0456, device='cuda:3')
epoch:  45000 quantization_loss:  0.016321001574397087
p mean is: tensor(0.0467, device='cuda:3')
epoch:  46000 quantization_loss:  0.016401534900069237
p mean is: tensor(0.0483, device='cuda:3')
epoch:  47000 quantization_loss:  0.016562113538384438
p mean is: tensor(0.0501, device='cuda:3')
epoch:  48000 quantization_loss:  0.016143692657351494
p mean is: tensor(0.0520, device='cuda:3')
epoch:  49000 quantization_loss:  0.016178784891963005
p mean is: tensor(0.0535, device='cuda:3')
epoch:  50000 quantization_loss:  0.016113443300127983
p mean is: tensor(0.0544, device='cuda:3')
epoch:  51000 quantization_loss:  0.016029048711061478
p mean is: tensor(0.0562, device='cuda:3')
epoch:  52000 quantization_loss:  0.01631852425634861
p mean is: tensor(0.0581, device='cuda:3')
epoch:  53000 quantization_loss:  0.016036130487918854
p mean is: tensor(0.0598, device='cuda:3')
epoch:  54000 quantization_loss:  0.0160124022513628
p mean is: tensor(0.0617, device='cuda:3')
epoch:  55000 quantization_loss:  0.01626972109079361
p mean is: tensor(0.0632, device='cuda:3')
epoch:  56000 quantization_loss:  0.015991689637303352
p mean is: tensor(0.0654, device='cuda:3')
epoch:  57000 quantization_loss:  0.01591135375201702
p mean is: tensor(0.0666, device='cuda:3')
epoch:  58000 quantization_loss:  0.015930239111185074
p mean is: tensor(0.0685, device='cuda:3')
epoch:  59000 quantization_loss:  0.01583467237651348
p mean is: tensor(0.0693, device='cuda:3')
epoch:  60000 quantization_loss:  0.015790700912475586
p mean is: tensor(0.0693, device='cuda:3')
epoch:  61000 quantization_loss:  0.015806565061211586
p mean is: tensor(0.0701, device='cuda:3')
epoch:  62000 quantization_loss:  0.0157617200165987
p mean is: tensor(0.0708, device='cuda:3')
epoch:  63000 quantization_loss:  0.01580527052283287
p mean is: tensor(0.0720, device='cuda:3')
epoch:  64000 quantization_loss:  0.0157353226095438
p mean is: tensor(0.0715, device='cuda:3')
epoch:  65000 quantization_loss:  0.015748681500554085
p mean is: tensor(0.0720, device='cuda:3')
epoch:  66000 quantization_loss:  0.015704916790127754
p mean is: tensor(0.0728, device='cuda:3')
epoch:  67000 quantization_loss:  0.01565686985850334
p mean is: tensor(0.0736, device='cuda:3')
epoch:  68000 quantization_loss:  0.015780137851834297
p mean is: tensor(0.0747, device='cuda:3')
epoch:  69000 quantization_loss:  0.015723219141364098
p mean is: tensor(0.0754, device='cuda:3')
epoch:  70000 quantization_loss:  0.015584724955260754
p mean is: tensor(0.0761, device='cuda:3')
epoch:  71000 quantization_loss:  0.015621382743120193
p mean is: tensor(0.0767, device='cuda:3')
epoch:  72000 quantization_loss:  0.015575068071484566
p mean is: tensor(0.0776, device='cuda:3')
epoch:  73000 quantization_loss:  0.015587450936436653
p mean is: tensor(0.0788, device='cuda:3')
epoch:  74000 quantization_loss:  0.01558538619428873
p mean is: tensor(0.0781, device='cuda:3')
epoch:  75000 quantization_loss:  0.015532800927758217
p mean is: tensor(0.0791, device='cuda:3')
epoch:  76000 quantization_loss:  0.015555460005998611
p mean is: tensor(0.0796, device='cuda:3')
epoch:  77000 quantization_loss:  0.015567057766020298
p mean is: tensor(0.0803, device='cuda:3')
epoch:  78000 quantization_loss:  0.0156162790954113
p mean is: tensor(0.0807, device='cuda:3')
epoch:  79000 quantization_loss:  0.015546295791864395
p mean is: tensor(0.0809, device='cuda:3')
here
1.1.weight           | nonzeros =    8482 /   16384             ( 51.77%) | total_pruned =    7902 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =    7277 /   16384             ( 44.42%) | total_pruned =    9107 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    7554 /   16384             ( 46.11%) | total_pruned =    8830 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =    7460 /   16384             ( 45.53%) | total_pruned =    8924 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =    7399 /   16384             ( 45.16%) | total_pruned =    8985 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =    6021 /   16384             ( 36.75%) | total_pruned =   10363 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     133 /     384             ( 34.64%) | total_pruned =     251 | shape = torch.Size([3, 128, 1, 1])
alive: 44789, pruned : 55435, total: 100224, Compression rate :       2.24x  ( 55.31% pruned)
PSNR of output image is:  21.85371626198684
Experiment done
