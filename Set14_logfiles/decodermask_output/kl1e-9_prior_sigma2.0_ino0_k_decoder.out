(3, 512, 512)
Starting vanilla DIP on 0 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '19.667524659423606'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 16, 16])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/0/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/2.0/1e-09
epoch:  0 quantization_loss:  0.08282452076673508
p mean is: tensor(0.0003, device='cuda:2')
epoch:  1000 quantization_loss:  0.07857945561408997
p mean is: tensor(0.0047, device='cuda:2')
epoch:  2000 quantization_loss:  0.07185328751802444
p mean is: tensor(0.0106, device='cuda:2')
epoch:  3000 quantization_loss:  0.054623451083898544
p mean is: tensor(0.0213, device='cuda:2')
epoch:  4000 quantization_loss:  0.04655107483267784
p mean is: tensor(0.0266, device='cuda:2')
epoch:  5000 quantization_loss:  0.041260991245508194
p mean is: tensor(0.0344, device='cuda:2')
epoch:  6000 quantization_loss:  0.038368068635463715
p mean is: tensor(0.0468, device='cuda:2')
epoch:  7000 quantization_loss:  0.03248623386025429
p mean is: tensor(0.0598, device='cuda:2')
epoch:  8000 quantization_loss:  0.031098224222660065
p mean is: tensor(0.0747, device='cuda:2')
epoch:  9000 quantization_loss:  0.030001221224665642
p mean is: tensor(0.0931, device='cuda:2')
epoch:  10000 quantization_loss:  0.028166325762867928
p mean is: tensor(0.1133, device='cuda:2')
epoch:  11000 quantization_loss:  0.027166621759533882
p mean is: tensor(0.1353, device='cuda:2')
epoch:  12000 quantization_loss:  0.02619197592139244
p mean is: tensor(0.1606, device='cuda:2')
epoch:  13000 quantization_loss:  0.02577117644250393
p mean is: tensor(0.1869, device='cuda:2')
epoch:  14000 quantization_loss:  0.025132013484835625
p mean is: tensor(0.2182, device='cuda:2')
epoch:  15000 quantization_loss:  0.02537275291979313
p mean is: tensor(0.2523, device='cuda:2')
epoch:  16000 quantization_loss:  0.024215776473283768
p mean is: tensor(0.2889, device='cuda:2')
epoch:  17000 quantization_loss:  0.02405274473130703
p mean is: tensor(0.3266, device='cuda:2')
epoch:  18000 quantization_loss:  0.024062396958470345
p mean is: tensor(0.3643, device='cuda:2')
epoch:  19000 quantization_loss:  0.02341216616332531
p mean is: tensor(0.4024, device='cuda:2')
epoch:  20000 quantization_loss:  0.023212915286421776
p mean is: tensor(0.4388, device='cuda:2')
epoch:  21000 quantization_loss:  0.02303777076303959
p mean is: tensor(0.4763, device='cuda:2')
epoch:  22000 quantization_loss:  0.02274734154343605
p mean is: tensor(0.5112, device='cuda:2')
epoch:  23000 quantization_loss:  0.022529853507876396
p mean is: tensor(0.5449, device='cuda:2')
epoch:  24000 quantization_loss:  0.022476395592093468
p mean is: tensor(0.5776, device='cuda:2')
epoch:  25000 quantization_loss:  0.02239575982093811
p mean is: tensor(0.6081, device='cuda:2')
epoch:  26000 quantization_loss:  0.02230599895119667
p mean is: tensor(0.6357, device='cuda:2')
epoch:  27000 quantization_loss:  0.02222723700106144
p mean is: tensor(0.6620, device='cuda:2')
epoch:  28000 quantization_loss:  0.022224579006433487
p mean is: tensor(0.6863, device='cuda:2')
epoch:  29000 quantization_loss:  0.02194576896727085
p mean is: tensor(0.7085, device='cuda:2')
epoch:  30000 quantization_loss:  0.02202567830681801
p mean is: tensor(0.7297, device='cuda:2')
epoch:  31000 quantization_loss:  0.021768812090158463
p mean is: tensor(0.7491, device='cuda:2')
epoch:  32000 quantization_loss:  0.02183346450328827
p mean is: tensor(0.7660, device='cuda:2')
epoch:  33000 quantization_loss:  0.02167561650276184
p mean is: tensor(0.7815, device='cuda:2')
epoch:  34000 quantization_loss:  0.02161005139350891
p mean is: tensor(0.7960, device='cuda:2')
epoch:  35000 quantization_loss:  0.021470041945576668
p mean is: tensor(0.8079, device='cuda:2')
epoch:  36000 quantization_loss:  0.02144644595682621
p mean is: tensor(0.8193, device='cuda:2')
epoch:  37000 quantization_loss:  0.021545883268117905
p mean is: tensor(0.8304, device='cuda:2')
epoch:  38000 quantization_loss:  0.021362729370594025
p mean is: tensor(0.8402, device='cuda:2')
epoch:  39000 quantization_loss:  0.021335698664188385
p mean is: tensor(0.8492, device='cuda:2')
epoch:  40000 quantization_loss:  0.02134304866194725
p mean is: tensor(0.8574, device='cuda:2')
epoch:  41000 quantization_loss:  0.0212746262550354
p mean is: tensor(0.8653, device='cuda:2')
epoch:  42000 quantization_loss:  0.021245913580060005
p mean is: tensor(0.8709, device='cuda:2')
epoch:  43000 quantization_loss:  0.021263109520077705
p mean is: tensor(0.8761, device='cuda:2')
epoch:  44000 quantization_loss:  0.021297438070178032
p mean is: tensor(0.8816, device='cuda:2')
epoch:  45000 quantization_loss:  0.02121635526418686
p mean is: tensor(0.8861, device='cuda:2')
epoch:  46000 quantization_loss:  0.021272314712405205
p mean is: tensor(0.8906, device='cuda:2')
epoch:  47000 quantization_loss:  0.021177848801016808
p mean is: tensor(0.8941, device='cuda:2')
epoch:  48000 quantization_loss:  0.02116052806377411
p mean is: tensor(0.8976, device='cuda:2')
epoch:  49000 quantization_loss:  0.0211550984531641
p mean is: tensor(0.9006, device='cuda:2')
epoch:  50000 quantization_loss:  0.021145321428775787
p mean is: tensor(0.9040, device='cuda:2')
epoch:  51000 quantization_loss:  0.021127240732312202
p mean is: tensor(0.9073, device='cuda:2')
epoch:  52000 quantization_loss:  0.02112266793847084
p mean is: tensor(0.9103, device='cuda:2')
epoch:  53000 quantization_loss:  0.021144118160009384
p mean is: tensor(0.9122, device='cuda:2')
epoch:  54000 quantization_loss:  0.021350819617509842
p mean is: tensor(0.9141, device='cuda:2')
epoch:  55000 quantization_loss:  0.02110147848725319
p mean is: tensor(0.9156, device='cuda:2')
epoch:  56000 quantization_loss:  0.021075807511806488
p mean is: tensor(0.9169, device='cuda:2')
epoch:  57000 quantization_loss:  0.02106626331806183
p mean is: tensor(0.9186, device='cuda:2')
epoch:  58000 quantization_loss:  0.021078968420624733
p mean is: tensor(0.9198, device='cuda:2')
epoch:  59000 quantization_loss:  0.021069876849651337
p mean is: tensor(0.9218, device='cuda:2')
epoch:  60000 quantization_loss:  0.021061496809124947
p mean is: tensor(0.9232, device='cuda:2')
epoch:  61000 quantization_loss:  0.02125929668545723
p mean is: tensor(0.9244, device='cuda:2')
epoch:  62000 quantization_loss:  0.021035674959421158
p mean is: tensor(0.9256, device='cuda:2')
epoch:  63000 quantization_loss:  0.021043235436081886
p mean is: tensor(0.9267, device='cuda:2')
epoch:  64000 quantization_loss:  0.021038085222244263
p mean is: tensor(0.9278, device='cuda:2')
epoch:  65000 quantization_loss:  0.021033816039562225
p mean is: tensor(0.9283, device='cuda:2')
epoch:  66000 quantization_loss:  0.02102726884186268
p mean is: tensor(0.9288, device='cuda:2')
epoch:  67000 quantization_loss:  0.021022096276283264
p mean is: tensor(0.9290, device='cuda:2')
epoch:  68000 quantization_loss:  0.021013746038079262
p mean is: tensor(0.9295, device='cuda:2')
epoch:  69000 quantization_loss:  0.02100815623998642
p mean is: tensor(0.9301, device='cuda:2')
epoch:  70000 quantization_loss:  0.02103673852980137
p mean is: tensor(0.9305, device='cuda:2')
epoch:  71000 quantization_loss:  0.021001089364290237
p mean is: tensor(0.9310, device='cuda:2')
epoch:  72000 quantization_loss:  0.021025400608778
p mean is: tensor(0.9313, device='cuda:2')
epoch:  73000 quantization_loss:  0.021123433485627174
p mean is: tensor(0.9316, device='cuda:2')
epoch:  74000 quantization_loss:  0.020994218066334724
p mean is: tensor(0.9321, device='cuda:2')
epoch:  75000 quantization_loss:  0.020991932600736618
p mean is: tensor(0.9324, device='cuda:2')
epoch:  76000 quantization_loss:  0.020991168916225433
p mean is: tensor(0.9326, device='cuda:2')
epoch:  77000 quantization_loss:  0.021007446572184563
p mean is: tensor(0.9328, device='cuda:2')
epoch:  78000 quantization_loss:  0.02098783664405346
p mean is: tensor(0.9333, device='cuda:2')
epoch:  79000 quantization_loss:  0.020990055054426193
p mean is: tensor(0.9338, device='cuda:2')
here
1.1.weight           | nonzeros =   11656 /   16384             ( 71.14%) | total_pruned =    4728 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =   12958 /   16384             ( 79.09%) | total_pruned =    3426 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =   11269 /   16384             ( 68.78%) | total_pruned =    5115 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =   11404 /   16384             ( 69.60%) | total_pruned =    4980 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =   11880 /   16384             ( 72.51%) | total_pruned =    4504 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =   10588 /   16384             ( 64.62%) | total_pruned =    5796 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     222 /     384             ( 57.81%) | total_pruned =     162 | shape = torch.Size([3, 128, 1, 1])
alive: 70573, pruned : 29651, total: 100224, Compression rate :       1.42x  ( 29.58% pruned)
PSNR of output image is:  18.42120496389156
Experiment done
