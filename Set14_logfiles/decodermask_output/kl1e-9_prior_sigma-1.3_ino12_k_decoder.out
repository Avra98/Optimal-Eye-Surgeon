(3, 256, 256)
Starting vanilla DIP on 12 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.850834960987626'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 8, 8])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/12/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-1.3/1e-09
epoch:  0 quantization_loss:  0.11730203032493591
p mean is: tensor(-0.0002, device='cuda:4')
epoch:  1000 quantization_loss:  0.10654953122138977
p mean is: tensor(-0.0059, device='cuda:4')
epoch:  2000 quantization_loss:  0.0660310834646225
p mean is: tensor(-0.0028, device='cuda:4')
epoch:  3000 quantization_loss:  0.052993178367614746
p mean is: tensor(-0.0097, device='cuda:4')
epoch:  4000 quantization_loss:  0.043185725808143616
p mean is: tensor(-0.0179, device='cuda:4')
epoch:  5000 quantization_loss:  0.03942226245999336
p mean is: tensor(-0.0270, device='cuda:4')
epoch:  6000 quantization_loss:  0.0360984243452549
p mean is: tensor(-0.0373, device='cuda:4')
epoch:  7000 quantization_loss:  0.0333072766661644
p mean is: tensor(-0.0475, device='cuda:4')
epoch:  8000 quantization_loss:  0.030718902125954628
p mean is: tensor(-0.0569, device='cuda:4')
epoch:  9000 quantization_loss:  0.02924574352800846
p mean is: tensor(-0.0690, device='cuda:4')
epoch:  10000 quantization_loss:  0.026521725580096245
p mean is: tensor(-0.0817, device='cuda:4')
epoch:  11000 quantization_loss:  0.023447750136256218
p mean is: tensor(-0.0965, device='cuda:4')
epoch:  12000 quantization_loss:  0.023131422698497772
p mean is: tensor(-0.1111, device='cuda:4')
epoch:  13000 quantization_loss:  0.02113347128033638
p mean is: tensor(-0.1275, device='cuda:4')
epoch:  14000 quantization_loss:  0.020544560626149178
p mean is: tensor(-0.1462, device='cuda:4')
epoch:  15000 quantization_loss:  0.020637115463614464
p mean is: tensor(-0.1651, device='cuda:4')
epoch:  16000 quantization_loss:  0.01983516477048397
p mean is: tensor(-0.1891, device='cuda:4')
epoch:  17000 quantization_loss:  0.018910139799118042
p mean is: tensor(-0.2148, device='cuda:4')
epoch:  18000 quantization_loss:  0.018889836966991425
p mean is: tensor(-0.2448, device='cuda:4')
epoch:  19000 quantization_loss:  0.01844344101846218
p mean is: tensor(-0.2758, device='cuda:4')
epoch:  20000 quantization_loss:  0.018514959141612053
p mean is: tensor(-0.3078, device='cuda:4')
epoch:  21000 quantization_loss:  0.017991313710808754
p mean is: tensor(-0.3402, device='cuda:4')
epoch:  22000 quantization_loss:  0.01786736026406288
p mean is: tensor(-0.3745, device='cuda:4')
epoch:  23000 quantization_loss:  0.017925327643752098
p mean is: tensor(-0.4067, device='cuda:4')
epoch:  24000 quantization_loss:  0.01772775687277317
p mean is: tensor(-0.4373, device='cuda:4')
epoch:  25000 quantization_loss:  0.017129043117165565
p mean is: tensor(-0.4669, device='cuda:4')
epoch:  26000 quantization_loss:  0.01714983955025673
p mean is: tensor(-0.4958, device='cuda:4')
epoch:  27000 quantization_loss:  0.016842640936374664
p mean is: tensor(-0.5233, device='cuda:4')
epoch:  28000 quantization_loss:  0.016940882429480553
p mean is: tensor(-0.5496, device='cuda:4')
epoch:  29000 quantization_loss:  0.016775373369455338
p mean is: tensor(-0.5748, device='cuda:4')
epoch:  30000 quantization_loss:  0.016637904569506645
p mean is: tensor(-0.5996, device='cuda:4')
epoch:  31000 quantization_loss:  0.016582492738962173
p mean is: tensor(-0.6234, device='cuda:4')
epoch:  32000 quantization_loss:  0.016590885818004608
p mean is: tensor(-0.6471, device='cuda:4')
epoch:  33000 quantization_loss:  0.01643887348473072
p mean is: tensor(-0.6696, device='cuda:4')
epoch:  34000 quantization_loss:  0.016404764726758003
p mean is: tensor(-0.6907, device='cuda:4')
epoch:  35000 quantization_loss:  0.016260141506791115
p mean is: tensor(-0.7106, device='cuda:4')
epoch:  36000 quantization_loss:  0.01618240214884281
p mean is: tensor(-0.7298, device='cuda:4')
epoch:  37000 quantization_loss:  0.016201769933104515
p mean is: tensor(-0.7479, device='cuda:4')
epoch:  38000 quantization_loss:  0.016149479895830154
p mean is: tensor(-0.7644, device='cuda:4')
epoch:  39000 quantization_loss:  0.016097255051136017
p mean is: tensor(-0.7799, device='cuda:4')
epoch:  40000 quantization_loss:  0.01598379760980606
p mean is: tensor(-0.7952, device='cuda:4')
epoch:  41000 quantization_loss:  0.016091952100396156
p mean is: tensor(-0.8096, device='cuda:4')
epoch:  42000 quantization_loss:  0.015912186354398727
p mean is: tensor(-0.8220, device='cuda:4')
epoch:  43000 quantization_loss:  0.015944743528962135
p mean is: tensor(-0.8333, device='cuda:4')
epoch:  44000 quantization_loss:  0.01586451567709446
p mean is: tensor(-0.8428, device='cuda:4')
epoch:  45000 quantization_loss:  0.015844708308577538
p mean is: tensor(-0.8509, device='cuda:4')
epoch:  46000 quantization_loss:  0.01587837003171444
p mean is: tensor(-0.8588, device='cuda:4')
epoch:  47000 quantization_loss:  0.01582803763449192
p mean is: tensor(-0.8660, device='cuda:4')
epoch:  48000 quantization_loss:  0.015796082094311714
p mean is: tensor(-0.8723, device='cuda:4')
epoch:  49000 quantization_loss:  0.015741920098662376
p mean is: tensor(-0.8779, device='cuda:4')
epoch:  50000 quantization_loss:  0.01570069044828415
p mean is: tensor(-0.8830, device='cuda:4')
epoch:  51000 quantization_loss:  0.01568054035305977
p mean is: tensor(-0.8878, device='cuda:4')
epoch:  52000 quantization_loss:  0.01570892706513405
p mean is: tensor(-0.8918, device='cuda:4')
epoch:  53000 quantization_loss:  0.015667477622628212
p mean is: tensor(-0.8957, device='cuda:4')
epoch:  54000 quantization_loss:  0.015654131770133972
p mean is: tensor(-0.8992, device='cuda:4')
epoch:  55000 quantization_loss:  0.015946540981531143
p mean is: tensor(-0.9026, device='cuda:4')
epoch:  56000 quantization_loss:  0.015644166618585587
p mean is: tensor(-0.9050, device='cuda:4')
epoch:  57000 quantization_loss:  0.015609927475452423
p mean is: tensor(-0.9077, device='cuda:4')
epoch:  58000 quantization_loss:  0.015604165382683277
p mean is: tensor(-0.9097, device='cuda:4')
epoch:  59000 quantization_loss:  0.01559242233633995
p mean is: tensor(-0.9112, device='cuda:4')
epoch:  60000 quantization_loss:  0.015740130096673965
p mean is: tensor(-0.9126, device='cuda:4')
epoch:  61000 quantization_loss:  0.015584884211421013
p mean is: tensor(-0.9138, device='cuda:4')
epoch:  62000 quantization_loss:  0.015594449825584888
p mean is: tensor(-0.9144, device='cuda:4')
epoch:  63000 quantization_loss:  0.015561642125248909
p mean is: tensor(-0.9146, device='cuda:4')
epoch:  64000 quantization_loss:  0.015544775873422623
p mean is: tensor(-0.9144, device='cuda:4')
epoch:  65000 quantization_loss:  0.015569373965263367
p mean is: tensor(-0.9150, device='cuda:4')
epoch:  66000 quantization_loss:  0.015546186827123165
p mean is: tensor(-0.9155, device='cuda:4')
epoch:  67000 quantization_loss:  0.01578199490904808
p mean is: tensor(-0.9151, device='cuda:4')
epoch:  68000 quantization_loss:  0.015530235134065151
p mean is: tensor(-0.9155, device='cuda:4')
epoch:  69000 quantization_loss:  0.015525841154158115
p mean is: tensor(-0.9158, device='cuda:4')
epoch:  70000 quantization_loss:  0.015517527237534523
p mean is: tensor(-0.9159, device='cuda:4')
epoch:  71000 quantization_loss:  0.015553226694464684
p mean is: tensor(-0.9160, device='cuda:4')
epoch:  72000 quantization_loss:  0.01551781315356493
p mean is: tensor(-0.9158, device='cuda:4')
epoch:  73000 quantization_loss:  0.015713652595877647
p mean is: tensor(-0.9157, device='cuda:4')
epoch:  74000 quantization_loss:  0.015510066412389278
p mean is: tensor(-0.9157, device='cuda:4')
epoch:  75000 quantization_loss:  0.015505583956837654
p mean is: tensor(-0.9155, device='cuda:4')
epoch:  76000 quantization_loss:  0.015502762980759144
p mean is: tensor(-0.9154, device='cuda:4')
epoch:  77000 quantization_loss:  0.015508943237364292
p mean is: tensor(-0.9147, device='cuda:4')
epoch:  78000 quantization_loss:  0.015500620007514954
p mean is: tensor(-0.9143, device='cuda:4')
epoch:  79000 quantization_loss:  0.015498791821300983
p mean is: tensor(-0.9136, device='cuda:4')
here
1.1.weight           | nonzeros =    4710 /   16384             ( 28.75%) | total_pruned =   11674 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =    2747 /   16384             ( 16.77%) | total_pruned =   13637 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    2214 /   16384             ( 13.51%) | total_pruned =   14170 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =    1418 /   16384             (  8.65%) | total_pruned =   14966 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =     955 /   16384             (  5.83%) | total_pruned =   15429 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =    2335 /   16384             ( 14.25%) | total_pruned =   14049 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     261 /     384             ( 67.97%) | total_pruned =     123 | shape = torch.Size([3, 128, 1, 1])
alive: 15063, pruned : 85161, total: 100224, Compression rate :       6.65x  ( 84.97% pruned)
PSNR of output image is:  20.368096921179703
Experiment done
