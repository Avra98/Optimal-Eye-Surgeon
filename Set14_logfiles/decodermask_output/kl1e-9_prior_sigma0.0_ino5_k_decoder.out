(3, 512, 512)
Starting vanilla DIP on 5 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.083187640763374'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 16, 16])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/5/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/0.0/1e-09
epoch:  0 quantization_loss:  0.06492811441421509
p mean is: tensor(-9.1559e-06, device='cuda:3')
epoch:  1000 quantization_loss:  0.05888303741812706
p mean is: tensor(-0.0053, device='cuda:3')
epoch:  2000 quantization_loss:  0.04696191847324371
p mean is: tensor(-0.0021, device='cuda:3')
epoch:  3000 quantization_loss:  0.04230976849794388
p mean is: tensor(0.0006, device='cuda:3')
epoch:  4000 quantization_loss:  0.04008799046278
p mean is: tensor(0.0031, device='cuda:3')
epoch:  5000 quantization_loss:  0.03856604918837547
p mean is: tensor(0.0064, device='cuda:3')
epoch:  6000 quantization_loss:  0.03707904368638992
p mean is: tensor(0.0104, device='cuda:3')
epoch:  7000 quantization_loss:  0.03459759056568146
p mean is: tensor(0.0129, device='cuda:3')
epoch:  8000 quantization_loss:  0.0326276458799839
p mean is: tensor(0.0169, device='cuda:3')
epoch:  9000 quantization_loss:  0.030653253197669983
p mean is: tensor(0.0186, device='cuda:3')
epoch:  10000 quantization_loss:  0.03019709698855877
p mean is: tensor(0.0204, device='cuda:3')
epoch:  11000 quantization_loss:  0.029028695076704025
p mean is: tensor(0.0226, device='cuda:3')
epoch:  12000 quantization_loss:  0.028289493173360825
p mean is: tensor(0.0246, device='cuda:3')
epoch:  13000 quantization_loss:  0.027416469529271126
p mean is: tensor(0.0266, device='cuda:3')
epoch:  14000 quantization_loss:  0.02715933695435524
p mean is: tensor(0.0306, device='cuda:3')
epoch:  15000 quantization_loss:  0.02623659558594227
p mean is: tensor(0.0326, device='cuda:3')
epoch:  16000 quantization_loss:  0.025709742680191994
p mean is: tensor(0.0356, device='cuda:3')
epoch:  17000 quantization_loss:  0.025338133797049522
p mean is: tensor(0.0385, device='cuda:3')
epoch:  18000 quantization_loss:  0.024991702288389206
p mean is: tensor(0.0406, device='cuda:3')
epoch:  19000 quantization_loss:  0.024559009820222855
p mean is: tensor(0.0433, device='cuda:3')
epoch:  20000 quantization_loss:  0.024135803803801537
p mean is: tensor(0.0449, device='cuda:3')
epoch:  21000 quantization_loss:  0.023936297744512558
p mean is: tensor(0.0460, device='cuda:3')
epoch:  22000 quantization_loss:  0.023794425651431084
p mean is: tensor(0.0489, device='cuda:3')
epoch:  23000 quantization_loss:  0.023511378094553947
p mean is: tensor(0.0523, device='cuda:3')
epoch:  24000 quantization_loss:  0.023397743701934814
p mean is: tensor(0.0537, device='cuda:3')
epoch:  25000 quantization_loss:  0.023179488256573677
p mean is: tensor(0.0557, device='cuda:3')
epoch:  26000 quantization_loss:  0.022940801456570625
p mean is: tensor(0.0583, device='cuda:3')
epoch:  27000 quantization_loss:  0.02286149002611637
p mean is: tensor(0.0607, device='cuda:3')
epoch:  28000 quantization_loss:  0.022753341123461723
p mean is: tensor(0.0632, device='cuda:3')
epoch:  29000 quantization_loss:  0.02257455885410309
p mean is: tensor(0.0651, device='cuda:3')
epoch:  30000 quantization_loss:  0.022556187584996223
p mean is: tensor(0.0667, device='cuda:3')
epoch:  31000 quantization_loss:  0.022486474364995956
p mean is: tensor(0.0692, device='cuda:3')
epoch:  32000 quantization_loss:  0.02242731861770153
p mean is: tensor(0.0707, device='cuda:3')
epoch:  33000 quantization_loss:  0.0228675976395607
p mean is: tensor(0.0722, device='cuda:3')
epoch:  34000 quantization_loss:  0.02231062576174736
p mean is: tensor(0.0746, device='cuda:3')
epoch:  35000 quantization_loss:  0.02236419916152954
p mean is: tensor(0.0773, device='cuda:3')
epoch:  36000 quantization_loss:  0.02224142476916313
p mean is: tensor(0.0798, device='cuda:3')
epoch:  37000 quantization_loss:  0.022246619686484337
p mean is: tensor(0.0812, device='cuda:3')
epoch:  38000 quantization_loss:  0.022176889702677727
p mean is: tensor(0.0829, device='cuda:3')
epoch:  39000 quantization_loss:  0.022131886333227158
p mean is: tensor(0.0844, device='cuda:3')
epoch:  40000 quantization_loss:  0.02219689078629017
p mean is: tensor(0.0860, device='cuda:3')
epoch:  41000 quantization_loss:  0.022072147578001022
p mean is: tensor(0.0881, device='cuda:3')
epoch:  42000 quantization_loss:  0.02208786830306053
p mean is: tensor(0.0894, device='cuda:3')
epoch:  43000 quantization_loss:  0.021946297958493233
p mean is: tensor(0.0900, device='cuda:3')
epoch:  44000 quantization_loss:  0.021939601749181747
p mean is: tensor(0.0905, device='cuda:3')
epoch:  45000 quantization_loss:  0.021912313997745514
p mean is: tensor(0.0906, device='cuda:3')
epoch:  46000 quantization_loss:  0.021925855427980423
p mean is: tensor(0.0910, device='cuda:3')
epoch:  47000 quantization_loss:  0.02191174030303955
p mean is: tensor(0.0910, device='cuda:3')
epoch:  48000 quantization_loss:  0.021840842440724373
p mean is: tensor(0.0909, device='cuda:3')
epoch:  49000 quantization_loss:  0.021682724356651306
p mean is: tensor(0.0911, device='cuda:3')
epoch:  50000 quantization_loss:  0.02179451286792755
p mean is: tensor(0.0908, device='cuda:3')
epoch:  51000 quantization_loss:  0.021753499284386635
p mean is: tensor(0.0908, device='cuda:3')
epoch:  52000 quantization_loss:  0.021646922454237938
p mean is: tensor(0.0913, device='cuda:3')
epoch:  53000 quantization_loss:  0.02173272706568241
p mean is: tensor(0.0916, device='cuda:3')
epoch:  54000 quantization_loss:  0.021613340824842453
p mean is: tensor(0.0916, device='cuda:3')
epoch:  55000 quantization_loss:  0.02161286771297455
p mean is: tensor(0.0911, device='cuda:3')
epoch:  56000 quantization_loss:  0.02160564996302128
p mean is: tensor(0.0918, device='cuda:3')
epoch:  57000 quantization_loss:  0.02158515527844429
p mean is: tensor(0.0924, device='cuda:3')
epoch:  58000 quantization_loss:  0.021609444171190262
p mean is: tensor(0.0930, device='cuda:3')
epoch:  59000 quantization_loss:  0.021550441160798073
p mean is: tensor(0.0934, device='cuda:3')
epoch:  60000 quantization_loss:  0.02152685448527336
p mean is: tensor(0.0930, device='cuda:3')
epoch:  61000 quantization_loss:  0.02146471105515957
p mean is: tensor(0.0932, device='cuda:3')
epoch:  62000 quantization_loss:  0.02146759442985058
p mean is: tensor(0.0932, device='cuda:3')
epoch:  63000 quantization_loss:  0.021456345915794373
p mean is: tensor(0.0927, device='cuda:3')
epoch:  64000 quantization_loss:  0.021487247198820114
p mean is: tensor(0.0926, device='cuda:3')
epoch:  65000 quantization_loss:  0.021452270448207855
p mean is: tensor(0.0924, device='cuda:3')
epoch:  66000 quantization_loss:  0.021470898762345314
p mean is: tensor(0.0933, device='cuda:3')
epoch:  67000 quantization_loss:  0.021433526650071144
p mean is: tensor(0.0936, device='cuda:3')
epoch:  68000 quantization_loss:  0.02143920585513115
p mean is: tensor(0.0942, device='cuda:3')
epoch:  69000 quantization_loss:  0.02143407054245472
p mean is: tensor(0.0944, device='cuda:3')
epoch:  70000 quantization_loss:  0.021444953978061676
p mean is: tensor(0.0939, device='cuda:3')
epoch:  71000 quantization_loss:  0.0214469563215971
p mean is: tensor(0.0946, device='cuda:3')
epoch:  72000 quantization_loss:  0.02143818698823452
p mean is: tensor(0.0947, device='cuda:3')
epoch:  73000 quantization_loss:  0.021421989426016808
p mean is: tensor(0.0947, device='cuda:3')
epoch:  74000 quantization_loss:  0.021411513909697533
p mean is: tensor(0.0948, device='cuda:3')
epoch:  75000 quantization_loss:  0.021419374272227287
p mean is: tensor(0.0949, device='cuda:3')
epoch:  76000 quantization_loss:  0.0214094165712595
p mean is: tensor(0.0952, device='cuda:3')
epoch:  77000 quantization_loss:  0.021416526287794113
p mean is: tensor(0.0950, device='cuda:3')
epoch:  78000 quantization_loss:  0.021661022678017616
p mean is: tensor(0.0953, device='cuda:3')
epoch:  79000 quantization_loss:  0.021414732560515404
p mean is: tensor(0.0955, device='cuda:3')
here
1.1.weight           | nonzeros =    8589 /   16384             ( 52.42%) | total_pruned =    7795 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =    7699 /   16384             ( 46.99%) | total_pruned =    8685 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    8038 /   16384             ( 49.06%) | total_pruned =    8346 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =    7726 /   16384             ( 47.16%) | total_pruned =    8658 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =    7132 /   16384             ( 43.53%) | total_pruned =    9252 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =    6496 /   16384             ( 39.65%) | total_pruned =    9888 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     181 /     384             ( 47.14%) | total_pruned =     203 | shape = torch.Size([3, 128, 1, 1])
alive: 46433, pruned : 53791, total: 100224, Compression rate :       2.16x  ( 53.67% pruned)
PSNR of output image is:  19.029592025296072
Experiment done
