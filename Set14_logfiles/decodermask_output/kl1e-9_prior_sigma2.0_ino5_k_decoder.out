(3, 512, 512)
Starting vanilla DIP on 5 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.090194901471857'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 16, 16])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/5/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/2.0/1e-09
epoch:  0 quantization_loss:  0.06440391391515732
p mean is: tensor(0.0003, device='cuda:4')
epoch:  1000 quantization_loss:  0.05842507630586624
p mean is: tensor(0.0042, device='cuda:4')
epoch:  2000 quantization_loss:  0.04848560690879822
p mean is: tensor(0.0148, device='cuda:4')
epoch:  3000 quantization_loss:  0.042555227875709534
p mean is: tensor(0.0292, device='cuda:4')
epoch:  4000 quantization_loss:  0.040856797248125076
p mean is: tensor(0.0443, device='cuda:4')
epoch:  5000 quantization_loss:  0.03833068534731865
p mean is: tensor(0.0621, device='cuda:4')
epoch:  6000 quantization_loss:  0.03611253574490547
p mean is: tensor(0.0817, device='cuda:4')
epoch:  7000 quantization_loss:  0.034648895263671875
p mean is: tensor(0.1009, device='cuda:4')
epoch:  8000 quantization_loss:  0.03285646438598633
p mean is: tensor(0.1219, device='cuda:4')
epoch:  9000 quantization_loss:  0.03158867359161377
p mean is: tensor(0.1434, device='cuda:4')
epoch:  10000 quantization_loss:  0.03007526323199272
p mean is: tensor(0.1652, device='cuda:4')
epoch:  11000 quantization_loss:  0.028550731018185616
p mean is: tensor(0.1899, device='cuda:4')
epoch:  12000 quantization_loss:  0.02738892287015915
p mean is: tensor(0.2159, device='cuda:4')
epoch:  13000 quantization_loss:  0.02675941400229931
p mean is: tensor(0.2442, device='cuda:4')
epoch:  14000 quantization_loss:  0.025874216109514236
p mean is: tensor(0.2758, device='cuda:4')
epoch:  15000 quantization_loss:  0.02537698671221733
p mean is: tensor(0.3091, device='cuda:4')
epoch:  16000 quantization_loss:  0.02499784342944622
p mean is: tensor(0.3437, device='cuda:4')
epoch:  17000 quantization_loss:  0.024306265637278557
p mean is: tensor(0.3787, device='cuda:4')
epoch:  18000 quantization_loss:  0.023884963244199753
p mean is: tensor(0.4144, device='cuda:4')
epoch:  19000 quantization_loss:  0.02334154210984707
p mean is: tensor(0.4502, device='cuda:4')
epoch:  20000 quantization_loss:  0.023187343031167984
p mean is: tensor(0.4849, device='cuda:4')
epoch:  21000 quantization_loss:  0.022821787744760513
p mean is: tensor(0.5201, device='cuda:4')
epoch:  22000 quantization_loss:  0.022684156894683838
p mean is: tensor(0.5526, device='cuda:4')
epoch:  23000 quantization_loss:  0.02239200845360756
p mean is: tensor(0.5850, device='cuda:4')
epoch:  24000 quantization_loss:  0.022232944145798683
p mean is: tensor(0.6170, device='cuda:4')
epoch:  25000 quantization_loss:  0.022144075483083725
p mean is: tensor(0.6480, device='cuda:4')
epoch:  26000 quantization_loss:  0.022012151777744293
p mean is: tensor(0.6775, device='cuda:4')
epoch:  27000 quantization_loss:  0.0218508243560791
p mean is: tensor(0.7046, device='cuda:4')
epoch:  28000 quantization_loss:  0.02174830250442028
p mean is: tensor(0.7310, device='cuda:4')
epoch:  29000 quantization_loss:  0.021655578166246414
p mean is: tensor(0.7558, device='cuda:4')
epoch:  30000 quantization_loss:  0.02152612805366516
p mean is: tensor(0.7780, device='cuda:4')
epoch:  31000 quantization_loss:  0.02157985419034958
p mean is: tensor(0.7990, device='cuda:4')
epoch:  32000 quantization_loss:  0.021357648074626923
p mean is: tensor(0.8180, device='cuda:4')
epoch:  33000 quantization_loss:  0.0213069636374712
p mean is: tensor(0.8356, device='cuda:4')
epoch:  34000 quantization_loss:  0.02136555127799511
p mean is: tensor(0.8516, device='cuda:4')
epoch:  35000 quantization_loss:  0.021256256848573685
p mean is: tensor(0.8660, device='cuda:4')
epoch:  36000 quantization_loss:  0.02103295549750328
p mean is: tensor(0.8779, device='cuda:4')
epoch:  37000 quantization_loss:  0.021025924012064934
p mean is: tensor(0.8892, device='cuda:4')
epoch:  38000 quantization_loss:  0.020988410338759422
p mean is: tensor(0.8985, device='cuda:4')
epoch:  39000 quantization_loss:  0.02094576135277748
p mean is: tensor(0.9080, device='cuda:4')
epoch:  40000 quantization_loss:  0.02090696059167385
p mean is: tensor(0.9163, device='cuda:4')
epoch:  41000 quantization_loss:  0.020930681377649307
p mean is: tensor(0.9241, device='cuda:4')
epoch:  42000 quantization_loss:  0.02087859995663166
p mean is: tensor(0.9316, device='cuda:4')
epoch:  43000 quantization_loss:  0.020811287686228752
p mean is: tensor(0.9371, device='cuda:4')
epoch:  44000 quantization_loss:  0.020795460790395737
p mean is: tensor(0.9421, device='cuda:4')
epoch:  45000 quantization_loss:  0.02077324315905571
p mean is: tensor(0.9472, device='cuda:4')
epoch:  46000 quantization_loss:  0.020751144737005234
p mean is: tensor(0.9523, device='cuda:4')
epoch:  47000 quantization_loss:  0.02073049731552601
p mean is: tensor(0.9564, device='cuda:4')
epoch:  48000 quantization_loss:  0.0207133200019598
p mean is: tensor(0.9616, device='cuda:4')
epoch:  49000 quantization_loss:  0.0207158625125885
p mean is: tensor(0.9659, device='cuda:4')
epoch:  50000 quantization_loss:  0.020726952701807022
p mean is: tensor(0.9698, device='cuda:4')
epoch:  51000 quantization_loss:  0.020707333460450172
p mean is: tensor(0.9733, device='cuda:4')
epoch:  52000 quantization_loss:  0.020749032497406006
p mean is: tensor(0.9767, device='cuda:4')
epoch:  53000 quantization_loss:  0.0206754170358181
p mean is: tensor(0.9787, device='cuda:4')
epoch:  54000 quantization_loss:  0.02067001909017563
p mean is: tensor(0.9813, device='cuda:4')
epoch:  55000 quantization_loss:  0.020819928497076035
p mean is: tensor(0.9833, device='cuda:4')
epoch:  56000 quantization_loss:  0.020671796053647995
p mean is: tensor(0.9853, device='cuda:4')
epoch:  57000 quantization_loss:  0.02065468020737171
p mean is: tensor(0.9877, device='cuda:4')
epoch:  58000 quantization_loss:  0.02064061351120472
p mean is: tensor(0.9898, device='cuda:4')
epoch:  59000 quantization_loss:  0.020685140043497086
p mean is: tensor(0.9921, device='cuda:4')
epoch:  60000 quantization_loss:  0.020633207634091377
p mean is: tensor(0.9943, device='cuda:4')
epoch:  61000 quantization_loss:  0.02061770111322403
p mean is: tensor(0.9962, device='cuda:4')
epoch:  62000 quantization_loss:  0.02062210999429226
p mean is: tensor(0.9970, device='cuda:4')
epoch:  63000 quantization_loss:  0.020660804584622383
p mean is: tensor(0.9988, device='cuda:4')
epoch:  64000 quantization_loss:  0.020622609183192253
p mean is: tensor(1.0004, device='cuda:4')
epoch:  65000 quantization_loss:  0.020640039816498756
p mean is: tensor(1.0022, device='cuda:4')
epoch:  66000 quantization_loss:  0.020600728690624237
p mean is: tensor(1.0040, device='cuda:4')
epoch:  67000 quantization_loss:  0.02059430629014969
p mean is: tensor(1.0052, device='cuda:4')
epoch:  68000 quantization_loss:  0.0205951277166605
p mean is: tensor(1.0061, device='cuda:4')
epoch:  69000 quantization_loss:  0.02061951719224453
p mean is: tensor(1.0067, device='cuda:4')
epoch:  70000 quantization_loss:  0.02058861218392849
p mean is: tensor(1.0080, device='cuda:4')
epoch:  71000 quantization_loss:  0.020598093047738075
p mean is: tensor(1.0092, device='cuda:4')
epoch:  72000 quantization_loss:  0.020591355860233307
p mean is: tensor(1.0102, device='cuda:4')
epoch:  73000 quantization_loss:  0.02058274857699871
p mean is: tensor(1.0114, device='cuda:4')
epoch:  74000 quantization_loss:  0.02060112915933132
p mean is: tensor(1.0122, device='cuda:4')
epoch:  75000 quantization_loss:  0.020574821159243584
p mean is: tensor(1.0134, device='cuda:4')
epoch:  76000 quantization_loss:  0.02058512344956398
p mean is: tensor(1.0148, device='cuda:4')
epoch:  77000 quantization_loss:  0.020571768283843994
p mean is: tensor(1.0163, device='cuda:4')
epoch:  78000 quantization_loss:  0.020595427602529526
p mean is: tensor(1.0172, device='cuda:4')
epoch:  79000 quantization_loss:  0.020594768226146698
p mean is: tensor(1.0178, device='cuda:4')
here
1.1.weight           | nonzeros =   11422 /   16384             ( 69.71%) | total_pruned =    4962 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =   11907 /   16384             ( 72.67%) | total_pruned =    4477 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    9996 /   16384             ( 61.01%) | total_pruned =    6388 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =   10641 /   16384             ( 64.95%) | total_pruned =    5743 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =   12886 /   16384             ( 78.65%) | total_pruned =    3498 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =   12810 /   16384             ( 78.19%) | total_pruned =    3574 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     255 /     384             ( 66.41%) | total_pruned =     129 | shape = torch.Size([3, 128, 1, 1])
alive: 70513, pruned : 29711, total: 100224, Compression rate :       1.42x  ( 29.64% pruned)
PSNR of output image is:  19.34538263695838
Experiment done
