(3, 512, 512)
Starting vanilla DIP on 10 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.167158507236188'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 16, 16])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/10/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-1.3/1e-09
epoch:  0 quantization_loss:  0.06150982901453972
p mean is: tensor(-0.0002, device='cuda:2')
epoch:  1000 quantization_loss:  0.05736073479056358
p mean is: tensor(-0.0113, device='cuda:2')
epoch:  2000 quantization_loss:  0.038520827889442444
p mean is: tensor(-0.0124, device='cuda:2')
epoch:  3000 quantization_loss:  0.0323663204908371
p mean is: tensor(-0.0125, device='cuda:2')
epoch:  4000 quantization_loss:  0.029545947909355164
p mean is: tensor(-0.0176, device='cuda:2')
epoch:  5000 quantization_loss:  0.027980681508779526
p mean is: tensor(-0.0220, device='cuda:2')
epoch:  6000 quantization_loss:  0.02687264233827591
p mean is: tensor(-0.0276, device='cuda:2')
epoch:  7000 quantization_loss:  0.02630050666630268
p mean is: tensor(-0.0357, device='cuda:2')
epoch:  8000 quantization_loss:  0.02536715567111969
p mean is: tensor(-0.0466, device='cuda:2')
epoch:  9000 quantization_loss:  0.02489943988621235
p mean is: tensor(-0.0590, device='cuda:2')
epoch:  10000 quantization_loss:  0.024089813232421875
p mean is: tensor(-0.0737, device='cuda:2')
epoch:  11000 quantization_loss:  0.023772448301315308
p mean is: tensor(-0.0919, device='cuda:2')
epoch:  12000 quantization_loss:  0.02322247251868248
p mean is: tensor(-0.1135, device='cuda:2')
epoch:  13000 quantization_loss:  0.022734232246875763
p mean is: tensor(-0.1376, device='cuda:2')
epoch:  14000 quantization_loss:  0.022541526705026627
p mean is: tensor(-0.1633, device='cuda:2')
epoch:  15000 quantization_loss:  0.02200981415808201
p mean is: tensor(-0.1927, device='cuda:2')
epoch:  16000 quantization_loss:  0.02183801680803299
p mean is: tensor(-0.2223, device='cuda:2')
epoch:  17000 quantization_loss:  0.02150370553135872
p mean is: tensor(-0.2519, device='cuda:2')
epoch:  18000 quantization_loss:  0.021314742043614388
p mean is: tensor(-0.2806, device='cuda:2')
epoch:  19000 quantization_loss:  0.021078571677207947
p mean is: tensor(-0.3094, device='cuda:2')
epoch:  20000 quantization_loss:  0.020944204181432724
p mean is: tensor(-0.3356, device='cuda:2')
epoch:  21000 quantization_loss:  0.020611818879842758
p mean is: tensor(-0.3613, device='cuda:2')
epoch:  22000 quantization_loss:  0.02055281400680542
p mean is: tensor(-0.3855, device='cuda:2')
epoch:  23000 quantization_loss:  0.020435668528079987
p mean is: tensor(-0.4084, device='cuda:2')
epoch:  24000 quantization_loss:  0.02020934224128723
p mean is: tensor(-0.4307, device='cuda:2')
epoch:  25000 quantization_loss:  0.020077044144272804
p mean is: tensor(-0.4509, device='cuda:2')
epoch:  26000 quantization_loss:  0.019935686141252518
p mean is: tensor(-0.4696, device='cuda:2')
epoch:  27000 quantization_loss:  0.019889118149876595
p mean is: tensor(-0.4885, device='cuda:2')
epoch:  28000 quantization_loss:  0.01977299526333809
p mean is: tensor(-0.5055, device='cuda:2')
epoch:  29000 quantization_loss:  0.019722459837794304
p mean is: tensor(-0.5207, device='cuda:2')
epoch:  30000 quantization_loss:  0.01963234692811966
p mean is: tensor(-0.5346, device='cuda:2')
epoch:  31000 quantization_loss:  0.01954921893775463
p mean is: tensor(-0.5473, device='cuda:2')
epoch:  32000 quantization_loss:  0.019431186839938164
p mean is: tensor(-0.5580, device='cuda:2')
epoch:  33000 quantization_loss:  0.019397875294089317
p mean is: tensor(-0.5681, device='cuda:2')
epoch:  34000 quantization_loss:  0.019320789724588394
p mean is: tensor(-0.5773, device='cuda:2')
epoch:  35000 quantization_loss:  0.01925557106733322
p mean is: tensor(-0.5854, device='cuda:2')
epoch:  36000 quantization_loss:  0.01923036202788353
p mean is: tensor(-0.5927, device='cuda:2')
epoch:  37000 quantization_loss:  0.01920606940984726
p mean is: tensor(-0.5993, device='cuda:2')
epoch:  38000 quantization_loss:  0.019233083352446556
p mean is: tensor(-0.6049, device='cuda:2')
epoch:  39000 quantization_loss:  0.01921774074435234
p mean is: tensor(-0.6093, device='cuda:2')
epoch:  40000 quantization_loss:  0.019099975004792213
p mean is: tensor(-0.6130, device='cuda:2')
epoch:  41000 quantization_loss:  0.01909526251256466
p mean is: tensor(-0.6156, device='cuda:2')
epoch:  42000 quantization_loss:  0.01910586841404438
p mean is: tensor(-0.6181, device='cuda:2')
epoch:  43000 quantization_loss:  0.019054075703024864
p mean is: tensor(-0.6207, device='cuda:2')
epoch:  44000 quantization_loss:  0.019073937088251114
p mean is: tensor(-0.6237, device='cuda:2')
epoch:  45000 quantization_loss:  0.01902521401643753
p mean is: tensor(-0.6258, device='cuda:2')
epoch:  46000 quantization_loss:  0.019012263044714928
p mean is: tensor(-0.6274, device='cuda:2')
epoch:  47000 quantization_loss:  0.01900661550462246
p mean is: tensor(-0.6284, device='cuda:2')
epoch:  48000 quantization_loss:  0.018984409049153328
p mean is: tensor(-0.6294, device='cuda:2')
epoch:  49000 quantization_loss:  0.018978986889123917
p mean is: tensor(-0.6299, device='cuda:2')
epoch:  50000 quantization_loss:  0.01896885596215725
p mean is: tensor(-0.6295, device='cuda:2')
epoch:  51000 quantization_loss:  0.018976490944623947
p mean is: tensor(-0.6294, device='cuda:2')
epoch:  52000 quantization_loss:  0.018926531076431274
p mean is: tensor(-0.6294, device='cuda:2')
epoch:  53000 quantization_loss:  0.01894601248204708
p mean is: tensor(-0.6299, device='cuda:2')
epoch:  54000 quantization_loss:  0.018929941579699516
p mean is: tensor(-0.6297, device='cuda:2')
epoch:  55000 quantization_loss:  0.018926581367850304
p mean is: tensor(-0.6298, device='cuda:2')
epoch:  56000 quantization_loss:  0.018902234733104706
p mean is: tensor(-0.6299, device='cuda:2')
epoch:  57000 quantization_loss:  0.018895694985985756
p mean is: tensor(-0.6299, device='cuda:2')
epoch:  58000 quantization_loss:  0.01889021508395672
p mean is: tensor(-0.6298, device='cuda:2')
epoch:  59000 quantization_loss:  0.018887894228100777
p mean is: tensor(-0.6301, device='cuda:2')
epoch:  60000 quantization_loss:  0.018891770392656326
p mean is: tensor(-0.6298, device='cuda:2')
epoch:  61000 quantization_loss:  0.018896622583270073
p mean is: tensor(-0.6298, device='cuda:2')
epoch:  62000 quantization_loss:  0.018890146166086197
p mean is: tensor(-0.6298, device='cuda:2')
epoch:  63000 quantization_loss:  0.018862145021557808
p mean is: tensor(-0.6296, device='cuda:2')
epoch:  64000 quantization_loss:  0.018872609362006187
p mean is: tensor(-0.6294, device='cuda:2')
epoch:  65000 quantization_loss:  0.01888054609298706
p mean is: tensor(-0.6292, device='cuda:2')
epoch:  66000 quantization_loss:  0.018869036808609962
p mean is: tensor(-0.6287, device='cuda:2')
epoch:  67000 quantization_loss:  0.018861033022403717
p mean is: tensor(-0.6285, device='cuda:2')
epoch:  68000 quantization_loss:  0.018859878182411194
p mean is: tensor(-0.6283, device='cuda:2')
epoch:  69000 quantization_loss:  0.01885085366666317
p mean is: tensor(-0.6285, device='cuda:2')
epoch:  70000 quantization_loss:  0.01886635087430477
p mean is: tensor(-0.6279, device='cuda:2')
epoch:  71000 quantization_loss:  0.018864130601286888
p mean is: tensor(-0.6277, device='cuda:2')
epoch:  72000 quantization_loss:  0.01884962059557438
p mean is: tensor(-0.6273, device='cuda:2')
epoch:  73000 quantization_loss:  0.018967635929584503
p mean is: tensor(-0.6269, device='cuda:2')
epoch:  74000 quantization_loss:  0.019160697236657143
p mean is: tensor(-0.6271, device='cuda:2')
epoch:  75000 quantization_loss:  0.0188333410769701
p mean is: tensor(-0.6269, device='cuda:2')
epoch:  76000 quantization_loss:  0.018830101937055588
p mean is: tensor(-0.6269, device='cuda:2')
epoch:  77000 quantization_loss:  0.0188334621489048
p mean is: tensor(-0.6272, device='cuda:2')
epoch:  78000 quantization_loss:  0.01883576810359955
p mean is: tensor(-0.6268, device='cuda:2')
epoch:  79000 quantization_loss:  0.01882447488605976
p mean is: tensor(-0.6267, device='cuda:2')
here
1.1.weight           | nonzeros =    5575 /   16384             ( 34.03%) | total_pruned =   10809 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =    4505 /   16384             ( 27.50%) | total_pruned =   11879 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    5145 /   16384             ( 31.40%) | total_pruned =   11239 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =    4292 /   16384             ( 26.20%) | total_pruned =   12092 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =    1929 /   16384             ( 11.77%) | total_pruned =   14455 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =    1471 /   16384             (  8.98%) | total_pruned =   14913 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     157 /     384             ( 40.89%) | total_pruned =     227 | shape = torch.Size([3, 128, 1, 1])
alive: 23569, pruned : 76655, total: 100224, Compression rate :       4.25x  ( 76.48% pruned)
PSNR of output image is:  20.225046739079442
Experiment done
