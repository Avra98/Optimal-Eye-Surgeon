(3, 512, 512)
Starting vanilla DIP on 4 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '19.74635164954757'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 16, 16])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/4/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/2.0/1e-09
epoch:  0 quantization_loss:  0.06519840657711029
p mean is: tensor(0.0003, device='cuda:3')
epoch:  1000 quantization_loss:  0.06324406713247299
p mean is: tensor(0.0047, device='cuda:3')
epoch:  2000 quantization_loss:  0.05455760657787323
p mean is: tensor(0.0117, device='cuda:3')
epoch:  3000 quantization_loss:  0.0439290925860405
p mean is: tensor(0.0194, device='cuda:3')
epoch:  4000 quantization_loss:  0.03624503314495087
p mean is: tensor(0.0251, device='cuda:3')
epoch:  5000 quantization_loss:  0.03341636806726456
p mean is: tensor(0.0327, device='cuda:3')
epoch:  6000 quantization_loss:  0.03117101639509201
p mean is: tensor(0.0447, device='cuda:3')
epoch:  7000 quantization_loss:  0.029857296496629715
p mean is: tensor(0.0603, device='cuda:3')
epoch:  8000 quantization_loss:  0.028355639427900314
p mean is: tensor(0.0783, device='cuda:3')
epoch:  9000 quantization_loss:  0.027132919058203697
p mean is: tensor(0.0996, device='cuda:3')
epoch:  10000 quantization_loss:  0.02646610513329506
p mean is: tensor(0.1231, device='cuda:3')
epoch:  11000 quantization_loss:  0.025797905400395393
p mean is: tensor(0.1502, device='cuda:3')
epoch:  12000 quantization_loss:  0.02560393512248993
p mean is: tensor(0.1809, device='cuda:3')
epoch:  13000 quantization_loss:  0.024754991754889488
p mean is: tensor(0.2139, device='cuda:3')
epoch:  14000 quantization_loss:  0.024320317432284355
p mean is: tensor(0.2479, device='cuda:3')
epoch:  15000 quantization_loss:  0.023829590529203415
p mean is: tensor(0.2857, device='cuda:3')
epoch:  16000 quantization_loss:  0.02318083494901657
p mean is: tensor(0.3248, device='cuda:3')
epoch:  17000 quantization_loss:  0.022843487560749054
p mean is: tensor(0.3652, device='cuda:3')
epoch:  18000 quantization_loss:  0.022714780643582344
p mean is: tensor(0.4039, device='cuda:3')
epoch:  19000 quantization_loss:  0.022363515570759773
p mean is: tensor(0.4436, device='cuda:3')
epoch:  20000 quantization_loss:  0.02198544517159462
p mean is: tensor(0.4829, device='cuda:3')
epoch:  21000 quantization_loss:  0.021784046664834023
p mean is: tensor(0.5205, device='cuda:3')
epoch:  22000 quantization_loss:  0.02172076143324375
p mean is: tensor(0.5585, device='cuda:3')
epoch:  23000 quantization_loss:  0.021573031321167946
p mean is: tensor(0.5956, device='cuda:3')
epoch:  24000 quantization_loss:  0.02151358686387539
p mean is: tensor(0.6308, device='cuda:3')
epoch:  25000 quantization_loss:  0.02128468081355095
p mean is: tensor(0.6645, device='cuda:3')
epoch:  26000 quantization_loss:  0.02122066728770733
p mean is: tensor(0.6971, device='cuda:3')
epoch:  27000 quantization_loss:  0.021146563813090324
p mean is: tensor(0.7287, device='cuda:3')
epoch:  28000 quantization_loss:  0.021031886339187622
p mean is: tensor(0.7573, device='cuda:3')
epoch:  29000 quantization_loss:  0.020948221907019615
p mean is: tensor(0.7840, device='cuda:3')
epoch:  30000 quantization_loss:  0.02086990512907505
p mean is: tensor(0.8097, device='cuda:3')
epoch:  31000 quantization_loss:  0.02083219401538372
p mean is: tensor(0.8331, device='cuda:3')
epoch:  32000 quantization_loss:  0.020798904821276665
p mean is: tensor(0.8537, device='cuda:3')
epoch:  33000 quantization_loss:  0.02073984593153
p mean is: tensor(0.8737, device='cuda:3')
epoch:  34000 quantization_loss:  0.020764430984854698
p mean is: tensor(0.8917, device='cuda:3')
epoch:  35000 quantization_loss:  0.02065306156873703
p mean is: tensor(0.9086, device='cuda:3')
epoch:  36000 quantization_loss:  0.02061738260090351
p mean is: tensor(0.9242, device='cuda:3')
epoch:  37000 quantization_loss:  0.0205992441624403
p mean is: tensor(0.9386, device='cuda:3')
epoch:  38000 quantization_loss:  0.02053864113986492
p mean is: tensor(0.9509, device='cuda:3')
epoch:  39000 quantization_loss:  0.020508795976638794
p mean is: tensor(0.9624, device='cuda:3')
epoch:  40000 quantization_loss:  0.020528007298707962
p mean is: tensor(0.9722, device='cuda:3')
epoch:  41000 quantization_loss:  0.020460359752178192
p mean is: tensor(0.9816, device='cuda:3')
epoch:  42000 quantization_loss:  0.020457657054066658
p mean is: tensor(0.9898, device='cuda:3')
epoch:  43000 quantization_loss:  0.020452609285712242
p mean is: tensor(0.9972, device='cuda:3')
epoch:  44000 quantization_loss:  0.02039167657494545
p mean is: tensor(1.0036, device='cuda:3')
epoch:  45000 quantization_loss:  0.020411409437656403
p mean is: tensor(1.0101, device='cuda:3')
epoch:  46000 quantization_loss:  0.02038026601076126
p mean is: tensor(1.0159, device='cuda:3')
epoch:  47000 quantization_loss:  0.02038048952817917
p mean is: tensor(1.0202, device='cuda:3')
epoch:  48000 quantization_loss:  0.020378148183226585
p mean is: tensor(1.0252, device='cuda:3')
epoch:  49000 quantization_loss:  0.020360508933663368
p mean is: tensor(1.0296, device='cuda:3')
epoch:  50000 quantization_loss:  0.020355360582470894
p mean is: tensor(1.0331, device='cuda:3')
epoch:  51000 quantization_loss:  0.020337995141744614
p mean is: tensor(1.0360, device='cuda:3')
epoch:  52000 quantization_loss:  0.020335381850600243
p mean is: tensor(1.0385, device='cuda:3')
epoch:  53000 quantization_loss:  0.020313022658228874
p mean is: tensor(1.0409, device='cuda:3')
epoch:  54000 quantization_loss:  0.020315255969762802
p mean is: tensor(1.0442, device='cuda:3')
epoch:  55000 quantization_loss:  0.020326057448983192
p mean is: tensor(1.0466, device='cuda:3')
epoch:  56000 quantization_loss:  0.02032640017569065
p mean is: tensor(1.0487, device='cuda:3')
epoch:  57000 quantization_loss:  0.020335087552666664
p mean is: tensor(1.0508, device='cuda:3')
epoch:  58000 quantization_loss:  0.020303985103964806
p mean is: tensor(1.0531, device='cuda:3')
epoch:  59000 quantization_loss:  0.020297536626458168
p mean is: tensor(1.0556, device='cuda:3')
epoch:  60000 quantization_loss:  0.02028815634548664
p mean is: tensor(1.0568, device='cuda:3')
epoch:  61000 quantization_loss:  0.02029447630047798
p mean is: tensor(1.0582, device='cuda:3')
epoch:  62000 quantization_loss:  0.020287295803427696
p mean is: tensor(1.0592, device='cuda:3')
epoch:  63000 quantization_loss:  0.020277205854654312
p mean is: tensor(1.0600, device='cuda:3')
epoch:  64000 quantization_loss:  0.020282063633203506
p mean is: tensor(1.0614, device='cuda:3')
epoch:  65000 quantization_loss:  0.020281963050365448
p mean is: tensor(1.0623, device='cuda:3')
epoch:  66000 quantization_loss:  0.020318159833550453
p mean is: tensor(1.0631, device='cuda:3')
epoch:  67000 quantization_loss:  0.020263688638806343
p mean is: tensor(1.0641, device='cuda:3')
epoch:  68000 quantization_loss:  0.020261863246560097
p mean is: tensor(1.0649, device='cuda:3')
epoch:  69000 quantization_loss:  0.020253045484423637
p mean is: tensor(1.0658, device='cuda:3')
epoch:  70000 quantization_loss:  0.020245935767889023
p mean is: tensor(1.0666, device='cuda:3')
epoch:  71000 quantization_loss:  0.020245393738150597
p mean is: tensor(1.0675, device='cuda:3')
epoch:  72000 quantization_loss:  0.020245082676410675
p mean is: tensor(1.0683, device='cuda:3')
epoch:  73000 quantization_loss:  0.02025091089308262
p mean is: tensor(1.0684, device='cuda:3')
epoch:  74000 quantization_loss:  0.020243031904101372
p mean is: tensor(1.0688, device='cuda:3')
epoch:  75000 quantization_loss:  0.020235802978277206
p mean is: tensor(1.0696, device='cuda:3')
epoch:  76000 quantization_loss:  0.02024306170642376
p mean is: tensor(1.0700, device='cuda:3')
epoch:  77000 quantization_loss:  0.020256295800209045
p mean is: tensor(1.0707, device='cuda:3')
epoch:  78000 quantization_loss:  0.020232606679201126
p mean is: tensor(1.0717, device='cuda:3')
epoch:  79000 quantization_loss:  0.020251594483852386
p mean is: tensor(1.0722, device='cuda:3')
here
1.1.weight           | nonzeros =   11475 /   16384             ( 70.04%) | total_pruned =    4909 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =   12580 /   16384             ( 76.78%) | total_pruned =    3804 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =   11453 /   16384             ( 69.90%) | total_pruned =    4931 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =   12276 /   16384             ( 74.93%) | total_pruned =    4108 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =   13070 /   16384             ( 79.77%) | total_pruned =    3314 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =   11917 /   16384             ( 72.74%) | total_pruned =    4467 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     239 /     384             ( 62.24%) | total_pruned =     145 | shape = torch.Size([3, 128, 1, 1])
alive: 73582, pruned : 26642, total: 100224, Compression rate :       1.36x  ( 26.58% pruned)
PSNR of output image is:  19.118819250399564
Experiment done
