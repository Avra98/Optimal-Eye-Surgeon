(3, 512, 512)
Starting vanilla DIP on 2 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.43418219381307'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 16, 16])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/2/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/0.0/1e-09
epoch:  0 quantization_loss:  0.09602754563093185
p mean is: tensor(-1.1188e-05, device='cuda:2')
epoch:  1000 quantization_loss:  0.09029845893383026
p mean is: tensor(-0.0047, device='cuda:2')
epoch:  2000 quantization_loss:  0.078048475086689
p mean is: tensor(-0.0009, device='cuda:2')
epoch:  3000 quantization_loss:  0.06701236963272095
p mean is: tensor(0.0061, device='cuda:2')
epoch:  4000 quantization_loss:  0.061242662370204926
p mean is: tensor(0.0102, device='cuda:2')
epoch:  5000 quantization_loss:  0.05606944113969803
p mean is: tensor(0.0128, device='cuda:2')
epoch:  6000 quantization_loss:  0.04685840383172035
p mean is: tensor(0.0116, device='cuda:2')
epoch:  7000 quantization_loss:  0.043256018310785294
p mean is: tensor(0.0119, device='cuda:2')
epoch:  8000 quantization_loss:  0.039375364780426025
p mean is: tensor(0.0125, device='cuda:2')
epoch:  9000 quantization_loss:  0.03775539994239807
p mean is: tensor(0.0129, device='cuda:2')
epoch:  10000 quantization_loss:  0.035401351749897
p mean is: tensor(0.0141, device='cuda:2')
epoch:  11000 quantization_loss:  0.033923693001270294
p mean is: tensor(0.0146, device='cuda:2')
epoch:  12000 quantization_loss:  0.03340237960219383
p mean is: tensor(0.0149, device='cuda:2')
epoch:  13000 quantization_loss:  0.03211008384823799
p mean is: tensor(0.0154, device='cuda:2')
epoch:  14000 quantization_loss:  0.031213359907269478
p mean is: tensor(0.0163, device='cuda:2')
epoch:  15000 quantization_loss:  0.031032448634505272
p mean is: tensor(0.0176, device='cuda:2')
epoch:  16000 quantization_loss:  0.030088990926742554
p mean is: tensor(0.0199, device='cuda:2')
epoch:  17000 quantization_loss:  0.029637552797794342
p mean is: tensor(0.0213, device='cuda:2')
epoch:  18000 quantization_loss:  0.0293585117906332
p mean is: tensor(0.0230, device='cuda:2')
epoch:  19000 quantization_loss:  0.028823763132095337
p mean is: tensor(0.0246, device='cuda:2')
epoch:  20000 quantization_loss:  0.02842755988240242
p mean is: tensor(0.0262, device='cuda:2')
epoch:  21000 quantization_loss:  0.028179364278912544
p mean is: tensor(0.0275, device='cuda:2')
epoch:  22000 quantization_loss:  0.02791900932788849
p mean is: tensor(0.0310, device='cuda:2')
epoch:  23000 quantization_loss:  0.02774661034345627
p mean is: tensor(0.0329, device='cuda:2')
epoch:  24000 quantization_loss:  0.02751768007874489
p mean is: tensor(0.0360, device='cuda:2')
epoch:  25000 quantization_loss:  0.027419865131378174
p mean is: tensor(0.0382, device='cuda:2')
epoch:  26000 quantization_loss:  0.02716258354485035
p mean is: tensor(0.0403, device='cuda:2')
epoch:  27000 quantization_loss:  0.027073271572589874
p mean is: tensor(0.0431, device='cuda:2')
epoch:  28000 quantization_loss:  0.02702634409070015
p mean is: tensor(0.0453, device='cuda:2')
epoch:  29000 quantization_loss:  0.026794133707880974
p mean is: tensor(0.0473, device='cuda:2')
epoch:  30000 quantization_loss:  0.026777073740959167
p mean is: tensor(0.0486, device='cuda:2')
epoch:  31000 quantization_loss:  0.02670503966510296
p mean is: tensor(0.0503, device='cuda:2')
epoch:  32000 quantization_loss:  0.026612240821123123
p mean is: tensor(0.0523, device='cuda:2')
epoch:  33000 quantization_loss:  0.026499655097723007
p mean is: tensor(0.0555, device='cuda:2')
epoch:  34000 quantization_loss:  0.026697726920247078
p mean is: tensor(0.0566, device='cuda:2')
epoch:  35000 quantization_loss:  0.026352617889642715
p mean is: tensor(0.0586, device='cuda:2')
epoch:  36000 quantization_loss:  0.02631516009569168
p mean is: tensor(0.0609, device='cuda:2')
epoch:  37000 quantization_loss:  0.02610844001173973
p mean is: tensor(0.0631, device='cuda:2')
epoch:  38000 quantization_loss:  0.026038257405161858
p mean is: tensor(0.0645, device='cuda:2')
epoch:  39000 quantization_loss:  0.026024840772151947
p mean is: tensor(0.0662, device='cuda:2')
epoch:  40000 quantization_loss:  0.025986820459365845
p mean is: tensor(0.0685, device='cuda:2')
epoch:  41000 quantization_loss:  0.025958813726902008
p mean is: tensor(0.0700, device='cuda:2')
epoch:  42000 quantization_loss:  0.02593965269625187
p mean is: tensor(0.0716, device='cuda:2')
epoch:  43000 quantization_loss:  0.02594343014061451
p mean is: tensor(0.0729, device='cuda:2')
epoch:  44000 quantization_loss:  0.025894654914736748
p mean is: tensor(0.0736, device='cuda:2')
epoch:  45000 quantization_loss:  0.02589692920446396
p mean is: tensor(0.0747, device='cuda:2')
epoch:  46000 quantization_loss:  0.02618388645350933
p mean is: tensor(0.0758, device='cuda:2')
epoch:  47000 quantization_loss:  0.025829413905739784
p mean is: tensor(0.0765, device='cuda:2')
epoch:  48000 quantization_loss:  0.025886787101626396
p mean is: tensor(0.0770, device='cuda:2')
epoch:  49000 quantization_loss:  0.025840528309345245
p mean is: tensor(0.0773, device='cuda:2')
epoch:  50000 quantization_loss:  0.02580518089234829
p mean is: tensor(0.0778, device='cuda:2')
epoch:  51000 quantization_loss:  0.025800704956054688
p mean is: tensor(0.0782, device='cuda:2')
epoch:  52000 quantization_loss:  0.02580275386571884
p mean is: tensor(0.0783, device='cuda:2')
epoch:  53000 quantization_loss:  0.02578960917890072
p mean is: tensor(0.0793, device='cuda:2')
epoch:  54000 quantization_loss:  0.02571200393140316
p mean is: tensor(0.0788, device='cuda:2')
epoch:  55000 quantization_loss:  0.025707866996526718
p mean is: tensor(0.0797, device='cuda:2')
epoch:  56000 quantization_loss:  0.025679193437099457
p mean is: tensor(0.0808, device='cuda:2')
epoch:  57000 quantization_loss:  0.025666985660791397
p mean is: tensor(0.0813, device='cuda:2')
epoch:  58000 quantization_loss:  0.02570917457342148
p mean is: tensor(0.0815, device='cuda:2')
epoch:  59000 quantization_loss:  0.025686362758278847
p mean is: tensor(0.0812, device='cuda:2')
epoch:  60000 quantization_loss:  0.02564813196659088
p mean is: tensor(0.0812, device='cuda:2')
epoch:  61000 quantization_loss:  0.025646157562732697
p mean is: tensor(0.0821, device='cuda:2')
epoch:  62000 quantization_loss:  0.02564927004277706
p mean is: tensor(0.0825, device='cuda:2')
epoch:  63000 quantization_loss:  0.02562127448618412
p mean is: tensor(0.0832, device='cuda:2')
epoch:  64000 quantization_loss:  0.025633135810494423
p mean is: tensor(0.0829, device='cuda:2')
epoch:  65000 quantization_loss:  0.025632603093981743
p mean is: tensor(0.0826, device='cuda:2')
epoch:  66000 quantization_loss:  0.025737784802913666
p mean is: tensor(0.0825, device='cuda:2')
epoch:  67000 quantization_loss:  0.025633320212364197
p mean is: tensor(0.0826, device='cuda:2')
epoch:  68000 quantization_loss:  0.02562566287815571
p mean is: tensor(0.0831, device='cuda:2')
epoch:  69000 quantization_loss:  0.02561289072036743
p mean is: tensor(0.0834, device='cuda:2')
epoch:  70000 quantization_loss:  0.02559652365744114
p mean is: tensor(0.0839, device='cuda:2')
epoch:  71000 quantization_loss:  0.025609450414776802
p mean is: tensor(0.0841, device='cuda:2')
epoch:  72000 quantization_loss:  0.02559470571577549
p mean is: tensor(0.0845, device='cuda:2')
epoch:  73000 quantization_loss:  0.02559557743370533
p mean is: tensor(0.0847, device='cuda:2')
epoch:  74000 quantization_loss:  0.02560523897409439
p mean is: tensor(0.0849, device='cuda:2')
epoch:  75000 quantization_loss:  0.02558521367609501
p mean is: tensor(0.0847, device='cuda:2')
epoch:  76000 quantization_loss:  0.025587402284145355
p mean is: tensor(0.0851, device='cuda:2')
epoch:  77000 quantization_loss:  0.02558138221502304
p mean is: tensor(0.0853, device='cuda:2')
epoch:  78000 quantization_loss:  0.025629546493291855
p mean is: tensor(0.0855, device='cuda:2')
epoch:  79000 quantization_loss:  0.025587577372789383
p mean is: tensor(0.0857, device='cuda:2')
here
1.1.weight           | nonzeros =    8577 /   16384             ( 52.35%) | total_pruned =    7807 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =    7714 /   16384             ( 47.08%) | total_pruned =    8670 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    8113 /   16384             ( 49.52%) | total_pruned =    8271 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =    7574 /   16384             ( 46.23%) | total_pruned =    8810 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =    5808 /   16384             ( 35.45%) | total_pruned =   10576 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =    6709 /   16384             ( 40.95%) | total_pruned =    9675 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =     122 /     128             ( 95.31%) | total_pruned =       6 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     233 /     384             ( 60.68%) | total_pruned =     151 | shape = torch.Size([3, 128, 1, 1])
alive: 45289, pruned : 54935, total: 100224, Compression rate :       2.21x  ( 54.81% pruned)
PSNR of output image is:  17.61785865929159
Experiment done
