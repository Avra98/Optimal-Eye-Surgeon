(3, 512, 512)
Starting vanilla DIP on 6 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.146192218601374'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 16, 16])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/6/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-1.3/1e-09
epoch:  0 quantization_loss:  0.06314101070165634
p mean is: tensor(-0.0002, device='cuda:2')
epoch:  1000 quantization_loss:  0.06149683892726898
p mean is: tensor(-0.0111, device='cuda:2')
epoch:  2000 quantization_loss:  0.06120956689119339
p mean is: tensor(-0.0196, device='cuda:2')
epoch:  3000 quantization_loss:  0.056818682700395584
p mean is: tensor(-0.0252, device='cuda:2')
epoch:  4000 quantization_loss:  0.05343557521700859
p mean is: tensor(-0.0285, device='cuda:2')
epoch:  5000 quantization_loss:  0.051734182983636856
p mean is: tensor(-0.0357, device='cuda:2')
epoch:  6000 quantization_loss:  0.050210777670145035
p mean is: tensor(-0.0441, device='cuda:2')
epoch:  7000 quantization_loss:  0.04870112985372543
p mean is: tensor(-0.0547, device='cuda:2')
epoch:  8000 quantization_loss:  0.04626832902431488
p mean is: tensor(-0.0703, device='cuda:2')
epoch:  9000 quantization_loss:  0.04389727860689163
p mean is: tensor(-0.0874, device='cuda:2')
epoch:  10000 quantization_loss:  0.042066752910614014
p mean is: tensor(-0.1064, device='cuda:2')
epoch:  11000 quantization_loss:  0.04068790003657341
p mean is: tensor(-0.1270, device='cuda:2')
epoch:  12000 quantization_loss:  0.03999645262956619
p mean is: tensor(-0.1516, device='cuda:2')
epoch:  13000 quantization_loss:  0.03931878134608269
p mean is: tensor(-0.1778, device='cuda:2')
epoch:  14000 quantization_loss:  0.039188988506793976
p mean is: tensor(-0.2070, device='cuda:2')
epoch:  15000 quantization_loss:  0.03885459899902344
p mean is: tensor(-0.2391, device='cuda:2')
epoch:  16000 quantization_loss:  0.03842370957136154
p mean is: tensor(-0.2722, device='cuda:2')
epoch:  17000 quantization_loss:  0.03746609762310982
p mean is: tensor(-0.3059, device='cuda:2')
epoch:  18000 quantization_loss:  0.036624666303396225
p mean is: tensor(-0.3400, device='cuda:2')
epoch:  19000 quantization_loss:  0.036278557032346725
p mean is: tensor(-0.3718, device='cuda:2')
epoch:  20000 quantization_loss:  0.03582945466041565
p mean is: tensor(-0.4019, device='cuda:2')
epoch:  21000 quantization_loss:  0.03541889041662216
p mean is: tensor(-0.4317, device='cuda:2')
epoch:  22000 quantization_loss:  0.03521464765071869
p mean is: tensor(-0.4580, device='cuda:2')
epoch:  23000 quantization_loss:  0.03498992696404457
p mean is: tensor(-0.4831, device='cuda:2')
epoch:  24000 quantization_loss:  0.03439253568649292
p mean is: tensor(-0.5056, device='cuda:2')
epoch:  25000 quantization_loss:  0.03421315923333168
p mean is: tensor(-0.5260, device='cuda:2')
epoch:  26000 quantization_loss:  0.033972013741731644
p mean is: tensor(-0.5457, device='cuda:2')
epoch:  27000 quantization_loss:  0.0336846224963665
p mean is: tensor(-0.5624, device='cuda:2')
epoch:  28000 quantization_loss:  0.0336429588496685
p mean is: tensor(-0.5766, device='cuda:2')
epoch:  29000 quantization_loss:  0.03346433490514755
p mean is: tensor(-0.5903, device='cuda:2')
epoch:  30000 quantization_loss:  0.03320888429880142
p mean is: tensor(-0.6023, device='cuda:2')
epoch:  31000 quantization_loss:  0.033005379140377045
p mean is: tensor(-0.6123, device='cuda:2')
epoch:  32000 quantization_loss:  0.03274768218398094
p mean is: tensor(-0.6210, device='cuda:2')
epoch:  33000 quantization_loss:  0.03267202153801918
p mean is: tensor(-0.6293, device='cuda:2')
epoch:  34000 quantization_loss:  0.03258567675948143
p mean is: tensor(-0.6356, device='cuda:2')
epoch:  35000 quantization_loss:  0.032632455229759216
p mean is: tensor(-0.6414, device='cuda:2')
epoch:  36000 quantization_loss:  0.03250151872634888
p mean is: tensor(-0.6460, device='cuda:2')
epoch:  37000 quantization_loss:  0.03219921141862869
p mean is: tensor(-0.6501, device='cuda:2')
epoch:  38000 quantization_loss:  0.032131750136613846
p mean is: tensor(-0.6540, device='cuda:2')
epoch:  39000 quantization_loss:  0.032320667058229446
p mean is: tensor(-0.6570, device='cuda:2')
epoch:  40000 quantization_loss:  0.032066456973552704
p mean is: tensor(-0.6601, device='cuda:2')
epoch:  41000 quantization_loss:  0.032048020511865616
p mean is: tensor(-0.6626, device='cuda:2')
epoch:  42000 quantization_loss:  0.0319766029715538
p mean is: tensor(-0.6644, device='cuda:2')
epoch:  43000 quantization_loss:  0.03202085942029953
p mean is: tensor(-0.6661, device='cuda:2')
epoch:  44000 quantization_loss:  0.031986698508262634
p mean is: tensor(-0.6672, device='cuda:2')
epoch:  45000 quantization_loss:  0.03196455538272858
p mean is: tensor(-0.6681, device='cuda:2')
epoch:  46000 quantization_loss:  0.03192773088812828
p mean is: tensor(-0.6688, device='cuda:2')
epoch:  47000 quantization_loss:  0.031918443739414215
p mean is: tensor(-0.6691, device='cuda:2')
epoch:  48000 quantization_loss:  0.0319242998957634
p mean is: tensor(-0.6700, device='cuda:2')
epoch:  49000 quantization_loss:  0.0318782702088356
p mean is: tensor(-0.6701, device='cuda:2')
epoch:  50000 quantization_loss:  0.031900424510240555
p mean is: tensor(-0.6703, device='cuda:2')
epoch:  51000 quantization_loss:  0.031846363097429276
p mean is: tensor(-0.6708, device='cuda:2')
epoch:  52000 quantization_loss:  0.031806960701942444
p mean is: tensor(-0.6710, device='cuda:2')
epoch:  53000 quantization_loss:  0.031730037182569504
p mean is: tensor(-0.6715, device='cuda:2')
epoch:  54000 quantization_loss:  0.03174464404582977
p mean is: tensor(-0.6720, device='cuda:2')
epoch:  55000 quantization_loss:  0.031711772084236145
p mean is: tensor(-0.6729, device='cuda:2')
epoch:  56000 quantization_loss:  0.03170529007911682
p mean is: tensor(-0.6729, device='cuda:2')
epoch:  57000 quantization_loss:  0.031687647104263306
p mean is: tensor(-0.6733, device='cuda:2')
epoch:  58000 quantization_loss:  0.03163978084921837
p mean is: tensor(-0.6737, device='cuda:2')
epoch:  59000 quantization_loss:  0.03162412717938423
p mean is: tensor(-0.6740, device='cuda:2')
epoch:  60000 quantization_loss:  0.03163934126496315
p mean is: tensor(-0.6742, device='cuda:2')
epoch:  61000 quantization_loss:  0.03161358833312988
p mean is: tensor(-0.6744, device='cuda:2')
epoch:  62000 quantization_loss:  0.03161817044019699
p mean is: tensor(-0.6746, device='cuda:2')
epoch:  63000 quantization_loss:  0.031722426414489746
p mean is: tensor(-0.6747, device='cuda:2')
epoch:  64000 quantization_loss:  0.03162335976958275
p mean is: tensor(-0.6753, device='cuda:2')
epoch:  65000 quantization_loss:  0.03159180283546448
p mean is: tensor(-0.6752, device='cuda:2')
epoch:  66000 quantization_loss:  0.03157821297645569
p mean is: tensor(-0.6754, device='cuda:2')
epoch:  67000 quantization_loss:  0.03159867599606514
p mean is: tensor(-0.6758, device='cuda:2')
epoch:  68000 quantization_loss:  0.03158919885754585
p mean is: tensor(-0.6761, device='cuda:2')
epoch:  69000 quantization_loss:  0.03158371150493622
p mean is: tensor(-0.6762, device='cuda:2')
epoch:  70000 quantization_loss:  0.03150863200426102
p mean is: tensor(-0.6762, device='cuda:2')
epoch:  71000 quantization_loss:  0.031519461423158646
p mean is: tensor(-0.6764, device='cuda:2')
epoch:  72000 quantization_loss:  0.03148004412651062
p mean is: tensor(-0.6767, device='cuda:2')
epoch:  73000 quantization_loss:  0.03146331384778023
p mean is: tensor(-0.6771, device='cuda:2')
epoch:  74000 quantization_loss:  0.03145046532154083
p mean is: tensor(-0.6773, device='cuda:2')
epoch:  75000 quantization_loss:  0.0314522311091423
p mean is: tensor(-0.6773, device='cuda:2')
epoch:  76000 quantization_loss:  0.031446244567632675
p mean is: tensor(-0.6779, device='cuda:2')
epoch:  77000 quantization_loss:  0.031438522040843964
p mean is: tensor(-0.6785, device='cuda:2')
epoch:  78000 quantization_loss:  0.031439170241355896
p mean is: tensor(-0.6788, device='cuda:2')
epoch:  79000 quantization_loss:  0.031438399106264114
p mean is: tensor(-0.6785, device='cuda:2')
here
1.1.weight           | nonzeros =    5404 /   16384             ( 32.98%) | total_pruned =   10980 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =    4515 /   16384             ( 27.56%) | total_pruned =   11869 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    5744 /   16384             ( 35.06%) | total_pruned =   10640 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =    4244 /   16384             ( 25.90%) | total_pruned =   12140 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =    1606 /   16384             (  9.80%) | total_pruned =   14778 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =    1979 /   16384             ( 12.08%) | total_pruned =   14405 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     170 /     384             ( 44.27%) | total_pruned =     214 | shape = torch.Size([3, 128, 1, 1])
alive: 24188, pruned : 76036, total: 100224, Compression rate :       4.14x  ( 75.87% pruned)
PSNR of output image is:  16.545625708480824
Experiment done
