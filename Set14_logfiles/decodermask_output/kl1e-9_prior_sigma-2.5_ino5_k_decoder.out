(3, 512, 512)
Starting vanilla DIP on 5 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.08367273572885'
[128, 128, 128, 128, 128]
Number of params in decoder: 100224
torch.Size([1, 128, 16, 16])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/decoder_mask/5/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-2.5/1e-09
epoch:  0 quantization_loss:  0.06483926624059677
p mean is: tensor(-0.0004, device='cuda:4')
epoch:  1000 quantization_loss:  0.06159503757953644
p mean is: tensor(-0.0175, device='cuda:4')
epoch:  2000 quantization_loss:  0.05034564062952995
p mean is: tensor(-0.0245, device='cuda:4')
epoch:  3000 quantization_loss:  0.04404313117265701
p mean is: tensor(-0.0256, device='cuda:4')
epoch:  4000 quantization_loss:  0.04099931940436363
p mean is: tensor(-0.0308, device='cuda:4')
epoch:  5000 quantization_loss:  0.0389399379491806
p mean is: tensor(-0.0357, device='cuda:4')
epoch:  6000 quantization_loss:  0.03759969770908356
p mean is: tensor(-0.0423, device='cuda:4')
epoch:  7000 quantization_loss:  0.03512754291296005
p mean is: tensor(-0.0509, device='cuda:4')
epoch:  8000 quantization_loss:  0.03415168821811676
p mean is: tensor(-0.0618, device='cuda:4')
epoch:  9000 quantization_loss:  0.03243672102689743
p mean is: tensor(-0.0764, device='cuda:4')
epoch:  10000 quantization_loss:  0.030503110960125923
p mean is: tensor(-0.0937, device='cuda:4')
epoch:  11000 quantization_loss:  0.030235428363084793
p mean is: tensor(-0.1163, device='cuda:4')
epoch:  12000 quantization_loss:  0.02872280590236187
p mean is: tensor(-0.1428, device='cuda:4')
epoch:  13000 quantization_loss:  0.027644731104373932
p mean is: tensor(-0.1731, device='cuda:4')
epoch:  14000 quantization_loss:  0.02689637430012226
p mean is: tensor(-0.2058, device='cuda:4')
epoch:  15000 quantization_loss:  0.026858845725655556
p mean is: tensor(-0.2412, device='cuda:4')
epoch:  16000 quantization_loss:  0.025943193584680557
p mean is: tensor(-0.2778, device='cuda:4')
epoch:  17000 quantization_loss:  0.025141142308712006
p mean is: tensor(-0.3154, device='cuda:4')
epoch:  18000 quantization_loss:  0.02479933388531208
p mean is: tensor(-0.3542, device='cuda:4')
epoch:  19000 quantization_loss:  0.024296311661601067
p mean is: tensor(-0.3925, device='cuda:4')
epoch:  20000 quantization_loss:  0.024257944896817207
p mean is: tensor(-0.4303, device='cuda:4')
epoch:  21000 quantization_loss:  0.02396368607878685
p mean is: tensor(-0.4669, device='cuda:4')
epoch:  22000 quantization_loss:  0.023788586258888245
p mean is: tensor(-0.5035, device='cuda:4')
epoch:  23000 quantization_loss:  0.02350660227239132
p mean is: tensor(-0.5378, device='cuda:4')
epoch:  24000 quantization_loss:  0.02319515310227871
p mean is: tensor(-0.5706, device='cuda:4')
epoch:  25000 quantization_loss:  0.02289750799536705
p mean is: tensor(-0.6027, device='cuda:4')
epoch:  26000 quantization_loss:  0.02264840342104435
p mean is: tensor(-0.6328, device='cuda:4')
epoch:  27000 quantization_loss:  0.022479765117168427
p mean is: tensor(-0.6607, device='cuda:4')
epoch:  28000 quantization_loss:  0.022318845614790916
p mean is: tensor(-0.6857, device='cuda:4')
epoch:  29000 quantization_loss:  0.022235123440623283
p mean is: tensor(-0.7089, device='cuda:4')
epoch:  30000 quantization_loss:  0.021841783076524734
p mean is: tensor(-0.7310, device='cuda:4')
epoch:  31000 quantization_loss:  0.021758006885647774
p mean is: tensor(-0.7514, device='cuda:4')
epoch:  32000 quantization_loss:  0.021658141165971756
p mean is: tensor(-0.7711, device='cuda:4')
epoch:  33000 quantization_loss:  0.021613458171486855
p mean is: tensor(-0.7878, device='cuda:4')
epoch:  34000 quantization_loss:  0.02149706706404686
p mean is: tensor(-0.8038, device='cuda:4')
epoch:  35000 quantization_loss:  0.021474501118063927
p mean is: tensor(-0.8174, device='cuda:4')
epoch:  36000 quantization_loss:  0.02145121805369854
p mean is: tensor(-0.8302, device='cuda:4')
epoch:  37000 quantization_loss:  0.021440258249640465
p mean is: tensor(-0.8417, device='cuda:4')
epoch:  38000 quantization_loss:  0.021375609561800957
p mean is: tensor(-0.8524, device='cuda:4')
epoch:  39000 quantization_loss:  0.021306559443473816
p mean is: tensor(-0.8617, device='cuda:4')
epoch:  40000 quantization_loss:  0.02143821306526661
p mean is: tensor(-0.8707, device='cuda:4')
epoch:  41000 quantization_loss:  0.021267104893922806
p mean is: tensor(-0.8788, device='cuda:4')
epoch:  42000 quantization_loss:  0.021260133013129234
p mean is: tensor(-0.8866, device='cuda:4')
epoch:  43000 quantization_loss:  0.021252702921628952
p mean is: tensor(-0.8945, device='cuda:4')
epoch:  44000 quantization_loss:  0.021258307620882988
p mean is: tensor(-0.9015, device='cuda:4')
epoch:  45000 quantization_loss:  0.021200090646743774
p mean is: tensor(-0.9073, device='cuda:4')
epoch:  46000 quantization_loss:  0.02118544466793537
p mean is: tensor(-0.9121, device='cuda:4')
epoch:  47000 quantization_loss:  0.0215764120221138
p mean is: tensor(-0.9178, device='cuda:4')
epoch:  48000 quantization_loss:  0.021140430122613907
p mean is: tensor(-0.9225, device='cuda:4')
epoch:  49000 quantization_loss:  0.021039607003331184
p mean is: tensor(-0.9269, device='cuda:4')
epoch:  50000 quantization_loss:  0.020940130576491356
p mean is: tensor(-0.9311, device='cuda:4')
epoch:  51000 quantization_loss:  0.020970849320292473
p mean is: tensor(-0.9349, device='cuda:4')
epoch:  52000 quantization_loss:  0.020931290462613106
p mean is: tensor(-0.9379, device='cuda:4')
epoch:  53000 quantization_loss:  0.020939704030752182
p mean is: tensor(-0.9413, device='cuda:4')
epoch:  54000 quantization_loss:  0.020950205624103546
p mean is: tensor(-0.9444, device='cuda:4')
epoch:  55000 quantization_loss:  0.020908191800117493
p mean is: tensor(-0.9469, device='cuda:4')
epoch:  56000 quantization_loss:  0.020894011482596397
p mean is: tensor(-0.9492, device='cuda:4')
epoch:  57000 quantization_loss:  0.020890595391392708
p mean is: tensor(-0.9513, device='cuda:4')
epoch:  58000 quantization_loss:  0.020880399271845818
p mean is: tensor(-0.9531, device='cuda:4')
epoch:  59000 quantization_loss:  0.020998015999794006
p mean is: tensor(-0.9545, device='cuda:4')
epoch:  60000 quantization_loss:  0.020869974046945572
p mean is: tensor(-0.9559, device='cuda:4')
epoch:  61000 quantization_loss:  0.020876659080386162
p mean is: tensor(-0.9579, device='cuda:4')
epoch:  62000 quantization_loss:  0.02085854858160019
p mean is: tensor(-0.9592, device='cuda:4')
epoch:  63000 quantization_loss:  0.020859455689787865
p mean is: tensor(-0.9607, device='cuda:4')
epoch:  64000 quantization_loss:  0.020876090973615646
p mean is: tensor(-0.9623, device='cuda:4')
epoch:  65000 quantization_loss:  0.020866069942712784
p mean is: tensor(-0.9637, device='cuda:4')
epoch:  66000 quantization_loss:  0.02088548243045807
p mean is: tensor(-0.9650, device='cuda:4')
epoch:  67000 quantization_loss:  0.020854957401752472
p mean is: tensor(-0.9660, device='cuda:4')
epoch:  68000 quantization_loss:  0.02085770294070244
p mean is: tensor(-0.9667, device='cuda:4')
epoch:  69000 quantization_loss:  0.020861903205513954
p mean is: tensor(-0.9677, device='cuda:4')
epoch:  70000 quantization_loss:  0.02086801640689373
p mean is: tensor(-0.9686, device='cuda:4')
epoch:  71000 quantization_loss:  0.02088893949985504
p mean is: tensor(-0.9694, device='cuda:4')
epoch:  72000 quantization_loss:  0.02085522748529911
p mean is: tensor(-0.9702, device='cuda:4')
epoch:  73000 quantization_loss:  0.0208272822201252
p mean is: tensor(-0.9712, device='cuda:4')
epoch:  74000 quantization_loss:  0.020835349336266518
p mean is: tensor(-0.9717, device='cuda:4')
epoch:  75000 quantization_loss:  0.020834878087043762
p mean is: tensor(-0.9725, device='cuda:4')
epoch:  76000 quantization_loss:  0.020838508382439613
p mean is: tensor(-0.9731, device='cuda:4')
epoch:  77000 quantization_loss:  0.020883629098534584
p mean is: tensor(-0.9739, device='cuda:4')
epoch:  78000 quantization_loss:  0.02082606963813305
p mean is: tensor(-0.9748, device='cuda:4')
epoch:  79000 quantization_loss:  0.020857244729995728
p mean is: tensor(-0.9754, device='cuda:4')
here
1.1.weight           | nonzeros =    6211 /   16384             ( 37.91%) | total_pruned =   10173 | shape = torch.Size([128, 128, 1, 1])
4.weight             | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
5.1.weight           | nonzeros =    5442 /   16384             ( 33.22%) | total_pruned =   10942 | shape = torch.Size([128, 128, 1, 1])
8.weight             | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
8.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =    6760 /   16384             ( 41.26%) | total_pruned =    9624 | shape = torch.Size([128, 128, 1, 1])
12.weight            | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
12.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
13.1.weight          | nonzeros =    5486 /   16384             ( 33.48%) | total_pruned =   10898 | shape = torch.Size([128, 128, 1, 1])
16.weight            | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
16.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
17.1.weight          | nonzeros =    3228 /   16384             ( 19.70%) | total_pruned =   13156 | shape = torch.Size([128, 128, 1, 1])
20.weight            | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
20.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
21.1.weight          | nonzeros =    2844 /   16384             ( 17.36%) | total_pruned =   13540 | shape = torch.Size([128, 128, 1, 1])
23.weight            | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
23.bias              | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
24.1.weight          | nonzeros =     176 /     384             ( 45.83%) | total_pruned =     208 | shape = torch.Size([3, 128, 1, 1])
alive: 30737, pruned : 69487, total: 100224, Compression rate :       3.26x  ( 69.33% pruned)
PSNR of output image is:  19.284949304334404
Experiment done
