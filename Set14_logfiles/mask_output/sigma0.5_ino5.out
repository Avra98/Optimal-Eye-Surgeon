(3, 512, 512)
Noisy PSNR is '20.20659856513457'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/5/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/0.5/1e-09
epoch:  0 quantization_loss:  0.06166321784257889
p mean is: tensor(9.5396e-05, device='cuda:2')
epoch:  1000 quantization_loss:  0.05612966790795326
p mean is: tensor(0.0048, device='cuda:2')
epoch:  2000 quantization_loss:  0.055877987295389175
p mean is: tensor(0.0086, device='cuda:2')
epoch:  3000 quantization_loss:  0.05602136626839638
p mean is: tensor(0.0124, device='cuda:2')
epoch:  4000 quantization_loss:  0.05557449534535408
p mean is: tensor(0.0159, device='cuda:2')
epoch:  5000 quantization_loss:  0.05512143298983574
p mean is: tensor(0.0193, device='cuda:2')
epoch:  6000 quantization_loss:  0.052745550870895386
p mean is: tensor(0.0228, device='cuda:2')
epoch:  7000 quantization_loss:  0.04907119646668434
p mean is: tensor(0.0267, device='cuda:2')
epoch:  8000 quantization_loss:  0.04514358565211296
p mean is: tensor(0.0318, device='cuda:2')
epoch:  9000 quantization_loss:  0.039202939718961716
p mean is: tensor(0.0380, device='cuda:2')
epoch:  10000 quantization_loss:  0.03573676943778992
p mean is: tensor(0.0458, device='cuda:2')
epoch:  11000 quantization_loss:  0.03361055999994278
p mean is: tensor(0.0565, device='cuda:2')
epoch:  12000 quantization_loss:  0.03248276561498642
p mean is: tensor(0.0703, device='cuda:2')
epoch:  13000 quantization_loss:  0.029864948242902756
p mean is: tensor(0.0879, device='cuda:2')
epoch:  14000 quantization_loss:  0.02896728180348873
p mean is: tensor(0.1092, device='cuda:2')
epoch:  15000 quantization_loss:  0.028424760326743126
p mean is: tensor(0.1343, device='cuda:2')
epoch:  16000 quantization_loss:  0.02790169231593609
p mean is: tensor(0.1622, device='cuda:2')
epoch:  17000 quantization_loss:  0.027065398171544075
p mean is: tensor(0.1917, device='cuda:2')
epoch:  18000 quantization_loss:  0.026578746736049652
p mean is: tensor(0.2213, device='cuda:2')
epoch:  19000 quantization_loss:  0.02617615833878517
p mean is: tensor(0.2501, device='cuda:2')
epoch:  20000 quantization_loss:  0.026422258466482162
p mean is: tensor(0.2771, device='cuda:2')
epoch:  21000 quantization_loss:  0.025677436962723732
p mean is: tensor(0.3021, device='cuda:2')
epoch:  22000 quantization_loss:  0.025803470984101295
p mean is: tensor(0.3249, device='cuda:2')
epoch:  23000 quantization_loss:  0.025566423311829567
p mean is: tensor(0.3453, device='cuda:2')
epoch:  24000 quantization_loss:  0.025256255641579628
p mean is: tensor(0.3633, device='cuda:2')
epoch:  25000 quantization_loss:  0.02511006034910679
p mean is: tensor(0.3791, device='cuda:2')
epoch:  26000 quantization_loss:  0.025014275684952736
p mean is: tensor(0.3931, device='cuda:2')
epoch:  27000 quantization_loss:  0.025010038167238235
p mean is: tensor(0.4052, device='cuda:2')
epoch:  28000 quantization_loss:  0.024857185781002045
p mean is: tensor(0.4156, device='cuda:2')
epoch:  29000 quantization_loss:  0.024763591587543488
p mean is: tensor(0.4248, device='cuda:2')
epoch:  30000 quantization_loss:  0.024747192859649658
p mean is: tensor(0.4328, device='cuda:2')
epoch:  31000 quantization_loss:  0.024656420573592186
p mean is: tensor(0.4397, device='cuda:2')
epoch:  32000 quantization_loss:  0.024628913030028343
p mean is: tensor(0.4458, device='cuda:2')
epoch:  33000 quantization_loss:  0.024551259353756905
p mean is: tensor(0.4511, device='cuda:2')
epoch:  34000 quantization_loss:  0.02451242320239544
p mean is: tensor(0.4558, device='cuda:2')
epoch:  35000 quantization_loss:  0.024473125115036964
p mean is: tensor(0.4600, device='cuda:2')
epoch:  36000 quantization_loss:  0.024436281993985176
p mean is: tensor(0.4636, device='cuda:2')
epoch:  37000 quantization_loss:  0.02437039650976658
p mean is: tensor(0.4669, device='cuda:2')
epoch:  38000 quantization_loss:  0.024356551468372345
p mean is: tensor(0.4698, device='cuda:2')
epoch:  39000 quantization_loss:  0.024325188249349594
p mean is: tensor(0.4724, device='cuda:2')
epoch:  40000 quantization_loss:  0.024291569367051125
p mean is: tensor(0.4748, device='cuda:2')
epoch:  41000 quantization_loss:  0.024280590936541557
p mean is: tensor(0.4769, device='cuda:2')
epoch:  42000 quantization_loss:  0.0242402832955122
p mean is: tensor(0.4789, device='cuda:2')
epoch:  43000 quantization_loss:  0.025031229481101036
p mean is: tensor(0.4806, device='cuda:2')
epoch:  44000 quantization_loss:  0.024211477488279343
p mean is: tensor(0.4822, device='cuda:2')
epoch:  45000 quantization_loss:  0.024442952126264572
p mean is: tensor(0.4837, device='cuda:2')
epoch:  46000 quantization_loss:  0.024175046011805534
p mean is: tensor(0.4850, device='cuda:2')
epoch:  47000 quantization_loss:  0.02415788173675537
p mean is: tensor(0.4863, device='cuda:2')
epoch:  48000 quantization_loss:  0.024150775745511055
p mean is: tensor(0.4874, device='cuda:2')
epoch:  49000 quantization_loss:  0.02414393611252308
p mean is: tensor(0.4884, device='cuda:2')
epoch:  50000 quantization_loss:  0.024119311943650246
p mean is: tensor(0.4894, device='cuda:2')
epoch:  51000 quantization_loss:  0.02410118095576763
p mean is: tensor(0.4903, device='cuda:2')
epoch:  52000 quantization_loss:  0.024114884436130524
p mean is: tensor(0.4911, device='cuda:2')
epoch:  53000 quantization_loss:  0.024112500250339508
p mean is: tensor(0.4920, device='cuda:2')
epoch:  54000 quantization_loss:  0.024118391796946526
p mean is: tensor(0.4927, device='cuda:2')
epoch:  55000 quantization_loss:  0.02408905141055584
p mean is: tensor(0.4934, device='cuda:2')
epoch:  56000 quantization_loss:  0.02410292997956276
p mean is: tensor(0.4941, device='cuda:2')
epoch:  57000 quantization_loss:  0.024060983210802078
p mean is: tensor(0.4947, device='cuda:2')
epoch:  58000 quantization_loss:  0.024052908644080162
p mean is: tensor(0.4953, device='cuda:2')
epoch:  59000 quantization_loss:  0.02405931055545807
p mean is: tensor(0.4959, device='cuda:2')
epoch:  60000 quantization_loss:  0.02404402755200863
p mean is: tensor(0.4965, device='cuda:2')
epoch:  61000 quantization_loss:  0.024049974977970123
p mean is: tensor(0.4970, device='cuda:2')
epoch:  62000 quantization_loss:  0.024034133180975914
p mean is: tensor(0.4975, device='cuda:2')
epoch:  63000 quantization_loss:  0.02402772195637226
p mean is: tensor(0.4980, device='cuda:2')
epoch:  64000 quantization_loss:  0.02402297593653202
p mean is: tensor(0.4985, device='cuda:2')
epoch:  65000 quantization_loss:  0.024032263085246086
p mean is: tensor(0.4989, device='cuda:2')
epoch:  66000 quantization_loss:  0.024017270654439926
p mean is: tensor(0.4993, device='cuda:2')
epoch:  67000 quantization_loss:  0.024014024063944817
p mean is: tensor(0.4997, device='cuda:2')
epoch:  68000 quantization_loss:  0.02400982938706875
p mean is: tensor(0.5001, device='cuda:2')
epoch:  69000 quantization_loss:  0.024010322988033295
p mean is: tensor(0.5004, device='cuda:2')
epoch:  70000 quantization_loss:  0.024045361205935478
p mean is: tensor(0.5008, device='cuda:2')
epoch:  71000 quantization_loss:  0.024002805352211
p mean is: tensor(0.5012, device='cuda:2')
epoch:  72000 quantization_loss:  0.023996541276574135
p mean is: tensor(0.5015, device='cuda:2')
epoch:  73000 quantization_loss:  0.02399805188179016
p mean is: tensor(0.5018, device='cuda:2')
epoch:  74000 quantization_loss:  0.024005699902772903
p mean is: tensor(0.5021, device='cuda:2')
epoch:  75000 quantization_loss:  0.02398967556655407
p mean is: tensor(0.5024, device='cuda:2')
epoch:  76000 quantization_loss:  0.02406870387494564
p mean is: tensor(0.5027, device='cuda:2')
epoch:  77000 quantization_loss:  0.0239887498319149
p mean is: tensor(0.5030, device='cuda:2')
epoch:  78000 quantization_loss:  0.023991312831640244
p mean is: tensor(0.5032, device='cuda:2')
epoch:  79000 quantization_loss:  0.023989567533135414
p mean is: tensor(0.5035, device='cuda:2')
1.1.1.weight         | nonzeros =   10868 /   12800             ( 84.91%) | total_pruned =    1932 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.2.weight           | nonzeros =      11 /      16             ( 68.75%) | total_pruned =       5 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =    6147 /    6400             ( 96.05%) | total_pruned =     253 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.5.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =   12577 /   12800             ( 98.26%) | total_pruned =     223 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =   25269 /   25600             ( 98.71%) | total_pruned =     331 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =   50602 /   51200             ( 98.83%) | total_pruned =     598 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =  101331 /  102400             ( 98.96%) | total_pruned =    1069 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =  203835 /  204800             ( 99.53%) | total_pruned =     965 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =  406562 /  409600             ( 99.26%) | total_pruned =    3038 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  404401 /  409600             ( 98.73%) | total_pruned =    5199 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  394499 /  409600             ( 96.31%) | total_pruned =   15101 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  377843 /  409600             ( 92.25%) | total_pruned =   31757 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  351645 /  409600             ( 85.85%) | total_pruned =   57955 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  114729 /  147456             ( 77.81%) | total_pruned =   32727 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  112599 /  147456             ( 76.36%) | total_pruned =   34857 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =  117400 /  147456             ( 79.62%) | total_pruned =   30056 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   59631 /   73728             ( 80.88%) | total_pruned =   14097 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =   15477 /   18432             ( 83.97%) | total_pruned =    2955 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    3464 /    4608             ( 75.17%) | total_pruned =    1144 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      15 /      16             ( 93.75%) | total_pruned =       1 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      30 /      48             ( 62.50%) | total_pruned =      18 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       3 /       3             (100.00%) | total_pruned =       0 | shape = torch.Size([3])
alive: 2771844, pruned : 237023, total: 3008867, Compression rate :       1.09x  (  7.88% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  18.264555991561796
Experiment done
