(3, 512, 512)
Noisy PSNR is '20.487720984319544'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/13/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/1.0/1e-09
epoch:  0 quantization_loss:  0.09057477116584778
p mean is: tensor(0.0002, device='cuda:4')
epoch:  1000 quantization_loss:  0.06764080375432968
p mean is: tensor(0.0060, device='cuda:4')
epoch:  2000 quantization_loss:  0.06463409215211868
p mean is: tensor(0.0098, device='cuda:4')
epoch:  3000 quantization_loss:  0.06220443174242973
p mean is: tensor(0.0136, device='cuda:4')
epoch:  4000 quantization_loss:  0.06349807232618332
p mean is: tensor(0.0171, device='cuda:4')
epoch:  5000 quantization_loss:  0.06109664961695671
p mean is: tensor(0.0209, device='cuda:4')
epoch:  6000 quantization_loss:  0.06162796914577484
p mean is: tensor(0.0252, device='cuda:4')
epoch:  7000 quantization_loss:  0.06177886202931404
p mean is: tensor(0.0296, device='cuda:4')
epoch:  8000 quantization_loss:  0.05264482647180557
p mean is: tensor(0.0337, device='cuda:4')
epoch:  9000 quantization_loss:  0.04367491602897644
p mean is: tensor(0.0390, device='cuda:4')
epoch:  10000 quantization_loss:  0.036454278975725174
p mean is: tensor(0.0458, device='cuda:4')
epoch:  11000 quantization_loss:  0.03320712223649025
p mean is: tensor(0.0551, device='cuda:4')
epoch:  12000 quantization_loss:  0.031542617827653885
p mean is: tensor(0.0678, device='cuda:4')
epoch:  13000 quantization_loss:  0.030788438394665718
p mean is: tensor(0.0850, device='cuda:4')
epoch:  14000 quantization_loss:  0.028409602120518684
p mean is: tensor(0.1081, device='cuda:4')
epoch:  15000 quantization_loss:  0.02762116678059101
p mean is: tensor(0.1379, device='cuda:4')
epoch:  16000 quantization_loss:  0.026788370683789253
p mean is: tensor(0.1755, device='cuda:4')
epoch:  17000 quantization_loss:  0.02575087733566761
p mean is: tensor(0.2209, device='cuda:4')
epoch:  18000 quantization_loss:  0.024852946400642395
p mean is: tensor(0.2729, device='cuda:4')
epoch:  19000 quantization_loss:  0.024651093408465385
p mean is: tensor(0.3298, device='cuda:4')
epoch:  20000 quantization_loss:  0.02408532239496708
p mean is: tensor(0.3890, device='cuda:4')
epoch:  21000 quantization_loss:  0.023181339725852013
p mean is: tensor(0.4481, device='cuda:4')
epoch:  22000 quantization_loss:  0.02274886518716812
p mean is: tensor(0.5045, device='cuda:4')
epoch:  23000 quantization_loss:  0.022544842213392258
p mean is: tensor(0.5568, device='cuda:4')
epoch:  24000 quantization_loss:  0.02234690822660923
p mean is: tensor(0.6045, device='cuda:4')
epoch:  25000 quantization_loss:  0.022184638306498528
p mean is: tensor(0.6473, device='cuda:4')
epoch:  26000 quantization_loss:  0.02203482761979103
p mean is: tensor(0.6854, device='cuda:4')
epoch:  27000 quantization_loss:  0.021863672882318497
p mean is: tensor(0.7190, device='cuda:4')
epoch:  28000 quantization_loss:  0.021715892478823662
p mean is: tensor(0.7487, device='cuda:4')
epoch:  29000 quantization_loss:  0.02169627510011196
p mean is: tensor(0.7748, device='cuda:4')
epoch:  30000 quantization_loss:  0.021568015217781067
p mean is: tensor(0.7976, device='cuda:4')
epoch:  31000 quantization_loss:  0.02142634429037571
p mean is: tensor(0.8176, device='cuda:4')
epoch:  32000 quantization_loss:  0.02137766033411026
p mean is: tensor(0.8351, device='cuda:4')
epoch:  33000 quantization_loss:  0.021265784278512
p mean is: tensor(0.8505, device='cuda:4')
epoch:  34000 quantization_loss:  0.021231118589639664
p mean is: tensor(0.8641, device='cuda:4')
epoch:  35000 quantization_loss:  0.02113807015120983
p mean is: tensor(0.8761, device='cuda:4')
epoch:  36000 quantization_loss:  0.021090809255838394
p mean is: tensor(0.8867, device='cuda:4')
epoch:  37000 quantization_loss:  0.021052692085504532
p mean is: tensor(0.8961, device='cuda:4')
epoch:  38000 quantization_loss:  0.02102428860962391
p mean is: tensor(0.9044, device='cuda:4')
epoch:  39000 quantization_loss:  0.020929645746946335
p mean is: tensor(0.9120, device='cuda:4')
epoch:  40000 quantization_loss:  0.020859364420175552
p mean is: tensor(0.9187, device='cuda:4')
epoch:  41000 quantization_loss:  0.020862672477960587
p mean is: tensor(0.9247, device='cuda:4')
epoch:  42000 quantization_loss:  0.020841730758547783
p mean is: tensor(0.9302, device='cuda:4')
epoch:  43000 quantization_loss:  0.020769890397787094
p mean is: tensor(0.9350, device='cuda:4')
epoch:  44000 quantization_loss:  0.020759113132953644
p mean is: tensor(0.9394, device='cuda:4')
epoch:  45000 quantization_loss:  0.020726008340716362
p mean is: tensor(0.9434, device='cuda:4')
epoch:  46000 quantization_loss:  0.020702967420220375
p mean is: tensor(0.9471, device='cuda:4')
epoch:  47000 quantization_loss:  0.020714065060019493
p mean is: tensor(0.9505, device='cuda:4')
epoch:  48000 quantization_loss:  0.020657282322645187
p mean is: tensor(0.9536, device='cuda:4')
epoch:  49000 quantization_loss:  0.020627381280064583
p mean is: tensor(0.9564, device='cuda:4')
epoch:  50000 quantization_loss:  0.020657256245613098
p mean is: tensor(0.9590, device='cuda:4')
epoch:  51000 quantization_loss:  0.02059067413210869
p mean is: tensor(0.9615, device='cuda:4')
epoch:  52000 quantization_loss:  0.020598160102963448
p mean is: tensor(0.9638, device='cuda:4')
epoch:  53000 quantization_loss:  0.02056163176894188
p mean is: tensor(0.9659, device='cuda:4')
epoch:  54000 quantization_loss:  0.02056041918694973
p mean is: tensor(0.9679, device='cuda:4')
epoch:  55000 quantization_loss:  0.020546918734908104
p mean is: tensor(0.9698, device='cuda:4')
epoch:  56000 quantization_loss:  0.020546717569231987
p mean is: tensor(0.9716, device='cuda:4')
epoch:  57000 quantization_loss:  0.02052382566034794
p mean is: tensor(0.9732, device='cuda:4')
epoch:  58000 quantization_loss:  0.020511973649263382
p mean is: tensor(0.9748, device='cuda:4')
epoch:  59000 quantization_loss:  0.020500460639595985
p mean is: tensor(0.9763, device='cuda:4')
epoch:  60000 quantization_loss:  0.02050814963877201
p mean is: tensor(0.9777, device='cuda:4')
epoch:  61000 quantization_loss:  0.020498042926192284
p mean is: tensor(0.9791, device='cuda:4')
epoch:  62000 quantization_loss:  0.020491644740104675
p mean is: tensor(0.9804, device='cuda:4')
epoch:  63000 quantization_loss:  0.02047976851463318
p mean is: tensor(0.9816, device='cuda:4')
epoch:  64000 quantization_loss:  0.020463962107896805
p mean is: tensor(0.9827, device='cuda:4')
epoch:  65000 quantization_loss:  0.02046143263578415
p mean is: tensor(0.9839, device='cuda:4')
epoch:  66000 quantization_loss:  0.02052500657737255
p mean is: tensor(0.9849, device='cuda:4')
epoch:  67000 quantization_loss:  0.020459145307540894
p mean is: tensor(0.9859, device='cuda:4')
epoch:  68000 quantization_loss:  0.020444801077246666
p mean is: tensor(0.9869, device='cuda:4')
epoch:  69000 quantization_loss:  0.020440438762307167
p mean is: tensor(0.9879, device='cuda:4')
epoch:  70000 quantization_loss:  0.020449794828891754
p mean is: tensor(0.9889, device='cuda:4')
epoch:  71000 quantization_loss:  0.020439309999346733
p mean is: tensor(0.9898, device='cuda:4')
epoch:  72000 quantization_loss:  0.020434720441699028
p mean is: tensor(0.9907, device='cuda:4')
epoch:  73000 quantization_loss:  0.02042868360877037
p mean is: tensor(0.9916, device='cuda:4')
epoch:  74000 quantization_loss:  0.02048015221953392
p mean is: tensor(0.9924, device='cuda:4')
epoch:  75000 quantization_loss:  0.020440436899662018
p mean is: tensor(0.9932, device='cuda:4')
epoch:  76000 quantization_loss:  0.0205078162252903
p mean is: tensor(0.9940, device='cuda:4')
epoch:  77000 quantization_loss:  0.020421773195266724
p mean is: tensor(0.9947, device='cuda:4')
epoch:  78000 quantization_loss:  0.020417213439941406
p mean is: tensor(0.9955, device='cuda:4')
epoch:  79000 quantization_loss:  0.020413996651768684
p mean is: tensor(0.9962, device='cuda:4')
1.1.1.weight         | nonzeros =   11625 /   12800             ( 90.82%) | total_pruned =    1175 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.2.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =    6256 /    6400             ( 97.75%) | total_pruned =     144 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.5.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =   12694 /   12800             ( 99.17%) | total_pruned =     106 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =   25480 /   25600             ( 99.53%) | total_pruned =     120 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =   51040 /   51200             ( 99.69%) | total_pruned =     160 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =  102216 /  102400             ( 99.82%) | total_pruned =     184 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =  204681 /  204800             ( 99.94%) | total_pruned =     119 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =  409352 /  409600             ( 99.94%) | total_pruned =     248 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  408919 /  409600             ( 99.83%) | total_pruned =     681 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  405239 /  409600             ( 98.94%) | total_pruned =    4361 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  395489 /  409600             ( 96.55%) | total_pruned =   14111 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  368661 /  409600             ( 90.01%) | total_pruned =   40939 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  119904 /  147456             ( 81.32%) | total_pruned =   27552 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  118545 /  147456             ( 80.39%) | total_pruned =   28911 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =  121338 /  147456             ( 82.29%) | total_pruned =   26118 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   62676 /   73728             ( 85.01%) | total_pruned =   11052 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =   14772 /   18432             ( 80.14%) | total_pruned =    3660 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      27 /      32             ( 84.38%) | total_pruned =       5 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    2951 /    4608             ( 64.04%) | total_pruned =    1657 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      15 /      16             ( 93.75%) | total_pruned =       1 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      28 /      48             ( 58.33%) | total_pruned =      20 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 2844782, pruned : 164085, total: 3008867, Compression rate :       1.06x  (  5.45% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  18.60596757078898
Experiment done
