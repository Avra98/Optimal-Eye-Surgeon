(3, 256, 256)
Noisy PSNR is '20.220377511375553'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/9/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/10.0/1e-09
epoch:  0 quantization_loss:  0.06920222193002701
p mean is: tensor(0.0014, device='cuda:2')
epoch:  1000 quantization_loss:  0.07050714641809464
p mean is: tensor(0.0403, device='cuda:2')
epoch:  2000 quantization_loss:  0.06603348255157471
p mean is: tensor(0.0683, device='cuda:2')
epoch:  3000 quantization_loss:  0.06785531342029572
p mean is: tensor(0.0959, device='cuda:2')
epoch:  4000 quantization_loss:  0.0677085742354393
p mean is: tensor(0.1230, device='cuda:2')
epoch:  5000 quantization_loss:  0.06806743144989014
p mean is: tensor(0.1496, device='cuda:2')
epoch:  6000 quantization_loss:  0.06722167134284973
p mean is: tensor(0.1764, device='cuda:2')
epoch:  7000 quantization_loss:  0.06608271598815918
p mean is: tensor(0.2033, device='cuda:2')
epoch:  8000 quantization_loss:  0.06742653995752335
p mean is: tensor(0.2301, device='cuda:2')
epoch:  9000 quantization_loss:  0.06668366491794586
p mean is: tensor(0.2579, device='cuda:2')
epoch:  10000 quantization_loss:  0.06602820754051208
p mean is: tensor(0.2863, device='cuda:2')
epoch:  11000 quantization_loss:  0.06636666506528854
p mean is: tensor(0.3153, device='cuda:2')
epoch:  12000 quantization_loss:  0.06671546399593353
p mean is: tensor(0.3444, device='cuda:2')
epoch:  13000 quantization_loss:  0.06592663377523422
p mean is: tensor(0.3742, device='cuda:2')
epoch:  14000 quantization_loss:  0.06612763553857803
p mean is: tensor(0.4044, device='cuda:2')
epoch:  15000 quantization_loss:  0.05697641149163246
p mean is: tensor(0.4341, device='cuda:2')
epoch:  16000 quantization_loss:  0.04763263463973999
p mean is: tensor(0.4705, device='cuda:2')
epoch:  17000 quantization_loss:  0.040101658552885056
p mean is: tensor(0.5239, device='cuda:2')
epoch:  18000 quantization_loss:  0.03427755832672119
p mean is: tensor(0.6001, device='cuda:2')
epoch:  19000 quantization_loss:  0.03150930628180504
p mean is: tensor(0.7031, device='cuda:2')
epoch:  20000 quantization_loss:  0.028670091181993484
p mean is: tensor(0.8343, device='cuda:2')
epoch:  21000 quantization_loss:  0.02693818509578705
p mean is: tensor(1.0005, device='cuda:2')
epoch:  22000 quantization_loss:  0.02566809579730034
p mean is: tensor(1.2078, device='cuda:2')
epoch:  23000 quantization_loss:  0.024533623829483986
p mean is: tensor(1.4545, device='cuda:2')
epoch:  24000 quantization_loss:  0.022048212587833405
p mean is: tensor(1.7311, device='cuda:2')
epoch:  25000 quantization_loss:  0.020839553326368332
p mean is: tensor(2.0216, device='cuda:2')
epoch:  26000 quantization_loss:  0.01978994905948639
p mean is: tensor(2.3062, device='cuda:2')
epoch:  27000 quantization_loss:  0.019009657204151154
p mean is: tensor(2.5696, device='cuda:2')
epoch:  28000 quantization_loss:  0.018424442037940025
p mean is: tensor(2.8049, device='cuda:2')
epoch:  29000 quantization_loss:  0.017755845561623573
p mean is: tensor(3.0121, device='cuda:2')
epoch:  30000 quantization_loss:  0.0173639003187418
p mean is: tensor(3.1940, device='cuda:2')
epoch:  31000 quantization_loss:  0.017140289768576622
p mean is: tensor(3.3521, device='cuda:2')
epoch:  32000 quantization_loss:  0.016869638115167618
p mean is: tensor(3.4914, device='cuda:2')
epoch:  33000 quantization_loss:  0.016679327934980392
p mean is: tensor(3.6164, device='cuda:2')
epoch:  34000 quantization_loss:  0.016000758856534958
p mean is: tensor(3.7295, device='cuda:2')
epoch:  35000 quantization_loss:  0.015829136595129967
p mean is: tensor(3.8321, device='cuda:2')
epoch:  36000 quantization_loss:  0.015696929767727852
p mean is: tensor(3.9259, device='cuda:2')
epoch:  37000 quantization_loss:  0.015521577559411526
p mean is: tensor(4.0122, device='cuda:2')
epoch:  38000 quantization_loss:  0.01541880238801241
p mean is: tensor(4.0919, device='cuda:2')
epoch:  39000 quantization_loss:  0.015311820432543755
p mean is: tensor(4.1660, device='cuda:2')
epoch:  40000 quantization_loss:  0.015182729810476303
p mean is: tensor(4.2349, device='cuda:2')
epoch:  41000 quantization_loss:  0.015129153616726398
p mean is: tensor(4.2995, device='cuda:2')
epoch:  42000 quantization_loss:  0.01506811287254095
p mean is: tensor(4.3600, device='cuda:2')
epoch:  43000 quantization_loss:  0.014986693859100342
p mean is: tensor(4.4169, device='cuda:2')
epoch:  44000 quantization_loss:  0.014942650683224201
p mean is: tensor(4.4707, device='cuda:2')
epoch:  45000 quantization_loss:  0.014851946383714676
p mean is: tensor(4.5216, device='cuda:2')
epoch:  46000 quantization_loss:  0.014799727126955986
p mean is: tensor(4.5698, device='cuda:2')
epoch:  47000 quantization_loss:  0.014770100824534893
p mean is: tensor(4.6158, device='cuda:2')
epoch:  48000 quantization_loss:  0.014707568101584911
p mean is: tensor(4.6596, device='cuda:2')
epoch:  49000 quantization_loss:  0.014662543311715126
p mean is: tensor(4.7014, device='cuda:2')
epoch:  50000 quantization_loss:  0.014623678289353848
p mean is: tensor(4.7414, device='cuda:2')
epoch:  51000 quantization_loss:  0.01365785300731659
p mean is: tensor(4.7797, device='cuda:2')
epoch:  52000 quantization_loss:  0.013464577496051788
p mean is: tensor(4.8163, device='cuda:2')
epoch:  53000 quantization_loss:  0.014529120177030563
p mean is: tensor(4.8515, device='cuda:2')
epoch:  54000 quantization_loss:  0.01333819329738617
p mean is: tensor(4.8854, device='cuda:2')
epoch:  55000 quantization_loss:  0.013322475366294384
p mean is: tensor(4.9182, device='cuda:2')
epoch:  56000 quantization_loss:  0.013278667815029621
p mean is: tensor(4.9498, device='cuda:2')
epoch:  57000 quantization_loss:  0.01324479840695858
p mean is: tensor(4.9804, device='cuda:2')
epoch:  58000 quantization_loss:  0.013212671503424644
p mean is: tensor(5.0100, device='cuda:2')
epoch:  59000 quantization_loss:  0.013243217952549458
p mean is: tensor(5.0387, device='cuda:2')
epoch:  60000 quantization_loss:  0.013170669786632061
p mean is: tensor(5.0664, device='cuda:2')
epoch:  61000 quantization_loss:  0.013149509206414223
p mean is: tensor(5.0934, device='cuda:2')
epoch:  62000 quantization_loss:  0.013138972222805023
p mean is: tensor(5.1196, device='cuda:2')
epoch:  63000 quantization_loss:  0.013118073344230652
p mean is: tensor(5.1451, device='cuda:2')
epoch:  64000 quantization_loss:  0.013096087612211704
p mean is: tensor(5.1697, device='cuda:2')
epoch:  65000 quantization_loss:  0.013100668787956238
p mean is: tensor(5.1938, device='cuda:2')
epoch:  66000 quantization_loss:  0.013075897470116615
p mean is: tensor(5.2173, device='cuda:2')
epoch:  67000 quantization_loss:  0.013066171668469906
p mean is: tensor(5.2401, device='cuda:2')
epoch:  68000 quantization_loss:  0.013054554350674152
p mean is: tensor(5.2624, device='cuda:2')
epoch:  69000 quantization_loss:  0.013037641532719135
p mean is: tensor(5.2841, device='cuda:2')
epoch:  70000 quantization_loss:  0.013038660399615765
p mean is: tensor(5.3053, device='cuda:2')
epoch:  71000 quantization_loss:  0.013024454936385155
p mean is: tensor(5.3260, device='cuda:2')
epoch:  72000 quantization_loss:  0.013018190860748291
p mean is: tensor(5.3462, device='cuda:2')
epoch:  73000 quantization_loss:  0.013012818992137909
p mean is: tensor(5.3659, device='cuda:2')
epoch:  74000 quantization_loss:  0.012999339960515499
p mean is: tensor(5.3853, device='cuda:2')
epoch:  75000 quantization_loss:  0.012997064739465714
p mean is: tensor(5.4042, device='cuda:2')
epoch:  76000 quantization_loss:  0.01298851240426302
p mean is: tensor(5.4226, device='cuda:2')
epoch:  77000 quantization_loss:  0.012982307001948357
p mean is: tensor(5.4407, device='cuda:2')
epoch:  78000 quantization_loss:  0.01298053190112114
p mean is: tensor(5.4585, device='cuda:2')
epoch:  79000 quantization_loss:  0.012979421764612198
p mean is: tensor(5.4758, device='cuda:2')
1.1.1.weight         | nonzeros =   12742 /   12800             ( 99.55%) | total_pruned =      58 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.2.weight           | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =    6380 /    6400             ( 99.69%) | total_pruned =      20 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.5.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =   12791 /   12800             ( 99.93%) | total_pruned =       9 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =   25586 /   25600             ( 99.95%) | total_pruned =      14 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =   51185 /   51200             ( 99.97%) | total_pruned =      15 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =  102387 /  102400             ( 99.99%) | total_pruned =      13 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =  204792 /  204800             (100.00%) | total_pruned =       8 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =  409582 /  409600             (100.00%) | total_pruned =      18 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  409516 /  409600             ( 99.98%) | total_pruned =      84 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  409333 /  409600             ( 99.93%) | total_pruned =     267 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  409023 /  409600             ( 99.86%) | total_pruned =     577 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  407548 /  409600             ( 99.50%) | total_pruned =    2052 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  140602 /  147456             ( 95.35%) | total_pruned =    6854 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  136525 /  147456             ( 92.59%) | total_pruned =   10931 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =  137311 /  147456             ( 93.12%) | total_pruned =   10145 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   68212 /   73728             ( 92.52%) | total_pruned =    5516 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =   16734 /   18432             ( 90.79%) | total_pruned =    1698 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      26 /      32             ( 81.25%) | total_pruned =       6 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    3576 /    4608             ( 77.60%) | total_pruned =    1032 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      32 /      48             ( 66.67%) | total_pruned =      16 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 2966631, pruned : 42236, total: 3008867, Compression rate :       1.01x  (  1.40% pruned)
(3, 256, 256) (3, 256, 256) (3, 256, 256)
PSNR of output image is:  24.074819021633882
Experiment done
