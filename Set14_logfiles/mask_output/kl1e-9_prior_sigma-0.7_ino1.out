(3, 256, 256)
Starting vanilla DIP on 1 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.47653610119882'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/1/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-0.7/1e-09
epoch:  0 quantization_loss:  0.09135841578245163
p mean is: tensor(-0.0001, device='cuda:4')
epoch:  1000 quantization_loss:  0.07220254093408585
p mean is: tensor(-0.0022, device='cuda:4')
epoch:  2000 quantization_loss:  0.07330228388309479
p mean is: tensor(-0.0037, device='cuda:4')
epoch:  3000 quantization_loss:  0.07311400026082993
p mean is: tensor(-0.0048, device='cuda:4')
epoch:  4000 quantization_loss:  0.07154138386249542
p mean is: tensor(-0.0060, device='cuda:4')
epoch:  5000 quantization_loss:  0.06984882801771164
p mean is: tensor(-0.0074, device='cuda:4')
epoch:  6000 quantization_loss:  0.06907491385936737
p mean is: tensor(-0.0087, device='cuda:4')
epoch:  7000 quantization_loss:  0.07413861900568008
p mean is: tensor(-0.0103, device='cuda:4')
epoch:  8000 quantization_loss:  0.06833828240633011
p mean is: tensor(-0.0117, device='cuda:4')
epoch:  9000 quantization_loss:  0.07002294808626175
p mean is: tensor(-0.0130, device='cuda:4')
epoch:  10000 quantization_loss:  0.07057467848062515
p mean is: tensor(-0.0143, device='cuda:4')
epoch:  11000 quantization_loss:  0.07008113712072372
p mean is: tensor(-0.0156, device='cuda:4')
epoch:  12000 quantization_loss:  0.07240332663059235
p mean is: tensor(-0.0171, device='cuda:4')
epoch:  13000 quantization_loss:  0.06994452327489853
p mean is: tensor(-0.0188, device='cuda:4')
epoch:  14000 quantization_loss:  0.06976521015167236
p mean is: tensor(-0.0204, device='cuda:4')
epoch:  15000 quantization_loss:  0.057463549077510834
p mean is: tensor(-0.0224, device='cuda:4')
epoch:  16000 quantization_loss:  0.0456414669752121
p mean is: tensor(-0.0249, device='cuda:4')
epoch:  17000 quantization_loss:  0.036700036376714706
p mean is: tensor(-0.0282, device='cuda:4')
epoch:  18000 quantization_loss:  0.034317586570978165
p mean is: tensor(-0.0325, device='cuda:4')
epoch:  19000 quantization_loss:  0.02967885695397854
p mean is: tensor(-0.0385, device='cuda:4')
epoch:  20000 quantization_loss:  0.028470739722251892
p mean is: tensor(-0.0467, device='cuda:4')
epoch:  21000 quantization_loss:  0.027649233117699623
p mean is: tensor(-0.0578, device='cuda:4')
epoch:  22000 quantization_loss:  0.0266888327896595
p mean is: tensor(-0.0726, device='cuda:4')
epoch:  23000 quantization_loss:  0.024726497009396553
p mean is: tensor(-0.0915, device='cuda:4')
epoch:  24000 quantization_loss:  0.023802263662219048
p mean is: tensor(-0.1152, device='cuda:4')
epoch:  25000 quantization_loss:  0.022730248048901558
p mean is: tensor(-0.1437, device='cuda:4')
epoch:  26000 quantization_loss:  0.02168685756623745
p mean is: tensor(-0.1771, device='cuda:4')
epoch:  27000 quantization_loss:  0.021473148837685585
p mean is: tensor(-0.2147, device='cuda:4')
epoch:  28000 quantization_loss:  0.02062569558620453
p mean is: tensor(-0.2553, device='cuda:4')
epoch:  29000 quantization_loss:  0.02056218683719635
p mean is: tensor(-0.2969, device='cuda:4')
epoch:  30000 quantization_loss:  0.02050093375146389
p mean is: tensor(-0.3382, device='cuda:4')
epoch:  31000 quantization_loss:  0.019776195287704468
p mean is: tensor(-0.3781, device='cuda:4')
epoch:  32000 quantization_loss:  0.019528407603502274
p mean is: tensor(-0.4150, device='cuda:4')
epoch:  33000 quantization_loss:  0.019487349316477776
p mean is: tensor(-0.4485, device='cuda:4')
epoch:  34000 quantization_loss:  0.01883814111351967
p mean is: tensor(-0.4781, device='cuda:4')
epoch:  35000 quantization_loss:  0.018586916849017143
p mean is: tensor(-0.5041, device='cuda:4')
epoch:  36000 quantization_loss:  0.01848738081753254
p mean is: tensor(-0.5270, device='cuda:4')
epoch:  37000 quantization_loss:  0.018442925065755844
p mean is: tensor(-0.5465, device='cuda:4')
epoch:  38000 quantization_loss:  0.018250180408358574
p mean is: tensor(-0.5633, device='cuda:4')
epoch:  39000 quantization_loss:  0.018267624080181122
p mean is: tensor(-0.5778, device='cuda:4')
epoch:  40000 quantization_loss:  0.01807897537946701
p mean is: tensor(-0.5904, device='cuda:4')
epoch:  41000 quantization_loss:  0.018005331978201866
p mean is: tensor(-0.6011, device='cuda:4')
epoch:  42000 quantization_loss:  0.01802186109125614
p mean is: tensor(-0.6104, device='cuda:4')
epoch:  43000 quantization_loss:  0.017936237156391144
p mean is: tensor(-0.6183, device='cuda:4')
epoch:  44000 quantization_loss:  0.01792306639254093
p mean is: tensor(-0.6252, device='cuda:4')
epoch:  45000 quantization_loss:  0.017643198370933533
p mean is: tensor(-0.6312, device='cuda:4')
epoch:  46000 quantization_loss:  0.017672991380095482
p mean is: tensor(-0.6364, device='cuda:4')
epoch:  47000 quantization_loss:  0.01753857731819153
p mean is: tensor(-0.6409, device='cuda:4')
epoch:  48000 quantization_loss:  0.017493005841970444
p mean is: tensor(-0.6448, device='cuda:4')
epoch:  49000 quantization_loss:  0.017477601766586304
p mean is: tensor(-0.6481, device='cuda:4')
epoch:  50000 quantization_loss:  0.01747046783566475
p mean is: tensor(-0.6511, device='cuda:4')
epoch:  51000 quantization_loss:  0.017412260174751282
p mean is: tensor(-0.6538, device='cuda:4')
epoch:  52000 quantization_loss:  0.01734679751098156
p mean is: tensor(-0.6561, device='cuda:4')
epoch:  53000 quantization_loss:  0.017337264493107796
p mean is: tensor(-0.6583, device='cuda:4')
epoch:  54000 quantization_loss:  0.017284616827964783
p mean is: tensor(-0.6601, device='cuda:4')
epoch:  55000 quantization_loss:  0.01725952886044979
p mean is: tensor(-0.6619, device='cuda:4')
epoch:  56000 quantization_loss:  0.017235253006219864
p mean is: tensor(-0.6634, device='cuda:4')
epoch:  57000 quantization_loss:  0.017204949632287025
p mean is: tensor(-0.6648, device='cuda:4')
epoch:  58000 quantization_loss:  0.017208905890583992
p mean is: tensor(-0.6660, device='cuda:4')
epoch:  59000 quantization_loss:  0.017163366079330444
p mean is: tensor(-0.6672, device='cuda:4')
epoch:  60000 quantization_loss:  0.01717415824532509
p mean is: tensor(-0.6683, device='cuda:4')
epoch:  61000 quantization_loss:  0.01713573932647705
p mean is: tensor(-0.6692, device='cuda:4')
epoch:  62000 quantization_loss:  0.017122996971011162
p mean is: tensor(-0.6701, device='cuda:4')
epoch:  63000 quantization_loss:  0.01710120029747486
p mean is: tensor(-0.6710, device='cuda:4')
epoch:  64000 quantization_loss:  0.01709233596920967
p mean is: tensor(-0.6719, device='cuda:4')
epoch:  65000 quantization_loss:  0.017081597819924355
p mean is: tensor(-0.6727, device='cuda:4')
epoch:  66000 quantization_loss:  0.01706705242395401
p mean is: tensor(-0.6734, device='cuda:4')
epoch:  67000 quantization_loss:  0.017048506066203117
p mean is: tensor(-0.6741, device='cuda:4')
epoch:  68000 quantization_loss:  0.01703270711004734
p mean is: tensor(-0.6747, device='cuda:4')
epoch:  69000 quantization_loss:  0.017035339027643204
p mean is: tensor(-0.6753, device='cuda:4')
epoch:  70000 quantization_loss:  0.017040826380252838
p mean is: tensor(-0.6759, device='cuda:4')
epoch:  71000 quantization_loss:  0.01701660454273224
p mean is: tensor(-0.6764, device='cuda:4')
epoch:  72000 quantization_loss:  0.0170102808624506
p mean is: tensor(-0.6770, device='cuda:4')
epoch:  73000 quantization_loss:  0.016996638849377632
p mean is: tensor(-0.6775, device='cuda:4')
epoch:  74000 quantization_loss:  0.01698612980544567
p mean is: tensor(-0.6779, device='cuda:4')
epoch:  75000 quantization_loss:  0.016979921609163284
p mean is: tensor(-0.6784, device='cuda:4')
epoch:  76000 quantization_loss:  0.01697055995464325
p mean is: tensor(-0.6789, device='cuda:4')
epoch:  77000 quantization_loss:  0.016966437920928
p mean is: tensor(-0.6793, device='cuda:4')
epoch:  78000 quantization_loss:  0.016967061907052994
p mean is: tensor(-0.6797, device='cuda:4')
epoch:  79000 quantization_loss:  0.016965141519904137
p mean is: tensor(-0.6801, device='cuda:4')
here
1.1.1.weight         | nonzeros =     320 /   12800             (  2.50%) | total_pruned =   12480 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =      56 /    6400             (  0.88%) | total_pruned =    6344 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       5 /      16             ( 31.25%) | total_pruned =      11 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      41 /   12800             (  0.32%) | total_pruned =   12759 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      10 /      32             ( 31.25%) | total_pruned =      22 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =      70 /   25600             (  0.27%) | total_pruned =   25530 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =      57 /   51200             (  0.11%) | total_pruned =   51143 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =      99 /  102400             (  0.10%) | total_pruned =  102301 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =      70 /  204800             (  0.03%) | total_pruned =  204730 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     161 /  409600             (  0.04%) | total_pruned =  409439 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     233 /  409600             (  0.06%) | total_pruned =  409367 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    1500 /  409600             (  0.37%) | total_pruned =  408100 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    4913 /  409600             (  1.20%) | total_pruned =  404687 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   21627 /  409600             (  5.28%) | total_pruned =  387973 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   24413 /  147456             ( 16.56%) | total_pruned =  123043 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   25118 /  147456             ( 17.03%) | total_pruned =  122338 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   25667 /  147456             ( 17.41%) | total_pruned =  121789 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   12936 /   73728             ( 17.55%) | total_pruned =   60792 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2633 /   18432             ( 14.28%) | total_pruned =   15799 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1123 /    4608             ( 24.37%) | total_pruned =    3485 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      33 /      48             ( 68.75%) | total_pruned =      15 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 122185, pruned : 2886682, total: 3008867, Compression rate :      24.63x  ( 95.94% pruned)
PSNR of output image is:  20.256839544172337
Experiment done
