(3, 512, 512)
Starting vanilla DIP on 2 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.42880281303451'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/2/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-0.7/1e-09
epoch:  0 quantization_loss:  0.10284309834241867
p mean is: tensor(-0.0001, device='cuda:1')
epoch:  1000 quantization_loss:  0.08149261772632599
p mean is: tensor(-0.0048, device='cuda:1')
epoch:  2000 quantization_loss:  0.07842598110437393
p mean is: tensor(-0.0082, device='cuda:1')
epoch:  3000 quantization_loss:  0.07802345603704453
p mean is: tensor(-0.0115, device='cuda:1')
epoch:  4000 quantization_loss:  0.07839687168598175
p mean is: tensor(-0.0148, device='cuda:1')
epoch:  5000 quantization_loss:  0.07676664739847183
p mean is: tensor(-0.0183, device='cuda:1')
epoch:  6000 quantization_loss:  0.07609543949365616
p mean is: tensor(-0.0221, device='cuda:1')
epoch:  7000 quantization_loss:  0.07181204110383987
p mean is: tensor(-0.0265, device='cuda:1')
epoch:  8000 quantization_loss:  0.07045959681272507
p mean is: tensor(-0.0322, device='cuda:1')
epoch:  9000 quantization_loss:  0.0658881664276123
p mean is: tensor(-0.0401, device='cuda:1')
epoch:  10000 quantization_loss:  0.0604189932346344
p mean is: tensor(-0.0502, device='cuda:1')
epoch:  11000 quantization_loss:  0.0563669390976429
p mean is: tensor(-0.0632, device='cuda:1')
epoch:  12000 quantization_loss:  0.05468469485640526
p mean is: tensor(-0.0799, device='cuda:1')
epoch:  13000 quantization_loss:  0.05406172201037407
p mean is: tensor(-0.1010, device='cuda:1')
epoch:  14000 quantization_loss:  0.050451647490262985
p mean is: tensor(-0.1275, device='cuda:1')
epoch:  15000 quantization_loss:  0.04950782656669617
p mean is: tensor(-0.1590, device='cuda:1')
epoch:  16000 quantization_loss:  0.04891034588217735
p mean is: tensor(-0.1953, device='cuda:1')
epoch:  17000 quantization_loss:  0.048497751355171204
p mean is: tensor(-0.2354, device='cuda:1')
epoch:  18000 quantization_loss:  0.04839187487959862
p mean is: tensor(-0.2777, device='cuda:1')
epoch:  19000 quantization_loss:  0.04794783145189285
p mean is: tensor(-0.3204, device='cuda:1')
epoch:  20000 quantization_loss:  0.047558609396219254
p mean is: tensor(-0.3618, device='cuda:1')
epoch:  21000 quantization_loss:  0.04730294272303581
p mean is: tensor(-0.4006, device='cuda:1')
epoch:  22000 quantization_loss:  0.04533957317471504
p mean is: tensor(-0.4357, device='cuda:1')
epoch:  23000 quantization_loss:  0.04496315121650696
p mean is: tensor(-0.4668, device='cuda:1')
epoch:  24000 quantization_loss:  0.04483344033360481
p mean is: tensor(-0.4938, device='cuda:1')
epoch:  25000 quantization_loss:  0.04477137327194214
p mean is: tensor(-0.5175, device='cuda:1')
epoch:  26000 quantization_loss:  0.04468332231044769
p mean is: tensor(-0.5380, device='cuda:1')
epoch:  27000 quantization_loss:  0.04446890577673912
p mean is: tensor(-0.5559, device='cuda:1')
epoch:  28000 quantization_loss:  0.044403232634067535
p mean is: tensor(-0.5713, device='cuda:1')
epoch:  29000 quantization_loss:  0.04432214796543121
p mean is: tensor(-0.5848, device='cuda:1')
epoch:  30000 quantization_loss:  0.04416341707110405
p mean is: tensor(-0.5963, device='cuda:1')
epoch:  31000 quantization_loss:  0.04417042434215546
p mean is: tensor(-0.6065, device='cuda:1')
epoch:  32000 quantization_loss:  0.04404753819108009
p mean is: tensor(-0.6155, device='cuda:1')
epoch:  33000 quantization_loss:  0.04402988404035568
p mean is: tensor(-0.6232, device='cuda:1')
epoch:  34000 quantization_loss:  0.04392576590180397
p mean is: tensor(-0.6300, device='cuda:1')
epoch:  35000 quantization_loss:  0.043911539018154144
p mean is: tensor(-0.6360, device='cuda:1')
epoch:  36000 quantization_loss:  0.04388578608632088
p mean is: tensor(-0.6414, device='cuda:1')
epoch:  37000 quantization_loss:  0.04389377310872078
p mean is: tensor(-0.6461, device='cuda:1')
epoch:  38000 quantization_loss:  0.04381226375699043
p mean is: tensor(-0.6503, device='cuda:1')
epoch:  39000 quantization_loss:  0.0437626838684082
p mean is: tensor(-0.6541, device='cuda:1')
epoch:  40000 quantization_loss:  0.043747033923864365
p mean is: tensor(-0.6575, device='cuda:1')
epoch:  41000 quantization_loss:  0.04370173066854477
p mean is: tensor(-0.6606, device='cuda:1')
epoch:  42000 quantization_loss:  0.04400881379842758
p mean is: tensor(-0.6635, device='cuda:1')
epoch:  43000 quantization_loss:  0.0436721071600914
p mean is: tensor(-0.6660, device='cuda:1')
epoch:  44000 quantization_loss:  0.04363575205206871
p mean is: tensor(-0.6683, device='cuda:1')
epoch:  45000 quantization_loss:  0.043622538447380066
p mean is: tensor(-0.6704, device='cuda:1')
epoch:  46000 quantization_loss:  0.04359913989901543
p mean is: tensor(-0.6724, device='cuda:1')
epoch:  47000 quantization_loss:  0.043606627732515335
p mean is: tensor(-0.6741, device='cuda:1')
epoch:  48000 quantization_loss:  0.04357501491904259
p mean is: tensor(-0.6758, device='cuda:1')
epoch:  49000 quantization_loss:  0.04357476904988289
p mean is: tensor(-0.6774, device='cuda:1')
epoch:  50000 quantization_loss:  0.04355660080909729
p mean is: tensor(-0.6788, device='cuda:1')
epoch:  51000 quantization_loss:  0.04355102404952049
p mean is: tensor(-0.6802, device='cuda:1')
epoch:  52000 quantization_loss:  0.043540824204683304
p mean is: tensor(-0.6815, device='cuda:1')
epoch:  53000 quantization_loss:  0.043528713285923004
p mean is: tensor(-0.6827, device='cuda:1')
epoch:  54000 quantization_loss:  0.04351498931646347
p mean is: tensor(-0.6839, device='cuda:1')
epoch:  55000 quantization_loss:  0.04351133480668068
p mean is: tensor(-0.6849, device='cuda:1')
epoch:  56000 quantization_loss:  0.04351191595196724
p mean is: tensor(-0.6859, device='cuda:1')
epoch:  57000 quantization_loss:  0.04349569231271744
p mean is: tensor(-0.6870, device='cuda:1')
epoch:  58000 quantization_loss:  0.04348936676979065
p mean is: tensor(-0.6879, device='cuda:1')
epoch:  59000 quantization_loss:  0.043489422649145126
p mean is: tensor(-0.6888, device='cuda:1')
epoch:  60000 quantization_loss:  0.04354704171419144
p mean is: tensor(-0.6896, device='cuda:1')
epoch:  61000 quantization_loss:  0.04354896768927574
p mean is: tensor(-0.6905, device='cuda:1')
epoch:  62000 quantization_loss:  0.04347255080938339
p mean is: tensor(-0.6914, device='cuda:1')
epoch:  63000 quantization_loss:  0.04346630722284317
p mean is: tensor(-0.6921, device='cuda:1')
epoch:  64000 quantization_loss:  0.043462254106998444
p mean is: tensor(-0.6928, device='cuda:1')
epoch:  65000 quantization_loss:  0.043455928564071655
p mean is: tensor(-0.6935, device='cuda:1')
epoch:  66000 quantization_loss:  0.043459489941596985
p mean is: tensor(-0.6942, device='cuda:1')
epoch:  67000 quantization_loss:  0.04345618188381195
p mean is: tensor(-0.6949, device='cuda:1')
epoch:  68000 quantization_loss:  0.04345536604523659
p mean is: tensor(-0.6956, device='cuda:1')
epoch:  69000 quantization_loss:  0.04344470053911209
p mean is: tensor(-0.6962, device='cuda:1')
epoch:  70000 quantization_loss:  0.04346352443099022
p mean is: tensor(-0.6969, device='cuda:1')
epoch:  71000 quantization_loss:  0.04344167932868004
p mean is: tensor(-0.6975, device='cuda:1')
epoch:  72000 quantization_loss:  0.043440159410238266
p mean is: tensor(-0.6981, device='cuda:1')
epoch:  73000 quantization_loss:  0.0434408076107502
p mean is: tensor(-0.6987, device='cuda:1')
epoch:  74000 quantization_loss:  0.043433040380477905
p mean is: tensor(-0.6993, device='cuda:1')
epoch:  75000 quantization_loss:  0.04343142360448837
p mean is: tensor(-0.6999, device='cuda:1')
epoch:  76000 quantization_loss:  0.04343976825475693
p mean is: tensor(-0.7004, device='cuda:1')
epoch:  77000 quantization_loss:  0.04342427849769592
p mean is: tensor(-0.7009, device='cuda:1')
epoch:  78000 quantization_loss:  0.043428391218185425
p mean is: tensor(-0.7014, device='cuda:1')
epoch:  79000 quantization_loss:  0.043427154421806335
p mean is: tensor(-0.7019, device='cuda:1')
here
1.1.1.weight         | nonzeros =    1171 /   12800             (  9.15%) | total_pruned =   11629 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     165 /    6400             (  2.58%) | total_pruned =    6235 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       4 /      16             ( 25.00%) | total_pruned =      12 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     185 /   12800             (  1.45%) | total_pruned =   12615 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     347 /   25600             (  1.36%) | total_pruned =   25253 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     286 /   51200             (  0.56%) | total_pruned =   50914 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     744 /  102400             (  0.73%) | total_pruned =  101656 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     465 /  204800             (  0.23%) | total_pruned =  204335 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =    1249 /  409600             (  0.30%) | total_pruned =  408351 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    1565 /  409600             (  0.38%) | total_pruned =  408035 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    7140 /  409600             (  1.74%) | total_pruned =  402460 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   20948 /  409600             (  5.11%) | total_pruned =  388652 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   49458 /  409600             ( 12.07%) | total_pruned =  360142 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   31482 /  147456             ( 21.35%) | total_pruned =  115974 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   23212 /  147456             ( 15.74%) | total_pruned =  124244 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   21045 /  147456             ( 14.27%) | total_pruned =  126411 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    8083 /   73728             ( 10.96%) | total_pruned =   65645 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2403 /   18432             ( 13.04%) | total_pruned =   16029 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1524 /    4608             ( 33.07%) | total_pruned =    3084 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      24 /      48             ( 50.00%) | total_pruned =      24 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 172771, pruned : 2836096, total: 3008867, Compression rate :      17.42x  ( 94.26% pruned)
PSNR of output image is:  14.384821959031726
Experiment done
