(3, 512, 512)
Starting vanilla DIP on 13 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.494743888232524'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/13/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-1.0/1e-09
epoch:  0 quantization_loss:  0.0905168354511261
p mean is: tensor(-0.0002, device='cuda:1')
epoch:  1000 quantization_loss:  0.06531579792499542
p mean is: tensor(-0.0069, device='cuda:1')
epoch:  2000 quantization_loss:  0.06435761600732803
p mean is: tensor(-0.0114, device='cuda:1')
epoch:  3000 quantization_loss:  0.06268373876810074
p mean is: tensor(-0.0157, device='cuda:1')
epoch:  4000 quantization_loss:  0.06313741952180862
p mean is: tensor(-0.0199, device='cuda:1')
epoch:  5000 quantization_loss:  0.06284269690513611
p mean is: tensor(-0.0243, device='cuda:1')
epoch:  6000 quantization_loss:  0.061934806406497955
p mean is: tensor(-0.0288, device='cuda:1')
epoch:  7000 quantization_loss:  0.055759724229574203
p mean is: tensor(-0.0335, device='cuda:1')
epoch:  8000 quantization_loss:  0.0460176020860672
p mean is: tensor(-0.0388, device='cuda:1')
epoch:  9000 quantization_loss:  0.03976370766758919
p mean is: tensor(-0.0457, device='cuda:1')
epoch:  10000 quantization_loss:  0.03662211820483208
p mean is: tensor(-0.0549, device='cuda:1')
epoch:  11000 quantization_loss:  0.03486447408795357
p mean is: tensor(-0.0675, device='cuda:1')
epoch:  12000 quantization_loss:  0.03339233994483948
p mean is: tensor(-0.0847, device='cuda:1')
epoch:  13000 quantization_loss:  0.03189021721482277
p mean is: tensor(-0.1072, device='cuda:1')
epoch:  14000 quantization_loss:  0.02986719086766243
p mean is: tensor(-0.1362, device='cuda:1')
epoch:  15000 quantization_loss:  0.0283379964530468
p mean is: tensor(-0.1720, device='cuda:1')
epoch:  16000 quantization_loss:  0.02750886045396328
p mean is: tensor(-0.2149, device='cuda:1')
epoch:  17000 quantization_loss:  0.027050133794546127
p mean is: tensor(-0.2644, device='cuda:1')
epoch:  18000 quantization_loss:  0.026654452085494995
p mean is: tensor(-0.3194, device='cuda:1')
epoch:  19000 quantization_loss:  0.026223400607705116
p mean is: tensor(-0.3776, device='cuda:1')
epoch:  20000 quantization_loss:  0.02591867372393608
p mean is: tensor(-0.4363, device='cuda:1')
epoch:  21000 quantization_loss:  0.025890877470374107
p mean is: tensor(-0.4930, device='cuda:1')
epoch:  22000 quantization_loss:  0.02549556829035282
p mean is: tensor(-0.5459, device='cuda:1')
epoch:  23000 quantization_loss:  0.025404732674360275
p mean is: tensor(-0.5944, device='cuda:1')
epoch:  24000 quantization_loss:  0.02521444298326969
p mean is: tensor(-0.6378, device='cuda:1')
epoch:  25000 quantization_loss:  0.025051366537809372
p mean is: tensor(-0.6763, device='cuda:1')
epoch:  26000 quantization_loss:  0.024949265643954277
p mean is: tensor(-0.7103, device='cuda:1')
epoch:  27000 quantization_loss:  0.024844489991664886
p mean is: tensor(-0.7401, device='cuda:1')
epoch:  28000 quantization_loss:  0.024750888347625732
p mean is: tensor(-0.7662, device='cuda:1')
epoch:  29000 quantization_loss:  0.024673976004123688
p mean is: tensor(-0.7890, device='cuda:1')
epoch:  30000 quantization_loss:  0.024552766233682632
p mean is: tensor(-0.8090, device='cuda:1')
epoch:  31000 quantization_loss:  0.024489669129252434
p mean is: tensor(-0.8265, device='cuda:1')
epoch:  32000 quantization_loss:  0.024419700726866722
p mean is: tensor(-0.8419, device='cuda:1')
epoch:  33000 quantization_loss:  0.02434389479458332
p mean is: tensor(-0.8556, device='cuda:1')
epoch:  34000 quantization_loss:  0.024321042001247406
p mean is: tensor(-0.8675, device='cuda:1')
epoch:  35000 quantization_loss:  0.024236582219600677
p mean is: tensor(-0.8781, device='cuda:1')
epoch:  36000 quantization_loss:  0.024190032854676247
p mean is: tensor(-0.8875, device='cuda:1')
epoch:  37000 quantization_loss:  0.024177053943276405
p mean is: tensor(-0.8958, device='cuda:1')
epoch:  38000 quantization_loss:  0.024143394082784653
p mean is: tensor(-0.9033, device='cuda:1')
epoch:  39000 quantization_loss:  0.024093344807624817
p mean is: tensor(-0.9100, device='cuda:1')
epoch:  40000 quantization_loss:  0.024059969931840897
p mean is: tensor(-0.9160, device='cuda:1')
epoch:  41000 quantization_loss:  0.024055998772382736
p mean is: tensor(-0.9214, device='cuda:1')
epoch:  42000 quantization_loss:  0.023639410734176636
p mean is: tensor(-0.9262, device='cuda:1')
epoch:  43000 quantization_loss:  0.0235074944794178
p mean is: tensor(-0.9305, device='cuda:1')
epoch:  44000 quantization_loss:  0.02348393015563488
p mean is: tensor(-0.9343, device='cuda:1')
epoch:  45000 quantization_loss:  0.0233993548899889
p mean is: tensor(-0.9379, device='cuda:1')
epoch:  46000 quantization_loss:  0.02336611971259117
p mean is: tensor(-0.9411, device='cuda:1')
epoch:  47000 quantization_loss:  0.023358376696705818
p mean is: tensor(-0.9442, device='cuda:1')
epoch:  48000 quantization_loss:  0.023326218128204346
p mean is: tensor(-0.9471, device='cuda:1')
epoch:  49000 quantization_loss:  0.023332655429840088
p mean is: tensor(-0.9498, device='cuda:1')
epoch:  50000 quantization_loss:  0.023290561512112617
p mean is: tensor(-0.9523, device='cuda:1')
epoch:  51000 quantization_loss:  0.023285241797566414
p mean is: tensor(-0.9547, device='cuda:1')
epoch:  52000 quantization_loss:  0.023290526121854782
p mean is: tensor(-0.9570, device='cuda:1')
epoch:  53000 quantization_loss:  0.02326110005378723
p mean is: tensor(-0.9591, device='cuda:1')
epoch:  54000 quantization_loss:  0.023244602605700493
p mean is: tensor(-0.9611, device='cuda:1')
epoch:  55000 quantization_loss:  0.023227421566843987
p mean is: tensor(-0.9630, device='cuda:1')
epoch:  56000 quantization_loss:  0.023217547684907913
p mean is: tensor(-0.9648, device='cuda:1')
epoch:  57000 quantization_loss:  0.02323845773935318
p mean is: tensor(-0.9665, device='cuda:1')
epoch:  58000 quantization_loss:  0.02319515310227871
p mean is: tensor(-0.9681, device='cuda:1')
epoch:  59000 quantization_loss:  0.023195689544081688
p mean is: tensor(-0.9697, device='cuda:1')
epoch:  60000 quantization_loss:  0.023173945024609566
p mean is: tensor(-0.9712, device='cuda:1')
epoch:  61000 quantization_loss:  0.023166311904788017
p mean is: tensor(-0.9726, device='cuda:1')
epoch:  62000 quantization_loss:  0.023160673677921295
p mean is: tensor(-0.9739, device='cuda:1')
epoch:  63000 quantization_loss:  0.023161381483078003
p mean is: tensor(-0.9752, device='cuda:1')
epoch:  64000 quantization_loss:  0.023157984018325806
p mean is: tensor(-0.9764, device='cuda:1')
epoch:  65000 quantization_loss:  0.023169931024312973
p mean is: tensor(-0.9777, device='cuda:1')
epoch:  66000 quantization_loss:  0.023139169439673424
p mean is: tensor(-0.9789, device='cuda:1')
epoch:  67000 quantization_loss:  0.023134831339120865
p mean is: tensor(-0.9800, device='cuda:1')
epoch:  68000 quantization_loss:  0.023132530972361565
p mean is: tensor(-0.9811, device='cuda:1')
epoch:  69000 quantization_loss:  0.023131422698497772
p mean is: tensor(-0.9823, device='cuda:1')
epoch:  70000 quantization_loss:  0.02311907336115837
p mean is: tensor(-0.9833, device='cuda:1')
epoch:  71000 quantization_loss:  0.02312113530933857
p mean is: tensor(-0.9844, device='cuda:1')
epoch:  72000 quantization_loss:  0.023118427023291588
p mean is: tensor(-0.9854, device='cuda:1')
epoch:  73000 quantization_loss:  0.023113951086997986
p mean is: tensor(-0.9864, device='cuda:1')
epoch:  74000 quantization_loss:  0.023108473047614098
p mean is: tensor(-0.9873, device='cuda:1')
epoch:  75000 quantization_loss:  0.023101119324564934
p mean is: tensor(-0.9883, device='cuda:1')
epoch:  76000 quantization_loss:  0.02322116121649742
p mean is: tensor(-0.9891, device='cuda:1')
epoch:  77000 quantization_loss:  0.023109694942831993
p mean is: tensor(-0.9900, device='cuda:1')
epoch:  78000 quantization_loss:  0.02309688739478588
p mean is: tensor(-0.9909, device='cuda:1')
epoch:  79000 quantization_loss:  0.02318049967288971
p mean is: tensor(-0.9917, device='cuda:1')
here
1.1.1.weight         | nonzeros =    1273 /   12800             (  9.95%) | total_pruned =   11527 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     187 /    6400             (  2.92%) | total_pruned =    6213 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     152 /   12800             (  1.19%) | total_pruned =   12648 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     199 /   25600             (  0.78%) | total_pruned =   25401 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      12 /      32             ( 37.50%) | total_pruned =      20 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     239 /   51200             (  0.47%) | total_pruned =   50961 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     473 /  102400             (  0.46%) | total_pruned =  101927 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     459 /  204800             (  0.22%) | total_pruned =  204341 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     527 /  409600             (  0.13%) | total_pruned =  409073 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     635 /  409600             (  0.16%) | total_pruned =  408965 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    3496 /  409600             (  0.85%) | total_pruned =  406104 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   12750 /  409600             (  3.11%) | total_pruned =  396850 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   41748 /  409600             ( 10.19%) | total_pruned =  367852 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   28791 /  147456             ( 19.53%) | total_pruned =  118665 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   27313 /  147456             ( 18.52%) | total_pruned =  120143 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   23786 /  147456             ( 16.13%) | total_pruned =  123670 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   11646 /   73728             ( 15.80%) | total_pruned =   62082 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2866 /   18432             ( 15.55%) | total_pruned =   15566 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1109 /    4608             ( 24.07%) | total_pruned =    3499 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      29 /      48             ( 60.42%) | total_pruned =      19 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 158928, pruned : 2849939, total: 3008867, Compression rate :      18.93x  ( 94.72% pruned)
PSNR of output image is:  17.825116948067503
Experiment done
