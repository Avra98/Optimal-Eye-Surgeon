(3, 512, 512)
Starting vanilla DIP on 10 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.183804288903566'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/10/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-1.8/1e-09
epoch:  0 quantization_loss:  0.05962609499692917
p mean is: tensor(-0.0003, device='cuda:1')
epoch:  1000 quantization_loss:  0.05699179694056511
p mean is: tensor(-0.0151, device='cuda:1')
epoch:  2000 quantization_loss:  0.05632372200489044
p mean is: tensor(-0.0273, device='cuda:1')
epoch:  3000 quantization_loss:  0.056729186326265335
p mean is: tensor(-0.0394, device='cuda:1')
epoch:  4000 quantization_loss:  0.05598517507314682
p mean is: tensor(-0.0513, device='cuda:1')
epoch:  5000 quantization_loss:  0.056140851229429245
p mean is: tensor(-0.0632, device='cuda:1')
epoch:  6000 quantization_loss:  0.05584529787302017
p mean is: tensor(-0.0751, device='cuda:1')
epoch:  7000 quantization_loss:  0.055861879140138626
p mean is: tensor(-0.0875, device='cuda:1')
epoch:  8000 quantization_loss:  0.05523867532610893
p mean is: tensor(-0.1011, device='cuda:1')
epoch:  9000 quantization_loss:  0.05534989759325981
p mean is: tensor(-0.1157, device='cuda:1')
epoch:  10000 quantization_loss:  0.04853803664445877
p mean is: tensor(-0.1312, device='cuda:1')
epoch:  11000 quantization_loss:  0.04069778695702553
p mean is: tensor(-0.1503, device='cuda:1')
epoch:  12000 quantization_loss:  0.038308050483465195
p mean is: tensor(-0.1747, device='cuda:1')
epoch:  13000 quantization_loss:  0.036867231130599976
p mean is: tensor(-0.2064, device='cuda:1')
epoch:  14000 quantization_loss:  0.03565631061792374
p mean is: tensor(-0.2475, device='cuda:1')
epoch:  15000 quantization_loss:  0.03379041701555252
p mean is: tensor(-0.2998, device='cuda:1')
epoch:  16000 quantization_loss:  0.030273688957095146
p mean is: tensor(-0.3642, device='cuda:1')
epoch:  17000 quantization_loss:  0.029270481318235397
p mean is: tensor(-0.4402, device='cuda:1')
epoch:  18000 quantization_loss:  0.028693370521068573
p mean is: tensor(-0.5266, device='cuda:1')
epoch:  19000 quantization_loss:  0.02839013934135437
p mean is: tensor(-0.6203, device='cuda:1')
epoch:  20000 quantization_loss:  0.027786973863840103
p mean is: tensor(-0.7169, device='cuda:1')
epoch:  21000 quantization_loss:  0.0274486243724823
p mean is: tensor(-0.8127, device='cuda:1')
epoch:  22000 quantization_loss:  0.027141282334923744
p mean is: tensor(-0.9038, device='cuda:1')
epoch:  23000 quantization_loss:  0.02680918574333191
p mean is: tensor(-0.9884, device='cuda:1')
epoch:  24000 quantization_loss:  0.027016857638955116
p mean is: tensor(-1.0654, device='cuda:1')
epoch:  25000 quantization_loss:  0.026454567909240723
p mean is: tensor(-1.1349, device='cuda:1')
epoch:  26000 quantization_loss:  0.02629120647907257
p mean is: tensor(-1.1968, device='cuda:1')
epoch:  27000 quantization_loss:  0.02616133913397789
p mean is: tensor(-1.2519, device='cuda:1')
epoch:  28000 quantization_loss:  0.026005107909440994
p mean is: tensor(-1.3009, device='cuda:1')
epoch:  29000 quantization_loss:  0.025849442929029465
p mean is: tensor(-1.3446, device='cuda:1')
epoch:  30000 quantization_loss:  0.025716425850987434
p mean is: tensor(-1.3836, device='cuda:1')
epoch:  31000 quantization_loss:  0.025682969018816948
p mean is: tensor(-1.4182, device='cuda:1')
epoch:  32000 quantization_loss:  0.025512099266052246
p mean is: tensor(-1.4493, device='cuda:1')
epoch:  33000 quantization_loss:  0.025437595322728157
p mean is: tensor(-1.4771, device='cuda:1')
epoch:  34000 quantization_loss:  0.025430889800190926
p mean is: tensor(-1.5020, device='cuda:1')
epoch:  35000 quantization_loss:  0.0253036729991436
p mean is: tensor(-1.5245, device='cuda:1')
epoch:  36000 quantization_loss:  0.02522720955312252
p mean is: tensor(-1.5449, device='cuda:1')
epoch:  37000 quantization_loss:  0.025204161182045937
p mean is: tensor(-1.5633, device='cuda:1')
epoch:  38000 quantization_loss:  0.02514144405722618
p mean is: tensor(-1.5800, device='cuda:1')
epoch:  39000 quantization_loss:  0.02510032057762146
p mean is: tensor(-1.5951, device='cuda:1')
epoch:  40000 quantization_loss:  0.02505853958427906
p mean is: tensor(-1.6090, device='cuda:1')
epoch:  41000 quantization_loss:  0.02503284625709057
p mean is: tensor(-1.6215, device='cuda:1')
epoch:  42000 quantization_loss:  0.02499125339090824
p mean is: tensor(-1.6332, device='cuda:1')
epoch:  43000 quantization_loss:  0.024962415918707848
p mean is: tensor(-1.6437, device='cuda:1')
epoch:  44000 quantization_loss:  0.024948013946413994
p mean is: tensor(-1.6535, device='cuda:1')
epoch:  45000 quantization_loss:  0.024928905069828033
p mean is: tensor(-1.6624, device='cuda:1')
epoch:  46000 quantization_loss:  0.02494160272181034
p mean is: tensor(-1.6706, device='cuda:1')
epoch:  47000 quantization_loss:  0.02491646446287632
p mean is: tensor(-1.6782, device='cuda:1')
epoch:  48000 quantization_loss:  0.0248604416847229
p mean is: tensor(-1.6853, device='cuda:1')
epoch:  49000 quantization_loss:  0.024832138791680336
p mean is: tensor(-1.6918, device='cuda:1')
epoch:  50000 quantization_loss:  0.02483413740992546
p mean is: tensor(-1.6979, device='cuda:1')
epoch:  51000 quantization_loss:  0.02480749785900116
p mean is: tensor(-1.7037, device='cuda:1')
epoch:  52000 quantization_loss:  0.02478862926363945
p mean is: tensor(-1.7090, device='cuda:1')
epoch:  53000 quantization_loss:  0.024781446903944016
p mean is: tensor(-1.7140, device='cuda:1')
epoch:  54000 quantization_loss:  0.024768371134996414
p mean is: tensor(-1.7187, device='cuda:1')
epoch:  55000 quantization_loss:  0.02475951611995697
p mean is: tensor(-1.7231, device='cuda:1')
epoch:  56000 quantization_loss:  0.024735931307077408
p mean is: tensor(-1.7272, device='cuda:1')
epoch:  57000 quantization_loss:  0.024727996438741684
p mean is: tensor(-1.7310, device='cuda:1')
epoch:  58000 quantization_loss:  0.024720223620533943
p mean is: tensor(-1.7347, device='cuda:1')
epoch:  59000 quantization_loss:  0.024729903787374496
p mean is: tensor(-1.7381, device='cuda:1')
epoch:  60000 quantization_loss:  0.02470674365758896
p mean is: tensor(-1.7414, device='cuda:1')
epoch:  61000 quantization_loss:  0.024701524525880814
p mean is: tensor(-1.7444, device='cuda:1')
epoch:  62000 quantization_loss:  0.024690795689821243
p mean is: tensor(-1.7473, device='cuda:1')
epoch:  63000 quantization_loss:  0.02468792349100113
p mean is: tensor(-1.7501, device='cuda:1')
epoch:  64000 quantization_loss:  0.024684185162186623
p mean is: tensor(-1.7529, device='cuda:1')
epoch:  65000 quantization_loss:  0.024686302989721298
p mean is: tensor(-1.7555, device='cuda:1')
epoch:  66000 quantization_loss:  0.024677317589521408
p mean is: tensor(-1.7579, device='cuda:1')
epoch:  67000 quantization_loss:  0.024665292352437973
p mean is: tensor(-1.7603, device='cuda:1')
epoch:  68000 quantization_loss:  0.0246665608137846
p mean is: tensor(-1.7626, device='cuda:1')
epoch:  69000 quantization_loss:  0.02465899847447872
p mean is: tensor(-1.7648, device='cuda:1')
epoch:  70000 quantization_loss:  0.024651046842336655
p mean is: tensor(-1.7669, device='cuda:1')
epoch:  71000 quantization_loss:  0.024651378393173218
p mean is: tensor(-1.7690, device='cuda:1')
epoch:  72000 quantization_loss:  0.024645447731018066
p mean is: tensor(-1.7709, device='cuda:1')
epoch:  73000 quantization_loss:  0.024640865623950958
p mean is: tensor(-1.7727, device='cuda:1')
epoch:  74000 quantization_loss:  0.02464199811220169
p mean is: tensor(-1.7746, device='cuda:1')
epoch:  75000 quantization_loss:  0.02465069852769375
p mean is: tensor(-1.7764, device='cuda:1')
epoch:  76000 quantization_loss:  0.02464134991168976
p mean is: tensor(-1.7781, device='cuda:1')
epoch:  77000 quantization_loss:  0.024636322632431984
p mean is: tensor(-1.7797, device='cuda:1')
epoch:  78000 quantization_loss:  0.024630391970276833
p mean is: tensor(-1.7814, device='cuda:1')
epoch:  79000 quantization_loss:  0.02462783083319664
p mean is: tensor(-1.7830, device='cuda:1')
here
1.1.1.weight         | nonzeros =     845 /   12800             (  6.60%) | total_pruned =   11955 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     116 /    6400             (  1.81%) | total_pruned =    6284 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      39 /   12800             (  0.30%) | total_pruned =   12761 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =      92 /   25600             (  0.36%) | total_pruned =   25508 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =       9 /      32             ( 28.12%) | total_pruned =      23 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =      43 /   51200             (  0.08%) | total_pruned =   51157 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =      14 /  102400             (  0.01%) | total_pruned =  102386 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =       1 /  204800             (  0.00%) | total_pruned =  204799 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =       6 /  409600             (  0.00%) | total_pruned =  409594 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =      74 /  409600             (  0.02%) | total_pruned =  409526 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    1472 /  409600             (  0.36%) | total_pruned =  408128 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    5781 /  409600             (  1.41%) | total_pruned =  403819 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   23591 /  409600             (  5.76%) | total_pruned =  386009 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   25642 /  147456             ( 17.39%) | total_pruned =  121814 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   24801 /  147456             ( 16.82%) | total_pruned =  122655 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   22824 /  147456             ( 15.48%) | total_pruned =  124632 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    9377 /   73728             ( 12.72%) | total_pruned =   64351 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2142 /   18432             ( 11.62%) | total_pruned =   16290 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1024 /    4608             ( 22.22%) | total_pruned =    3584 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      24 /      48             ( 50.00%) | total_pruned =      24 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 119161, pruned : 2889706, total: 3008867, Compression rate :      25.25x  ( 96.04% pruned)
PSNR of output image is:  13.109099826736097
Experiment done
