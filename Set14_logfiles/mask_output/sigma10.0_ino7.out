(3, 512, 512)
Noisy PSNR is '20.30164621368464'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/7/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/10.0/1e-09
epoch:  0 quantization_loss:  0.08884093165397644
p mean is: tensor(0.0014, device='cuda:4')
epoch:  1000 quantization_loss:  0.08131923526525497
p mean is: tensor(0.0631, device='cuda:4')
epoch:  2000 quantization_loss:  0.0794120579957962
p mean is: tensor(0.1042, device='cuda:4')
epoch:  3000 quantization_loss:  0.07962703704833984
p mean is: tensor(0.1428, device='cuda:4')
epoch:  4000 quantization_loss:  0.0777793675661087
p mean is: tensor(0.1808, device='cuda:4')
epoch:  5000 quantization_loss:  0.07722136378288269
p mean is: tensor(0.2195, device='cuda:4')
epoch:  6000 quantization_loss:  0.07595659047365189
p mean is: tensor(0.2594, device='cuda:4')
epoch:  7000 quantization_loss:  0.07633056491613388
p mean is: tensor(0.3011, device='cuda:4')
epoch:  8000 quantization_loss:  0.06793709844350815
p mean is: tensor(0.3455, device='cuda:4')
epoch:  9000 quantization_loss:  0.059280432760715485
p mean is: tensor(0.3987, device='cuda:4')
epoch:  10000 quantization_loss:  0.052970148622989655
p mean is: tensor(0.4690, device='cuda:4')
epoch:  11000 quantization_loss:  0.050128959119319916
p mean is: tensor(0.5646, device='cuda:4')
epoch:  12000 quantization_loss:  0.045104820281267166
p mean is: tensor(0.6909, device='cuda:4')
epoch:  13000 quantization_loss:  0.04354158043861389
p mean is: tensor(0.8528, device='cuda:4')
epoch:  14000 quantization_loss:  0.040080562233924866
p mean is: tensor(1.0529, device='cuda:4')
epoch:  15000 quantization_loss:  0.03748412802815437
p mean is: tensor(1.2870, device='cuda:4')
epoch:  16000 quantization_loss:  0.035879503935575485
p mean is: tensor(1.5461, device='cuda:4')
epoch:  17000 quantization_loss:  0.03475990146398544
p mean is: tensor(1.8167, device='cuda:4')
epoch:  18000 quantization_loss:  0.03358420729637146
p mean is: tensor(2.0837, device='cuda:4')
epoch:  19000 quantization_loss:  0.03285076096653938
p mean is: tensor(2.3352, device='cuda:4')
epoch:  20000 quantization_loss:  0.03215477615594864
p mean is: tensor(2.5653, device='cuda:4')
epoch:  21000 quantization_loss:  0.031513579189777374
p mean is: tensor(2.7718, device='cuda:4')
epoch:  22000 quantization_loss:  0.030996255576610565
p mean is: tensor(2.9558, device='cuda:4')
epoch:  23000 quantization_loss:  0.03071894310414791
p mean is: tensor(3.1196, device='cuda:4')
epoch:  24000 quantization_loss:  0.030411310493946075
p mean is: tensor(3.2652, device='cuda:4')
epoch:  25000 quantization_loss:  0.030094753950834274
p mean is: tensor(3.3961, device='cuda:4')
epoch:  26000 quantization_loss:  0.0299689918756485
p mean is: tensor(3.5141, device='cuda:4')
epoch:  27000 quantization_loss:  0.02968529798090458
p mean is: tensor(3.6215, device='cuda:4')
epoch:  28000 quantization_loss:  0.029642809182405472
p mean is: tensor(3.7195, device='cuda:4')
epoch:  29000 quantization_loss:  0.029401391744613647
p mean is: tensor(3.8096, device='cuda:4')
epoch:  30000 quantization_loss:  0.029245490208268166
p mean is: tensor(3.8928, device='cuda:4')
epoch:  31000 quantization_loss:  0.029096011072397232
p mean is: tensor(3.9701, device='cuda:4')
epoch:  32000 quantization_loss:  0.029035035520792007
p mean is: tensor(4.0422, device='cuda:4')
epoch:  33000 quantization_loss:  0.02889695204794407
p mean is: tensor(4.1097, device='cuda:4')
epoch:  34000 quantization_loss:  0.028829537332057953
p mean is: tensor(4.1732, device='cuda:4')
epoch:  35000 quantization_loss:  0.028702307492494583
p mean is: tensor(4.2331, device='cuda:4')
epoch:  36000 quantization_loss:  0.028625482693314552
p mean is: tensor(4.2899, device='cuda:4')
epoch:  37000 quantization_loss:  0.028552254661917686
p mean is: tensor(4.3438, device='cuda:4')
epoch:  38000 quantization_loss:  0.02799900993704796
p mean is: tensor(4.3947, device='cuda:4')
epoch:  39000 quantization_loss:  0.027919631451368332
p mean is: tensor(4.4434, device='cuda:4')
epoch:  40000 quantization_loss:  0.027856476604938507
p mean is: tensor(4.4900, device='cuda:4')
epoch:  41000 quantization_loss:  0.027802329510450363
p mean is: tensor(4.5346, device='cuda:4')
epoch:  42000 quantization_loss:  0.027740728110074997
p mean is: tensor(4.5774, device='cuda:4')
epoch:  43000 quantization_loss:  0.027681995183229446
p mean is: tensor(4.6186, device='cuda:4')
epoch:  44000 quantization_loss:  0.02765072137117386
p mean is: tensor(4.6582, device='cuda:4')
epoch:  45000 quantization_loss:  0.027616949751973152
p mean is: tensor(4.6964, device='cuda:4')
epoch:  46000 quantization_loss:  0.027589615434408188
p mean is: tensor(4.7332, device='cuda:4')
epoch:  47000 quantization_loss:  0.027591779828071594
p mean is: tensor(4.7687, device='cuda:4')
epoch:  48000 quantization_loss:  0.027505896985530853
p mean is: tensor(4.8031, device='cuda:4')
epoch:  49000 quantization_loss:  0.027470681816339493
p mean is: tensor(4.8363, device='cuda:4')
epoch:  50000 quantization_loss:  0.027451934292912483
p mean is: tensor(4.8685, device='cuda:4')
epoch:  51000 quantization_loss:  0.02741432376205921
p mean is: tensor(4.8997, device='cuda:4')
epoch:  52000 quantization_loss:  0.027407480403780937
p mean is: tensor(4.9301, device='cuda:4')
epoch:  53000 quantization_loss:  0.02737974189221859
p mean is: tensor(4.9595, device='cuda:4')
epoch:  54000 quantization_loss:  0.027354734018445015
p mean is: tensor(4.9882, device='cuda:4')
epoch:  55000 quantization_loss:  0.027333814650774002
p mean is: tensor(5.0160, device='cuda:4')
epoch:  56000 quantization_loss:  0.0273380596190691
p mean is: tensor(5.0431, device='cuda:4')
epoch:  57000 quantization_loss:  0.0273150447756052
p mean is: tensor(5.0695, device='cuda:4')
epoch:  58000 quantization_loss:  0.027294352650642395
p mean is: tensor(5.0952, device='cuda:4')
epoch:  59000 quantization_loss:  0.027279255911707878
p mean is: tensor(5.1203, device='cuda:4')
epoch:  60000 quantization_loss:  0.0272660031914711
p mean is: tensor(5.1448, device='cuda:4')
epoch:  61000 quantization_loss:  0.02725171484053135
p mean is: tensor(5.1688, device='cuda:4')
epoch:  62000 quantization_loss:  0.027232952415943146
p mean is: tensor(5.1921, device='cuda:4')
epoch:  63000 quantization_loss:  0.027234483510255814
p mean is: tensor(5.2149, device='cuda:4')
epoch:  64000 quantization_loss:  0.027215268462896347
p mean is: tensor(5.2372, device='cuda:4')
epoch:  65000 quantization_loss:  0.0272048506885767
p mean is: tensor(5.2590, device='cuda:4')
epoch:  66000 quantization_loss:  0.02722112089395523
p mean is: tensor(5.2804, device='cuda:4')
epoch:  67000 quantization_loss:  0.027190912514925003
p mean is: tensor(5.3013, device='cuda:4')
epoch:  68000 quantization_loss:  0.027181968092918396
p mean is: tensor(5.3217, device='cuda:4')
epoch:  69000 quantization_loss:  0.027183769270777702
p mean is: tensor(5.3417, device='cuda:4')
epoch:  70000 quantization_loss:  0.02717287465929985
p mean is: tensor(5.3614, device='cuda:4')
epoch:  71000 quantization_loss:  0.027157669886946678
p mean is: tensor(5.3806, device='cuda:4')
epoch:  72000 quantization_loss:  0.02714931219816208
p mean is: tensor(5.3995, device='cuda:4')
epoch:  73000 quantization_loss:  0.027141980826854706
p mean is: tensor(5.4180, device='cuda:4')
epoch:  74000 quantization_loss:  0.027141287922859192
p mean is: tensor(5.4361, device='cuda:4')
epoch:  75000 quantization_loss:  0.027135169133543968
p mean is: tensor(5.4540, device='cuda:4')
epoch:  76000 quantization_loss:  0.02714254893362522
p mean is: tensor(5.4715, device='cuda:4')
epoch:  77000 quantization_loss:  0.027123717591166496
p mean is: tensor(5.4887, device='cuda:4')
epoch:  78000 quantization_loss:  0.027202319353818893
p mean is: tensor(5.5055, device='cuda:4')
epoch:  79000 quantization_loss:  0.027115097269415855
p mean is: tensor(5.5221, device='cuda:4')
1.1.1.weight         | nonzeros =   12271 /   12800             ( 95.87%) | total_pruned =     529 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.2.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =    6324 /    6400             ( 98.81%) | total_pruned =      76 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.5.weight           | nonzeros =      12 /      16             ( 75.00%) | total_pruned =       4 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =   12754 /   12800             ( 99.64%) | total_pruned =      46 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =   25540 /   25600             ( 99.77%) | total_pruned =      60 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =   51116 /   51200             ( 99.84%) | total_pruned =      84 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =  102295 /  102400             ( 99.90%) | total_pruned =     105 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =  204555 /  204800             ( 99.88%) | total_pruned =     245 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =  409241 /  409600             ( 99.91%) | total_pruned =     359 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  408958 /  409600             ( 99.84%) | total_pruned =     642 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  408203 /  409600             ( 99.66%) | total_pruned =    1397 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  406741 /  409600             ( 99.30%) | total_pruned =    2859 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  401633 /  409600             ( 98.05%) | total_pruned =    7967 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  133024 /  147456             ( 90.21%) | total_pruned =   14432 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  131897 /  147456             ( 89.45%) | total_pruned =   15559 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =     117 /     128             ( 91.41%) | total_pruned =      11 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =  134039 /  147456             ( 90.90%) | total_pruned =   13417 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =     114 /     128             ( 89.06%) | total_pruned =      14 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   66299 /   73728             ( 89.92%) | total_pruned =    7429 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =   15785 /   18432             ( 85.64%) | total_pruned =    2647 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      29 /      32             ( 90.62%) | total_pruned =       3 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      21 /      32             ( 65.62%) | total_pruned =      11 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    3312 /    4608             ( 71.88%) | total_pruned =    1296 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      31 /      48             ( 64.58%) | total_pruned =      17 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 2937034, pruned : 71833, total: 3008867, Compression rate :       1.02x  (  2.39% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  17.403551449763185
Experiment done
