(3, 512, 512)
Noisy PSNR is '20.199274802511567'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/5/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/1.0/1e-09
epoch:  0 quantization_loss:  0.05738738924264908
p mean is: tensor(0.0002, device='cuda:4')
epoch:  1000 quantization_loss:  0.05407414585351944
p mean is: tensor(0.0087, device='cuda:4')
epoch:  2000 quantization_loss:  0.05322463437914848
p mean is: tensor(0.0153, device='cuda:4')
epoch:  3000 quantization_loss:  0.052335649728775024
p mean is: tensor(0.0219, device='cuda:4')
epoch:  4000 quantization_loss:  0.05277188867330551
p mean is: tensor(0.0284, device='cuda:4')
epoch:  5000 quantization_loss:  0.05259813368320465
p mean is: tensor(0.0354, device='cuda:4')
epoch:  6000 quantization_loss:  0.05304423347115517
p mean is: tensor(0.0428, device='cuda:4')
epoch:  7000 quantization_loss:  0.05291218310594559
p mean is: tensor(0.0510, device='cuda:4')
epoch:  8000 quantization_loss:  0.04988355189561844
p mean is: tensor(0.0591, device='cuda:4')
epoch:  9000 quantization_loss:  0.04492030292749405
p mean is: tensor(0.0679, device='cuda:4')
epoch:  10000 quantization_loss:  0.04014822095632553
p mean is: tensor(0.0795, device='cuda:4')
epoch:  11000 quantization_loss:  0.03176243603229523
p mean is: tensor(0.0925, device='cuda:4')
epoch:  12000 quantization_loss:  0.02817292883992195
p mean is: tensor(0.1090, device='cuda:4')
epoch:  13000 quantization_loss:  0.026051824912428856
p mean is: tensor(0.1306, device='cuda:4')
epoch:  14000 quantization_loss:  0.024229833856225014
p mean is: tensor(0.1587, device='cuda:4')
epoch:  15000 quantization_loss:  0.02333039976656437
p mean is: tensor(0.1938, device='cuda:4')
epoch:  16000 quantization_loss:  0.022516097873449326
p mean is: tensor(0.2364, device='cuda:4')
epoch:  17000 quantization_loss:  0.02182547189295292
p mean is: tensor(0.2860, device='cuda:4')
epoch:  18000 quantization_loss:  0.021393410861492157
p mean is: tensor(0.3407, device='cuda:4')
epoch:  19000 quantization_loss:  0.02094055898487568
p mean is: tensor(0.3984, device='cuda:4')
epoch:  20000 quantization_loss:  0.020603898912668228
p mean is: tensor(0.4563, device='cuda:4')
epoch:  21000 quantization_loss:  0.020470932126045227
p mean is: tensor(0.5121, device='cuda:4')
epoch:  22000 quantization_loss:  0.020158451050519943
p mean is: tensor(0.5645, device='cuda:4')
epoch:  23000 quantization_loss:  0.019983652979135513
p mean is: tensor(0.6123, device='cuda:4')
epoch:  24000 quantization_loss:  0.01984749175608158
p mean is: tensor(0.6553, device='cuda:4')
epoch:  25000 quantization_loss:  0.019688796252012253
p mean is: tensor(0.6934, device='cuda:4')
epoch:  26000 quantization_loss:  0.019496649503707886
p mean is: tensor(0.7271, device='cuda:4')
epoch:  27000 quantization_loss:  0.019534965977072716
p mean is: tensor(0.7567, device='cuda:4')
epoch:  28000 quantization_loss:  0.019366955384612083
p mean is: tensor(0.7827, device='cuda:4')
epoch:  29000 quantization_loss:  0.019230909645557404
p mean is: tensor(0.8053, device='cuda:4')
epoch:  30000 quantization_loss:  0.01918899640440941
p mean is: tensor(0.8250, device='cuda:4')
epoch:  31000 quantization_loss:  0.019055161625146866
p mean is: tensor(0.8423, device='cuda:4')
epoch:  32000 quantization_loss:  0.018998973071575165
p mean is: tensor(0.8573, device='cuda:4')
epoch:  33000 quantization_loss:  0.018938638269901276
p mean is: tensor(0.8705, device='cuda:4')
epoch:  34000 quantization_loss:  0.0188936535269022
p mean is: tensor(0.8822, device='cuda:4')
epoch:  35000 quantization_loss:  0.018835684284567833
p mean is: tensor(0.8925, device='cuda:4')
epoch:  36000 quantization_loss:  0.01879665069282055
p mean is: tensor(0.9015, device='cuda:4')
epoch:  37000 quantization_loss:  0.01876734383404255
p mean is: tensor(0.9096, device='cuda:4')
epoch:  38000 quantization_loss:  0.018717186525464058
p mean is: tensor(0.9167, device='cuda:4')
epoch:  39000 quantization_loss:  0.018695693463087082
p mean is: tensor(0.9231, device='cuda:4')
epoch:  40000 quantization_loss:  0.018658848479390144
p mean is: tensor(0.9288, device='cuda:4')
epoch:  41000 quantization_loss:  0.01862357370555401
p mean is: tensor(0.9339, device='cuda:4')
epoch:  42000 quantization_loss:  0.018604716286063194
p mean is: tensor(0.9385, device='cuda:4')
epoch:  43000 quantization_loss:  0.018590735271573067
p mean is: tensor(0.9427, device='cuda:4')
epoch:  44000 quantization_loss:  0.018571604043245316
p mean is: tensor(0.9465, device='cuda:4')
epoch:  45000 quantization_loss:  0.018536973744630814
p mean is: tensor(0.9499, device='cuda:4')
epoch:  46000 quantization_loss:  0.01853586919605732
p mean is: tensor(0.9531, device='cuda:4')
epoch:  47000 quantization_loss:  0.018513673916459084
p mean is: tensor(0.9560, device='cuda:4')
epoch:  48000 quantization_loss:  0.018526025116443634
p mean is: tensor(0.9586, device='cuda:4')
epoch:  49000 quantization_loss:  0.018488364294171333
p mean is: tensor(0.9610, device='cuda:4')
epoch:  50000 quantization_loss:  0.01847555674612522
p mean is: tensor(0.9633, device='cuda:4')
epoch:  51000 quantization_loss:  0.01845494657754898
p mean is: tensor(0.9654, device='cuda:4')
epoch:  52000 quantization_loss:  0.018443023785948753
p mean is: tensor(0.9674, device='cuda:4')
epoch:  53000 quantization_loss:  0.018430065363645554
p mean is: tensor(0.9692, device='cuda:4')
epoch:  54000 quantization_loss:  0.018421584740281105
p mean is: tensor(0.9709, device='cuda:4')
epoch:  55000 quantization_loss:  0.018420783802866936
p mean is: tensor(0.9726, device='cuda:4')
epoch:  56000 quantization_loss:  0.018412308767437935
p mean is: tensor(0.9741, device='cuda:4')
epoch:  57000 quantization_loss:  0.01839456893503666
p mean is: tensor(0.9755, device='cuda:4')
epoch:  58000 quantization_loss:  0.018402094021439552
p mean is: tensor(0.9769, device='cuda:4')
epoch:  59000 quantization_loss:  0.018394555896520615
p mean is: tensor(0.9781, device='cuda:4')
epoch:  60000 quantization_loss:  0.0183823574334383
p mean is: tensor(0.9793, device='cuda:4')
epoch:  61000 quantization_loss:  0.018379444256424904
p mean is: tensor(0.9805, device='cuda:4')
epoch:  62000 quantization_loss:  0.018369723111391068
p mean is: tensor(0.9817, device='cuda:4')
epoch:  63000 quantization_loss:  0.018409838899970055
p mean is: tensor(0.9827, device='cuda:4')
epoch:  64000 quantization_loss:  0.018362436443567276
p mean is: tensor(0.9837, device='cuda:4')
epoch:  65000 quantization_loss:  0.018355386331677437
p mean is: tensor(0.9846, device='cuda:4')
epoch:  66000 quantization_loss:  0.01835528574883938
p mean is: tensor(0.9855, device='cuda:4')
epoch:  67000 quantization_loss:  0.01835964247584343
p mean is: tensor(0.9864, device='cuda:4')
epoch:  68000 quantization_loss:  0.018336549401283264
p mean is: tensor(0.9873, device='cuda:4')
epoch:  69000 quantization_loss:  0.01835455372929573
p mean is: tensor(0.9881, device='cuda:4')
epoch:  70000 quantization_loss:  0.018336499109864235
p mean is: tensor(0.9889, device='cuda:4')
epoch:  71000 quantization_loss:  0.018337193876504898
p mean is: tensor(0.9897, device='cuda:4')
epoch:  72000 quantization_loss:  0.018334807828068733
p mean is: tensor(0.9905, device='cuda:4')
epoch:  73000 quantization_loss:  0.018342571333050728
p mean is: tensor(0.9912, device='cuda:4')
epoch:  74000 quantization_loss:  0.01831621676683426
p mean is: tensor(0.9918, device='cuda:4')
epoch:  75000 quantization_loss:  0.018267663195729256
p mean is: tensor(0.9924, device='cuda:4')
epoch:  76000 quantization_loss:  0.018243717029690742
p mean is: tensor(0.9929, device='cuda:4')
epoch:  77000 quantization_loss:  0.018234407529234886
p mean is: tensor(0.9936, device='cuda:4')
epoch:  78000 quantization_loss:  0.0182211771607399
p mean is: tensor(0.9942, device='cuda:4')
epoch:  79000 quantization_loss:  0.018203584477305412
p mean is: tensor(0.9947, device='cuda:4')
1.1.1.weight         | nonzeros =   11517 /   12800             ( 89.98%) | total_pruned =    1283 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.2.weight           | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =    6157 /    6400             ( 96.20%) | total_pruned =     243 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.5.weight           | nonzeros =      11 /      16             ( 68.75%) | total_pruned =       5 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =   12697 /   12800             ( 99.20%) | total_pruned =     103 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =   25477 /   25600             ( 99.52%) | total_pruned =     123 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =   51043 /   51200             ( 99.69%) | total_pruned =     157 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =  102203 /  102400             ( 99.81%) | total_pruned =     197 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =  204733 /  204800             ( 99.97%) | total_pruned =      67 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =  409367 /  409600             ( 99.94%) | total_pruned =     233 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  409167 /  409600             ( 99.89%) | total_pruned =     433 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  405760 /  409600             ( 99.06%) | total_pruned =    3840 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  397054 /  409600             ( 96.94%) | total_pruned =   12546 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  376036 /  409600             ( 91.81%) | total_pruned =   33564 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  120945 /  147456             ( 82.02%) | total_pruned =   26511 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  116480 /  147456             ( 78.99%) | total_pruned =   30976 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =  116682 /  147456             ( 79.13%) | total_pruned =   30774 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   59256 /   73728             ( 80.37%) | total_pruned =   14472 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =   15235 /   18432             ( 82.66%) | total_pruned =    3197 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    3253 /    4608             ( 70.59%) | total_pruned =    1355 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      28 /      48             ( 58.33%) | total_pruned =      20 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       3 /       3             (100.00%) | total_pruned =       0 | shape = torch.Size([3])
alive: 2846020, pruned : 162847, total: 3008867, Compression rate :       1.06x  (  5.41% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  20.443424720415404
Experiment done
