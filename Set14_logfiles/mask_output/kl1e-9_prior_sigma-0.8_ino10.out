(3, 512, 512)
Starting vanilla DIP on 10 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.15854504892979'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/10/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-0.8/1e-09
epoch:  0 quantization_loss:  0.06101296469569206
p mean is: tensor(-0.0001, device='cuda:4')
epoch:  1000 quantization_loss:  0.05586548149585724
p mean is: tensor(-0.0058, device='cuda:4')
epoch:  2000 quantization_loss:  0.05513850972056389
p mean is: tensor(-0.0099, device='cuda:4')
epoch:  3000 quantization_loss:  0.05516896769404411
p mean is: tensor(-0.0139, device='cuda:4')
epoch:  4000 quantization_loss:  0.056754034012556076
p mean is: tensor(-0.0180, device='cuda:4')
epoch:  5000 quantization_loss:  0.055235616862773895
p mean is: tensor(-0.0219, device='cuda:4')
epoch:  6000 quantization_loss:  0.05499272793531418
p mean is: tensor(-0.0260, device='cuda:4')
epoch:  7000 quantization_loss:  0.05498916655778885
p mean is: tensor(-0.0300, device='cuda:4')
epoch:  8000 quantization_loss:  0.04752006381750107
p mean is: tensor(-0.0347, device='cuda:4')
epoch:  9000 quantization_loss:  0.04164019972085953
p mean is: tensor(-0.0407, device='cuda:4')
epoch:  10000 quantization_loss:  0.03672271966934204
p mean is: tensor(-0.0482, device='cuda:4')
epoch:  11000 quantization_loss:  0.03322899341583252
p mean is: tensor(-0.0577, device='cuda:4')
epoch:  12000 quantization_loss:  0.027157727628946304
p mean is: tensor(-0.0703, device='cuda:4')
epoch:  13000 quantization_loss:  0.025603951886296272
p mean is: tensor(-0.0863, device='cuda:4')
epoch:  14000 quantization_loss:  0.023678380995988846
p mean is: tensor(-0.1069, device='cuda:4')
epoch:  15000 quantization_loss:  0.02246885374188423
p mean is: tensor(-0.1326, device='cuda:4')
epoch:  16000 quantization_loss:  0.02166559360921383
p mean is: tensor(-0.1637, device='cuda:4')
epoch:  17000 quantization_loss:  0.020626245066523552
p mean is: tensor(-0.2004, device='cuda:4')
epoch:  18000 quantization_loss:  0.02006934955716133
p mean is: tensor(-0.2410, device='cuda:4')
epoch:  19000 quantization_loss:  0.01950788125395775
p mean is: tensor(-0.2846, device='cuda:4')
epoch:  20000 quantization_loss:  0.01914464496076107
p mean is: tensor(-0.3293, device='cuda:4')
epoch:  21000 quantization_loss:  0.01870645210146904
p mean is: tensor(-0.3737, device='cuda:4')
epoch:  22000 quantization_loss:  0.01838817074894905
p mean is: tensor(-0.4158, device='cuda:4')
epoch:  23000 quantization_loss:  0.018132835626602173
p mean is: tensor(-0.4550, device='cuda:4')
epoch:  24000 quantization_loss:  0.017877323552966118
p mean is: tensor(-0.4906, device='cuda:4')
epoch:  25000 quantization_loss:  0.017680685967206955
p mean is: tensor(-0.5226, device='cuda:4')
epoch:  26000 quantization_loss:  0.01753227412700653
p mean is: tensor(-0.5512, device='cuda:4')
epoch:  27000 quantization_loss:  0.017326747998595238
p mean is: tensor(-0.5764, device='cuda:4')
epoch:  28000 quantization_loss:  0.017183655872941017
p mean is: tensor(-0.5987, device='cuda:4')
epoch:  29000 quantization_loss:  0.017065584659576416
p mean is: tensor(-0.6182, device='cuda:4')
epoch:  30000 quantization_loss:  0.01689823716878891
p mean is: tensor(-0.6353, device='cuda:4')
epoch:  31000 quantization_loss:  0.016789304092526436
p mean is: tensor(-0.6504, device='cuda:4')
epoch:  32000 quantization_loss:  0.01671711541712284
p mean is: tensor(-0.6637, device='cuda:4')
epoch:  33000 quantization_loss:  0.01664639264345169
p mean is: tensor(-0.6753, device='cuda:4')
epoch:  34000 quantization_loss:  0.016569461673498154
p mean is: tensor(-0.6854, device='cuda:4')
epoch:  35000 quantization_loss:  0.01646292395889759
p mean is: tensor(-0.6945, device='cuda:4')
epoch:  36000 quantization_loss:  0.01641840860247612
p mean is: tensor(-0.7024, device='cuda:4')
epoch:  37000 quantization_loss:  0.016339635476469994
p mean is: tensor(-0.7096, device='cuda:4')
epoch:  38000 quantization_loss:  0.01628625951707363
p mean is: tensor(-0.7160, device='cuda:4')
epoch:  39000 quantization_loss:  0.016237253323197365
p mean is: tensor(-0.7217, device='cuda:4')
epoch:  40000 quantization_loss:  0.016155051067471504
p mean is: tensor(-0.7268, device='cuda:4')
epoch:  41000 quantization_loss:  0.016139255836606026
p mean is: tensor(-0.7315, device='cuda:4')
epoch:  42000 quantization_loss:  0.016134312376379967
p mean is: tensor(-0.7356, device='cuda:4')
epoch:  43000 quantization_loss:  0.016070103272795677
p mean is: tensor(-0.7394, device='cuda:4')
epoch:  44000 quantization_loss:  0.016072165220975876
p mean is: tensor(-0.7429, device='cuda:4')
epoch:  45000 quantization_loss:  0.016003064811229706
p mean is: tensor(-0.7460, device='cuda:4')
epoch:  46000 quantization_loss:  0.015982460230588913
p mean is: tensor(-0.7489, device='cuda:4')
epoch:  47000 quantization_loss:  0.015925314277410507
p mean is: tensor(-0.7516, device='cuda:4')
epoch:  48000 quantization_loss:  0.015914933755993843
p mean is: tensor(-0.7541, device='cuda:4')
epoch:  49000 quantization_loss:  0.01591569371521473
p mean is: tensor(-0.7565, device='cuda:4')
epoch:  50000 quantization_loss:  0.01589006558060646
p mean is: tensor(-0.7586, device='cuda:4')
epoch:  51000 quantization_loss:  0.01587403565645218
p mean is: tensor(-0.7607, device='cuda:4')
epoch:  52000 quantization_loss:  0.015852047130465508
p mean is: tensor(-0.7627, device='cuda:4')
epoch:  53000 quantization_loss:  0.015840204432606697
p mean is: tensor(-0.7645, device='cuda:4')
epoch:  54000 quantization_loss:  0.015825927257537842
p mean is: tensor(-0.7662, device='cuda:4')
epoch:  55000 quantization_loss:  0.015811366960406303
p mean is: tensor(-0.7679, device='cuda:4')
epoch:  56000 quantization_loss:  0.015818670392036438
p mean is: tensor(-0.7694, device='cuda:4')
epoch:  57000 quantization_loss:  0.015849554911255836
p mean is: tensor(-0.7709, device='cuda:4')
epoch:  58000 quantization_loss:  0.015769412741065025
p mean is: tensor(-0.7723, device='cuda:4')
epoch:  59000 quantization_loss:  0.01576516032218933
p mean is: tensor(-0.7736, device='cuda:4')
epoch:  60000 quantization_loss:  0.01576240174472332
p mean is: tensor(-0.7749, device='cuda:4')
epoch:  61000 quantization_loss:  0.01579638570547104
p mean is: tensor(-0.7761, device='cuda:4')
epoch:  62000 quantization_loss:  0.015742510557174683
p mean is: tensor(-0.7773, device='cuda:4')
epoch:  63000 quantization_loss:  0.015737013891339302
p mean is: tensor(-0.7785, device='cuda:4')
epoch:  64000 quantization_loss:  0.015730639919638634
p mean is: tensor(-0.7796, device='cuda:4')
epoch:  65000 quantization_loss:  0.015729445964097977
p mean is: tensor(-0.7807, device='cuda:4')
epoch:  66000 quantization_loss:  0.015717100352048874
p mean is: tensor(-0.7817, device='cuda:4')
epoch:  67000 quantization_loss:  0.015719251707196236
p mean is: tensor(-0.7827, device='cuda:4')
epoch:  68000 quantization_loss:  0.01572190225124359
p mean is: tensor(-0.7837, device='cuda:4')
epoch:  69000 quantization_loss:  0.015709253028035164
p mean is: tensor(-0.7847, device='cuda:4')
epoch:  70000 quantization_loss:  0.01570703461766243
p mean is: tensor(-0.7856, device='cuda:4')
epoch:  71000 quantization_loss:  0.0157003253698349
p mean is: tensor(-0.7865, device='cuda:4')
epoch:  72000 quantization_loss:  0.015749678015708923
p mean is: tensor(-0.7874, device='cuda:4')
epoch:  73000 quantization_loss:  0.01568937860429287
p mean is: tensor(-0.7883, device='cuda:4')
epoch:  74000 quantization_loss:  0.015694398432970047
p mean is: tensor(-0.7892, device='cuda:4')
epoch:  75000 quantization_loss:  0.01567871682345867
p mean is: tensor(-0.7900, device='cuda:4')
epoch:  76000 quantization_loss:  0.015682796016335487
p mean is: tensor(-0.7908, device='cuda:4')
epoch:  77000 quantization_loss:  0.01568143628537655
p mean is: tensor(-0.7915, device='cuda:4')
epoch:  78000 quantization_loss:  0.015679579228162766
p mean is: tensor(-0.7923, device='cuda:4')
epoch:  79000 quantization_loss:  0.015671316534280777
p mean is: tensor(-0.7931, device='cuda:4')
here
1.1.1.weight         | nonzeros =    1371 /   12800             ( 10.71%) | total_pruned =   11429 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     331 /    6400             (  5.17%) | total_pruned =    6069 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     290 /   12800             (  2.27%) | total_pruned =   12510 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      13 /      32             ( 40.62%) | total_pruned =      19 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     418 /   25600             (  1.63%) | total_pruned =   25182 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      13 /      32             ( 40.62%) | total_pruned =      19 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     443 /   51200             (  0.87%) | total_pruned =   50757 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     838 /  102400             (  0.82%) | total_pruned =  101562 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     616 /  204800             (  0.30%) | total_pruned =  204184 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =    1381 /  409600             (  0.34%) | total_pruned =  408219 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    2079 /  409600             (  0.51%) | total_pruned =  407521 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    8189 /  409600             (  2.00%) | total_pruned =  401411 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   22539 /  409600             (  5.50%) | total_pruned =  387061 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   51291 /  409600             ( 12.52%) | total_pruned =  358309 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   31426 /  147456             ( 21.31%) | total_pruned =  116030 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   29354 /  147456             ( 19.91%) | total_pruned =  118102 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   28624 /  147456             ( 19.41%) | total_pruned =  118832 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   12668 /   73728             ( 17.18%) | total_pruned =   61060 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2848 /   18432             ( 15.45%) | total_pruned =   15584 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1174 /    4608             ( 25.48%) | total_pruned =    3434 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      30 /      48             ( 62.50%) | total_pruned =      18 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 197265, pruned : 2811602, total: 3008867, Compression rate :      15.25x  ( 93.44% pruned)
PSNR of output image is:  21.912868100033187
Experiment done
