(3, 256, 256)
Starting vanilla DIP on 1 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.511942853982003'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/1/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/clean_img/-1.3/1e-09
epoch:  0 quantization_loss:  0.08133617043495178
p mean is: tensor(-0.0002, device='cuda:2')
epoch:  1000 quantization_loss:  0.06796196848154068
p mean is: tensor(-0.0042, device='cuda:2')
epoch:  2000 quantization_loss:  0.06773025542497635
p mean is: tensor(-0.0068, device='cuda:2')
epoch:  3000 quantization_loss:  0.0645470917224884
p mean is: tensor(-0.0092, device='cuda:2')
epoch:  4000 quantization_loss:  0.0670078918337822
p mean is: tensor(-0.0117, device='cuda:2')
epoch:  5000 quantization_loss:  0.06701598316431046
p mean is: tensor(-0.0143, device='cuda:2')
epoch:  6000 quantization_loss:  0.06404203176498413
p mean is: tensor(-0.0166, device='cuda:2')
epoch:  7000 quantization_loss:  0.06459517031908035
p mean is: tensor(-0.0192, device='cuda:2')
epoch:  8000 quantization_loss:  0.06443054974079132
p mean is: tensor(-0.0217, device='cuda:2')
epoch:  9000 quantization_loss:  0.06482316553592682
p mean is: tensor(-0.0244, device='cuda:2')
epoch:  10000 quantization_loss:  0.06533484160900116
p mean is: tensor(-0.0272, device='cuda:2')
epoch:  11000 quantization_loss:  0.06438851356506348
p mean is: tensor(-0.0298, device='cuda:2')
epoch:  12000 quantization_loss:  0.04096599668264389
p mean is: tensor(-0.0334, device='cuda:2')
epoch:  13000 quantization_loss:  0.0375814288854599
p mean is: tensor(-0.0380, device='cuda:2')
epoch:  14000 quantization_loss:  0.03445793688297272
p mean is: tensor(-0.0440, device='cuda:2')
epoch:  15000 quantization_loss:  0.031327467411756516
p mean is: tensor(-0.0526, device='cuda:2')
epoch:  16000 quantization_loss:  0.02893237955868244
p mean is: tensor(-0.0645, device='cuda:2')
epoch:  17000 quantization_loss:  0.025639640167355537
p mean is: tensor(-0.0811, device='cuda:2')
epoch:  18000 quantization_loss:  0.024422524496912956
p mean is: tensor(-0.1034, device='cuda:2')
epoch:  19000 quantization_loss:  0.023577937856316566
p mean is: tensor(-0.1329, device='cuda:2')
epoch:  20000 quantization_loss:  0.02267647348344326
p mean is: tensor(-0.1710, device='cuda:2')
epoch:  21000 quantization_loss:  0.02105933614075184
p mean is: tensor(-0.2189, device='cuda:2')
epoch:  22000 quantization_loss:  0.020344482734799385
p mean is: tensor(-0.2770, device='cuda:2')
epoch:  23000 quantization_loss:  0.020030375570058823
p mean is: tensor(-0.3445, device='cuda:2')
epoch:  24000 quantization_loss:  0.019366629421710968
p mean is: tensor(-0.4196, device='cuda:2')
epoch:  25000 quantization_loss:  0.018907437101006508
p mean is: tensor(-0.4991, device='cuda:2')
epoch:  26000 quantization_loss:  0.018446311354637146
p mean is: tensor(-0.5790, device='cuda:2')
epoch:  27000 quantization_loss:  0.01801261119544506
p mean is: tensor(-0.6558, device='cuda:2')
epoch:  28000 quantization_loss:  0.017976360395550728
p mean is: tensor(-0.7270, device='cuda:2')
epoch:  29000 quantization_loss:  0.017620600759983063
p mean is: tensor(-0.7913, device='cuda:2')
epoch:  30000 quantization_loss:  0.017401989549398422
p mean is: tensor(-0.8482, device='cuda:2')
epoch:  31000 quantization_loss:  0.017263205721974373
p mean is: tensor(-0.8980, device='cuda:2')
epoch:  32000 quantization_loss:  0.01712149567902088
p mean is: tensor(-0.9416, device='cuda:2')
epoch:  33000 quantization_loss:  0.017064232379198074
p mean is: tensor(-0.9796, device='cuda:2')
epoch:  34000 quantization_loss:  0.01691603474318981
p mean is: tensor(-1.0128, device='cuda:2')
epoch:  35000 quantization_loss:  0.01688300631940365
p mean is: tensor(-1.0416, device='cuda:2')
epoch:  36000 quantization_loss:  0.0167850274592638
p mean is: tensor(-1.0669, device='cuda:2')
epoch:  37000 quantization_loss:  0.016763653606176376
p mean is: tensor(-1.0889, device='cuda:2')
epoch:  38000 quantization_loss:  0.01670302264392376
p mean is: tensor(-1.1083, device='cuda:2')
epoch:  39000 quantization_loss:  0.016610929742455482
p mean is: tensor(-1.1252, device='cuda:2')
epoch:  40000 quantization_loss:  0.01663806661963463
p mean is: tensor(-1.1401, device='cuda:2')
epoch:  41000 quantization_loss:  0.016489962115883827
p mean is: tensor(-1.1532, device='cuda:2')
epoch:  42000 quantization_loss:  0.016457349061965942
p mean is: tensor(-1.1647, device='cuda:2')
epoch:  43000 quantization_loss:  0.016396375373005867
p mean is: tensor(-1.1748, device='cuda:2')
epoch:  44000 quantization_loss:  0.01633032038807869
p mean is: tensor(-1.1837, device='cuda:2')
epoch:  45000 quantization_loss:  0.016289502382278442
p mean is: tensor(-1.1916, device='cuda:2')
epoch:  46000 quantization_loss:  0.016271833330392838
p mean is: tensor(-1.1986, device='cuda:2')
epoch:  47000 quantization_loss:  0.016243761405348778
p mean is: tensor(-1.2048, device='cuda:2')
epoch:  48000 quantization_loss:  0.016226008534431458
p mean is: tensor(-1.2103, device='cuda:2')
epoch:  49000 quantization_loss:  0.016198640689253807
p mean is: tensor(-1.2152, device='cuda:2')
epoch:  50000 quantization_loss:  0.016179561614990234
p mean is: tensor(-1.2196, device='cuda:2')
epoch:  51000 quantization_loss:  0.016168618574738503
p mean is: tensor(-1.2235, device='cuda:2')
epoch:  52000 quantization_loss:  0.016155462712049484
p mean is: tensor(-1.2271, device='cuda:2')
epoch:  53000 quantization_loss:  0.016122765839099884
p mean is: tensor(-1.2302, device='cuda:2')
epoch:  54000 quantization_loss:  0.016136091202497482
p mean is: tensor(-1.2331, device='cuda:2')
epoch:  55000 quantization_loss:  0.016094960272312164
p mean is: tensor(-1.2358, device='cuda:2')
epoch:  56000 quantization_loss:  0.016056828200817108
p mean is: tensor(-1.2383, device='cuda:2')
epoch:  57000 quantization_loss:  0.016055338084697723
p mean is: tensor(-1.2405, device='cuda:2')
epoch:  58000 quantization_loss:  0.016106953844428062
p mean is: tensor(-1.2426, device='cuda:2')
epoch:  59000 quantization_loss:  0.016042359173297882
p mean is: tensor(-1.2445, device='cuda:2')
epoch:  60000 quantization_loss:  0.016018357127904892
p mean is: tensor(-1.2463, device='cuda:2')
epoch:  61000 quantization_loss:  0.016009200364351273
p mean is: tensor(-1.2478, device='cuda:2')
epoch:  62000 quantization_loss:  0.015998177230358124
p mean is: tensor(-1.2493, device='cuda:2')
epoch:  63000 quantization_loss:  0.01599123887717724
p mean is: tensor(-1.2507, device='cuda:2')
epoch:  64000 quantization_loss:  0.016010841354727745
p mean is: tensor(-1.2520, device='cuda:2')
epoch:  65000 quantization_loss:  0.015977317467331886
p mean is: tensor(-1.2532, device='cuda:2')
epoch:  66000 quantization_loss:  0.01596965081989765
p mean is: tensor(-1.2544, device='cuda:2')
epoch:  67000 quantization_loss:  0.015965189784765244
p mean is: tensor(-1.2555, device='cuda:2')
epoch:  68000 quantization_loss:  0.015952643007040024
p mean is: tensor(-1.2565, device='cuda:2')
epoch:  69000 quantization_loss:  0.015974482521414757
p mean is: tensor(-1.2575, device='cuda:2')
epoch:  70000 quantization_loss:  0.015949614346027374
p mean is: tensor(-1.2584, device='cuda:2')
epoch:  71000 quantization_loss:  0.01594514399766922
p mean is: tensor(-1.2593, device='cuda:2')
epoch:  72000 quantization_loss:  0.015936044976115227
p mean is: tensor(-1.2601, device='cuda:2')
epoch:  73000 quantization_loss:  0.015938496217131615
p mean is: tensor(-1.2609, device='cuda:2')
epoch:  74000 quantization_loss:  0.01593131758272648
p mean is: tensor(-1.2616, device='cuda:2')
epoch:  75000 quantization_loss:  0.01592503860592842
p mean is: tensor(-1.2623, device='cuda:2')
epoch:  76000 quantization_loss:  0.01593373343348503
p mean is: tensor(-1.2630, device='cuda:2')
epoch:  77000 quantization_loss:  0.015927426517009735
p mean is: tensor(-1.2637, device='cuda:2')
epoch:  78000 quantization_loss:  0.015921063721179962
p mean is: tensor(-1.2643, device='cuda:2')
epoch:  79000 quantization_loss:  0.015922872349619865
p mean is: tensor(-1.2649, device='cuda:2')
here
1.1.1.weight         | nonzeros =      26 /   12800             (  0.20%) | total_pruned =   12774 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =      15 /    6400             (  0.23%) | total_pruned =    6385 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       3 /      16             ( 18.75%) | total_pruned =      13 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =       6 /   12800             (  0.05%) | total_pruned =   12794 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =       4 /      32             ( 12.50%) | total_pruned =      28 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =       6 /   25600             (  0.02%) | total_pruned =   25594 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =       8 /      32             ( 25.00%) | total_pruned =      24 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =       1 /   51200             (  0.00%) | total_pruned =   51199 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =       2 /  102400             (  0.00%) | total_pruned =  102398 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =       0 /  204800             (  0.00%) | total_pruned =  204800 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      27 /     128             ( 21.09%) | total_pruned =     101 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =       0 /  409600             (  0.00%) | total_pruned =  409600 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =       0 /  409600             (  0.00%) | total_pruned =  409600 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =     200 /  409600             (  0.05%) | total_pruned =  409400 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    1183 /  409600             (  0.29%) | total_pruned =  408417 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    8397 /  409600             (  2.05%) | total_pruned =  401203 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   20348 /  147456             ( 13.80%) | total_pruned =  127108 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   26475 /  147456             ( 17.95%) | total_pruned =  120981 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   21777 /  147456             ( 14.77%) | total_pruned =  125679 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    9323 /   73728             ( 12.65%) | total_pruned =   64405 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2463 /   18432             ( 13.36%) | total_pruned =   15969 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1148 /    4608             ( 24.91%) | total_pruned =    3460 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      30 /      48             ( 62.50%) | total_pruned =      18 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 92417, pruned : 2916450, total: 3008867, Compression rate :      32.56x  ( 96.93% pruned)
PSNR of output image is:  11.224634518487731
Experiment done
