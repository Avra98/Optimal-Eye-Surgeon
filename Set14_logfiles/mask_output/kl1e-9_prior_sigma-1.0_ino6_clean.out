(3, 512, 512)
Starting vanilla DIP on 6 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.141437741405497'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/6/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/clean_img/-1.0/1e-09
epoch:  0 quantization_loss:  0.058096371591091156
p mean is: tensor(-0.0002, device='cuda:1')
epoch:  1000 quantization_loss:  0.04343390837311745
p mean is: tensor(-0.0095, device='cuda:1')
epoch:  2000 quantization_loss:  0.039846956729888916
p mean is: tensor(-0.0172, device='cuda:1')
epoch:  3000 quantization_loss:  0.03874041512608528
p mean is: tensor(-0.0254, device='cuda:1')
epoch:  4000 quantization_loss:  0.039565037935972214
p mean is: tensor(-0.0342, device='cuda:1')
epoch:  5000 quantization_loss:  0.03743062540888786
p mean is: tensor(-0.0441, device='cuda:1')
epoch:  6000 quantization_loss:  0.035522110760211945
p mean is: tensor(-0.0552, device='cuda:1')
epoch:  7000 quantization_loss:  0.03410746902227402
p mean is: tensor(-0.0700, device='cuda:1')
epoch:  8000 quantization_loss:  0.03205002099275589
p mean is: tensor(-0.0891, device='cuda:1')
epoch:  9000 quantization_loss:  0.029733922332525253
p mean is: tensor(-0.1127, device='cuda:1')
epoch:  10000 quantization_loss:  0.027794647961854935
p mean is: tensor(-0.1417, device='cuda:1')
epoch:  11000 quantization_loss:  0.026068193838000298
p mean is: tensor(-0.1766, device='cuda:1')
epoch:  12000 quantization_loss:  0.024824613705277443
p mean is: tensor(-0.2178, device='cuda:1')
epoch:  13000 quantization_loss:  0.02366325445473194
p mean is: tensor(-0.2651, device='cuda:1')
epoch:  14000 quantization_loss:  0.022243889048695564
p mean is: tensor(-0.3173, device='cuda:1')
epoch:  15000 quantization_loss:  0.021080415695905685
p mean is: tensor(-0.3721, device='cuda:1')
epoch:  16000 quantization_loss:  0.019641088321805
p mean is: tensor(-0.4270, device='cuda:1')
epoch:  17000 quantization_loss:  0.018847137689590454
p mean is: tensor(-0.4801, device='cuda:1')
epoch:  18000 quantization_loss:  0.018279993906617165
p mean is: tensor(-0.5299, device='cuda:1')
epoch:  19000 quantization_loss:  0.017942283302545547
p mean is: tensor(-0.5757, device='cuda:1')
epoch:  20000 quantization_loss:  0.016832757741212845
p mean is: tensor(-0.6174, device='cuda:1')
epoch:  21000 quantization_loss:  0.01653948239982128
p mean is: tensor(-0.6549, device='cuda:1')
epoch:  22000 quantization_loss:  0.016048463061451912
p mean is: tensor(-0.6887, device='cuda:1')
epoch:  23000 quantization_loss:  0.01584385335445404
p mean is: tensor(-0.7188, device='cuda:1')
epoch:  24000 quantization_loss:  0.01566890999674797
p mean is: tensor(-0.7457, device='cuda:1')
epoch:  25000 quantization_loss:  0.015397501178085804
p mean is: tensor(-0.7697, device='cuda:1')
epoch:  26000 quantization_loss:  0.015228410251438618
p mean is: tensor(-0.7909, device='cuda:1')
epoch:  27000 quantization_loss:  0.014988934621214867
p mean is: tensor(-0.8097, device='cuda:1')
epoch:  28000 quantization_loss:  0.014843430370092392
p mean is: tensor(-0.8265, device='cuda:1')
epoch:  29000 quantization_loss:  0.014757640659809113
p mean is: tensor(-0.8414, device='cuda:1')
epoch:  30000 quantization_loss:  0.014626453630626202
p mean is: tensor(-0.8546, device='cuda:1')
epoch:  31000 quantization_loss:  0.014506446197628975
p mean is: tensor(-0.8663, device='cuda:1')
epoch:  32000 quantization_loss:  0.014445405453443527
p mean is: tensor(-0.8769, device='cuda:1')
epoch:  33000 quantization_loss:  0.014335455372929573
p mean is: tensor(-0.8864, device='cuda:1')
epoch:  34000 quantization_loss:  0.014291750267148018
p mean is: tensor(-0.8949, device='cuda:1')
epoch:  35000 quantization_loss:  0.014286969788372517
p mean is: tensor(-0.9025, device='cuda:1')
epoch:  36000 quantization_loss:  0.014153959229588509
p mean is: tensor(-0.9094, device='cuda:1')
epoch:  37000 quantization_loss:  0.014094681479036808
p mean is: tensor(-0.9156, device='cuda:1')
epoch:  38000 quantization_loss:  0.014037052169442177
p mean is: tensor(-0.9213, device='cuda:1')
epoch:  39000 quantization_loss:  0.013980275951325893
p mean is: tensor(-0.9263, device='cuda:1')
epoch:  40000 quantization_loss:  0.013961926102638245
p mean is: tensor(-0.9310, device='cuda:1')
epoch:  41000 quantization_loss:  0.013918742537498474
p mean is: tensor(-0.9353, device='cuda:1')
epoch:  42000 quantization_loss:  0.01383355725556612
p mean is: tensor(-0.9392, device='cuda:1')
epoch:  43000 quantization_loss:  0.013779685832560062
p mean is: tensor(-0.9428, device='cuda:1')
epoch:  44000 quantization_loss:  0.013648727908730507
p mean is: tensor(-0.9462, device='cuda:1')
epoch:  45000 quantization_loss:  0.013537018559873104
p mean is: tensor(-0.9492, device='cuda:1')
epoch:  46000 quantization_loss:  0.01352025382220745
p mean is: tensor(-0.9519, device='cuda:1')
epoch:  47000 quantization_loss:  0.013520031236112118
p mean is: tensor(-0.9545, device='cuda:1')
epoch:  48000 quantization_loss:  0.013448779471218586
p mean is: tensor(-0.9570, device='cuda:1')
epoch:  49000 quantization_loss:  0.013413827866315842
p mean is: tensor(-0.9593, device='cuda:1')
epoch:  50000 quantization_loss:  0.01342099905014038
p mean is: tensor(-0.9615, device='cuda:1')
epoch:  51000 quantization_loss:  0.013392641209065914
p mean is: tensor(-0.9637, device='cuda:1')
epoch:  52000 quantization_loss:  0.013389309868216515
p mean is: tensor(-0.9657, device='cuda:1')
epoch:  53000 quantization_loss:  0.013372495770454407
p mean is: tensor(-0.9676, device='cuda:1')
epoch:  54000 quantization_loss:  0.013352761045098305
p mean is: tensor(-0.9693, device='cuda:1')
epoch:  55000 quantization_loss:  0.013341483660042286
p mean is: tensor(-0.9710, device='cuda:1')
epoch:  56000 quantization_loss:  0.013335445895791054
p mean is: tensor(-0.9727, device='cuda:1')
epoch:  57000 quantization_loss:  0.013433312065899372
p mean is: tensor(-0.9742, device='cuda:1')
epoch:  58000 quantization_loss:  0.013328701257705688
p mean is: tensor(-0.9757, device='cuda:1')
epoch:  59000 quantization_loss:  0.013302265666425228
p mean is: tensor(-0.9772, device='cuda:1')
epoch:  60000 quantization_loss:  0.013297272846102715
p mean is: tensor(-0.9786, device='cuda:1')
epoch:  61000 quantization_loss:  0.01330110989511013
p mean is: tensor(-0.9799, device='cuda:1')
epoch:  62000 quantization_loss:  0.013280569575726986
p mean is: tensor(-0.9812, device='cuda:1')
epoch:  63000 quantization_loss:  0.013277633115649223
p mean is: tensor(-0.9824, device='cuda:1')
epoch:  64000 quantization_loss:  0.013275631703436375
p mean is: tensor(-0.9837, device='cuda:1')
epoch:  65000 quantization_loss:  0.013265859335660934
p mean is: tensor(-0.9849, device='cuda:1')
epoch:  66000 quantization_loss:  0.013265597634017467
p mean is: tensor(-0.9860, device='cuda:1')
epoch:  67000 quantization_loss:  0.013272954151034355
p mean is: tensor(-0.9871, device='cuda:1')
epoch:  68000 quantization_loss:  0.013252395205199718
p mean is: tensor(-0.9882, device='cuda:1')
epoch:  69000 quantization_loss:  0.013257496058940887
p mean is: tensor(-0.9892, device='cuda:1')
epoch:  70000 quantization_loss:  0.013253038749098778
p mean is: tensor(-0.9901, device='cuda:1')
epoch:  71000 quantization_loss:  0.013248027302324772
p mean is: tensor(-0.9912, device='cuda:1')
epoch:  72000 quantization_loss:  0.01329449750483036
p mean is: tensor(-0.9921, device='cuda:1')
epoch:  73000 quantization_loss:  0.013232944533228874
p mean is: tensor(-0.9930, device='cuda:1')
epoch:  74000 quantization_loss:  0.013239934109151363
p mean is: tensor(-0.9939, device='cuda:1')
epoch:  75000 quantization_loss:  0.013283887878060341
p mean is: tensor(-0.9947, device='cuda:1')
epoch:  76000 quantization_loss:  0.013227785006165504
p mean is: tensor(-0.9956, device='cuda:1')
epoch:  77000 quantization_loss:  0.013231197372078896
p mean is: tensor(-0.9964, device='cuda:1')
epoch:  78000 quantization_loss:  0.013233375735580921
p mean is: tensor(-0.9972, device='cuda:1')
epoch:  79000 quantization_loss:  0.013220790773630142
p mean is: tensor(-0.9980, device='cuda:1')
here
1.1.1.weight         | nonzeros =    1089 /   12800             (  8.51%) | total_pruned =   11711 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     167 /    6400             (  2.61%) | total_pruned =    6233 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      58 /   12800             (  0.45%) | total_pruned =   12742 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     129 /   25600             (  0.50%) | total_pruned =   25471 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =       8 /      32             ( 25.00%) | total_pruned =      24 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =      73 /   51200             (  0.14%) | total_pruned =   51127 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     129 /  102400             (  0.13%) | total_pruned =  102271 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =      38 /  204800             (  0.02%) | total_pruned =  204762 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     246 /  409600             (  0.06%) | total_pruned =  409354 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     512 /  409600             (  0.12%) | total_pruned =  409088 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    3919 /  409600             (  0.96%) | total_pruned =  405681 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   12209 /  409600             (  2.98%) | total_pruned =  397391 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   41011 /  409600             ( 10.01%) | total_pruned =  368589 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   33134 /  147456             ( 22.47%) | total_pruned =  114322 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   31229 /  147456             ( 21.18%) | total_pruned =  116227 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   27786 /  147456             ( 18.84%) | total_pruned =  119670 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   11861 /   73728             ( 16.09%) | total_pruned =   61867 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    3099 /   18432             ( 16.81%) | total_pruned =   15333 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1364 /    4608             ( 29.60%) | total_pruned =    3244 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      32 /      48             ( 66.67%) | total_pruned =      16 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 169418, pruned : 2839449, total: 3008867, Compression rate :      17.76x  ( 94.37% pruned)
PSNR of output image is:  18.85392915967723
Experiment done
