(3, 512, 512)
Starting vanilla DIP on 8 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '21.64971696082379'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/8/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/clean_img/-1.0/1e-09
epoch:  0 quantization_loss:  0.18951717019081116
p mean is: tensor(-0.0002, device='cuda:3')
epoch:  1000 quantization_loss:  0.15994921326637268
p mean is: tensor(-0.0057, device='cuda:3')
epoch:  2000 quantization_loss:  0.1573307365179062
p mean is: tensor(-0.0100, device='cuda:3')
epoch:  3000 quantization_loss:  0.1561749130487442
p mean is: tensor(-0.0142, device='cuda:3')
epoch:  4000 quantization_loss:  0.1582311987876892
p mean is: tensor(-0.0185, device='cuda:3')
epoch:  5000 quantization_loss:  0.15636618435382843
p mean is: tensor(-0.0230, device='cuda:3')
epoch:  6000 quantization_loss:  0.15529075264930725
p mean is: tensor(-0.0275, device='cuda:3')
epoch:  7000 quantization_loss:  0.15538926422595978
p mean is: tensor(-0.0320, device='cuda:3')
epoch:  8000 quantization_loss:  0.151289165019989
p mean is: tensor(-0.0369, device='cuda:3')
epoch:  9000 quantization_loss:  0.13784700632095337
p mean is: tensor(-0.0426, device='cuda:3')
epoch:  10000 quantization_loss:  0.13221533596515656
p mean is: tensor(-0.0497, device='cuda:3')
epoch:  11000 quantization_loss:  0.13122683763504028
p mean is: tensor(-0.0590, device='cuda:3')
epoch:  12000 quantization_loss:  0.13039886951446533
p mean is: tensor(-0.0717, device='cuda:3')
epoch:  13000 quantization_loss:  0.12991340458393097
p mean is: tensor(-0.0890, device='cuda:3')
epoch:  14000 quantization_loss:  0.12938988208770752
p mean is: tensor(-0.1122, device='cuda:3')
epoch:  15000 quantization_loss:  0.1214829757809639
p mean is: tensor(-0.1420, device='cuda:3')
epoch:  16000 quantization_loss:  0.11826988309621811
p mean is: tensor(-0.1778, device='cuda:3')
epoch:  17000 quantization_loss:  0.11679220199584961
p mean is: tensor(-0.2199, device='cuda:3')
epoch:  18000 quantization_loss:  0.11898895353078842
p mean is: tensor(-0.2685, device='cuda:3')
epoch:  19000 quantization_loss:  0.11524695158004761
p mean is: tensor(-0.3224, device='cuda:3')
epoch:  20000 quantization_loss:  0.11439472436904907
p mean is: tensor(-0.3794, device='cuda:3')
epoch:  21000 quantization_loss:  0.10991831868886948
p mean is: tensor(-0.4363, device='cuda:3')
epoch:  22000 quantization_loss:  0.10890568792819977
p mean is: tensor(-0.4910, device='cuda:3')
epoch:  23000 quantization_loss:  0.10869410634040833
p mean is: tensor(-0.5425, device='cuda:3')
epoch:  24000 quantization_loss:  0.10684055835008621
p mean is: tensor(-0.5897, device='cuda:3')
epoch:  25000 quantization_loss:  0.10683611780405045
p mean is: tensor(-0.6324, device='cuda:3')
epoch:  26000 quantization_loss:  0.1067686378955841
p mean is: tensor(-0.6705, device='cuda:3')
epoch:  27000 quantization_loss:  0.10625864565372467
p mean is: tensor(-0.7045, device='cuda:3')
epoch:  28000 quantization_loss:  0.10709211230278015
p mean is: tensor(-0.7346, device='cuda:3')
epoch:  29000 quantization_loss:  0.1058940589427948
p mean is: tensor(-0.7613, device='cuda:3')
epoch:  30000 quantization_loss:  0.10553497076034546
p mean is: tensor(-0.7847, device='cuda:3')
epoch:  31000 quantization_loss:  0.10250024497509003
p mean is: tensor(-0.8050, device='cuda:3')
epoch:  32000 quantization_loss:  0.10242027789354324
p mean is: tensor(-0.8228, device='cuda:3')
epoch:  33000 quantization_loss:  0.10201098769903183
p mean is: tensor(-0.8385, device='cuda:3')
epoch:  34000 quantization_loss:  0.09904663264751434
p mean is: tensor(-0.8523, device='cuda:3')
epoch:  35000 quantization_loss:  0.09806883335113525
p mean is: tensor(-0.8642, device='cuda:3')
epoch:  36000 quantization_loss:  0.09732994437217712
p mean is: tensor(-0.8745, device='cuda:3')
epoch:  37000 quantization_loss:  0.09734388440847397
p mean is: tensor(-0.8838, device='cuda:3')
epoch:  38000 quantization_loss:  0.09716571867465973
p mean is: tensor(-0.8921, device='cuda:3')
epoch:  39000 quantization_loss:  0.09736096113920212
p mean is: tensor(-0.8995, device='cuda:3')
epoch:  40000 quantization_loss:  0.09694552421569824
p mean is: tensor(-0.9064, device='cuda:3')
epoch:  41000 quantization_loss:  0.09686845541000366
p mean is: tensor(-0.9126, device='cuda:3')
epoch:  42000 quantization_loss:  0.09681965410709381
p mean is: tensor(-0.9182, device='cuda:3')
epoch:  43000 quantization_loss:  0.09674482047557831
p mean is: tensor(-0.9233, device='cuda:3')
epoch:  44000 quantization_loss:  0.09665921330451965
p mean is: tensor(-0.9280, device='cuda:3')
epoch:  45000 quantization_loss:  0.0966329500079155
p mean is: tensor(-0.9323, device='cuda:3')
epoch:  46000 quantization_loss:  0.09653376787900925
p mean is: tensor(-0.9362, device='cuda:3')
epoch:  47000 quantization_loss:  0.09655176103115082
p mean is: tensor(-0.9398, device='cuda:3')
epoch:  48000 quantization_loss:  0.09651412069797516
p mean is: tensor(-0.9432, device='cuda:3')
epoch:  49000 quantization_loss:  0.09647136181592941
p mean is: tensor(-0.9464, device='cuda:3')
epoch:  50000 quantization_loss:  0.09644851833581924
p mean is: tensor(-0.9493, device='cuda:3')
epoch:  51000 quantization_loss:  0.09640715271234512
p mean is: tensor(-0.9520, device='cuda:3')
epoch:  52000 quantization_loss:  0.09637576341629028
p mean is: tensor(-0.9546, device='cuda:3')
epoch:  53000 quantization_loss:  0.09633712470531464
p mean is: tensor(-0.9570, device='cuda:3')
epoch:  54000 quantization_loss:  0.09634294360876083
p mean is: tensor(-0.9593, device='cuda:3')
epoch:  55000 quantization_loss:  0.09632802754640579
p mean is: tensor(-0.9614, device='cuda:3')
epoch:  56000 quantization_loss:  0.09630808234214783
p mean is: tensor(-0.9635, device='cuda:3')
epoch:  57000 quantization_loss:  0.09628971666097641
p mean is: tensor(-0.9655, device='cuda:3')
epoch:  58000 quantization_loss:  0.09630171209573746
p mean is: tensor(-0.9673, device='cuda:3')
epoch:  59000 quantization_loss:  0.09626825898885727
p mean is: tensor(-0.9691, device='cuda:3')
epoch:  60000 quantization_loss:  0.09625161439180374
p mean is: tensor(-0.9707, device='cuda:3')
epoch:  61000 quantization_loss:  0.09626012295484543
p mean is: tensor(-0.9723, device='cuda:3')
epoch:  62000 quantization_loss:  0.09624174982309341
p mean is: tensor(-0.9738, device='cuda:3')
epoch:  63000 quantization_loss:  0.09622412919998169
p mean is: tensor(-0.9753, device='cuda:3')
epoch:  64000 quantization_loss:  0.09621523320674896
p mean is: tensor(-0.9767, device='cuda:3')
epoch:  65000 quantization_loss:  0.09620154649019241
p mean is: tensor(-0.9781, device='cuda:3')
epoch:  66000 quantization_loss:  0.09619572013616562
p mean is: tensor(-0.9795, device='cuda:3')
epoch:  67000 quantization_loss:  0.09619665890932083
p mean is: tensor(-0.9808, device='cuda:3')
epoch:  68000 quantization_loss:  0.09617821127176285
p mean is: tensor(-0.9821, device='cuda:3')
epoch:  69000 quantization_loss:  0.09619156271219254
p mean is: tensor(-0.9834, device='cuda:3')
epoch:  70000 quantization_loss:  0.09616928547620773
p mean is: tensor(-0.9845, device='cuda:3')
epoch:  71000 quantization_loss:  0.09615837037563324
p mean is: tensor(-0.9857, device='cuda:3')
epoch:  72000 quantization_loss:  0.0961599200963974
p mean is: tensor(-0.9868, device='cuda:3')
epoch:  73000 quantization_loss:  0.09615685790777206
p mean is: tensor(-0.9879, device='cuda:3')
epoch:  74000 quantization_loss:  0.09614624828100204
p mean is: tensor(-0.9889, device='cuda:3')
epoch:  75000 quantization_loss:  0.0961555764079094
p mean is: tensor(-0.9899, device='cuda:3')
epoch:  76000 quantization_loss:  0.09614680707454681
p mean is: tensor(-0.9908, device='cuda:3')
epoch:  77000 quantization_loss:  0.09614066034555435
p mean is: tensor(-0.9919, device='cuda:3')
epoch:  78000 quantization_loss:  0.09613700211048126
p mean is: tensor(-0.9928, device='cuda:3')
epoch:  79000 quantization_loss:  0.09613284468650818
p mean is: tensor(-0.9937, device='cuda:3')
here
1.1.1.weight         | nonzeros =    1510 /   12800             ( 11.80%) | total_pruned =   11290 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     207 /    6400             (  3.23%) | total_pruned =    6193 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     126 /   12800             (  0.98%) | total_pruned =   12674 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     211 /   25600             (  0.82%) | total_pruned =   25389 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     150 /   51200             (  0.29%) | total_pruned =   51050 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     386 /  102400             (  0.38%) | total_pruned =  102014 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     172 /  204800             (  0.08%) | total_pruned =  204628 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     539 /  409600             (  0.13%) | total_pruned =  409061 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     775 /  409600             (  0.19%) | total_pruned =  408825 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    4230 /  409600             (  1.03%) | total_pruned =  405370 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   15040 /  409600             (  3.67%) | total_pruned =  394560 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   45939 /  409600             ( 11.22%) | total_pruned =  363661 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   32748 /  147456             ( 22.21%) | total_pruned =  114708 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   25403 /  147456             ( 17.23%) | total_pruned =  122053 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   14425 /  147456             (  9.78%) | total_pruned =  133031 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    6581 /   73728             (  8.93%) | total_pruned =   67147 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2833 /   18432             ( 15.37%) | total_pruned =   15599 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1388 /    4608             ( 30.12%) | total_pruned =    3220 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      33 /      48             ( 68.75%) | total_pruned =      15 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 153879, pruned : 2854988, total: 3008867, Compression rate :      19.55x  ( 94.89% pruned)
PSNR of output image is:  10.18064837774464
Experiment done
