Starting vanilla DIP on 8 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '21.52755229875631'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/8/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-0.05/1e-09
epoch:  0 quantization_loss:  0.14335070550441742
p mean is: tensor(-6.3004e-06, device='cuda:2')
epoch:  1000 quantization_loss:  0.11780276894569397
p mean is: tensor(-1.8930e-05, device='cuda:2')
epoch:  2000 quantization_loss:  0.11558207869529724
p mean is: tensor(-0.0002, device='cuda:2')
epoch:  3000 quantization_loss:  0.11248647421598434
p mean is: tensor(-0.0004, device='cuda:2')
epoch:  4000 quantization_loss:  0.10996189713478088
p mean is: tensor(-0.0006, device='cuda:2')
epoch:  5000 quantization_loss:  0.10225430876016617
p mean is: tensor(-0.0010, device='cuda:2')
epoch:  6000 quantization_loss:  0.09531573951244354
p mean is: tensor(-0.0016, device='cuda:2')
epoch:  7000 quantization_loss:  0.09044444561004639
p mean is: tensor(-0.0024, device='cuda:2')
epoch:  8000 quantization_loss:  0.08708882331848145
p mean is: tensor(-0.0032, device='cuda:2')
epoch:  9000 quantization_loss:  0.08568646013736725
p mean is: tensor(-0.0042, device='cuda:2')
epoch:  10000 quantization_loss:  0.08420787751674652
p mean is: tensor(-0.0054, device='cuda:2')
epoch:  11000 quantization_loss:  0.08249635249376297
p mean is: tensor(-0.0068, device='cuda:2')
epoch:  12000 quantization_loss:  0.07996058464050293
p mean is: tensor(-0.0086, device='cuda:2')
epoch:  13000 quantization_loss:  0.07867574691772461
p mean is: tensor(-0.0107, device='cuda:2')
epoch:  14000 quantization_loss:  0.07480394095182419
p mean is: tensor(-0.0129, device='cuda:2')
epoch:  15000 quantization_loss:  0.07270187884569168
p mean is: tensor(-0.0154, device='cuda:2')
epoch:  16000 quantization_loss:  0.07111167907714844
p mean is: tensor(-0.0181, device='cuda:2')
epoch:  17000 quantization_loss:  0.06887848675251007
p mean is: tensor(-0.0206, device='cuda:2')
epoch:  18000 quantization_loss:  0.06814872473478317
p mean is: tensor(-0.0232, device='cuda:2')
epoch:  19000 quantization_loss:  0.0677606388926506
p mean is: tensor(-0.0254, device='cuda:2')
epoch:  20000 quantization_loss:  0.06735479086637497
p mean is: tensor(-0.0276, device='cuda:2')
epoch:  21000 quantization_loss:  0.06686092168092728
p mean is: tensor(-0.0296, device='cuda:2')
epoch:  22000 quantization_loss:  0.06653130799531937
p mean is: tensor(-0.0313, device='cuda:2')
epoch:  23000 quantization_loss:  0.06611283868551254
p mean is: tensor(-0.0327, device='cuda:2')
epoch:  24000 quantization_loss:  0.06599516421556473
p mean is: tensor(-0.0339, device='cuda:2')
epoch:  25000 quantization_loss:  0.06575575470924377
p mean is: tensor(-0.0349, device='cuda:2')
epoch:  26000 quantization_loss:  0.06545940041542053
p mean is: tensor(-0.0359, device='cuda:2')
epoch:  27000 quantization_loss:  0.06527853012084961
p mean is: tensor(-0.0366, device='cuda:2')
epoch:  28000 quantization_loss:  0.06509823352098465
p mean is: tensor(-0.0373, device='cuda:2')
epoch:  29000 quantization_loss:  0.06488228589296341
p mean is: tensor(-0.0379, device='cuda:2')
epoch:  30000 quantization_loss:  0.06477013975381851
p mean is: tensor(-0.0384, device='cuda:2')
epoch:  31000 quantization_loss:  0.06484703719615936
p mean is: tensor(-0.0388, device='cuda:2')
epoch:  32000 quantization_loss:  0.06454403698444366
p mean is: tensor(-0.0392, device='cuda:2')
epoch:  33000 quantization_loss:  0.06442882865667343
p mean is: tensor(-0.0395, device='cuda:2')
epoch:  34000 quantization_loss:  0.06432317197322845
p mean is: tensor(-0.0397, device='cuda:2')
epoch:  35000 quantization_loss:  0.06422478705644608
p mean is: tensor(-0.0399, device='cuda:2')
epoch:  36000 quantization_loss:  0.0641375407576561
p mean is: tensor(-0.0402, device='cuda:2')
epoch:  37000 quantization_loss:  0.06409177929162979
p mean is: tensor(-0.0404, device='cuda:2')
epoch:  38000 quantization_loss:  0.06404349207878113
p mean is: tensor(-0.0406, device='cuda:2')
epoch:  39000 quantization_loss:  0.06398497521877289
p mean is: tensor(-0.0408, device='cuda:2')
epoch:  40000 quantization_loss:  0.06398019939661026
p mean is: tensor(-0.0410, device='cuda:2')
epoch:  41000 quantization_loss:  0.06389331817626953
p mean is: tensor(-0.0411, device='cuda:2')
epoch:  42000 quantization_loss:  0.06403421610593796
p mean is: tensor(-0.0413, device='cuda:2')
epoch:  43000 quantization_loss:  0.06381551921367645
p mean is: tensor(-0.0415, device='cuda:2')
epoch:  44000 quantization_loss:  0.06378131359815598
p mean is: tensor(-0.0417, device='cuda:2')
epoch:  45000 quantization_loss:  0.06375718861818314
p mean is: tensor(-0.0420, device='cuda:2')
epoch:  46000 quantization_loss:  0.06371188908815384
p mean is: tensor(-0.0421, device='cuda:2')
epoch:  47000 quantization_loss:  0.06371985375881195
p mean is: tensor(-0.0423, device='cuda:2')
epoch:  48000 quantization_loss:  0.06369253247976303
p mean is: tensor(-0.0425, device='cuda:2')
epoch:  49000 quantization_loss:  0.06368941813707352
p mean is: tensor(-0.0427, device='cuda:2')
epoch:  50000 quantization_loss:  0.06365659832954407
p mean is: tensor(-0.0428, device='cuda:2')
epoch:  51000 quantization_loss:  0.06363357603549957
p mean is: tensor(-0.0430, device='cuda:2')
epoch:  52000 quantization_loss:  0.06362713873386383
p mean is: tensor(-0.0431, device='cuda:2')
epoch:  53000 quantization_loss:  0.06361847370862961
p mean is: tensor(-0.0433, device='cuda:2')
epoch:  54000 quantization_loss:  0.06359435617923737
p mean is: tensor(-0.0434, device='cuda:2')
epoch:  55000 quantization_loss:  0.06358116120100021
p mean is: tensor(-0.0435, device='cuda:2')
epoch:  56000 quantization_loss:  0.0636667013168335
p mean is: tensor(-0.0437, device='cuda:2')
epoch:  57000 quantization_loss:  0.06359461694955826
p mean is: tensor(-0.0438, device='cuda:2')
epoch:  58000 quantization_loss:  0.06355457007884979
p mean is: tensor(-0.0440, device='cuda:2')
epoch:  59000 quantization_loss:  0.06354739516973495
p mean is: tensor(-0.0440, device='cuda:2')
epoch:  60000 quantization_loss:  0.0635424554347992
p mean is: tensor(-0.0441, device='cuda:2')
epoch:  61000 quantization_loss:  0.06355851888656616
p mean is: tensor(-0.0442, device='cuda:2')
epoch:  62000 quantization_loss:  0.06352537125349045
p mean is: tensor(-0.0443, device='cuda:2')
epoch:  63000 quantization_loss:  0.06353915482759476
p mean is: tensor(-0.0445, device='cuda:2')
epoch:  64000 quantization_loss:  0.0635155737400055
p mean is: tensor(-0.0445, device='cuda:2')
epoch:  65000 quantization_loss:  0.06350570172071457
p mean is: tensor(-0.0446, device='cuda:2')
epoch:  66000 quantization_loss:  0.06349576264619827
p mean is: tensor(-0.0447, device='cuda:2')
epoch:  67000 quantization_loss:  0.06350340694189072
p mean is: tensor(-0.0448, device='cuda:2')
epoch:  68000 quantization_loss:  0.06349828094244003
p mean is: tensor(-0.0449, device='cuda:2')
epoch:  69000 quantization_loss:  0.06348451972007751
p mean is: tensor(-0.0449, device='cuda:2')
epoch:  70000 quantization_loss:  0.06347526609897614
p mean is: tensor(-0.0450, device='cuda:2')
epoch:  71000 quantization_loss:  0.06347306072711945
p mean is: tensor(-0.0451, device='cuda:2')
epoch:  72000 quantization_loss:  0.06347975134849548
p mean is: tensor(-0.0452, device='cuda:2')
epoch:  73000 quantization_loss:  0.06346814334392548
p mean is: tensor(-0.0453, device='cuda:2')
epoch:  74000 quantization_loss:  0.06346608698368073
p mean is: tensor(-0.0454, device='cuda:2')
epoch:  75000 quantization_loss:  0.06346401572227478
p mean is: tensor(-0.0455, device='cuda:2')
epoch:  76000 quantization_loss:  0.0634697675704956
p mean is: tensor(-0.0456, device='cuda:2')
epoch:  77000 quantization_loss:  0.06345353275537491
p mean is: tensor(-0.0457, device='cuda:2')
epoch:  78000 quantization_loss:  0.06345804035663605
p mean is: tensor(-0.0459, device='cuda:2')
epoch:  79000 quantization_loss:  0.06353823840618134
p mean is: tensor(-0.0460, device='cuda:2')
here
1.1.1.weight         | nonzeros =    3584 /   12800             ( 28.00%) | total_pruned =    9216 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =    1000 /    6400             ( 15.62%) | total_pruned =    5400 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =    1785 /   12800             ( 13.95%) | total_pruned =   11015 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =    3381 /   25600             ( 13.21%) | total_pruned =   22219 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      10 /      32             ( 31.25%) | total_pruned =      22 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =    6062 /   51200             ( 11.84%) | total_pruned =   45138 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =   12431 /  102400             ( 12.14%) | total_pruned =   89969 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =   22205 /  204800             ( 10.84%) | total_pruned =  182595 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =   58028 /  409600             ( 14.17%) | total_pruned =  351572 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   75887 /  409600             ( 18.53%) | total_pruned =  333713 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   90932 /  409600             ( 22.20%) | total_pruned =  318668 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  117290 /  409600             ( 28.64%) | total_pruned =  292310 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  109637 /  409600             ( 26.77%) | total_pruned =  299963 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   36310 /  147456             ( 24.62%) | total_pruned =  111146 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   32654 /  147456             ( 22.14%) | total_pruned =  114802 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   31625 /  147456             ( 21.45%) | total_pruned =  115831 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   13907 /   73728             ( 18.86%) | total_pruned =   59821 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2454 /   18432             ( 13.31%) | total_pruned =   15978 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      13 /      32             ( 40.62%) | total_pruned =      19 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      13 /      32             ( 40.62%) | total_pruned =      19 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1046 /    4608             ( 22.70%) | total_pruned =    3562 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      28 /      48             ( 58.33%) | total_pruned =      20 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       3 /       3             (100.00%) | total_pruned =       0 | shape = torch.Size([3])
alive: 621620, pruned : 2387247, total: 3008867, Compression rate :       4.84x  ( 79.34% pruned)
PSNR of output image is:  11.650121473806465
Experiment done
