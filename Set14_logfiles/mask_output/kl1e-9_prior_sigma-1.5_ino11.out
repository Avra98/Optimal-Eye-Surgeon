(3, 512, 512)
Starting vanilla DIP on 11 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.30988301278569'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/11/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-1.5/1e-09
epoch:  0 quantization_loss:  0.06470678746700287
p mean is: tensor(-0.0003, device='cuda:1')
epoch:  1000 quantization_loss:  0.05663550645112991
p mean is: tensor(-0.0134, device='cuda:1')
epoch:  2000 quantization_loss:  0.056276481598615646
p mean is: tensor(-0.0257, device='cuda:1')
epoch:  3000 quantization_loss:  0.05585291236639023
p mean is: tensor(-0.0390, device='cuda:1')
epoch:  4000 quantization_loss:  0.05551227927207947
p mean is: tensor(-0.0530, device='cuda:1')
epoch:  5000 quantization_loss:  0.05526141822338104
p mean is: tensor(-0.0674, device='cuda:1')
epoch:  6000 quantization_loss:  0.052744753658771515
p mean is: tensor(-0.0826, device='cuda:1')
epoch:  7000 quantization_loss:  0.04662371426820755
p mean is: tensor(-0.1002, device='cuda:1')
epoch:  8000 quantization_loss:  0.043030645698308945
p mean is: tensor(-0.1218, device='cuda:1')
epoch:  9000 quantization_loss:  0.038912124931812286
p mean is: tensor(-0.1487, device='cuda:1')
epoch:  10000 quantization_loss:  0.03521832451224327
p mean is: tensor(-0.1824, device='cuda:1')
epoch:  11000 quantization_loss:  0.0337786003947258
p mean is: tensor(-0.2244, device='cuda:1')
epoch:  12000 quantization_loss:  0.030903097242116928
p mean is: tensor(-0.2756, device='cuda:1')
epoch:  13000 quantization_loss:  0.028794242069125175
p mean is: tensor(-0.3358, device='cuda:1')
epoch:  14000 quantization_loss:  0.027700122445821762
p mean is: tensor(-0.4044, device='cuda:1')
epoch:  15000 quantization_loss:  0.02523856796324253
p mean is: tensor(-0.4791, device='cuda:1')
epoch:  16000 quantization_loss:  0.024803126230835915
p mean is: tensor(-0.5563, device='cuda:1')
epoch:  17000 quantization_loss:  0.02364063635468483
p mean is: tensor(-0.6336, device='cuda:1')
epoch:  18000 quantization_loss:  0.022810909897089005
p mean is: tensor(-0.7087, device='cuda:1')
epoch:  19000 quantization_loss:  0.02265339158475399
p mean is: tensor(-0.7793, device='cuda:1')
epoch:  20000 quantization_loss:  0.02193138189613819
p mean is: tensor(-0.8446, device='cuda:1')
epoch:  21000 quantization_loss:  0.021722832694649696
p mean is: tensor(-0.9041, device='cuda:1')
epoch:  22000 quantization_loss:  0.02103707380592823
p mean is: tensor(-0.9576, device='cuda:1')
epoch:  23000 quantization_loss:  0.02099141851067543
p mean is: tensor(-1.0056, device='cuda:1')
epoch:  24000 quantization_loss:  0.020609961822628975
p mean is: tensor(-1.0485, device='cuda:1')
epoch:  25000 quantization_loss:  0.020317042246460915
p mean is: tensor(-1.0867, device='cuda:1')
epoch:  26000 quantization_loss:  0.01986648142337799
p mean is: tensor(-1.1206, device='cuda:1')
epoch:  27000 quantization_loss:  0.019995559006929398
p mean is: tensor(-1.1511, device='cuda:1')
epoch:  28000 quantization_loss:  0.01940026320517063
p mean is: tensor(-1.1783, device='cuda:1')
epoch:  29000 quantization_loss:  0.01927344873547554
p mean is: tensor(-1.2027, device='cuda:1')
epoch:  30000 quantization_loss:  0.019268782809376717
p mean is: tensor(-1.2247, device='cuda:1')
epoch:  31000 quantization_loss:  0.019103126600384712
p mean is: tensor(-1.2446, device='cuda:1')
epoch:  32000 quantization_loss:  0.018932363018393517
p mean is: tensor(-1.2626, device='cuda:1')
epoch:  33000 quantization_loss:  0.018817787989974022
p mean is: tensor(-1.2788, device='cuda:1')
epoch:  34000 quantization_loss:  0.018793847411870956
p mean is: tensor(-1.2935, device='cuda:1')
epoch:  35000 quantization_loss:  0.018660932779312134
p mean is: tensor(-1.3069, device='cuda:1')
epoch:  36000 quantization_loss:  0.018562382087111473
p mean is: tensor(-1.3191, device='cuda:1')
epoch:  37000 quantization_loss:  0.018564613536000252
p mean is: tensor(-1.3301, device='cuda:1')
epoch:  38000 quantization_loss:  0.01846449077129364
p mean is: tensor(-1.3403, device='cuda:1')
epoch:  39000 quantization_loss:  0.01845366507768631
p mean is: tensor(-1.3497, device='cuda:1')
epoch:  40000 quantization_loss:  0.018398160114884377
p mean is: tensor(-1.3583, device='cuda:1')
epoch:  41000 quantization_loss:  0.018329694867134094
p mean is: tensor(-1.3662, device='cuda:1')
epoch:  42000 quantization_loss:  0.018291788175702095
p mean is: tensor(-1.3735, device='cuda:1')
epoch:  43000 quantization_loss:  0.01815866120159626
p mean is: tensor(-1.3803, device='cuda:1')
epoch:  44000 quantization_loss:  0.018098587170243263
p mean is: tensor(-1.3864, device='cuda:1')
epoch:  45000 quantization_loss:  0.018073832616209984
p mean is: tensor(-1.3921, device='cuda:1')
epoch:  46000 quantization_loss:  0.018030505627393723
p mean is: tensor(-1.3975, device='cuda:1')
epoch:  47000 quantization_loss:  0.017979877069592476
p mean is: tensor(-1.4026, device='cuda:1')
epoch:  48000 quantization_loss:  0.01797259785234928
p mean is: tensor(-1.4074, device='cuda:1')
epoch:  49000 quantization_loss:  0.017953861504793167
p mean is: tensor(-1.4119, device='cuda:1')
epoch:  50000 quantization_loss:  0.01804063655436039
p mean is: tensor(-1.4160, device='cuda:1')
epoch:  51000 quantization_loss:  0.017906829714775085
p mean is: tensor(-1.4199, device='cuda:1')
epoch:  52000 quantization_loss:  0.0179042499512434
p mean is: tensor(-1.4235, device='cuda:1')
epoch:  53000 quantization_loss:  0.01788044162094593
p mean is: tensor(-1.4270, device='cuda:1')
epoch:  54000 quantization_loss:  0.017990415915846825
p mean is: tensor(-1.4305, device='cuda:1')
epoch:  55000 quantization_loss:  0.01785912550985813
p mean is: tensor(-1.4336, device='cuda:1')
epoch:  56000 quantization_loss:  0.01786070317029953
p mean is: tensor(-1.4367, device='cuda:1')
epoch:  57000 quantization_loss:  0.017845945432782173
p mean is: tensor(-1.4395, device='cuda:1')
epoch:  58000 quantization_loss:  0.017846660688519478
p mean is: tensor(-1.4422, device='cuda:1')
epoch:  59000 quantization_loss:  0.017825061455368996
p mean is: tensor(-1.4448, device='cuda:1')
epoch:  60000 quantization_loss:  0.017812255769968033
p mean is: tensor(-1.4473, device='cuda:1')
epoch:  61000 quantization_loss:  0.017804311588406563
p mean is: tensor(-1.4496, device='cuda:1')
epoch:  62000 quantization_loss:  0.01780058443546295
p mean is: tensor(-1.4518, device='cuda:1')
epoch:  63000 quantization_loss:  0.017805539071559906
p mean is: tensor(-1.4540, device='cuda:1')
epoch:  64000 quantization_loss:  0.017784222960472107
p mean is: tensor(-1.4561, device='cuda:1')
epoch:  65000 quantization_loss:  0.017776012420654297
p mean is: tensor(-1.4581, device='cuda:1')
epoch:  66000 quantization_loss:  0.01778714545071125
p mean is: tensor(-1.4600, device='cuda:1')
epoch:  67000 quantization_loss:  0.01777099072933197
p mean is: tensor(-1.4619, device='cuda:1')
epoch:  68000 quantization_loss:  0.01776914857327938
p mean is: tensor(-1.4636, device='cuda:1')
epoch:  69000 quantization_loss:  0.01778513751924038
p mean is: tensor(-1.4654, device='cuda:1')
epoch:  70000 quantization_loss:  0.017751704901456833
p mean is: tensor(-1.4671, device='cuda:1')
epoch:  71000 quantization_loss:  0.017746303230524063
p mean is: tensor(-1.4688, device='cuda:1')
epoch:  72000 quantization_loss:  0.017753129824995995
p mean is: tensor(-1.4703, device='cuda:1')
epoch:  73000 quantization_loss:  0.01773996651172638
p mean is: tensor(-1.4719, device='cuda:1')
epoch:  74000 quantization_loss:  0.017730699852108955
p mean is: tensor(-1.4734, device='cuda:1')
epoch:  75000 quantization_loss:  0.017736563459038734
p mean is: tensor(-1.4749, device='cuda:1')
epoch:  76000 quantization_loss:  0.017724106088280678
p mean is: tensor(-1.4764, device='cuda:1')
epoch:  77000 quantization_loss:  0.017723849043250084
p mean is: tensor(-1.4778, device='cuda:1')
epoch:  78000 quantization_loss:  0.017718782648444176
p mean is: tensor(-1.4791, device='cuda:1')
epoch:  79000 quantization_loss:  0.017716165632009506
p mean is: tensor(-1.4805, device='cuda:1')
here
1.1.1.weight         | nonzeros =    1233 /   12800             (  9.63%) | total_pruned =   11567 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =      11 /      16             ( 68.75%) | total_pruned =       5 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     186 /    6400             (  2.91%) | total_pruned =    6214 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     103 /   12800             (  0.80%) | total_pruned =   12697 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     135 /   25600             (  0.53%) | total_pruned =   25465 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =      73 /   51200             (  0.14%) | total_pruned =   51127 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =      80 /  102400             (  0.08%) | total_pruned =  102320 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =       0 /  204800             (  0.00%) | total_pruned =  204800 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =      36 /  409600             (  0.01%) | total_pruned =  409564 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =      65 /  409600             (  0.02%) | total_pruned =  409535 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    2074 /  409600             (  0.51%) | total_pruned =  407526 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    7267 /  409600             (  1.77%) | total_pruned =  402333 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   36232 /  409600             (  8.85%) | total_pruned =  373368 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   34204 /  147456             ( 23.20%) | total_pruned =  113252 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   30284 /  147456             ( 20.54%) | total_pruned =  117172 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   28332 /  147456             ( 19.21%) | total_pruned =  119124 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   16291 /   73728             ( 22.10%) | total_pruned =   57437 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    3822 /   18432             ( 20.74%) | total_pruned =   14610 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1373 /    4608             ( 29.80%) | total_pruned =    3235 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      33 /      48             ( 68.75%) | total_pruned =      15 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 163186, pruned : 2845681, total: 3008867, Compression rate :      18.44x  ( 94.58% pruned)
PSNR of output image is:  12.644196826371783
Experiment done
