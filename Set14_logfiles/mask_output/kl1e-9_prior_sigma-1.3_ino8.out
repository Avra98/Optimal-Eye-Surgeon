Starting vanilla DIP on 8 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '21.515984519739945'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/8/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-1.3/1e-09
epoch:  0 quantization_loss:  0.1574084609746933
p mean is: tensor(-0.0002, device='cuda:1')
epoch:  1000 quantization_loss:  0.1276017129421234
p mean is: tensor(-0.0068, device='cuda:1')
epoch:  2000 quantization_loss:  0.1171579584479332
p mean is: tensor(-0.0106, device='cuda:1')
epoch:  3000 quantization_loss:  0.12009430676698685
p mean is: tensor(-0.0147, device='cuda:1')
epoch:  4000 quantization_loss:  0.116639643907547
p mean is: tensor(-0.0188, device='cuda:1')
epoch:  5000 quantization_loss:  0.10806179791688919
p mean is: tensor(-0.0230, device='cuda:1')
epoch:  6000 quantization_loss:  0.09878761321306229
p mean is: tensor(-0.0278, device='cuda:1')
epoch:  7000 quantization_loss:  0.09374236315488815
p mean is: tensor(-0.0346, device='cuda:1')
epoch:  8000 quantization_loss:  0.09044048935174942
p mean is: tensor(-0.0436, device='cuda:1')
epoch:  9000 quantization_loss:  0.08527890592813492
p mean is: tensor(-0.0561, device='cuda:1')
epoch:  10000 quantization_loss:  0.0815245509147644
p mean is: tensor(-0.0722, device='cuda:1')
epoch:  11000 quantization_loss:  0.07908367365598679
p mean is: tensor(-0.0934, device='cuda:1')
epoch:  12000 quantization_loss:  0.0788290798664093
p mean is: tensor(-0.1208, device='cuda:1')
epoch:  13000 quantization_loss:  0.0760430321097374
p mean is: tensor(-0.1559, device='cuda:1')
epoch:  14000 quantization_loss:  0.07503343373537064
p mean is: tensor(-0.1995, device='cuda:1')
epoch:  15000 quantization_loss:  0.07423713058233261
p mean is: tensor(-0.2519, device='cuda:1')
epoch:  16000 quantization_loss:  0.07378383725881577
p mean is: tensor(-0.3129, device='cuda:1')
epoch:  17000 quantization_loss:  0.07271548360586166
p mean is: tensor(-0.3808, device='cuda:1')
epoch:  18000 quantization_loss:  0.07221358269453049
p mean is: tensor(-0.4525, device='cuda:1')
epoch:  19000 quantization_loss:  0.07196904718875885
p mean is: tensor(-0.5247, device='cuda:1')
epoch:  20000 quantization_loss:  0.07146041840314865
p mean is: tensor(-0.5951, device='cuda:1')
epoch:  21000 quantization_loss:  0.07183840870857239
p mean is: tensor(-0.6618, device='cuda:1')
epoch:  22000 quantization_loss:  0.07089003920555115
p mean is: tensor(-0.7234, device='cuda:1')
epoch:  23000 quantization_loss:  0.07055193185806274
p mean is: tensor(-0.7795, device='cuda:1')
epoch:  24000 quantization_loss:  0.0702618882060051
p mean is: tensor(-0.8300, device='cuda:1')
epoch:  25000 quantization_loss:  0.07003168016672134
p mean is: tensor(-0.8754, device='cuda:1')
epoch:  26000 quantization_loss:  0.06997963786125183
p mean is: tensor(-0.9160, device='cuda:1')
epoch:  27000 quantization_loss:  0.06964246183633804
p mean is: tensor(-0.9521, device='cuda:1')
epoch:  28000 quantization_loss:  0.0695166066288948
p mean is: tensor(-0.9841, device='cuda:1')
epoch:  29000 quantization_loss:  0.06937194615602493
p mean is: tensor(-1.0125, device='cuda:1')
epoch:  30000 quantization_loss:  0.06929652392864227
p mean is: tensor(-1.0378, device='cuda:1')
epoch:  31000 quantization_loss:  0.06912516802549362
p mean is: tensor(-1.0603, device='cuda:1')
epoch:  32000 quantization_loss:  0.0690593495965004
p mean is: tensor(-1.0804, device='cuda:1')
epoch:  33000 quantization_loss:  0.06893353164196014
p mean is: tensor(-1.0984, device='cuda:1')
epoch:  34000 quantization_loss:  0.0688442662358284
p mean is: tensor(-1.1146, device='cuda:1')
epoch:  35000 quantization_loss:  0.06878636032342911
p mean is: tensor(-1.1291, device='cuda:1')
epoch:  36000 quantization_loss:  0.0687207281589508
p mean is: tensor(-1.1421, device='cuda:1')
epoch:  37000 quantization_loss:  0.06866886466741562
p mean is: tensor(-1.1538, device='cuda:1')
epoch:  38000 quantization_loss:  0.06862041354179382
p mean is: tensor(-1.1644, device='cuda:1')
epoch:  39000 quantization_loss:  0.06855373829603195
p mean is: tensor(-1.1739, device='cuda:1')
epoch:  40000 quantization_loss:  0.0685562938451767
p mean is: tensor(-1.1827, device='cuda:1')
epoch:  41000 quantization_loss:  0.06847942620515823
p mean is: tensor(-1.1906, device='cuda:1')
epoch:  42000 quantization_loss:  0.06845159083604813
p mean is: tensor(-1.1977, device='cuda:1')
epoch:  43000 quantization_loss:  0.06844177097082138
p mean is: tensor(-1.2042, device='cuda:1')
epoch:  44000 quantization_loss:  0.06837587058544159
p mean is: tensor(-1.2102, device='cuda:1')
epoch:  45000 quantization_loss:  0.06844079494476318
p mean is: tensor(-1.2157, device='cuda:1')
epoch:  46000 quantization_loss:  0.0683128833770752
p mean is: tensor(-1.2208, device='cuda:1')
epoch:  47000 quantization_loss:  0.06828752160072327
p mean is: tensor(-1.2255, device='cuda:1')
epoch:  48000 quantization_loss:  0.06828289479017258
p mean is: tensor(-1.2297, device='cuda:1')
epoch:  49000 quantization_loss:  0.06824527680873871
p mean is: tensor(-1.2338, device='cuda:1')
epoch:  50000 quantization_loss:  0.06825155764818192
p mean is: tensor(-1.2375, device='cuda:1')
epoch:  51000 quantization_loss:  0.06822260469198227
p mean is: tensor(-1.2409, device='cuda:1')
epoch:  52000 quantization_loss:  0.06821418553590775
p mean is: tensor(-1.2441, device='cuda:1')
epoch:  53000 quantization_loss:  0.06821073591709137
p mean is: tensor(-1.2471, device='cuda:1')
epoch:  54000 quantization_loss:  0.06819628924131393
p mean is: tensor(-1.2500, device='cuda:1')
epoch:  55000 quantization_loss:  0.06817634403705597
p mean is: tensor(-1.2526, device='cuda:1')
epoch:  56000 quantization_loss:  0.06825331598520279
p mean is: tensor(-1.2551, device='cuda:1')
epoch:  57000 quantization_loss:  0.06816070526838303
p mean is: tensor(-1.2574, device='cuda:1')
epoch:  58000 quantization_loss:  0.06815088540315628
p mean is: tensor(-1.2596, device='cuda:1')
epoch:  59000 quantization_loss:  0.06813997030258179
p mean is: tensor(-1.2617, device='cuda:1')
epoch:  60000 quantization_loss:  0.06813451647758484
p mean is: tensor(-1.2637, device='cuda:1')
epoch:  61000 quantization_loss:  0.06812113523483276
p mean is: tensor(-1.2655, device='cuda:1')
epoch:  62000 quantization_loss:  0.06813216209411621
p mean is: tensor(-1.2674, device='cuda:1')
epoch:  63000 quantization_loss:  0.06810862571001053
p mean is: tensor(-1.2691, device='cuda:1')
epoch:  64000 quantization_loss:  0.06813988834619522
p mean is: tensor(-1.2709, device='cuda:1')
epoch:  65000 quantization_loss:  0.06810526549816132
p mean is: tensor(-1.2725, device='cuda:1')
epoch:  66000 quantization_loss:  0.06809934228658676
p mean is: tensor(-1.2740, device='cuda:1')
epoch:  67000 quantization_loss:  0.068097323179245
p mean is: tensor(-1.2754, device='cuda:1')
epoch:  68000 quantization_loss:  0.06808459758758545
p mean is: tensor(-1.2769, device='cuda:1')
epoch:  69000 quantization_loss:  0.06808045506477356
p mean is: tensor(-1.2783, device='cuda:1')
epoch:  70000 quantization_loss:  0.06808272749185562
p mean is: tensor(-1.2796, device='cuda:1')
epoch:  71000 quantization_loss:  0.06807230412960052
p mean is: tensor(-1.2809, device='cuda:1')
epoch:  72000 quantization_loss:  0.06807701289653778
p mean is: tensor(-1.2822, device='cuda:1')
epoch:  73000 quantization_loss:  0.0680704414844513
p mean is: tensor(-1.2834, device='cuda:1')
epoch:  74000 quantization_loss:  0.0680638998746872
p mean is: tensor(-1.2846, device='cuda:1')
epoch:  75000 quantization_loss:  0.06806369125843048
p mean is: tensor(-1.2857, device='cuda:1')
epoch:  76000 quantization_loss:  0.06806065142154694
p mean is: tensor(-1.2868, device='cuda:1')
epoch:  77000 quantization_loss:  0.06805279105901718
p mean is: tensor(-1.2879, device='cuda:1')
epoch:  78000 quantization_loss:  0.06805521249771118
p mean is: tensor(-1.2889, device='cuda:1')
epoch:  79000 quantization_loss:  0.06809595972299576
p mean is: tensor(-1.2899, device='cuda:1')
here
1.1.1.weight         | nonzeros =     901 /   12800             (  7.04%) | total_pruned =   11899 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     109 /    6400             (  1.70%) | total_pruned =    6291 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      72 /   12800             (  0.56%) | total_pruned =   12728 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =       9 /      32             ( 28.12%) | total_pruned =      23 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     146 /   25600             (  0.57%) | total_pruned =   25454 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      12 /      32             ( 37.50%) | total_pruned =      20 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =      94 /   51200             (  0.18%) | total_pruned =   51106 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     150 /  102400             (  0.15%) | total_pruned =  102250 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =      25 /  204800             (  0.01%) | total_pruned =  204775 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     113 /  409600             (  0.03%) | total_pruned =  409487 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     112 /  409600             (  0.03%) | total_pruned =  409488 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    2023 /  409600             (  0.49%) | total_pruned =  407577 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    7833 /  409600             (  1.91%) | total_pruned =  401767 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   32112 /  409600             (  7.84%) | total_pruned =  377488 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   30402 /  147456             ( 20.62%) | total_pruned =  117054 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   31997 /  147456             ( 21.70%) | total_pruned =  115459 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   18716 /  147456             ( 12.69%) | total_pruned =  128740 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    6205 /   73728             (  8.42%) | total_pruned =   67523 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    1823 /   18432             (  9.89%) | total_pruned =   16609 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1015 /    4608             ( 22.03%) | total_pruned =    3593 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      30 /      48             ( 62.50%) | total_pruned =      18 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 135140, pruned : 2873727, total: 3008867, Compression rate :      22.26x  ( 95.51% pruned)
PSNR of output image is:  11.33144158551831
Experiment done
