(3, 512, 512)
Starting vanilla DIP on 2 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.435971436307575'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/2/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/clean_img/-1.0/1e-09
epoch:  0 quantization_loss:  0.08902781456708908
p mean is: tensor(-0.0002, device='cuda:1')
epoch:  1000 quantization_loss:  0.0739893764257431
p mean is: tensor(-0.0074, device='cuda:1')
epoch:  2000 quantization_loss:  0.07243689894676208
p mean is: tensor(-0.0124, device='cuda:1')
epoch:  3000 quantization_loss:  0.06967441737651825
p mean is: tensor(-0.0174, device='cuda:1')
epoch:  4000 quantization_loss:  0.07045919448137283
p mean is: tensor(-0.0221, device='cuda:1')
epoch:  5000 quantization_loss:  0.06858548521995544
p mean is: tensor(-0.0275, device='cuda:1')
epoch:  6000 quantization_loss:  0.06188381090760231
p mean is: tensor(-0.0331, device='cuda:1')
epoch:  7000 quantization_loss:  0.059831563383340836
p mean is: tensor(-0.0404, device='cuda:1')
epoch:  8000 quantization_loss:  0.05368702486157417
p mean is: tensor(-0.0504, device='cuda:1')
epoch:  9000 quantization_loss:  0.05013551563024521
p mean is: tensor(-0.0633, device='cuda:1')
epoch:  10000 quantization_loss:  0.046804279088974
p mean is: tensor(-0.0800, device='cuda:1')
epoch:  11000 quantization_loss:  0.04525245726108551
p mean is: tensor(-0.1016, device='cuda:1')
epoch:  12000 quantization_loss:  0.03969888761639595
p mean is: tensor(-0.1293, device='cuda:1')
epoch:  13000 quantization_loss:  0.0368727408349514
p mean is: tensor(-0.1633, device='cuda:1')
epoch:  14000 quantization_loss:  0.036206942051649094
p mean is: tensor(-0.2043, device='cuda:1')
epoch:  15000 quantization_loss:  0.03582343831658363
p mean is: tensor(-0.2522, device='cuda:1')
epoch:  16000 quantization_loss:  0.03514033928513527
p mean is: tensor(-0.3058, device='cuda:1')
epoch:  17000 quantization_loss:  0.034959111362695694
p mean is: tensor(-0.3629, device='cuda:1')
epoch:  18000 quantization_loss:  0.03429432958364487
p mean is: tensor(-0.4211, device='cuda:1')
epoch:  19000 quantization_loss:  0.03402206301689148
p mean is: tensor(-0.4779, device='cuda:1')
epoch:  20000 quantization_loss:  0.03379372879862785
p mean is: tensor(-0.5316, device='cuda:1')
epoch:  21000 quantization_loss:  0.03365132957696915
p mean is: tensor(-0.5809, device='cuda:1')
epoch:  22000 quantization_loss:  0.033136650919914246
p mean is: tensor(-0.6253, device='cuda:1')
epoch:  23000 quantization_loss:  0.03293967992067337
p mean is: tensor(-0.6647, device='cuda:1')
epoch:  24000 quantization_loss:  0.03274557739496231
p mean is: tensor(-0.6995, device='cuda:1')
epoch:  25000 quantization_loss:  0.032599128782749176
p mean is: tensor(-0.7300, device='cuda:1')
epoch:  26000 quantization_loss:  0.03259655833244324
p mean is: tensor(-0.7569, device='cuda:1')
epoch:  27000 quantization_loss:  0.032409146428108215
p mean is: tensor(-0.7806, device='cuda:1')
epoch:  28000 quantization_loss:  0.032279059290885925
p mean is: tensor(-0.8013, device='cuda:1')
epoch:  29000 quantization_loss:  0.03222646936774254
p mean is: tensor(-0.8196, device='cuda:1')
epoch:  30000 quantization_loss:  0.032172493636608124
p mean is: tensor(-0.8356, device='cuda:1')
epoch:  31000 quantization_loss:  0.03209521248936653
p mean is: tensor(-0.8498, device='cuda:1')
epoch:  32000 quantization_loss:  0.03202890232205391
p mean is: tensor(-0.8624, device='cuda:1')
epoch:  33000 quantization_loss:  0.031995922327041626
p mean is: tensor(-0.8735, device='cuda:1')
epoch:  34000 quantization_loss:  0.031885694712400436
p mean is: tensor(-0.8833, device='cuda:1')
epoch:  35000 quantization_loss:  0.03182167559862137
p mean is: tensor(-0.8921, device='cuda:1')
epoch:  36000 quantization_loss:  0.03181133046746254
p mean is: tensor(-0.8999, device='cuda:1')
epoch:  37000 quantization_loss:  0.031778473407030106
p mean is: tensor(-0.9069, device='cuda:1')
epoch:  38000 quantization_loss:  0.03171495720744133
p mean is: tensor(-0.9132, device='cuda:1')
epoch:  39000 quantization_loss:  0.03167968615889549
p mean is: tensor(-0.9189, device='cuda:1')
epoch:  40000 quantization_loss:  0.03165088966488838
p mean is: tensor(-0.9240, device='cuda:1')
epoch:  41000 quantization_loss:  0.03163374960422516
p mean is: tensor(-0.9286, device='cuda:1')
epoch:  42000 quantization_loss:  0.031616561114788055
p mean is: tensor(-0.9328, device='cuda:1')
epoch:  43000 quantization_loss:  0.031577158719301224
p mean is: tensor(-0.9366, device='cuda:1')
epoch:  44000 quantization_loss:  0.031551115214824677
p mean is: tensor(-0.9402, device='cuda:1')
epoch:  45000 quantization_loss:  0.03155345469713211
p mean is: tensor(-0.9434, device='cuda:1')
epoch:  46000 quantization_loss:  0.03153332322835922
p mean is: tensor(-0.9464, device='cuda:1')
epoch:  47000 quantization_loss:  0.03151915967464447
p mean is: tensor(-0.9492, device='cuda:1')
epoch:  48000 quantization_loss:  0.03148233890533447
p mean is: tensor(-0.9517, device='cuda:1')
epoch:  49000 quantization_loss:  0.03147028759121895
p mean is: tensor(-0.9540, device='cuda:1')
epoch:  50000 quantization_loss:  0.031460583209991455
p mean is: tensor(-0.9563, device='cuda:1')
epoch:  51000 quantization_loss:  0.03143025189638138
p mean is: tensor(-0.9584, device='cuda:1')
epoch:  52000 quantization_loss:  0.03145435452461243
p mean is: tensor(-0.9604, device='cuda:1')
epoch:  53000 quantization_loss:  0.03141792118549347
p mean is: tensor(-0.9623, device='cuda:1')
epoch:  54000 quantization_loss:  0.031419236212968826
p mean is: tensor(-0.9640, device='cuda:1')
epoch:  55000 quantization_loss:  0.031398553401231766
p mean is: tensor(-0.9656, device='cuda:1')
epoch:  56000 quantization_loss:  0.03139190748333931
p mean is: tensor(-0.9672, device='cuda:1')
epoch:  57000 quantization_loss:  0.03138207271695137
p mean is: tensor(-0.9687, device='cuda:1')
epoch:  58000 quantization_loss:  0.03137553110718727
p mean is: tensor(-0.9701, device='cuda:1')
epoch:  59000 quantization_loss:  0.031366147100925446
p mean is: tensor(-0.9714, device='cuda:1')
epoch:  60000 quantization_loss:  0.03136278688907623
p mean is: tensor(-0.9727, device='cuda:1')
epoch:  61000 quantization_loss:  0.03135856240987778
p mean is: tensor(-0.9739, device='cuda:1')
epoch:  62000 quantization_loss:  0.03135889396071434
p mean is: tensor(-0.9752, device='cuda:1')
epoch:  63000 quantization_loss:  0.03134167566895485
p mean is: tensor(-0.9764, device='cuda:1')
epoch:  64000 quantization_loss:  0.03134061396121979
p mean is: tensor(-0.9775, device='cuda:1')
epoch:  65000 quantization_loss:  0.03134125843644142
p mean is: tensor(-0.9786, device='cuda:1')
epoch:  66000 quantization_loss:  0.031331129372119904
p mean is: tensor(-0.9796, device='cuda:1')
epoch:  67000 quantization_loss:  0.03133660927414894
p mean is: tensor(-0.9806, device='cuda:1')
epoch:  68000 quantization_loss:  0.03132602944970131
p mean is: tensor(-0.9816, device='cuda:1')
epoch:  69000 quantization_loss:  0.03131485730409622
p mean is: tensor(-0.9825, device='cuda:1')
epoch:  70000 quantization_loss:  0.031343407928943634
p mean is: tensor(-0.9833, device='cuda:1')
epoch:  71000 quantization_loss:  0.03131668269634247
p mean is: tensor(-0.9841, device='cuda:1')
epoch:  72000 quantization_loss:  0.03130905702710152
p mean is: tensor(-0.9850, device='cuda:1')
epoch:  73000 quantization_loss:  0.03130988031625748
p mean is: tensor(-0.9857, device='cuda:1')
epoch:  74000 quantization_loss:  0.031312163919210434
p mean is: tensor(-0.9865, device='cuda:1')
epoch:  75000 quantization_loss:  0.03129677101969719
p mean is: tensor(-0.9873, device='cuda:1')
epoch:  76000 quantization_loss:  0.03129861503839493
p mean is: tensor(-0.9880, device='cuda:1')
epoch:  77000 quantization_loss:  0.031300485134124756
p mean is: tensor(-0.9888, device='cuda:1')
epoch:  78000 quantization_loss:  0.031344424933195114
p mean is: tensor(-0.9895, device='cuda:1')
epoch:  79000 quantization_loss:  0.03129149600863457
p mean is: tensor(-0.9902, device='cuda:1')
here
1.1.1.weight         | nonzeros =     841 /   12800             (  6.57%) | total_pruned =   11959 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       4 /      16             ( 25.00%) | total_pruned =      12 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     110 /    6400             (  1.72%) | total_pruned =    6290 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     103 /   12800             (  0.80%) | total_pruned =   12697 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     185 /   25600             (  0.72%) | total_pruned =   25415 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     212 /   51200             (  0.41%) | total_pruned =   50988 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     349 /  102400             (  0.34%) | total_pruned =  102051 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =      90 /  204800             (  0.04%) | total_pruned =  204710 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     365 /  409600             (  0.09%) | total_pruned =  409235 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     308 /  409600             (  0.08%) | total_pruned =  409292 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    3062 /  409600             (  0.75%) | total_pruned =  406538 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   11629 /  409600             (  2.84%) | total_pruned =  397971 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   33833 /  409600             (  8.26%) | total_pruned =  375767 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   31285 /  147456             ( 21.22%) | total_pruned =  116171 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   33379 /  147456             ( 22.64%) | total_pruned =  114077 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   26297 /  147456             ( 17.83%) | total_pruned =  121159 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   11172 /   73728             ( 15.15%) | total_pruned =   62556 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2223 /   18432             ( 12.06%) | total_pruned =   16209 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =     968 /    4608             ( 21.01%) | total_pruned =    3640 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      28 /      48             ( 58.33%) | total_pruned =      20 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 157754, pruned : 2851113, total: 3008867, Compression rate :      19.07x  ( 94.76% pruned)
PSNR of output image is:  15.05000952485944
Experiment done
