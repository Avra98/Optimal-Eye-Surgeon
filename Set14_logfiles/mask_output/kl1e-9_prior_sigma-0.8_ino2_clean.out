(3, 512, 512)
Starting vanilla DIP on 2 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.444614614261994'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/2/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/clean_img/-0.8/1e-09
epoch:  0 quantization_loss:  0.08536843210458755
p mean is: tensor(-0.0001, device='cuda:3')
epoch:  1000 quantization_loss:  0.07614309340715408
p mean is: tensor(-0.0051, device='cuda:3')
epoch:  2000 quantization_loss:  0.07373350858688354
p mean is: tensor(-0.0089, device='cuda:3')
epoch:  3000 quantization_loss:  0.07196392863988876
p mean is: tensor(-0.0125, device='cuda:3')
epoch:  4000 quantization_loss:  0.07315444946289062
p mean is: tensor(-0.0165, device='cuda:3')
epoch:  5000 quantization_loss:  0.06529271602630615
p mean is: tensor(-0.0211, device='cuda:3')
epoch:  6000 quantization_loss:  0.0645870789885521
p mean is: tensor(-0.0268, device='cuda:3')
epoch:  7000 quantization_loss:  0.060363661497831345
p mean is: tensor(-0.0347, device='cuda:3')
epoch:  8000 quantization_loss:  0.056928329169750214
p mean is: tensor(-0.0453, device='cuda:3')
epoch:  9000 quantization_loss:  0.05213030055165291
p mean is: tensor(-0.0590, device='cuda:3')
epoch:  10000 quantization_loss:  0.05010727792978287
p mean is: tensor(-0.0764, device='cuda:3')
epoch:  11000 quantization_loss:  0.049398742616176605
p mean is: tensor(-0.0989, device='cuda:3')
epoch:  12000 quantization_loss:  0.04781874641776085
p mean is: tensor(-0.1271, device='cuda:3')
epoch:  13000 quantization_loss:  0.04203617200255394
p mean is: tensor(-0.1610, device='cuda:3')
epoch:  14000 quantization_loss:  0.04111612215638161
p mean is: tensor(-0.1997, device='cuda:3')
epoch:  15000 quantization_loss:  0.03858237341046333
p mean is: tensor(-0.2425, device='cuda:3')
epoch:  16000 quantization_loss:  0.0375060960650444
p mean is: tensor(-0.2874, device='cuda:3')
epoch:  17000 quantization_loss:  0.035696569830179214
p mean is: tensor(-0.3325, device='cuda:3')
epoch:  18000 quantization_loss:  0.034985657781362534
p mean is: tensor(-0.3757, device='cuda:3')
epoch:  19000 quantization_loss:  0.033935703337192535
p mean is: tensor(-0.4161, device='cuda:3')
epoch:  20000 quantization_loss:  0.03471212834119797
p mean is: tensor(-0.4534, device='cuda:3')
epoch:  21000 quantization_loss:  0.033216897398233414
p mean is: tensor(-0.4876, device='cuda:3')
epoch:  22000 quantization_loss:  0.03319432586431503
p mean is: tensor(-0.5184, device='cuda:3')
epoch:  23000 quantization_loss:  0.03290511667728424
p mean is: tensor(-0.5462, device='cuda:3')
epoch:  24000 quantization_loss:  0.03275590389966965
p mean is: tensor(-0.5709, device='cuda:3')
epoch:  25000 quantization_loss:  0.03245056793093681
p mean is: tensor(-0.5928, device='cuda:3')
epoch:  26000 quantization_loss:  0.03240886703133583
p mean is: tensor(-0.6123, device='cuda:3')
epoch:  27000 quantization_loss:  0.03218179941177368
p mean is: tensor(-0.6295, device='cuda:3')
epoch:  28000 quantization_loss:  0.03228667378425598
p mean is: tensor(-0.6447, device='cuda:3')
epoch:  29000 quantization_loss:  0.03196077048778534
p mean is: tensor(-0.6582, device='cuda:3')
epoch:  30000 quantization_loss:  0.03185980021953583
p mean is: tensor(-0.6701, device='cuda:3')
epoch:  31000 quantization_loss:  0.03175150230526924
p mean is: tensor(-0.6806, device='cuda:3')
epoch:  32000 quantization_loss:  0.031738921999931335
p mean is: tensor(-0.6899, device='cuda:3')
epoch:  33000 quantization_loss:  0.031666349619627
p mean is: tensor(-0.6983, device='cuda:3')
epoch:  34000 quantization_loss:  0.0315544568002224
p mean is: tensor(-0.7058, device='cuda:3')
epoch:  35000 quantization_loss:  0.03148781135678291
p mean is: tensor(-0.7125, device='cuda:3')
epoch:  36000 quantization_loss:  0.03139302507042885
p mean is: tensor(-0.7184, device='cuda:3')
epoch:  37000 quantization_loss:  0.03131773695349693
p mean is: tensor(-0.7237, device='cuda:3')
epoch:  38000 quantization_loss:  0.03130650147795677
p mean is: tensor(-0.7284, device='cuda:3')
epoch:  39000 quantization_loss:  0.03128577023744583
p mean is: tensor(-0.7328, device='cuda:3')
epoch:  40000 quantization_loss:  0.031215494498610497
p mean is: tensor(-0.7367, device='cuda:3')
epoch:  41000 quantization_loss:  0.031214116141200066
p mean is: tensor(-0.7404, device='cuda:3')
epoch:  42000 quantization_loss:  0.031195875257253647
p mean is: tensor(-0.7437, device='cuda:3')
epoch:  43000 quantization_loss:  0.03120085783302784
p mean is: tensor(-0.7468, device='cuda:3')
epoch:  44000 quantization_loss:  0.031110836192965508
p mean is: tensor(-0.7496, device='cuda:3')
epoch:  45000 quantization_loss:  0.031153351068496704
p mean is: tensor(-0.7521, device='cuda:3')
epoch:  46000 quantization_loss:  0.031022582203149796
p mean is: tensor(-0.7545, device='cuda:3')
epoch:  47000 quantization_loss:  0.031034953892230988
p mean is: tensor(-0.7567, device='cuda:3')
epoch:  48000 quantization_loss:  0.03120901808142662
p mean is: tensor(-0.7588, device='cuda:3')
epoch:  49000 quantization_loss:  0.03098195418715477
p mean is: tensor(-0.7608, device='cuda:3')
epoch:  50000 quantization_loss:  0.030949965119361877
p mean is: tensor(-0.7626, device='cuda:3')
epoch:  51000 quantization_loss:  0.030942894518375397
p mean is: tensor(-0.7644, device='cuda:3')
epoch:  52000 quantization_loss:  0.03092203289270401
p mean is: tensor(-0.7661, device='cuda:3')
epoch:  53000 quantization_loss:  0.030913956463336945
p mean is: tensor(-0.7676, device='cuda:3')
epoch:  54000 quantization_loss:  0.030905287712812424
p mean is: tensor(-0.7691, device='cuda:3')
epoch:  55000 quantization_loss:  0.030885277315974236
p mean is: tensor(-0.7705, device='cuda:3')
epoch:  56000 quantization_loss:  0.030891863629221916
p mean is: tensor(-0.7718, device='cuda:3')
epoch:  57000 quantization_loss:  0.030879074707627296
p mean is: tensor(-0.7731, device='cuda:3')
epoch:  58000 quantization_loss:  0.03086954727768898
p mean is: tensor(-0.7744, device='cuda:3')
epoch:  59000 quantization_loss:  0.03085346147418022
p mean is: tensor(-0.7755, device='cuda:3')
epoch:  60000 quantization_loss:  0.03084484487771988
p mean is: tensor(-0.7765, device='cuda:3')
epoch:  61000 quantization_loss:  0.030833257362246513
p mean is: tensor(-0.7776, device='cuda:3')
epoch:  62000 quantization_loss:  0.03085600957274437
p mean is: tensor(-0.7786, device='cuda:3')
epoch:  63000 quantization_loss:  0.030825063586235046
p mean is: tensor(-0.7795, device='cuda:3')
epoch:  64000 quantization_loss:  0.03081999532878399
p mean is: tensor(-0.7805, device='cuda:3')
epoch:  65000 quantization_loss:  0.030811943113803864
p mean is: tensor(-0.7815, device='cuda:3')
epoch:  66000 quantization_loss:  0.0308125801384449
p mean is: tensor(-0.7823, device='cuda:3')
epoch:  67000 quantization_loss:  0.03081114962697029
p mean is: tensor(-0.7832, device='cuda:3')
epoch:  68000 quantization_loss:  0.03079983964562416
p mean is: tensor(-0.7840, device='cuda:3')
epoch:  69000 quantization_loss:  0.03080613911151886
p mean is: tensor(-0.7848, device='cuda:3')
epoch:  70000 quantization_loss:  0.030832303687930107
p mean is: tensor(-0.7856, device='cuda:3')
epoch:  71000 quantization_loss:  0.030789710581302643
p mean is: tensor(-0.7864, device='cuda:3')
epoch:  72000 quantization_loss:  0.030788926407694817
p mean is: tensor(-0.7872, device='cuda:3')
epoch:  73000 quantization_loss:  0.030784841626882553
p mean is: tensor(-0.7879, device='cuda:3')
epoch:  74000 quantization_loss:  0.030779041349887848
p mean is: tensor(-0.7886, device='cuda:3')
epoch:  75000 quantization_loss:  0.030776234343647957
p mean is: tensor(-0.7894, device='cuda:3')
epoch:  76000 quantization_loss:  0.030776800587773323
p mean is: tensor(-0.7900, device='cuda:3')
epoch:  77000 quantization_loss:  0.030773676931858063
p mean is: tensor(-0.7907, device='cuda:3')
epoch:  78000 quantization_loss:  0.030773766338825226
p mean is: tensor(-0.7913, device='cuda:3')
epoch:  79000 quantization_loss:  0.030765598639845848
p mean is: tensor(-0.7920, device='cuda:3')
here
1.1.1.weight         | nonzeros =     988 /   12800             (  7.72%) | total_pruned =   11812 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     198 /    6400             (  3.09%) | total_pruned =    6202 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     129 /   12800             (  1.01%) | total_pruned =   12671 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      13 /      32             ( 40.62%) | total_pruned =      19 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     220 /   25600             (  0.86%) | total_pruned =   25380 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      13 /      32             ( 40.62%) | total_pruned =      19 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     253 /   51200             (  0.49%) | total_pruned =   50947 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     590 /  102400             (  0.58%) | total_pruned =  101810 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     432 /  204800             (  0.21%) | total_pruned =  204368 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     932 /  409600             (  0.23%) | total_pruned =  408668 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    1619 /  409600             (  0.40%) | total_pruned =  407981 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    6092 /  409600             (  1.49%) | total_pruned =  403508 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   17097 /  409600             (  4.17%) | total_pruned =  392503 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   47981 /  409600             ( 11.71%) | total_pruned =  361619 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   31691 /  147456             ( 21.49%) | total_pruned =  115765 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   30457 /  147456             ( 20.65%) | total_pruned =  116999 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   25622 /  147456             ( 17.38%) | total_pruned =  121834 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   11344 /   73728             ( 15.39%) | total_pruned =   62384 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    3212 /   18432             ( 17.43%) | total_pruned =   15220 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1402 /    4608             ( 30.43%) | total_pruned =    3206 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      26 /      48             ( 54.17%) | total_pruned =      22 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 181585, pruned : 2827282, total: 3008867, Compression rate :      16.57x  ( 93.97% pruned)
PSNR of output image is:  15.148303464860716
Experiment done
