(3, 512, 512)
Noisy PSNR is '20.310752035087663'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/11/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/0.0/1e-09
epoch:  0 quantization_loss:  0.06644296646118164
p mean is: tensor(-1.0884e-06, device='cuda:2')
epoch:  1000 quantization_loss:  0.05813782289624214
p mean is: tensor(-4.3004e-05, device='cuda:2')
epoch:  2000 quantization_loss:  0.05755981057882309
p mean is: tensor(-1.7518e-05, device='cuda:2')
epoch:  3000 quantization_loss:  0.05660640448331833
p mean is: tensor(-0.0001, device='cuda:2')
epoch:  4000 quantization_loss:  0.05650165304541588
p mean is: tensor(-0.0003, device='cuda:2')
epoch:  5000 quantization_loss:  0.05598895996809006
p mean is: tensor(-0.0006, device='cuda:2')
epoch:  6000 quantization_loss:  0.052529338747262955
p mean is: tensor(-0.0014, device='cuda:2')
epoch:  7000 quantization_loss:  0.0478413924574852
p mean is: tensor(-0.0020, device='cuda:2')
epoch:  8000 quantization_loss:  0.04378528892993927
p mean is: tensor(-0.0024, device='cuda:2')
epoch:  9000 quantization_loss:  0.04041796177625656
p mean is: tensor(-0.0033, device='cuda:2')
epoch:  10000 quantization_loss:  0.039539873600006104
p mean is: tensor(-0.0041, device='cuda:2')
epoch:  11000 quantization_loss:  0.03494546189904213
p mean is: tensor(-0.0049, device='cuda:2')
epoch:  12000 quantization_loss:  0.03256742283701897
p mean is: tensor(-0.0055, device='cuda:2')
epoch:  13000 quantization_loss:  0.03136786073446274
p mean is: tensor(-0.0057, device='cuda:2')
epoch:  14000 quantization_loss:  0.028588199988007545
p mean is: tensor(-0.0059, device='cuda:2')
epoch:  15000 quantization_loss:  0.02723514661192894
p mean is: tensor(-0.0058, device='cuda:2')
epoch:  16000 quantization_loss:  0.026631919667124748
p mean is: tensor(-0.0054, device='cuda:2')
epoch:  17000 quantization_loss:  0.026120033115148544
p mean is: tensor(-0.0049, device='cuda:2')
epoch:  18000 quantization_loss:  0.025729043409228325
p mean is: tensor(-0.0043, device='cuda:2')
epoch:  19000 quantization_loss:  0.02527930587530136
p mean is: tensor(-0.0037, device='cuda:2')
epoch:  20000 quantization_loss:  0.025123005732893944
p mean is: tensor(-0.0031, device='cuda:2')
epoch:  21000 quantization_loss:  0.02480236440896988
p mean is: tensor(-0.0027, device='cuda:2')
epoch:  22000 quantization_loss:  0.024527952075004578
p mean is: tensor(-0.0021, device='cuda:2')
epoch:  23000 quantization_loss:  0.024166638031601906
p mean is: tensor(-0.0015, device='cuda:2')
epoch:  24000 quantization_loss:  0.023631276562809944
p mean is: tensor(-0.0010, device='cuda:2')
epoch:  25000 quantization_loss:  0.02350209653377533
p mean is: tensor(-0.0006, device='cuda:2')
epoch:  26000 quantization_loss:  0.02364736795425415
p mean is: tensor(-7.2600e-05, device='cuda:2')
epoch:  27000 quantization_loss:  0.023080574348568916
p mean is: tensor(0.0003, device='cuda:2')
epoch:  28000 quantization_loss:  0.022953083738684654
p mean is: tensor(0.0006, device='cuda:2')
epoch:  29000 quantization_loss:  0.022925786674022675
p mean is: tensor(0.0008, device='cuda:2')
epoch:  30000 quantization_loss:  0.0227879136800766
p mean is: tensor(0.0011, device='cuda:2')
epoch:  31000 quantization_loss:  0.02269641123712063
p mean is: tensor(0.0013, device='cuda:2')
epoch:  32000 quantization_loss:  0.022594330832362175
p mean is: tensor(0.0014, device='cuda:2')
epoch:  33000 quantization_loss:  0.022503964602947235
p mean is: tensor(0.0015, device='cuda:2')
epoch:  34000 quantization_loss:  0.022458523511886597
p mean is: tensor(0.0016, device='cuda:2')
epoch:  35000 quantization_loss:  0.02238564006984234
p mean is: tensor(0.0016, device='cuda:2')
epoch:  36000 quantization_loss:  0.022340882569551468
p mean is: tensor(0.0017, device='cuda:2')
epoch:  37000 quantization_loss:  0.022300133481621742
p mean is: tensor(0.0016, device='cuda:2')
epoch:  38000 quantization_loss:  0.022260786965489388
p mean is: tensor(0.0016, device='cuda:2')
epoch:  39000 quantization_loss:  0.022237243130803108
p mean is: tensor(0.0017, device='cuda:2')
epoch:  40000 quantization_loss:  0.022177178412675858
p mean is: tensor(0.0016, device='cuda:2')
epoch:  41000 quantization_loss:  0.022128647193312645
p mean is: tensor(0.0015, device='cuda:2')
epoch:  42000 quantization_loss:  0.02240188606083393
p mean is: tensor(0.0014, device='cuda:2')
epoch:  43000 quantization_loss:  0.022099297493696213
p mean is: tensor(0.0013, device='cuda:2')
epoch:  44000 quantization_loss:  0.022059699520468712
p mean is: tensor(0.0012, device='cuda:2')
epoch:  45000 quantization_loss:  0.022054675966501236
p mean is: tensor(0.0011, device='cuda:2')
epoch:  46000 quantization_loss:  0.022043555974960327
p mean is: tensor(0.0010, device='cuda:2')
epoch:  47000 quantization_loss:  0.022010959684848785
p mean is: tensor(0.0009, device='cuda:2')
epoch:  48000 quantization_loss:  0.021988650783896446
p mean is: tensor(0.0008, device='cuda:2')
epoch:  49000 quantization_loss:  0.02197403647005558
p mean is: tensor(0.0007, device='cuda:2')
epoch:  50000 quantization_loss:  0.02197062224149704
p mean is: tensor(0.0007, device='cuda:2')
epoch:  51000 quantization_loss:  0.021949371322989464
p mean is: tensor(0.0006, device='cuda:2')
epoch:  52000 quantization_loss:  0.021932173520326614
p mean is: tensor(0.0006, device='cuda:2')
epoch:  53000 quantization_loss:  0.021928884088993073
p mean is: tensor(0.0005, device='cuda:2')
epoch:  54000 quantization_loss:  0.021914642304182053
p mean is: tensor(0.0003, device='cuda:2')
epoch:  55000 quantization_loss:  0.02190307527780533
p mean is: tensor(0.0002, device='cuda:2')
epoch:  56000 quantization_loss:  0.021904293447732925
p mean is: tensor(0.0001, device='cuda:2')
epoch:  57000 quantization_loss:  0.021890828385949135
p mean is: tensor(1.9657e-05, device='cuda:2')
epoch:  58000 quantization_loss:  0.021877415478229523
p mean is: tensor(-5.1533e-05, device='cuda:2')
epoch:  59000 quantization_loss:  0.021868959069252014
p mean is: tensor(-4.9584e-05, device='cuda:2')
epoch:  60000 quantization_loss:  0.021877752617001534
p mean is: tensor(-0.0002, device='cuda:2')
epoch:  61000 quantization_loss:  0.021863754838705063
p mean is: tensor(-0.0003, device='cuda:2')
epoch:  62000 quantization_loss:  0.021858569234609604
p mean is: tensor(-0.0004, device='cuda:2')
epoch:  63000 quantization_loss:  0.021855397149920464
p mean is: tensor(-0.0004, device='cuda:2')
epoch:  64000 quantization_loss:  0.021855544298887253
p mean is: tensor(-0.0004, device='cuda:2')
epoch:  65000 quantization_loss:  0.021838514134287834
p mean is: tensor(-0.0005, device='cuda:2')
epoch:  66000 quantization_loss:  0.02183910273015499
p mean is: tensor(-0.0006, device='cuda:2')
epoch:  67000 quantization_loss:  0.021843185648322105
p mean is: tensor(-0.0007, device='cuda:2')
epoch:  68000 quantization_loss:  0.02182926796376705
p mean is: tensor(-0.0007, device='cuda:2')
epoch:  69000 quantization_loss:  0.021828096359968185
p mean is: tensor(-0.0008, device='cuda:2')
epoch:  70000 quantization_loss:  0.021820727735757828
p mean is: tensor(-0.0008, device='cuda:2')
epoch:  71000 quantization_loss:  0.0218279417604208
p mean is: tensor(-0.0010, device='cuda:2')
epoch:  72000 quantization_loss:  0.021813474595546722
p mean is: tensor(-0.0010, device='cuda:2')
epoch:  73000 quantization_loss:  0.021817849949002266
p mean is: tensor(-0.0011, device='cuda:2')
epoch:  74000 quantization_loss:  0.02180590108036995
p mean is: tensor(-0.0011, device='cuda:2')
epoch:  75000 quantization_loss:  0.021810604259371758
p mean is: tensor(-0.0012, device='cuda:2')
epoch:  76000 quantization_loss:  0.021809497848153114
p mean is: tensor(-0.0012, device='cuda:2')
epoch:  77000 quantization_loss:  0.021802868694067
p mean is: tensor(-0.0013, device='cuda:2')
epoch:  78000 quantization_loss:  0.02181745506823063
p mean is: tensor(-0.0014, device='cuda:2')
epoch:  79000 quantization_loss:  0.021804530173540115
p mean is: tensor(-0.0014, device='cuda:2')
1.1.1.weight         | nonzeros =    6502 /   12800             ( 50.80%) | total_pruned =    6298 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.2.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =    3212 /    6400             ( 50.19%) | total_pruned =    3188 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.5.weight           | nonzeros =      11 /      16             ( 68.75%) | total_pruned =       5 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =    6415 /   12800             ( 50.12%) | total_pruned =    6385 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       9 /      32             ( 28.12%) | total_pruned =      23 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      12 /      32             ( 37.50%) | total_pruned =      20 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =   12811 /   25600             ( 50.04%) | total_pruned =   12789 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       5 /      32             ( 15.62%) | total_pruned =      27 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =   25842 /   51200             ( 50.47%) | total_pruned =   25358 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =   51382 /  102400             ( 50.18%) | total_pruned =   51018 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =  102481 /  204800             ( 50.04%) | total_pruned =  102319 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =  204186 /  409600             ( 49.85%) | total_pruned =  205414 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  199030 /  409600             ( 48.59%) | total_pruned =  210570 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  192510 /  409600             ( 47.00%) | total_pruned =  217090 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  192502 /  409600             ( 47.00%) | total_pruned =  217098 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  189933 /  409600             ( 46.37%) | total_pruned =  219667 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   68418 /  147456             ( 46.40%) | total_pruned =   79038 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   64864 /  147456             ( 43.99%) | total_pruned =   82592 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =      27 /     128             ( 21.09%) | total_pruned =     101 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   56846 /  147456             ( 38.55%) | total_pruned =   90610 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   27353 /   73728             ( 37.10%) | total_pruned =   46375 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    6705 /   18432             ( 36.38%) | total_pruned =   11727 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       7 /      32             ( 21.88%) | total_pruned =      25 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    2073 /    4608             ( 44.99%) | total_pruned =    2535 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      27 /      48             ( 56.25%) | total_pruned =      21 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 1414556, pruned : 1594311, total: 3008867, Compression rate :       2.13x  ( 52.99% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  18.48851916447146
Experiment done
