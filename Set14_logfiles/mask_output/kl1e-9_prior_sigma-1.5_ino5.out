Starting vanilla DIP on 5 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.182296066099056'
(3, 576, 576) (3, 576, 576) torch.Size([1, 32, 576, 576])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/5/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-1.5/1e-09
epoch:  0 quantization_loss:  0.06318030506372452
p mean is: tensor(-0.0003, device='cuda:4')
epoch:  1000 quantization_loss:  0.05928819999098778
p mean is: tensor(-0.0122, device='cuda:4')
epoch:  2000 quantization_loss:  0.055998411029577255
p mean is: tensor(-0.0214, device='cuda:4')
epoch:  3000 quantization_loss:  0.055190812796354294
p mean is: tensor(-0.0302, device='cuda:4')
epoch:  4000 quantization_loss:  0.055248159915208817
p mean is: tensor(-0.0389, device='cuda:4')
epoch:  5000 quantization_loss:  0.053953368216753006
p mean is: tensor(-0.0479, device='cuda:4')
epoch:  6000 quantization_loss:  0.046673256903886795
p mean is: tensor(-0.0575, device='cuda:4')
epoch:  7000 quantization_loss:  0.04250091314315796
p mean is: tensor(-0.0702, device='cuda:4')
epoch:  8000 quantization_loss:  0.035550445318222046
p mean is: tensor(-0.0868, device='cuda:4')
epoch:  9000 quantization_loss:  0.031997982412576675
p mean is: tensor(-0.1082, device='cuda:4')
epoch:  10000 quantization_loss:  0.028134703636169434
p mean is: tensor(-0.1363, device='cuda:4')
epoch:  11000 quantization_loss:  0.026384979486465454
p mean is: tensor(-0.1727, device='cuda:4')
epoch:  12000 quantization_loss:  0.025422165170311928
p mean is: tensor(-0.2190, device='cuda:4')
epoch:  13000 quantization_loss:  0.024930477142333984
p mean is: tensor(-0.2761, device='cuda:4')
epoch:  14000 quantization_loss:  0.024132542312145233
p mean is: tensor(-0.3438, device='cuda:4')
epoch:  15000 quantization_loss:  0.023549843579530716
p mean is: tensor(-0.4204, device='cuda:4')
epoch:  16000 quantization_loss:  0.022476980462670326
p mean is: tensor(-0.5026, device='cuda:4')
epoch:  17000 quantization_loss:  0.022617598995566368
p mean is: tensor(-0.5859, device='cuda:4')
epoch:  18000 quantization_loss:  0.02191312238574028
p mean is: tensor(-0.6672, device='cuda:4')
epoch:  19000 quantization_loss:  0.021563228219747543
p mean is: tensor(-0.7439, device='cuda:4')
epoch:  20000 quantization_loss:  0.021583814173936844
p mean is: tensor(-0.8145, device='cuda:4')
epoch:  21000 quantization_loss:  0.02116994559764862
p mean is: tensor(-0.8785, device='cuda:4')
epoch:  22000 quantization_loss:  0.021051790565252304
p mean is: tensor(-0.9359, device='cuda:4')
epoch:  23000 quantization_loss:  0.02077472396194935
p mean is: tensor(-0.9872, device='cuda:4')
epoch:  24000 quantization_loss:  0.02071474678814411
p mean is: tensor(-1.0326, device='cuda:4')
epoch:  25000 quantization_loss:  0.02048289217054844
p mean is: tensor(-1.0729, device='cuda:4')
epoch:  26000 quantization_loss:  0.02046683244407177
p mean is: tensor(-1.1090, device='cuda:4')
epoch:  27000 quantization_loss:  0.02032509818673134
p mean is: tensor(-1.1411, device='cuda:4')
epoch:  28000 quantization_loss:  0.020220130681991577
p mean is: tensor(-1.1698, device='cuda:4')
epoch:  29000 quantization_loss:  0.020153172314167023
p mean is: tensor(-1.1954, device='cuda:4')
epoch:  30000 quantization_loss:  0.02014094777405262
p mean is: tensor(-1.2184, device='cuda:4')
epoch:  31000 quantization_loss:  0.019995899870991707
p mean is: tensor(-1.2391, device='cuda:4')
epoch:  32000 quantization_loss:  0.01995055004954338
p mean is: tensor(-1.2578, device='cuda:4')
epoch:  33000 quantization_loss:  0.019907716661691666
p mean is: tensor(-1.2748, device='cuda:4')
epoch:  34000 quantization_loss:  0.02011013589799404
p mean is: tensor(-1.2903, device='cuda:4')
epoch:  35000 quantization_loss:  0.019818661734461784
p mean is: tensor(-1.3043, device='cuda:4')
epoch:  36000 quantization_loss:  0.01976541057229042
p mean is: tensor(-1.3171, device='cuda:4')
epoch:  37000 quantization_loss:  0.01978355646133423
p mean is: tensor(-1.3287, device='cuda:4')
epoch:  38000 quantization_loss:  0.019740818068385124
p mean is: tensor(-1.3393, device='cuda:4')
epoch:  39000 quantization_loss:  0.01967949979007244
p mean is: tensor(-1.3490, device='cuda:4')
epoch:  40000 quantization_loss:  0.019634626805782318
p mean is: tensor(-1.3580, device='cuda:4')
epoch:  41000 quantization_loss:  0.019747400656342506
p mean is: tensor(-1.3662, device='cuda:4')
epoch:  42000 quantization_loss:  0.019629133865237236
p mean is: tensor(-1.3737, device='cuda:4')
epoch:  43000 quantization_loss:  0.019467348232865334
p mean is: tensor(-1.3807, device='cuda:4')
epoch:  44000 quantization_loss:  0.019461791962385178
p mean is: tensor(-1.3872, device='cuda:4')
epoch:  45000 quantization_loss:  0.01946667954325676
p mean is: tensor(-1.3932, device='cuda:4')
epoch:  46000 quantization_loss:  0.019389890134334564
p mean is: tensor(-1.3988, device='cuda:4')
epoch:  47000 quantization_loss:  0.01937839202582836
p mean is: tensor(-1.4041, device='cuda:4')
epoch:  48000 quantization_loss:  0.019360175356268883
p mean is: tensor(-1.4090, device='cuda:4')
epoch:  49000 quantization_loss:  0.01936298795044422
p mean is: tensor(-1.4136, device='cuda:4')
epoch:  50000 quantization_loss:  0.019337687641382217
p mean is: tensor(-1.4179, device='cuda:4')
epoch:  51000 quantization_loss:  0.019305579364299774
p mean is: tensor(-1.4219, device='cuda:4')
epoch:  52000 quantization_loss:  0.019299782812595367
p mean is: tensor(-1.4258, device='cuda:4')
epoch:  53000 quantization_loss:  0.019294247031211853
p mean is: tensor(-1.4294, device='cuda:4')
epoch:  54000 quantization_loss:  0.019289348274469376
p mean is: tensor(-1.4327, device='cuda:4')
epoch:  55000 quantization_loss:  0.01927139237523079
p mean is: tensor(-1.4360, device='cuda:4')
epoch:  56000 quantization_loss:  0.019268527626991272
p mean is: tensor(-1.4390, device='cuda:4')
epoch:  57000 quantization_loss:  0.01924951560795307
p mean is: tensor(-1.4419, device='cuda:4')
epoch:  58000 quantization_loss:  0.01924813725054264
p mean is: tensor(-1.4447, device='cuda:4')
epoch:  59000 quantization_loss:  0.019230034202337265
p mean is: tensor(-1.4473, device='cuda:4')
epoch:  60000 quantization_loss:  0.01922733336687088
p mean is: tensor(-1.4498, device='cuda:4')
epoch:  61000 quantization_loss:  0.019216550514101982
p mean is: tensor(-1.4522, device='cuda:4')
epoch:  62000 quantization_loss:  0.019220976158976555
p mean is: tensor(-1.4545, device='cuda:4')
epoch:  63000 quantization_loss:  0.019211655482649803
p mean is: tensor(-1.4567, device='cuda:4')
epoch:  64000 quantization_loss:  0.019212616607546806
p mean is: tensor(-1.4588, device='cuda:4')
epoch:  65000 quantization_loss:  0.01921071670949459
p mean is: tensor(-1.4608, device='cuda:4')
epoch:  66000 quantization_loss:  0.019196780398488045
p mean is: tensor(-1.4628, device='cuda:4')
epoch:  67000 quantization_loss:  0.019184831529855728
p mean is: tensor(-1.4647, device='cuda:4')
epoch:  68000 quantization_loss:  0.01918174885213375
p mean is: tensor(-1.4665, device='cuda:4')
epoch:  69000 quantization_loss:  0.019194118678569794
p mean is: tensor(-1.4683, device='cuda:4')
epoch:  70000 quantization_loss:  0.019178487360477448
p mean is: tensor(-1.4699, device='cuda:4')
epoch:  71000 quantization_loss:  0.019287390634417534
p mean is: tensor(-1.4716, device='cuda:4')
epoch:  72000 quantization_loss:  0.01917198672890663
p mean is: tensor(-1.4732, device='cuda:4')
epoch:  73000 quantization_loss:  0.01916595920920372
p mean is: tensor(-1.4747, device='cuda:4')
epoch:  74000 quantization_loss:  0.019164247438311577
p mean is: tensor(-1.4762, device='cuda:4')
epoch:  75000 quantization_loss:  0.01915779709815979
p mean is: tensor(-1.4776, device='cuda:4')
epoch:  76000 quantization_loss:  0.019157394766807556
p mean is: tensor(-1.4790, device='cuda:4')
epoch:  77000 quantization_loss:  0.01914740726351738
p mean is: tensor(-1.4804, device='cuda:4')
epoch:  78000 quantization_loss:  0.019159700721502304
p mean is: tensor(-1.4817, device='cuda:4')
epoch:  79000 quantization_loss:  0.019153904169797897
p mean is: tensor(-1.4830, device='cuda:4')
here
1.1.1.weight         | nonzeros =    1199 /   12800             (  9.37%) | total_pruned =   11601 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     157 /    6400             (  2.45%) | total_pruned =    6243 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      74 /   12800             (  0.58%) | total_pruned =   12726 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =      80 /   25600             (  0.31%) | total_pruned =   25520 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =      48 /   51200             (  0.09%) | total_pruned =   51152 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     155 /  102400             (  0.15%) | total_pruned =  102245 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =       6 /  204800             (  0.00%) | total_pruned =  204794 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =      68 /  409600             (  0.02%) | total_pruned =  409532 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =      35 /  409600             (  0.01%) | total_pruned =  409565 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    1749 /  409600             (  0.43%) | total_pruned =  407851 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    7985 /  409600             (  1.95%) | total_pruned =  401615 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   31618 /  409600             (  7.72%) | total_pruned =  377982 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   29356 /  147456             ( 19.91%) | total_pruned =  118100 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   31094 /  147456             ( 21.09%) | total_pruned =  116362 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   26881 /  147456             ( 18.23%) | total_pruned =  120575 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   13570 /   73728             ( 18.41%) | total_pruned =   60158 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    3281 /   18432             ( 17.80%) | total_pruned =   15151 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1118 /    4608             ( 24.26%) | total_pruned =    3490 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      14 /      16             ( 87.50%) | total_pruned =       2 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      32 /      48             ( 66.67%) | total_pruned =      16 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 149862, pruned : 2859005, total: 3008867, Compression rate :      20.08x  ( 95.02% pruned)
PSNR of output image is:  19.901428646606465
Experiment done
