(3, 256, 256)
Starting vanilla DIP on 1 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.493456333544117'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/1/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-1.8/1e-09
epoch:  0 quantization_loss:  0.09222476184368134
p mean is: tensor(-0.0003, device='cuda:2')
epoch:  1000 quantization_loss:  0.07754350453615189
p mean is: tensor(-0.0074, device='cuda:2')
epoch:  2000 quantization_loss:  0.07784845679998398
p mean is: tensor(-0.0123, device='cuda:2')
epoch:  3000 quantization_loss:  0.07559188455343246
p mean is: tensor(-0.0170, device='cuda:2')
epoch:  4000 quantization_loss:  0.0752100795507431
p mean is: tensor(-0.0217, device='cuda:2')
epoch:  5000 quantization_loss:  0.07807059586048126
p mean is: tensor(-0.0261, device='cuda:2')
epoch:  6000 quantization_loss:  0.07762168347835541
p mean is: tensor(-0.0304, device='cuda:2')
epoch:  7000 quantization_loss:  0.07298225909471512
p mean is: tensor(-0.0347, device='cuda:2')
epoch:  8000 quantization_loss:  0.07154372334480286
p mean is: tensor(-0.0392, device='cuda:2')
epoch:  9000 quantization_loss:  0.06455906480550766
p mean is: tensor(-0.0440, device='cuda:2')
epoch:  10000 quantization_loss:  0.06130462884902954
p mean is: tensor(-0.0506, device='cuda:2')
epoch:  11000 quantization_loss:  0.05647129565477371
p mean is: tensor(-0.0598, device='cuda:2')
epoch:  12000 quantization_loss:  0.05066901072859764
p mean is: tensor(-0.0722, device='cuda:2')
epoch:  13000 quantization_loss:  0.04810885712504387
p mean is: tensor(-0.0893, device='cuda:2')
epoch:  14000 quantization_loss:  0.04091690480709076
p mean is: tensor(-0.1125, device='cuda:2')
epoch:  15000 quantization_loss:  0.0386248379945755
p mean is: tensor(-0.1430, device='cuda:2')
epoch:  16000 quantization_loss:  0.03753441572189331
p mean is: tensor(-0.1829, device='cuda:2')
epoch:  17000 quantization_loss:  0.03686920925974846
p mean is: tensor(-0.2343, device='cuda:2')
epoch:  18000 quantization_loss:  0.03743881359696388
p mean is: tensor(-0.2983, device='cuda:2')
epoch:  19000 quantization_loss:  0.034243300557136536
p mean is: tensor(-0.3748, device='cuda:2')
epoch:  20000 quantization_loss:  0.03327133506536484
p mean is: tensor(-0.4619, device='cuda:2')
epoch:  21000 quantization_loss:  0.03276751562952995
p mean is: tensor(-0.5570, device='cuda:2')
epoch:  22000 quantization_loss:  0.0321936197578907
p mean is: tensor(-0.6568, device='cuda:2')
epoch:  23000 quantization_loss:  0.03172813728451729
p mean is: tensor(-0.7563, device='cuda:2')
epoch:  24000 quantization_loss:  0.031523697078228
p mean is: tensor(-0.8522, device='cuda:2')
epoch:  25000 quantization_loss:  0.031157663092017174
p mean is: tensor(-0.9415, device='cuda:2')
epoch:  26000 quantization_loss:  0.030966414138674736
p mean is: tensor(-1.0230, device='cuda:2')
epoch:  27000 quantization_loss:  0.030746890231966972
p mean is: tensor(-1.0963, device='cuda:2')
epoch:  28000 quantization_loss:  0.030504830181598663
p mean is: tensor(-1.1615, device='cuda:2')
epoch:  29000 quantization_loss:  0.03019930049777031
p mean is: tensor(-1.2200, device='cuda:2')
epoch:  30000 quantization_loss:  0.030153172090649605
p mean is: tensor(-1.2722, device='cuda:2')
epoch:  31000 quantization_loss:  0.030395714566111565
p mean is: tensor(-1.3187, device='cuda:2')
epoch:  32000 quantization_loss:  0.02982034534215927
p mean is: tensor(-1.3601, device='cuda:2')
epoch:  33000 quantization_loss:  0.02978132851421833
p mean is: tensor(-1.3974, device='cuda:2')
epoch:  34000 quantization_loss:  0.029638556763529778
p mean is: tensor(-1.4306, device='cuda:2')
epoch:  35000 quantization_loss:  0.030046839267015457
p mean is: tensor(-1.4603, device='cuda:2')
epoch:  36000 quantization_loss:  0.02952214889228344
p mean is: tensor(-1.4870, device='cuda:2')
epoch:  37000 quantization_loss:  0.029512323439121246
p mean is: tensor(-1.5110, device='cuda:2')
epoch:  38000 quantization_loss:  0.029441500082612038
p mean is: tensor(-1.5326, device='cuda:2')
epoch:  39000 quantization_loss:  0.029322141781449318
p mean is: tensor(-1.5520, device='cuda:2')
epoch:  40000 quantization_loss:  0.0293299350887537
p mean is: tensor(-1.5696, device='cuda:2')
epoch:  41000 quantization_loss:  0.0292842797935009
p mean is: tensor(-1.5854, device='cuda:2')
epoch:  42000 quantization_loss:  0.029227416962385178
p mean is: tensor(-1.5996, device='cuda:2')
epoch:  43000 quantization_loss:  0.029213938862085342
p mean is: tensor(-1.6126, device='cuda:2')
epoch:  44000 quantization_loss:  0.0291766207665205
p mean is: tensor(-1.6244, device='cuda:2')
epoch:  45000 quantization_loss:  0.029135746881365776
p mean is: tensor(-1.6351, device='cuda:2')
epoch:  46000 quantization_loss:  0.029087964445352554
p mean is: tensor(-1.6448, device='cuda:2')
epoch:  47000 quantization_loss:  0.029079480096697807
p mean is: tensor(-1.6537, device='cuda:2')
epoch:  48000 quantization_loss:  0.02904997020959854
p mean is: tensor(-1.6618, device='cuda:2')
epoch:  49000 quantization_loss:  0.029071755707263947
p mean is: tensor(-1.6692, device='cuda:2')
epoch:  50000 quantization_loss:  0.029005711898207664
p mean is: tensor(-1.6759, device='cuda:2')
epoch:  51000 quantization_loss:  0.029008645564317703
p mean is: tensor(-1.6821, device='cuda:2')
epoch:  52000 quantization_loss:  0.028971470892429352
p mean is: tensor(-1.6878, device='cuda:2')
epoch:  53000 quantization_loss:  0.028938060626387596
p mean is: tensor(-1.6930, device='cuda:2')
epoch:  54000 quantization_loss:  0.028933990746736526
p mean is: tensor(-1.6978, device='cuda:2')
epoch:  55000 quantization_loss:  0.028902331367135048
p mean is: tensor(-1.7022, device='cuda:2')
epoch:  56000 quantization_loss:  0.028918296098709106
p mean is: tensor(-1.7063, device='cuda:2')
epoch:  57000 quantization_loss:  0.028896110132336617
p mean is: tensor(-1.7100, device='cuda:2')
epoch:  58000 quantization_loss:  0.028884587809443474
p mean is: tensor(-1.7135, device='cuda:2')
epoch:  59000 quantization_loss:  0.028873009607195854
p mean is: tensor(-1.7166, device='cuda:2')
epoch:  60000 quantization_loss:  0.0288684144616127
p mean is: tensor(-1.7196, device='cuda:2')
epoch:  61000 quantization_loss:  0.028852632269263268
p mean is: tensor(-1.7224, device='cuda:2')
epoch:  62000 quantization_loss:  0.02885705605149269
p mean is: tensor(-1.7250, device='cuda:2')
epoch:  63000 quantization_loss:  0.02885870821774006
p mean is: tensor(-1.7273, device='cuda:2')
epoch:  64000 quantization_loss:  0.02885037288069725
p mean is: tensor(-1.7295, device='cuda:2')
epoch:  65000 quantization_loss:  0.02883543074131012
p mean is: tensor(-1.7316, device='cuda:2')
epoch:  66000 quantization_loss:  0.028826531022787094
p mean is: tensor(-1.7336, device='cuda:2')
epoch:  67000 quantization_loss:  0.028815140947699547
p mean is: tensor(-1.7354, device='cuda:2')
epoch:  68000 quantization_loss:  0.02882024273276329
p mean is: tensor(-1.7371, device='cuda:2')
epoch:  69000 quantization_loss:  0.028812037780880928
p mean is: tensor(-1.7387, device='cuda:2')
epoch:  70000 quantization_loss:  0.02880416251718998
p mean is: tensor(-1.7403, device='cuda:2')
epoch:  71000 quantization_loss:  0.02880016155540943
p mean is: tensor(-1.7418, device='cuda:2')
epoch:  72000 quantization_loss:  0.028870778158307076
p mean is: tensor(-1.7431, device='cuda:2')
epoch:  73000 quantization_loss:  0.028797393664717674
p mean is: tensor(-1.7444, device='cuda:2')
epoch:  74000 quantization_loss:  0.028787465766072273
p mean is: tensor(-1.7457, device='cuda:2')
epoch:  75000 quantization_loss:  0.028786735609173775
p mean is: tensor(-1.7468, device='cuda:2')
epoch:  76000 quantization_loss:  0.028784198686480522
p mean is: tensor(-1.7480, device='cuda:2')
epoch:  77000 quantization_loss:  0.028778821229934692
p mean is: tensor(-1.7491, device='cuda:2')
epoch:  78000 quantization_loss:  0.028782857581973076
p mean is: tensor(-1.7501, device='cuda:2')
epoch:  79000 quantization_loss:  0.028773438185453415
p mean is: tensor(-1.7511, device='cuda:2')
here
1.1.1.weight         | nonzeros =      94 /   12800             (  0.73%) | total_pruned =   12706 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =      17 /    6400             (  0.27%) | total_pruned =    6383 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       5 /      16             ( 31.25%) | total_pruned =      11 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =       7 /   12800             (  0.05%) | total_pruned =   12793 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =       8 /      32             ( 25.00%) | total_pruned =      24 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =       6 /   25600             (  0.02%) | total_pruned =   25594 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =       9 /      32             ( 28.12%) | total_pruned =      23 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =       6 /   51200             (  0.01%) | total_pruned =   51194 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =       7 /  102400             (  0.01%) | total_pruned =  102393 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =       0 /  204800             (  0.00%) | total_pruned =  204800 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =       0 /  409600             (  0.00%) | total_pruned =  409600 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =       0 /  409600             (  0.00%) | total_pruned =  409600 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =      70 /  409600             (  0.02%) | total_pruned =  409530 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     504 /  409600             (  0.12%) | total_pruned =  409096 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    6938 /  409600             (  1.69%) | total_pruned =  402662 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   19135 /  147456             ( 12.98%) | total_pruned =  128321 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   24780 /  147456             ( 16.81%) | total_pruned =  122676 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   21559 /  147456             ( 14.62%) | total_pruned =  125897 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   11456 /   73728             ( 15.54%) | total_pruned =   62272 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    3248 /   18432             ( 17.62%) | total_pruned =   15184 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1257 /    4608             ( 27.28%) | total_pruned =    3351 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      29 /      48             ( 60.42%) | total_pruned =      19 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 90217, pruned : 2918650, total: 3008867, Compression rate :      33.35x  ( 97.00% pruned)
PSNR of output image is:  11.214423917795127
Experiment done
