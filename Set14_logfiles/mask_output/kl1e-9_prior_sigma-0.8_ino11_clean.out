(3, 512, 512)
Starting vanilla DIP on 11 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.31189423696143'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/11/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/clean_img/-0.8/1e-09
epoch:  0 quantization_loss:  0.06706246733665466
p mean is: tensor(-0.0001, device='cuda:4')
epoch:  1000 quantization_loss:  0.053917162120342255
p mean is: tensor(-0.0077, device='cuda:4')
epoch:  2000 quantization_loss:  0.050508853048086166
p mean is: tensor(-0.0145, device='cuda:4')
epoch:  3000 quantization_loss:  0.05147218331694603
p mean is: tensor(-0.0216, device='cuda:4')
epoch:  4000 quantization_loss:  0.0499223917722702
p mean is: tensor(-0.0293, device='cuda:4')
epoch:  5000 quantization_loss:  0.04972975701093674
p mean is: tensor(-0.0377, device='cuda:4')
epoch:  6000 quantization_loss:  0.049885574728250504
p mean is: tensor(-0.0465, device='cuda:4')
epoch:  7000 quantization_loss:  0.04414105787873268
p mean is: tensor(-0.0565, device='cuda:4')
epoch:  8000 quantization_loss:  0.04005122184753418
p mean is: tensor(-0.0680, device='cuda:4')
epoch:  9000 quantization_loss:  0.035291776061058044
p mean is: tensor(-0.0817, device='cuda:4')
epoch:  10000 quantization_loss:  0.03179728612303734
p mean is: tensor(-0.0983, device='cuda:4')
epoch:  11000 quantization_loss:  0.03010864555835724
p mean is: tensor(-0.1187, device='cuda:4')
epoch:  12000 quantization_loss:  0.02872202731668949
p mean is: tensor(-0.1442, device='cuda:4')
epoch:  13000 quantization_loss:  0.02663613110780716
p mean is: tensor(-0.1750, device='cuda:4')
epoch:  14000 quantization_loss:  0.02409954182803631
p mean is: tensor(-0.2109, device='cuda:4')
epoch:  15000 quantization_loss:  0.022688549011945724
p mean is: tensor(-0.2509, device='cuda:4')
epoch:  16000 quantization_loss:  0.02155468426644802
p mean is: tensor(-0.2941, device='cuda:4')
epoch:  17000 quantization_loss:  0.020998990163207054
p mean is: tensor(-0.3387, device='cuda:4')
epoch:  18000 quantization_loss:  0.020488210022449493
p mean is: tensor(-0.3830, device='cuda:4')
epoch:  19000 quantization_loss:  0.02000395394861698
p mean is: tensor(-0.4256, device='cuda:4')
epoch:  20000 quantization_loss:  0.01631280593574047
p mean is: tensor(-0.4649, device='cuda:4')
epoch:  21000 quantization_loss:  0.015977561473846436
p mean is: tensor(-0.5000, device='cuda:4')
epoch:  22000 quantization_loss:  0.01566448248922825
p mean is: tensor(-0.5314, device='cuda:4')
epoch:  23000 quantization_loss:  0.015430998988449574
p mean is: tensor(-0.5595, device='cuda:4')
epoch:  24000 quantization_loss:  0.01503776479512453
p mean is: tensor(-0.5841, device='cuda:4')
epoch:  25000 quantization_loss:  0.01501438207924366
p mean is: tensor(-0.6059, device='cuda:4')
epoch:  26000 quantization_loss:  0.014682574197649956
p mean is: tensor(-0.6251, device='cuda:4')
epoch:  27000 quantization_loss:  0.01448861788958311
p mean is: tensor(-0.6419, device='cuda:4')
epoch:  28000 quantization_loss:  0.014231676235795021
p mean is: tensor(-0.6567, device='cuda:4')
epoch:  29000 quantization_loss:  0.014106852933764458
p mean is: tensor(-0.6698, device='cuda:4')
epoch:  30000 quantization_loss:  0.014055915176868439
p mean is: tensor(-0.6812, device='cuda:4')
epoch:  31000 quantization_loss:  0.013920651748776436
p mean is: tensor(-0.6912, device='cuda:4')
epoch:  32000 quantization_loss:  0.013761227019131184
p mean is: tensor(-0.7002, device='cuda:4')
epoch:  33000 quantization_loss:  0.01365476381033659
p mean is: tensor(-0.7081, device='cuda:4')
epoch:  34000 quantization_loss:  0.01361072901636362
p mean is: tensor(-0.7151, device='cuda:4')
epoch:  35000 quantization_loss:  0.013535232283174992
p mean is: tensor(-0.7213, device='cuda:4')
epoch:  36000 quantization_loss:  0.013426074758172035
p mean is: tensor(-0.7269, device='cuda:4')
epoch:  37000 quantization_loss:  0.013155964203178883
p mean is: tensor(-0.7319, device='cuda:4')
epoch:  38000 quantization_loss:  0.013256300240755081
p mean is: tensor(-0.7363, device='cuda:4')
epoch:  39000 quantization_loss:  0.013044827617704868
p mean is: tensor(-0.7404, device='cuda:4')
epoch:  40000 quantization_loss:  0.012998562306165695
p mean is: tensor(-0.7441, device='cuda:4')
epoch:  41000 quantization_loss:  0.012918547727167606
p mean is: tensor(-0.7475, device='cuda:4')
epoch:  42000 quantization_loss:  0.01290758978575468
p mean is: tensor(-0.7506, device='cuda:4')
epoch:  43000 quantization_loss:  0.012882200069725513
p mean is: tensor(-0.7535, device='cuda:4')
epoch:  44000 quantization_loss:  0.012816023081541061
p mean is: tensor(-0.7561, device='cuda:4')
epoch:  45000 quantization_loss:  0.012796392664313316
p mean is: tensor(-0.7586, device='cuda:4')
epoch:  46000 quantization_loss:  0.012764906510710716
p mean is: tensor(-0.7609, device='cuda:4')
epoch:  47000 quantization_loss:  0.012742330320179462
p mean is: tensor(-0.7632, device='cuda:4')
epoch:  48000 quantization_loss:  0.01272423192858696
p mean is: tensor(-0.7653, device='cuda:4')
epoch:  49000 quantization_loss:  0.01270523201674223
p mean is: tensor(-0.7672, device='cuda:4')
epoch:  50000 quantization_loss:  0.012695426121354103
p mean is: tensor(-0.7691, device='cuda:4')
epoch:  51000 quantization_loss:  0.012691505253314972
p mean is: tensor(-0.7709, device='cuda:4')
epoch:  52000 quantization_loss:  0.012666227295994759
p mean is: tensor(-0.7725, device='cuda:4')
epoch:  53000 quantization_loss:  0.012731294147670269
p mean is: tensor(-0.7742, device='cuda:4')
epoch:  54000 quantization_loss:  0.012636600062251091
p mean is: tensor(-0.7757, device='cuda:4')
epoch:  55000 quantization_loss:  0.012634972110390663
p mean is: tensor(-0.7771, device='cuda:4')
epoch:  56000 quantization_loss:  0.012625031173229218
p mean is: tensor(-0.7785, device='cuda:4')
epoch:  57000 quantization_loss:  0.012590227648615837
p mean is: tensor(-0.7799, device='cuda:4')
epoch:  58000 quantization_loss:  0.012586831115186214
p mean is: tensor(-0.7811, device='cuda:4')
epoch:  59000 quantization_loss:  0.012581244111061096
p mean is: tensor(-0.7824, device='cuda:4')
epoch:  60000 quantization_loss:  0.012570913881063461
p mean is: tensor(-0.7836, device='cuda:4')
epoch:  61000 quantization_loss:  0.012568067759275436
p mean is: tensor(-0.7848, device='cuda:4')
epoch:  62000 quantization_loss:  0.012565108016133308
p mean is: tensor(-0.7859, device='cuda:4')
epoch:  63000 quantization_loss:  0.012554201297461987
p mean is: tensor(-0.7871, device='cuda:4')
epoch:  64000 quantization_loss:  0.01255641970783472
p mean is: tensor(-0.7881, device='cuda:4')
epoch:  65000 quantization_loss:  0.012541966512799263
p mean is: tensor(-0.7892, device='cuda:4')
epoch:  66000 quantization_loss:  0.012552421540021896
p mean is: tensor(-0.7902, device='cuda:4')
epoch:  67000 quantization_loss:  0.012538858689367771
p mean is: tensor(-0.7912, device='cuda:4')
epoch:  68000 quantization_loss:  0.012535817921161652
p mean is: tensor(-0.7921, device='cuda:4')
epoch:  69000 quantization_loss:  0.01252870261669159
p mean is: tensor(-0.7931, device='cuda:4')
epoch:  70000 quantization_loss:  0.012523687444627285
p mean is: tensor(-0.7940, device='cuda:4')
epoch:  71000 quantization_loss:  0.0125181395560503
p mean is: tensor(-0.7949, device='cuda:4')
epoch:  72000 quantization_loss:  0.012506674975156784
p mean is: tensor(-0.7957, device='cuda:4')
epoch:  73000 quantization_loss:  0.01261893380433321
p mean is: tensor(-0.7966, device='cuda:4')
epoch:  74000 quantization_loss:  0.01251106895506382
p mean is: tensor(-0.7974, device='cuda:4')
epoch:  75000 quantization_loss:  0.012508044019341469
p mean is: tensor(-0.7982, device='cuda:4')
epoch:  76000 quantization_loss:  0.012492094188928604
p mean is: tensor(-0.7990, device='cuda:4')
epoch:  77000 quantization_loss:  0.012500589713454247
p mean is: tensor(-0.7998, device='cuda:4')
epoch:  78000 quantization_loss:  0.012493441812694073
p mean is: tensor(-0.8004, device='cuda:4')
epoch:  79000 quantization_loss:  0.012491735629737377
p mean is: tensor(-0.8012, device='cuda:4')
here
1.1.1.weight         | nonzeros =    1839 /   12800             ( 14.37%) | total_pruned =   10961 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     167 /    6400             (  2.61%) | total_pruned =    6233 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       3 /      16             ( 18.75%) | total_pruned =      13 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      98 /   12800             (  0.77%) | total_pruned =   12702 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =       6 /      32             ( 18.75%) | total_pruned =      26 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     317 /   25600             (  1.24%) | total_pruned =   25283 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      12 /      32             ( 37.50%) | total_pruned =      20 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     350 /   51200             (  0.68%) | total_pruned =   50850 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     753 /  102400             (  0.74%) | total_pruned =  101647 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     633 /  204800             (  0.31%) | total_pruned =  204167 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =    1487 /  409600             (  0.36%) | total_pruned =  408113 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    2108 /  409600             (  0.51%) | total_pruned =  407492 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    8504 /  409600             (  2.08%) | total_pruned =  401096 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   20734 /  409600             (  5.06%) | total_pruned =  388866 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   55541 /  409600             ( 13.56%) | total_pruned =  354059 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   34392 /  147456             ( 23.32%) | total_pruned =  113064 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   25382 /  147456             ( 17.21%) | total_pruned =  122074 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   21477 /  147456             ( 14.57%) | total_pruned =  125979 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   12170 /   73728             ( 16.51%) | total_pruned =   61558 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2819 /   18432             ( 15.29%) | total_pruned =   15613 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1108 /    4608             ( 24.05%) | total_pruned =    3500 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      32 /      48             ( 66.67%) | total_pruned =      16 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 191164, pruned : 2817703, total: 3008867, Compression rate :      15.74x  ( 93.65% pruned)
PSNR of output image is:  19.125191600234462
Experiment done
