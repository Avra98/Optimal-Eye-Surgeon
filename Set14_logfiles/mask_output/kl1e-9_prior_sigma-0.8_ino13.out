(3, 512, 512)
Starting vanilla DIP on 13 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.489041845979973'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/13/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-0.8/1e-09
epoch:  0 quantization_loss:  0.07954944670200348
p mean is: tensor(-0.0001, device='cuda:4')
epoch:  1000 quantization_loss:  0.06281659752130508
p mean is: tensor(-0.0052, device='cuda:4')
epoch:  2000 quantization_loss:  0.06355585902929306
p mean is: tensor(-0.0082, device='cuda:4')
epoch:  3000 quantization_loss:  0.061814069747924805
p mean is: tensor(-0.0113, device='cuda:4')
epoch:  4000 quantization_loss:  0.062158890068531036
p mean is: tensor(-0.0143, device='cuda:4')
epoch:  5000 quantization_loss:  0.06178883835673332
p mean is: tensor(-0.0174, device='cuda:4')
epoch:  6000 quantization_loss:  0.061473239213228226
p mean is: tensor(-0.0204, device='cuda:4')
epoch:  7000 quantization_loss:  0.05920220911502838
p mean is: tensor(-0.0239, device='cuda:4')
epoch:  8000 quantization_loss:  0.05311868339776993
p mean is: tensor(-0.0276, device='cuda:4')
epoch:  9000 quantization_loss:  0.04453303664922714
p mean is: tensor(-0.0323, device='cuda:4')
epoch:  10000 quantization_loss:  0.04017570614814758
p mean is: tensor(-0.0381, device='cuda:4')
epoch:  11000 quantization_loss:  0.03716563060879707
p mean is: tensor(-0.0463, device='cuda:4')
epoch:  12000 quantization_loss:  0.03191555291414261
p mean is: tensor(-0.0568, device='cuda:4')
epoch:  13000 quantization_loss:  0.030822860077023506
p mean is: tensor(-0.0708, device='cuda:4')
epoch:  14000 quantization_loss:  0.028829969465732574
p mean is: tensor(-0.0886, device='cuda:4')
epoch:  15000 quantization_loss:  0.027828671038150787
p mean is: tensor(-0.1106, device='cuda:4')
epoch:  16000 quantization_loss:  0.02629357948899269
p mean is: tensor(-0.1377, device='cuda:4')
epoch:  17000 quantization_loss:  0.0259871743619442
p mean is: tensor(-0.1700, device='cuda:4')
epoch:  18000 quantization_loss:  0.025394611060619354
p mean is: tensor(-0.2074, device='cuda:4')
epoch:  19000 quantization_loss:  0.024694139137864113
p mean is: tensor(-0.2490, device='cuda:4')
epoch:  20000 quantization_loss:  0.024470485746860504
p mean is: tensor(-0.2932, device='cuda:4')
epoch:  21000 quantization_loss:  0.024293627589941025
p mean is: tensor(-0.3382, device='cuda:4')
epoch:  22000 quantization_loss:  0.023119818419218063
p mean is: tensor(-0.3821, device='cuda:4')
epoch:  23000 quantization_loss:  0.02262507937848568
p mean is: tensor(-0.4236, device='cuda:4')
epoch:  24000 quantization_loss:  0.02238457463681698
p mean is: tensor(-0.4617, device='cuda:4')
epoch:  25000 quantization_loss:  0.02222535014152527
p mean is: tensor(-0.4961, device='cuda:4')
epoch:  26000 quantization_loss:  0.022057365626096725
p mean is: tensor(-0.5268, device='cuda:4')
epoch:  27000 quantization_loss:  0.021888308227062225
p mean is: tensor(-0.5540, device='cuda:4')
epoch:  28000 quantization_loss:  0.021878574043512344
p mean is: tensor(-0.5783, device='cuda:4')
epoch:  29000 quantization_loss:  0.021718710660934448
p mean is: tensor(-0.5996, device='cuda:4')
epoch:  30000 quantization_loss:  0.021658414974808693
p mean is: tensor(-0.6185, device='cuda:4')
epoch:  31000 quantization_loss:  0.021505504846572876
p mean is: tensor(-0.6351, device='cuda:4')
epoch:  32000 quantization_loss:  0.0214215237647295
p mean is: tensor(-0.6494, device='cuda:4')
epoch:  33000 quantization_loss:  0.02139277569949627
p mean is: tensor(-0.6623, device='cuda:4')
epoch:  34000 quantization_loss:  0.021240105852484703
p mean is: tensor(-0.6736, device='cuda:4')
epoch:  35000 quantization_loss:  0.02119411528110504
p mean is: tensor(-0.6835, device='cuda:4')
epoch:  36000 quantization_loss:  0.021134065464138985
p mean is: tensor(-0.6924, device='cuda:4')
epoch:  37000 quantization_loss:  0.021093767136335373
p mean is: tensor(-0.7003, device='cuda:4')
epoch:  38000 quantization_loss:  0.021018726751208305
p mean is: tensor(-0.7074, device='cuda:4')
epoch:  39000 quantization_loss:  0.02101006731390953
p mean is: tensor(-0.7136, device='cuda:4')
epoch:  40000 quantization_loss:  0.020968109369277954
p mean is: tensor(-0.7193, device='cuda:4')
epoch:  41000 quantization_loss:  0.02090533636510372
p mean is: tensor(-0.7242, device='cuda:4')
epoch:  42000 quantization_loss:  0.020946603268384933
p mean is: tensor(-0.7287, device='cuda:4')
epoch:  43000 quantization_loss:  0.02080993726849556
p mean is: tensor(-0.7328, device='cuda:4')
epoch:  44000 quantization_loss:  0.02081027254462242
p mean is: tensor(-0.7366, device='cuda:4')
epoch:  45000 quantization_loss:  0.020775917917490005
p mean is: tensor(-0.7401, device='cuda:4')
epoch:  46000 quantization_loss:  0.020767614245414734
p mean is: tensor(-0.7431, device='cuda:4')
epoch:  47000 quantization_loss:  0.020711440593004227
p mean is: tensor(-0.7460, device='cuda:4')
epoch:  48000 quantization_loss:  0.020694682374596596
p mean is: tensor(-0.7485, device='cuda:4')
epoch:  49000 quantization_loss:  0.020670432597398758
p mean is: tensor(-0.7509, device='cuda:4')
epoch:  50000 quantization_loss:  0.020654480904340744
p mean is: tensor(-0.7531, device='cuda:4')
epoch:  51000 quantization_loss:  0.0206293947994709
p mean is: tensor(-0.7552, device='cuda:4')
epoch:  52000 quantization_loss:  0.020626861602067947
p mean is: tensor(-0.7571, device='cuda:4')
epoch:  53000 quantization_loss:  0.02061348594725132
p mean is: tensor(-0.7589, device='cuda:4')
epoch:  54000 quantization_loss:  0.02060888521373272
p mean is: tensor(-0.7606, device='cuda:4')
epoch:  55000 quantization_loss:  0.020575914531946182
p mean is: tensor(-0.7623, device='cuda:4')
epoch:  56000 quantization_loss:  0.020560109987854958
p mean is: tensor(-0.7638, device='cuda:4')
epoch:  57000 quantization_loss:  0.020539967343211174
p mean is: tensor(-0.7653, device='cuda:4')
epoch:  58000 quantization_loss:  0.020542342215776443
p mean is: tensor(-0.7666, device='cuda:4')
epoch:  59000 quantization_loss:  0.02053322270512581
p mean is: tensor(-0.7680, device='cuda:4')
epoch:  60000 quantization_loss:  0.020522557199001312
p mean is: tensor(-0.7692, device='cuda:4')
epoch:  61000 quantization_loss:  0.020510094240307808
p mean is: tensor(-0.7704, device='cuda:4')
epoch:  62000 quantization_loss:  0.020506013184785843
p mean is: tensor(-0.7716, device='cuda:4')
epoch:  63000 quantization_loss:  0.020515477284789085
p mean is: tensor(-0.7727, device='cuda:4')
epoch:  64000 quantization_loss:  0.020508453249931335
p mean is: tensor(-0.7738, device='cuda:4')
epoch:  65000 quantization_loss:  0.02049119584262371
p mean is: tensor(-0.7749, device='cuda:4')
epoch:  66000 quantization_loss:  0.020480811595916748
p mean is: tensor(-0.7758, device='cuda:4')
epoch:  67000 quantization_loss:  0.020480886101722717
p mean is: tensor(-0.7768, device='cuda:4')
epoch:  68000 quantization_loss:  0.020472319796681404
p mean is: tensor(-0.7777, device='cuda:4')
epoch:  69000 quantization_loss:  0.02046172320842743
p mean is: tensor(-0.7786, device='cuda:4')
epoch:  70000 quantization_loss:  0.02045341022312641
p mean is: tensor(-0.7795, device='cuda:4')
epoch:  71000 quantization_loss:  0.02045075222849846
p mean is: tensor(-0.7803, device='cuda:4')
epoch:  72000 quantization_loss:  0.02045990712940693
p mean is: tensor(-0.7811, device='cuda:4')
epoch:  73000 quantization_loss:  0.020443780347704887
p mean is: tensor(-0.7819, device='cuda:4')
epoch:  74000 quantization_loss:  0.020441267639398575
p mean is: tensor(-0.7827, device='cuda:4')
epoch:  75000 quantization_loss:  0.020477190613746643
p mean is: tensor(-0.7834, device='cuda:4')
epoch:  76000 quantization_loss:  0.020435217767953873
p mean is: tensor(-0.7840, device='cuda:4')
epoch:  77000 quantization_loss:  0.0204294603317976
p mean is: tensor(-0.7847, device='cuda:4')
epoch:  78000 quantization_loss:  0.02042815461754799
p mean is: tensor(-0.7853, device='cuda:4')
epoch:  79000 quantization_loss:  0.020429516211152077
p mean is: tensor(-0.7860, device='cuda:4')
here
1.1.1.weight         | nonzeros =    1222 /   12800             (  9.55%) | total_pruned =   11578 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     152 /    6400             (  2.38%) | total_pruned =    6248 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     184 /   12800             (  1.44%) | total_pruned =   12616 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     375 /   25600             (  1.46%) | total_pruned =   25225 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     351 /   51200             (  0.69%) | total_pruned =   50849 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     614 /  102400             (  0.60%) | total_pruned =  101786 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     306 /  204800             (  0.15%) | total_pruned =  204494 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     715 /  409600             (  0.17%) | total_pruned =  408885 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    1406 /  409600             (  0.34%) | total_pruned =  408194 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    6290 /  409600             (  1.54%) | total_pruned =  403310 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   17770 /  409600             (  4.34%) | total_pruned =  391830 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   45792 /  409600             ( 11.18%) | total_pruned =  363808 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   33106 /  147456             ( 22.45%) | total_pruned =  114350 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   33605 /  147456             ( 22.79%) | total_pruned =  113851 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   24798 /  147456             ( 16.82%) | total_pruned =  122658 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    9542 /   73728             ( 12.94%) | total_pruned =   64186 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    3551 /   18432             ( 19.27%) | total_pruned =   14881 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      26 /      32             ( 81.25%) | total_pruned =       6 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      26 /      32             ( 81.25%) | total_pruned =       6 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1670 /    4608             ( 36.24%) | total_pruned =    2938 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      29 /      48             ( 60.42%) | total_pruned =      19 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 182835, pruned : 2826032, total: 3008867, Compression rate :      16.46x  ( 93.92% pruned)
PSNR of output image is:  18.579221420664943
Experiment done
