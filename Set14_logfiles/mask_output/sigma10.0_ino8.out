(3, 512, 512)
Noisy PSNR is '21.64112411802208'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/8/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/10.0/1e-09
epoch:  0 quantization_loss:  0.18259452283382416
p mean is: tensor(0.0014, device='cuda:1')
epoch:  1000 quantization_loss:  0.15259279310703278
p mean is: tensor(0.0502, device='cuda:1')
epoch:  2000 quantization_loss:  0.14812996983528137
p mean is: tensor(0.0794, device='cuda:1')
epoch:  3000 quantization_loss:  0.14745067059993744
p mean is: tensor(0.1061, device='cuda:1')
epoch:  4000 quantization_loss:  0.151149183511734
p mean is: tensor(0.1317, device='cuda:1')
epoch:  5000 quantization_loss:  0.14440244436264038
p mean is: tensor(0.1567, device='cuda:1')
epoch:  6000 quantization_loss:  0.1428905874490738
p mean is: tensor(0.1818, device='cuda:1')
epoch:  7000 quantization_loss:  0.13862833380699158
p mean is: tensor(0.2065, device='cuda:1')
epoch:  8000 quantization_loss:  0.12431244552135468
p mean is: tensor(0.2342, device='cuda:1')
epoch:  9000 quantization_loss:  0.11424002796411514
p mean is: tensor(0.2706, device='cuda:1')
epoch:  10000 quantization_loss:  0.11061606556177139
p mean is: tensor(0.3214, device='cuda:1')
epoch:  11000 quantization_loss:  0.10931863635778427
p mean is: tensor(0.3924, device='cuda:1')
epoch:  12000 quantization_loss:  0.10570324212312698
p mean is: tensor(0.4901, device='cuda:1')
epoch:  13000 quantization_loss:  0.10367043316364288
p mean is: tensor(0.6200, device='cuda:1')
epoch:  14000 quantization_loss:  0.10062835365533829
p mean is: tensor(0.7876, device='cuda:1')
epoch:  15000 quantization_loss:  0.09894047677516937
p mean is: tensor(0.9959, device='cuda:1')
epoch:  16000 quantization_loss:  0.09692435711622238
p mean is: tensor(1.2418, device='cuda:1')
epoch:  17000 quantization_loss:  0.09606713801622391
p mean is: tensor(1.5152, device='cuda:1')
epoch:  18000 quantization_loss:  0.0938572883605957
p mean is: tensor(1.8003, device='cuda:1')
epoch:  19000 quantization_loss:  0.09235542267560959
p mean is: tensor(2.0797, device='cuda:1')
epoch:  20000 quantization_loss:  0.09165680408477783
p mean is: tensor(2.3403, device='cuda:1')
epoch:  21000 quantization_loss:  0.09063207358121872
p mean is: tensor(2.5765, device='cuda:1')
epoch:  22000 quantization_loss:  0.0906326174736023
p mean is: tensor(2.7870, device='cuda:1')
epoch:  23000 quantization_loss:  0.08591805398464203
p mean is: tensor(2.9710, device='cuda:1')
epoch:  24000 quantization_loss:  0.08475208282470703
p mean is: tensor(3.1317, device='cuda:1')
epoch:  25000 quantization_loss:  0.08425214141607285
p mean is: tensor(3.2744, device='cuda:1')
epoch:  26000 quantization_loss:  0.0839371308684349
p mean is: tensor(3.4028, device='cuda:1')
epoch:  27000 quantization_loss:  0.0836448073387146
p mean is: tensor(3.5192, device='cuda:1')
epoch:  28000 quantization_loss:  0.08347408473491669
p mean is: tensor(3.6253, device='cuda:1')
epoch:  29000 quantization_loss:  0.08325757831335068
p mean is: tensor(3.7226, device='cuda:1')
epoch:  30000 quantization_loss:  0.0830083116889
p mean is: tensor(3.8122, device='cuda:1')
epoch:  31000 quantization_loss:  0.08291482925415039
p mean is: tensor(3.8952, device='cuda:1')
epoch:  32000 quantization_loss:  0.08273325115442276
p mean is: tensor(3.9723, device='cuda:1')
epoch:  33000 quantization_loss:  0.08261452615261078
p mean is: tensor(4.0441, device='cuda:1')
epoch:  34000 quantization_loss:  0.08251646161079407
p mean is: tensor(4.1115, device='cuda:1')
epoch:  35000 quantization_loss:  0.08242671191692352
p mean is: tensor(4.1746, device='cuda:1')
epoch:  36000 quantization_loss:  0.08231350034475327
p mean is: tensor(4.2342, device='cuda:1')
epoch:  37000 quantization_loss:  0.08224722743034363
p mean is: tensor(4.2906, device='cuda:1')
epoch:  38000 quantization_loss:  0.08218817412853241
p mean is: tensor(4.3441, device='cuda:1')
epoch:  39000 quantization_loss:  0.08211781829595566
p mean is: tensor(4.3950, device='cuda:1')
epoch:  40000 quantization_loss:  0.08202412724494934
p mean is: tensor(4.4434, device='cuda:1')
epoch:  41000 quantization_loss:  0.08201117813587189
p mean is: tensor(4.4896, device='cuda:1')
epoch:  42000 quantization_loss:  0.08194085210561752
p mean is: tensor(4.5339, device='cuda:1')
epoch:  43000 quantization_loss:  0.08191173523664474
p mean is: tensor(4.5762, device='cuda:1')
epoch:  44000 quantization_loss:  0.08191428333520889
p mean is: tensor(4.6169, device='cuda:1')
epoch:  45000 quantization_loss:  0.08181524276733398
p mean is: tensor(4.6559, device='cuda:1')
epoch:  46000 quantization_loss:  0.08178956806659698
p mean is: tensor(4.6934, device='cuda:1')
epoch:  47000 quantization_loss:  0.08176226913928986
p mean is: tensor(4.7297, device='cuda:1')
epoch:  48000 quantization_loss:  0.08174411952495575
p mean is: tensor(4.7647, device='cuda:1')
epoch:  49000 quantization_loss:  0.08170291781425476
p mean is: tensor(4.7984, device='cuda:1')
epoch:  50000 quantization_loss:  0.08167682588100433
p mean is: tensor(4.8311, device='cuda:1')
epoch:  51000 quantization_loss:  0.08167523890733719
p mean is: tensor(4.8628, device='cuda:1')
epoch:  52000 quantization_loss:  0.08163954317569733
p mean is: tensor(4.8935, device='cuda:1')
epoch:  53000 quantization_loss:  0.08162680268287659
p mean is: tensor(4.9232, device='cuda:1')
epoch:  54000 quantization_loss:  0.08162225037813187
p mean is: tensor(4.9519, device='cuda:1')
epoch:  55000 quantization_loss:  0.08159738034009933
p mean is: tensor(4.9799, device='cuda:1')
epoch:  56000 quantization_loss:  0.08158408105373383
p mean is: tensor(5.0071, device='cuda:1')
epoch:  57000 quantization_loss:  0.08157766610383987
p mean is: tensor(5.0335, device='cuda:1')
epoch:  58000 quantization_loss:  0.0815601497888565
p mean is: tensor(5.0592, device='cuda:1')
epoch:  59000 quantization_loss:  0.08154939860105515
p mean is: tensor(5.0842, device='cuda:1')
epoch:  60000 quantization_loss:  0.08152881264686584
p mean is: tensor(5.1086, device='cuda:1')
epoch:  61000 quantization_loss:  0.08152472227811813
p mean is: tensor(5.1324, device='cuda:1')
epoch:  62000 quantization_loss:  0.08151987940073013
p mean is: tensor(5.1556, device='cuda:1')
epoch:  63000 quantization_loss:  0.08150787651538849
p mean is: tensor(5.1782, device='cuda:1')
epoch:  64000 quantization_loss:  0.08150541037321091
p mean is: tensor(5.2004, device='cuda:1')
epoch:  65000 quantization_loss:  0.08149109035730362
p mean is: tensor(5.2220, device='cuda:1')
epoch:  66000 quantization_loss:  0.08148147165775299
p mean is: tensor(5.2432, device='cuda:1')
epoch:  67000 quantization_loss:  0.0814765989780426
p mean is: tensor(5.2639, device='cuda:1')
epoch:  68000 quantization_loss:  0.08147154003381729
p mean is: tensor(5.2841, device='cuda:1')
epoch:  69000 quantization_loss:  0.08147434890270233
p mean is: tensor(5.3039, device='cuda:1')
epoch:  70000 quantization_loss:  0.08146005123853683
p mean is: tensor(5.3233, device='cuda:1')
epoch:  71000 quantization_loss:  0.08145405352115631
p mean is: tensor(5.3422, device='cuda:1')
epoch:  72000 quantization_loss:  0.08145322650671005
p mean is: tensor(5.3608, device='cuda:1')
epoch:  73000 quantization_loss:  0.08152300864458084
p mean is: tensor(5.3790, device='cuda:1')
epoch:  74000 quantization_loss:  0.08143595606088638
p mean is: tensor(5.3968, device='cuda:1')
epoch:  75000 quantization_loss:  0.0814470648765564
p mean is: tensor(5.4144, device='cuda:1')
epoch:  76000 quantization_loss:  0.08149657398462296
p mean is: tensor(5.4315, device='cuda:1')
epoch:  77000 quantization_loss:  0.08143758773803711
p mean is: tensor(5.4484, device='cuda:1')
epoch:  78000 quantization_loss:  0.08145984262228012
p mean is: tensor(5.4650, device='cuda:1')
epoch:  79000 quantization_loss:  0.08141952753067017
p mean is: tensor(5.4812, device='cuda:1')
1.1.1.weight         | nonzeros =   12333 /   12800             ( 96.35%) | total_pruned =     467 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.2.weight           | nonzeros =      12 /      16             ( 75.00%) | total_pruned =       4 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =    6297 /    6400             ( 98.39%) | total_pruned =     103 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.5.weight           | nonzeros =      14 /      16             ( 87.50%) | total_pruned =       2 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =   12744 /   12800             ( 99.56%) | total_pruned =      56 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =   25552 /   25600             ( 99.81%) | total_pruned =      48 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =   51132 /   51200             ( 99.87%) | total_pruned =      68 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =  102287 /  102400             ( 99.89%) | total_pruned =     113 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =  204682 /  204800             ( 99.94%) | total_pruned =     118 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =  409345 /  409600             ( 99.94%) | total_pruned =     255 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  409112 /  409600             ( 99.88%) | total_pruned =     488 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  408357 /  409600             ( 99.70%) | total_pruned =    1243 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  407028 /  409600             ( 99.37%) | total_pruned =    2572 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  401505 /  409600             ( 98.02%) | total_pruned =    8095 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     117 /     128             ( 91.41%) | total_pruned =      11 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  130141 /  147456             ( 88.26%) | total_pruned =   17315 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  131301 /  147456             ( 89.04%) | total_pruned =   16155 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =  135143 /  147456             ( 91.65%) | total_pruned =   12313 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   67651 /   73728             ( 91.76%) | total_pruned =    6077 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =   16144 /   18432             ( 87.59%) | total_pruned =    2288 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      28 /      32             ( 87.50%) | total_pruned =       4 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    3426 /    4608             ( 74.35%) | total_pruned =    1182 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      15 /      16             ( 93.75%) | total_pruned =       1 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      28 /      48             ( 58.33%) | total_pruned =      20 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 2937149, pruned : 71718, total: 3008867, Compression rate :       1.02x  (  2.38% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  10.529273775253593
Experiment done
