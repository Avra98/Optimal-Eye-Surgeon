Starting vanilla DIP on 0 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '19.673499509960717'
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/0/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-1.0/1e-09
epoch:  0 quantization_loss:  0.09223496168851852
p mean is: tensor(-0.0002, device='cuda:4')
epoch:  1000 quantization_loss:  0.07262393832206726
p mean is: tensor(-0.0074, device='cuda:4')
epoch:  2000 quantization_loss:  0.07224120199680328
p mean is: tensor(-0.0137, device='cuda:4')
epoch:  3000 quantization_loss:  0.07106087356805801
p mean is: tensor(-0.0196, device='cuda:4')
epoch:  4000 quantization_loss:  0.0708942636847496
p mean is: tensor(-0.0261, device='cuda:4')
epoch:  5000 quantization_loss:  0.0704769566655159
p mean is: tensor(-0.0326, device='cuda:4')
epoch:  6000 quantization_loss:  0.07062346488237381
p mean is: tensor(-0.0395, device='cuda:4')
epoch:  7000 quantization_loss:  0.07143261283636093
p mean is: tensor(-0.0466, device='cuda:4')
epoch:  8000 quantization_loss:  0.07029403746128082
p mean is: tensor(-0.0546, device='cuda:4')
epoch:  9000 quantization_loss:  0.06961267441511154
p mean is: tensor(-0.0633, device='cuda:4')
epoch:  10000 quantization_loss:  0.06720241904258728
p mean is: tensor(-0.0735, device='cuda:4')
epoch:  11000 quantization_loss:  0.06006399169564247
p mean is: tensor(-0.0857, device='cuda:4')
epoch:  12000 quantization_loss:  0.0571516789495945
p mean is: tensor(-0.1004, device='cuda:4')
epoch:  13000 quantization_loss:  0.052018072456121445
p mean is: tensor(-0.1185, device='cuda:4')
epoch:  14000 quantization_loss:  0.04411431774497032
p mean is: tensor(-0.1405, device='cuda:4')
epoch:  15000 quantization_loss:  0.04081850126385689
p mean is: tensor(-0.1674, device='cuda:4')
epoch:  16000 quantization_loss:  0.03960059583187103
p mean is: tensor(-0.2000, device='cuda:4')
epoch:  17000 quantization_loss:  0.0378543958067894
p mean is: tensor(-0.2391, device='cuda:4')
epoch:  18000 quantization_loss:  0.03682369366288185
p mean is: tensor(-0.2839, device='cuda:4')
epoch:  19000 quantization_loss:  0.0360889658331871
p mean is: tensor(-0.3332, device='cuda:4')
epoch:  20000 quantization_loss:  0.035700272768735886
p mean is: tensor(-0.3850, device='cuda:4')
epoch:  21000 quantization_loss:  0.03540559485554695
p mean is: tensor(-0.4378, device='cuda:4')
epoch:  22000 quantization_loss:  0.03517404571175575
p mean is: tensor(-0.4894, device='cuda:4')
epoch:  23000 quantization_loss:  0.03468587249517441
p mean is: tensor(-0.5386, device='cuda:4')
epoch:  24000 quantization_loss:  0.03404516726732254
p mean is: tensor(-0.5839, device='cuda:4')
epoch:  25000 quantization_loss:  0.033825285732746124
p mean is: tensor(-0.6251, device='cuda:4')
epoch:  26000 quantization_loss:  0.0330868624150753
p mean is: tensor(-0.6623, device='cuda:4')
epoch:  27000 quantization_loss:  0.03302815929055214
p mean is: tensor(-0.6955, device='cuda:4')
epoch:  28000 quantization_loss:  0.03287798538804054
p mean is: tensor(-0.7250, device='cuda:4')
epoch:  29000 quantization_loss:  0.03274856507778168
p mean is: tensor(-0.7512, device='cuda:4')
epoch:  30000 quantization_loss:  0.0326046384871006
p mean is: tensor(-0.7745, device='cuda:4')
epoch:  31000 quantization_loss:  0.03251459822058678
p mean is: tensor(-0.7952, device='cuda:4')
epoch:  32000 quantization_loss:  0.032304853200912476
p mean is: tensor(-0.8136, device='cuda:4')
epoch:  33000 quantization_loss:  0.032085057348012924
p mean is: tensor(-0.8300, device='cuda:4')
epoch:  34000 quantization_loss:  0.03198346868157387
p mean is: tensor(-0.8443, device='cuda:4')
epoch:  35000 quantization_loss:  0.03186928853392601
p mean is: tensor(-0.8571, device='cuda:4')
epoch:  36000 quantization_loss:  0.03183434531092644
p mean is: tensor(-0.8685, device='cuda:4')
epoch:  37000 quantization_loss:  0.031749177724123
p mean is: tensor(-0.8787, device='cuda:4')
epoch:  38000 quantization_loss:  0.03169212490320206
p mean is: tensor(-0.8878, device='cuda:4')
epoch:  39000 quantization_loss:  0.03164074569940567
p mean is: tensor(-0.8959, device='cuda:4')
epoch:  40000 quantization_loss:  0.03157741203904152
p mean is: tensor(-0.9034, device='cuda:4')
epoch:  41000 quantization_loss:  0.03158950433135033
p mean is: tensor(-0.9100, device='cuda:4')
epoch:  42000 quantization_loss:  0.031577032059431076
p mean is: tensor(-0.9161, device='cuda:4')
epoch:  43000 quantization_loss:  0.03148000314831734
p mean is: tensor(-0.9216, device='cuda:4')
epoch:  44000 quantization_loss:  0.031428366899490356
p mean is: tensor(-0.9267, device='cuda:4')
epoch:  45000 quantization_loss:  0.03132007271051407
p mean is: tensor(-0.9314, device='cuda:4')
epoch:  46000 quantization_loss:  0.03129548206925392
p mean is: tensor(-0.9357, device='cuda:4')
epoch:  47000 quantization_loss:  0.031270090490579605
p mean is: tensor(-0.9397, device='cuda:4')
epoch:  48000 quantization_loss:  0.03133520856499672
p mean is: tensor(-0.9433, device='cuda:4')
epoch:  49000 quantization_loss:  0.031238777562975883
p mean is: tensor(-0.9467, device='cuda:4')
here
1.1.1.weight         | nonzeros =    1604 /   12800             ( 12.53%) | total_pruned =   11196 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     351 /    6400             (  5.48%) | total_pruned =    6049 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     286 /   12800             (  2.23%) | total_pruned =   12514 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     363 /   25600             (  1.42%) | total_pruned =   25237 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     295 /   51200             (  0.58%) | total_pruned =   50905 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     527 /  102400             (  0.51%) | total_pruned =  101873 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     341 /  204800             (  0.17%) | total_pruned =  204459 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     698 /  409600             (  0.17%) | total_pruned =  408902 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     796 /  409600             (  0.19%) | total_pruned =  408804 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    4729 /  409600             (  1.15%) | total_pruned =  404871 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   17135 /  409600             (  4.18%) | total_pruned =  392465 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   53723 /  409600             ( 13.12%) | total_pruned =  355877 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   30679 /  147456             ( 20.81%) | total_pruned =  116777 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   26547 /  147456             ( 18.00%) | total_pruned =  120909 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   23916 /  147456             ( 16.22%) | total_pruned =  123540 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    8218 /   73728             ( 11.15%) | total_pruned =   65510 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2015 /   18432             ( 10.93%) | total_pruned =   16417 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1116 /    4608             ( 24.22%) | total_pruned =    3492 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      26 /      48             ( 54.17%) | total_pruned =      22 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 174691, pruned : 2834176, total: 3008867, Compression rate :      17.22x  ( 94.19% pruned)
PSNR of output image is:  15.685666967017916
(3, 512, 512) (1, 3, 512, 512) (3, 512, 512)
Experiment done
(3, 512, 512)
Starting vanilla DIP on 0 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '19.66518574375472'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/0/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-1.0/1e-09
epoch:  0 quantization_loss:  0.0801631361246109
p mean is: tensor(-0.0002, device='cuda:1')
epoch:  1000 quantization_loss:  0.07122671604156494
p mean is: tensor(-0.0075, device='cuda:1')
epoch:  2000 quantization_loss:  0.07064267247915268
p mean is: tensor(-0.0132, device='cuda:1')
epoch:  3000 quantization_loss:  0.06720321625471115
p mean is: tensor(-0.0197, device='cuda:1')
epoch:  4000 quantization_loss:  0.06729480624198914
p mean is: tensor(-0.0264, device='cuda:1')
epoch:  5000 quantization_loss:  0.06719198077917099
p mean is: tensor(-0.0336, device='cuda:1')
epoch:  6000 quantization_loss:  0.06574349105358124
p mean is: tensor(-0.0412, device='cuda:1')
epoch:  7000 quantization_loss:  0.0653858631849289
p mean is: tensor(-0.0491, device='cuda:1')
epoch:  8000 quantization_loss:  0.06528908759355545
p mean is: tensor(-0.0582, device='cuda:1')
epoch:  9000 quantization_loss:  0.06500241160392761
p mean is: tensor(-0.0682, device='cuda:1')
epoch:  10000 quantization_loss:  0.06454666703939438
p mean is: tensor(-0.0791, device='cuda:1')
epoch:  11000 quantization_loss:  0.059537194669246674
p mean is: tensor(-0.0916, device='cuda:1')
epoch:  12000 quantization_loss:  0.05135047063231468
p mean is: tensor(-0.1063, device='cuda:1')
epoch:  13000 quantization_loss:  0.044756822288036346
p mean is: tensor(-0.1236, device='cuda:1')
epoch:  14000 quantization_loss:  0.039026450365781784
p mean is: tensor(-0.1446, device='cuda:1')
epoch:  15000 quantization_loss:  0.03386559709906578
p mean is: tensor(-0.1699, device='cuda:1')
epoch:  16000 quantization_loss:  0.03127525374293327
p mean is: tensor(-0.2008, device='cuda:1')
epoch:  17000 quantization_loss:  0.030097095295786858
p mean is: tensor(-0.2380, device='cuda:1')
epoch:  18000 quantization_loss:  0.029652690514922142
p mean is: tensor(-0.2815, device='cuda:1')
epoch:  19000 quantization_loss:  0.02902698516845703
p mean is: tensor(-0.3304, device='cuda:1')
epoch:  20000 quantization_loss:  0.02884010411798954
p mean is: tensor(-0.3831, device='cuda:1')
epoch:  21000 quantization_loss:  0.028497960418462753
p mean is: tensor(-0.4376, device='cuda:1')
epoch:  22000 quantization_loss:  0.028118962422013283
p mean is: tensor(-0.4914, device='cuda:1')
epoch:  23000 quantization_loss:  0.027859410271048546
p mean is: tensor(-0.5427, device='cuda:1')
epoch:  24000 quantization_loss:  0.027234939858317375
p mean is: tensor(-0.5905, device='cuda:1')
epoch:  25000 quantization_loss:  0.027061427012085915
p mean is: tensor(-0.6338, device='cuda:1')
epoch:  26000 quantization_loss:  0.026876356452703476
p mean is: tensor(-0.6726, device='cuda:1')
epoch:  27000 quantization_loss:  0.026691053062677383
p mean is: tensor(-0.7071, device='cuda:1')
epoch:  28000 quantization_loss:  0.026673385873436928
p mean is: tensor(-0.7376, device='cuda:1')
epoch:  29000 quantization_loss:  0.026546157896518707
p mean is: tensor(-0.7644, device='cuda:1')
epoch:  30000 quantization_loss:  0.026466038078069687
p mean is: tensor(-0.7880, device='cuda:1')
epoch:  31000 quantization_loss:  0.026409104466438293
p mean is: tensor(-0.8087, device='cuda:1')
epoch:  32000 quantization_loss:  0.026324044913053513
p mean is: tensor(-0.8270, device='cuda:1')
epoch:  33000 quantization_loss:  0.026310766115784645
p mean is: tensor(-0.8431, device='cuda:1')
epoch:  34000 quantization_loss:  0.026220135390758514
p mean is: tensor(-0.8572, device='cuda:1')
epoch:  35000 quantization_loss:  0.026164637878537178
p mean is: tensor(-0.8697, device='cuda:1')
epoch:  36000 quantization_loss:  0.026119548827409744
p mean is: tensor(-0.8807, device='cuda:1')
epoch:  37000 quantization_loss:  0.026073461398482323
p mean is: tensor(-0.8905, device='cuda:1')
epoch:  38000 quantization_loss:  0.02601492591202259
p mean is: tensor(-0.8993, device='cuda:1')
epoch:  39000 quantization_loss:  0.025967052206397057
p mean is: tensor(-0.9071, device='cuda:1')
epoch:  40000 quantization_loss:  0.025919577106833458
p mean is: tensor(-0.9140, device='cuda:1')
epoch:  41000 quantization_loss:  0.025910375639796257
p mean is: tensor(-0.9203, device='cuda:1')
epoch:  42000 quantization_loss:  0.02588803693652153
p mean is: tensor(-0.9259, device='cuda:1')
epoch:  43000 quantization_loss:  0.025882158428430557
p mean is: tensor(-0.9312, device='cuda:1')
epoch:  44000 quantization_loss:  0.025827324017882347
p mean is: tensor(-0.9359, device='cuda:1')
epoch:  45000 quantization_loss:  0.025814026594161987
p mean is: tensor(-0.9400, device='cuda:1')
epoch:  46000 quantization_loss:  0.025792362168431282
p mean is: tensor(-0.9439, device='cuda:1')
epoch:  47000 quantization_loss:  0.025903556495904922
p mean is: tensor(-0.9474, device='cuda:1')
epoch:  48000 quantization_loss:  0.025760218501091003
p mean is: tensor(-0.9506, device='cuda:1')
epoch:  49000 quantization_loss:  0.025721831247210503
p mean is: tensor(-0.9536, device='cuda:1')
epoch:  50000 quantization_loss:  0.025693543255329132
p mean is: tensor(-0.9564, device='cuda:1')
epoch:  51000 quantization_loss:  0.025707993656396866
p mean is: tensor(-0.9589, device='cuda:1')
epoch:  52000 quantization_loss:  0.025677742436528206
p mean is: tensor(-0.9613, device='cuda:1')
epoch:  53000 quantization_loss:  0.0256696417927742
p mean is: tensor(-0.9635, device='cuda:1')
epoch:  54000 quantization_loss:  0.02565421536564827
p mean is: tensor(-0.9657, device='cuda:1')
epoch:  55000 quantization_loss:  0.02562536671757698
p mean is: tensor(-0.9677, device='cuda:1')
epoch:  56000 quantization_loss:  0.02563670091331005
p mean is: tensor(-0.9695, device='cuda:1')
epoch:  57000 quantization_loss:  0.02562669664621353
p mean is: tensor(-0.9713, device='cuda:1')
epoch:  58000 quantization_loss:  0.02562020532786846
p mean is: tensor(-0.9729, device='cuda:1')
epoch:  59000 quantization_loss:  0.025602595880627632
p mean is: tensor(-0.9745, device='cuda:1')
epoch:  60000 quantization_loss:  0.025598131120204926
p mean is: tensor(-0.9761, device='cuda:1')
epoch:  61000 quantization_loss:  0.0255968626588583
p mean is: tensor(-0.9776, device='cuda:1')
epoch:  62000 quantization_loss:  0.025584451854228973
p mean is: tensor(-0.9790, device='cuda:1')
epoch:  63000 quantization_loss:  0.02557235397398472
p mean is: tensor(-0.9803, device='cuda:1')
epoch:  64000 quantization_loss:  0.025568006560206413
p mean is: tensor(-0.9815, device='cuda:1')
epoch:  65000 quantization_loss:  0.025562820956110954
p mean is: tensor(-0.9827, device='cuda:1')
epoch:  66000 quantization_loss:  0.0259059090167284
p mean is: tensor(-0.9839, device='cuda:1')
epoch:  67000 quantization_loss:  0.025550371035933495
p mean is: tensor(-0.9850, device='cuda:1')
epoch:  68000 quantization_loss:  0.025546051561832428
p mean is: tensor(-0.9861, device='cuda:1')
epoch:  69000 quantization_loss:  0.025541624054312706
p mean is: tensor(-0.9872, device='cuda:1')
epoch:  70000 quantization_loss:  0.025534730404615402
p mean is: tensor(-0.9882, device='cuda:1')
epoch:  71000 quantization_loss:  0.025526661425828934
p mean is: tensor(-0.9892, device='cuda:1')
epoch:  72000 quantization_loss:  0.02552562952041626
p mean is: tensor(-0.9902, device='cuda:1')
epoch:  73000 quantization_loss:  0.025520220398902893
p mean is: tensor(-0.9912, device='cuda:1')
epoch:  74000 quantization_loss:  0.025524377822875977
p mean is: tensor(-0.9921, device='cuda:1')
epoch:  75000 quantization_loss:  0.025510799139738083
p mean is: tensor(-0.9929, device='cuda:1')
epoch:  76000 quantization_loss:  0.025513945147395134
p mean is: tensor(-0.9938, device='cuda:1')
epoch:  77000 quantization_loss:  0.02550986036658287
p mean is: tensor(-0.9946, device='cuda:1')
epoch:  78000 quantization_loss:  0.025505967438220978
p mean is: tensor(-0.9955, device='cuda:1')
epoch:  79000 quantization_loss:  0.025498192757368088
p mean is: tensor(-0.9963, device='cuda:1')
here
1.1.1.weight         | nonzeros =     898 /   12800             (  7.02%) | total_pruned =   11902 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     122 /    6400             (  1.91%) | total_pruned =    6278 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     106 /   12800             (  0.83%) | total_pruned =   12694 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     194 /   25600             (  0.76%) | total_pruned =   25406 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     195 /   51200             (  0.38%) | total_pruned =   51005 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     400 /  102400             (  0.39%) | total_pruned =  102000 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     271 /  204800             (  0.13%) | total_pruned =  204529 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     486 /  409600             (  0.12%) | total_pruned =  409114 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     737 /  409600             (  0.18%) | total_pruned =  408863 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    3413 /  409600             (  0.83%) | total_pruned =  406187 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   10877 /  409600             (  2.66%) | total_pruned =  398723 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   38778 /  409600             (  9.47%) | total_pruned =  370822 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   29486 /  147456             ( 20.00%) | total_pruned =  117970 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   21982 /  147456             ( 14.91%) | total_pruned =  125474 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   16866 /  147456             ( 11.44%) | total_pruned =  130590 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    8537 /   73728             ( 11.58%) | total_pruned =   65191 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2721 /   18432             ( 14.76%) | total_pruned =   15711 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      21 /      32             ( 65.62%) | total_pruned =      11 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      21 /      32             ( 65.62%) | total_pruned =      11 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1369 /    4608             ( 29.71%) | total_pruned =    3239 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      26 /      48             ( 54.17%) | total_pruned =      22 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 138658, pruned : 2870209, total: 3008867, Compression rate :      21.70x  ( 95.39% pruned)
PSNR of output image is:  16.953134052680078
Experiment done
