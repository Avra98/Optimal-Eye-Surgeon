(3, 512, 512)
Starting vanilla DIP on 2 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.428782723205888'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/2/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-1.5/1e-09
epoch:  0 quantization_loss:  0.09278084337711334
p mean is: tensor(-0.0003, device='cuda:2')
epoch:  1000 quantization_loss:  0.07410940527915955
p mean is: tensor(-0.0092, device='cuda:2')
epoch:  2000 quantization_loss:  0.07136330753564835
p mean is: tensor(-0.0158, device='cuda:2')
epoch:  3000 quantization_loss:  0.07186256349086761
p mean is: tensor(-0.0221, device='cuda:2')
epoch:  4000 quantization_loss:  0.06991075724363327
p mean is: tensor(-0.0286, device='cuda:2')
epoch:  5000 quantization_loss:  0.07046577334403992
p mean is: tensor(-0.0350, device='cuda:2')
epoch:  6000 quantization_loss:  0.06388163566589355
p mean is: tensor(-0.0417, device='cuda:2')
epoch:  7000 quantization_loss:  0.05830707401037216
p mean is: tensor(-0.0498, device='cuda:2')
epoch:  8000 quantization_loss:  0.05517297610640526
p mean is: tensor(-0.0610, device='cuda:2')
epoch:  9000 quantization_loss:  0.048347532749176025
p mean is: tensor(-0.0764, device='cuda:2')
epoch:  10000 quantization_loss:  0.04070472717285156
p mean is: tensor(-0.0963, device='cuda:2')
epoch:  11000 quantization_loss:  0.0372038260102272
p mean is: tensor(-0.1221, device='cuda:2')
epoch:  12000 quantization_loss:  0.03374429792165756
p mean is: tensor(-0.1555, device='cuda:2')
epoch:  13000 quantization_loss:  0.032357797026634216
p mean is: tensor(-0.1980, device='cuda:2')
epoch:  14000 quantization_loss:  0.031960416585206985
p mean is: tensor(-0.2507, device='cuda:2')
epoch:  15000 quantization_loss:  0.03207271918654442
p mean is: tensor(-0.3139, device='cuda:2')
epoch:  16000 quantization_loss:  0.030049830675125122
p mean is: tensor(-0.3866, device='cuda:2')
epoch:  17000 quantization_loss:  0.029163865372538567
p mean is: tensor(-0.4664, device='cuda:2')
epoch:  18000 quantization_loss:  0.02888321876525879
p mean is: tensor(-0.5496, device='cuda:2')
epoch:  19000 quantization_loss:  0.02839134819805622
p mean is: tensor(-0.6323, device='cuda:2')
epoch:  20000 quantization_loss:  0.028033440932631493
p mean is: tensor(-0.7113, device='cuda:2')
epoch:  21000 quantization_loss:  0.02771599590778351
p mean is: tensor(-0.7846, device='cuda:2')
epoch:  22000 quantization_loss:  0.02725970931351185
p mean is: tensor(-0.8514, device='cuda:2')
epoch:  23000 quantization_loss:  0.02700803615152836
p mean is: tensor(-0.9113, device='cuda:2')
epoch:  24000 quantization_loss:  0.026783188804984093
p mean is: tensor(-0.9649, device='cuda:2')
epoch:  25000 quantization_loss:  0.026616528630256653
p mean is: tensor(-1.0126, device='cuda:2')
epoch:  26000 quantization_loss:  0.026514451950788498
p mean is: tensor(-1.0550, device='cuda:2')
epoch:  27000 quantization_loss:  0.026369940489530563
p mean is: tensor(-1.0927, device='cuda:2')
epoch:  28000 quantization_loss:  0.026122134178876877
p mean is: tensor(-1.1263, device='cuda:2')
epoch:  29000 quantization_loss:  0.026005281135439873
p mean is: tensor(-1.1560, device='cuda:2')
epoch:  30000 quantization_loss:  0.02646789140999317
p mean is: tensor(-1.1826, device='cuda:2')
epoch:  31000 quantization_loss:  0.02582286298274994
p mean is: tensor(-1.2064, device='cuda:2')
epoch:  32000 quantization_loss:  0.025736302137374878
p mean is: tensor(-1.2278, device='cuda:2')
epoch:  33000 quantization_loss:  0.025663582608103752
p mean is: tensor(-1.2471, device='cuda:2')
epoch:  34000 quantization_loss:  0.02558000572025776
p mean is: tensor(-1.2644, device='cuda:2')
epoch:  35000 quantization_loss:  0.02549581788480282
p mean is: tensor(-1.2801, device='cuda:2')
epoch:  36000 quantization_loss:  0.025488397106528282
p mean is: tensor(-1.2943, device='cuda:2')
epoch:  37000 quantization_loss:  0.02543259970843792
p mean is: tensor(-1.3072, device='cuda:2')
epoch:  38000 quantization_loss:  0.025346552953124046
p mean is: tensor(-1.3188, device='cuda:2')
epoch:  39000 quantization_loss:  0.025300880894064903
p mean is: tensor(-1.3294, device='cuda:2')
epoch:  40000 quantization_loss:  0.02525459975004196
p mean is: tensor(-1.3392, device='cuda:2')
epoch:  41000 quantization_loss:  0.025237878784537315
p mean is: tensor(-1.3481, device='cuda:2')
epoch:  42000 quantization_loss:  0.02519141510128975
p mean is: tensor(-1.3564, device='cuda:2')
epoch:  43000 quantization_loss:  0.02522037923336029
p mean is: tensor(-1.3638, device='cuda:2')
epoch:  44000 quantization_loss:  0.025106465443968773
p mean is: tensor(-1.3707, device='cuda:2')
epoch:  45000 quantization_loss:  0.025123538449406624
p mean is: tensor(-1.3771, device='cuda:2')
epoch:  46000 quantization_loss:  0.0250767320394516
p mean is: tensor(-1.3830, device='cuda:2')
epoch:  47000 quantization_loss:  0.025051526725292206
p mean is: tensor(-1.3885, device='cuda:2')
epoch:  48000 quantization_loss:  0.025038855150341988
p mean is: tensor(-1.3936, device='cuda:2')
epoch:  49000 quantization_loss:  0.025071723386645317
p mean is: tensor(-1.3983, device='cuda:2')
epoch:  50000 quantization_loss:  0.025023967027664185
p mean is: tensor(-1.4027, device='cuda:2')
epoch:  51000 quantization_loss:  0.024975666776299477
p mean is: tensor(-1.4069, device='cuda:2')
epoch:  52000 quantization_loss:  0.024953385815024376
p mean is: tensor(-1.4107, device='cuda:2')
epoch:  53000 quantization_loss:  0.024942539632320404
p mean is: tensor(-1.4144, device='cuda:2')
epoch:  54000 quantization_loss:  0.024935495108366013
p mean is: tensor(-1.4179, device='cuda:2')
epoch:  55000 quantization_loss:  0.024915356189012527
p mean is: tensor(-1.4211, device='cuda:2')
epoch:  56000 quantization_loss:  0.02489950880408287
p mean is: tensor(-1.4242, device='cuda:2')
epoch:  57000 quantization_loss:  0.024896610528230667
p mean is: tensor(-1.4272, device='cuda:2')
epoch:  58000 quantization_loss:  0.024896513670682907
p mean is: tensor(-1.4300, device='cuda:2')
epoch:  59000 quantization_loss:  0.024893194437026978
p mean is: tensor(-1.4326, device='cuda:2')
epoch:  60000 quantization_loss:  0.024996818974614143
p mean is: tensor(-1.4351, device='cuda:2')
epoch:  61000 quantization_loss:  0.024878932163119316
p mean is: tensor(-1.4375, device='cuda:2')
epoch:  62000 quantization_loss:  0.024865886196494102
p mean is: tensor(-1.4399, device='cuda:2')
epoch:  63000 quantization_loss:  0.024851353839039803
p mean is: tensor(-1.4421, device='cuda:2')
epoch:  64000 quantization_loss:  0.0248402189463377
p mean is: tensor(-1.4442, device='cuda:2')
epoch:  65000 quantization_loss:  0.024835573509335518
p mean is: tensor(-1.4463, device='cuda:2')
epoch:  66000 quantization_loss:  0.02483981102705002
p mean is: tensor(-1.4483, device='cuda:2')
epoch:  67000 quantization_loss:  0.024824446067214012
p mean is: tensor(-1.4502, device='cuda:2')
epoch:  68000 quantization_loss:  0.0248184185475111
p mean is: tensor(-1.4520, device='cuda:2')
epoch:  69000 quantization_loss:  0.024826310575008392
p mean is: tensor(-1.4538, device='cuda:2')
epoch:  70000 quantization_loss:  0.024810045957565308
p mean is: tensor(-1.4556, device='cuda:2')
epoch:  71000 quantization_loss:  0.02481960691511631
p mean is: tensor(-1.4572, device='cuda:2')
epoch:  72000 quantization_loss:  0.024805894121527672
p mean is: tensor(-1.4589, device='cuda:2')
epoch:  73000 quantization_loss:  0.024799559265375137
p mean is: tensor(-1.4604, device='cuda:2')
epoch:  74000 quantization_loss:  0.024791544303297997
p mean is: tensor(-1.4619, device='cuda:2')
epoch:  75000 quantization_loss:  0.024715105071663857
p mean is: tensor(-1.4634, device='cuda:2')
epoch:  76000 quantization_loss:  0.02478983998298645
p mean is: tensor(-1.4649, device='cuda:2')
epoch:  77000 quantization_loss:  0.024787258356809616
p mean is: tensor(-1.4663, device='cuda:2')
epoch:  78000 quantization_loss:  0.024777637794613838
p mean is: tensor(-1.4677, device='cuda:2')
epoch:  79000 quantization_loss:  0.024783629924058914
p mean is: tensor(-1.4690, device='cuda:2')
here
1.1.1.weight         | nonzeros =     786 /   12800             (  6.14%) | total_pruned =   12014 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =      86 /    6400             (  1.34%) | total_pruned =    6314 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      53 /   12800             (  0.41%) | total_pruned =   12747 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     130 /   25600             (  0.51%) | total_pruned =   25470 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =       6 /      32             ( 18.75%) | total_pruned =      26 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     115 /   51200             (  0.22%) | total_pruned =   51085 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =      76 /  102400             (  0.07%) | total_pruned =  102324 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =       5 /  204800             (  0.00%) | total_pruned =  204795 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      49 /     128             ( 38.28%) | total_pruned =      79 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =      92 /  409600             (  0.02%) | total_pruned =  409508 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =      91 /  409600             (  0.02%) | total_pruned =  409509 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    1812 /  409600             (  0.44%) | total_pruned =  407788 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    6716 /  409600             (  1.64%) | total_pruned =  402884 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   30310 /  409600             (  7.40%) | total_pruned =  379290 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   32982 /  147456             ( 22.37%) | total_pruned =  114474 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   33747 /  147456             ( 22.89%) | total_pruned =  113709 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   28288 /  147456             ( 19.18%) | total_pruned =  119168 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   12955 /   73728             ( 17.57%) | total_pruned =   60773 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    3430 /   18432             ( 18.61%) | total_pruned =   15002 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1365 /    4608             ( 29.62%) | total_pruned =    3243 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      31 /      48             ( 64.58%) | total_pruned =      17 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       3 /       3             (100.00%) | total_pruned =       0 | shape = torch.Size([3])
alive: 154369, pruned : 2854498, total: 3008867, Compression rate :      19.49x  ( 94.87% pruned)
PSNR of output image is:  17.510976860961605
Experiment done
