(3, 512, 512)
Starting vanilla DIP on 0 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '19.670101786697998'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/0/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/clean_img/-1.3/1e-09
(3, 512, 512)
Starting vanilla DIP on 0 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '19.681434982931467'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/0/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/clean_img/-1.3/1e-09
(3, 512, 512)
Starting vanilla DIP on 0 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '19.66779965365254'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/0/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/clean_img/-1.3/1e-09
epoch:  0 quantization_loss:  0.07409325242042542
p mean is: tensor(-0.0002, device='cuda:3')
epoch:  1000 quantization_loss:  0.0648297592997551
p mean is: tensor(-0.0098, device='cuda:3')
epoch:  2000 quantization_loss:  0.06196475028991699
p mean is: tensor(-0.0169, device='cuda:3')
epoch:  3000 quantization_loss:  0.061301086097955704
p mean is: tensor(-0.0241, device='cuda:3')
epoch:  4000 quantization_loss:  0.060936689376831055
p mean is: tensor(-0.0311, device='cuda:3')
epoch:  5000 quantization_loss:  0.06082885339856148
p mean is: tensor(-0.0386, device='cuda:3')
epoch:  6000 quantization_loss:  0.06019933149218559
p mean is: tensor(-0.0471, device='cuda:3')
epoch:  7000 quantization_loss:  0.060161009430885315
p mean is: tensor(-0.0566, device='cuda:3')
epoch:  8000 quantization_loss:  0.0599682554602623
p mean is: tensor(-0.0672, device='cuda:3')
epoch:  9000 quantization_loss:  0.05939940735697746
p mean is: tensor(-0.0779, device='cuda:3')
epoch:  10000 quantization_loss:  0.05575934424996376
p mean is: tensor(-0.0904, device='cuda:3')
epoch:  11000 quantization_loss:  0.04875990375876427
p mean is: tensor(-0.1047, device='cuda:3')
epoch:  12000 quantization_loss:  0.04443403705954552
p mean is: tensor(-0.1214, device='cuda:3')
epoch:  13000 quantization_loss:  0.036043353378772736
p mean is: tensor(-0.1422, device='cuda:3')
epoch:  14000 quantization_loss:  0.030867503955960274
p mean is: tensor(-0.1675, device='cuda:3')
epoch:  15000 quantization_loss:  0.03135945647954941
p mean is: tensor(-0.1994, device='cuda:3')
epoch:  16000 quantization_loss:  0.028513919562101364
p mean is: tensor(-0.2393, device='cuda:3')
epoch:  17000 quantization_loss:  0.027339830994606018
p mean is: tensor(-0.2880, device='cuda:3')
epoch:  18000 quantization_loss:  0.026908721774816513
p mean is: tensor(-0.3452, device='cuda:3')
epoch:  19000 quantization_loss:  0.026375750079751015
p mean is: tensor(-0.4096, device='cuda:3')
epoch:  20000 quantization_loss:  0.02624850533902645
p mean is: tensor(-0.4785, device='cuda:3')
epoch:  21000 quantization_loss:  0.025917159393429756
p mean is: tensor(-0.5491, device='cuda:3')
epoch:  22000 quantization_loss:  0.02548699639737606
p mean is: tensor(-0.6184, device='cuda:3')
epoch:  23000 quantization_loss:  0.025282317772507668
p mean is: tensor(-0.6843, device='cuda:3')
epoch:  24000 quantization_loss:  0.02517208456993103
p mean is: tensor(-0.7453, device='cuda:3')
epoch:  25000 quantization_loss:  0.025026552379131317
p mean is: tensor(-0.8007, device='cuda:3')
epoch:  26000 quantization_loss:  0.024725008755922318
p mean is: tensor(-0.8503, device='cuda:3')
epoch:  27000 quantization_loss:  0.024640468880534172
p mean is: tensor(-0.8944, device='cuda:3')
epoch:  28000 quantization_loss:  0.024618299677968025
p mean is: tensor(-0.9336, device='cuda:3')
epoch:  29000 quantization_loss:  0.024459093809127808
p mean is: tensor(-0.9682, device='cuda:3')
epoch:  30000 quantization_loss:  0.02435036189854145
p mean is: tensor(-0.9990, device='cuda:3')
epoch:  31000 quantization_loss:  0.02424357645213604
p mean is: tensor(-1.0263, device='cuda:3')
epoch:  32000 quantization_loss:  0.024228882044553757
p mean is: tensor(-1.0504, device='cuda:3')
epoch:  33000 quantization_loss:  0.024090280756354332
p mean is: tensor(-1.0720, device='cuda:3')
epoch:  34000 quantization_loss:  0.024073541164398193
p mean is: tensor(-1.0911, device='cuda:3')
epoch:  35000 quantization_loss:  0.024031370878219604
p mean is: tensor(-1.1082, device='cuda:3')
epoch:  36000 quantization_loss:  0.024011168628931046
p mean is: tensor(-1.1234, device='cuda:3')
epoch:  37000 quantization_loss:  0.023940784856677055
p mean is: tensor(-1.1370, device='cuda:3')
epoch:  38000 quantization_loss:  0.02390349470078945
p mean is: tensor(-1.1493, device='cuda:3')
epoch:  39000 quantization_loss:  0.023876622319221497
p mean is: tensor(-1.1604, device='cuda:3')
epoch:  40000 quantization_loss:  0.023856045678257942
p mean is: tensor(-1.1704, device='cuda:3')
epoch:  41000 quantization_loss:  0.023809252306818962
p mean is: tensor(-1.1795, device='cuda:3')
epoch:  42000 quantization_loss:  0.023776868358254433
p mean is: tensor(-1.1878, device='cuda:3')
epoch:  43000 quantization_loss:  0.02375682070851326
p mean is: tensor(-1.1953, device='cuda:3')
epoch:  44000 quantization_loss:  0.023753231391310692
p mean is: tensor(-1.2022, device='cuda:3')
epoch:  45000 quantization_loss:  0.02369190938770771
p mean is: tensor(-1.2085, device='cuda:3')
epoch:  46000 quantization_loss:  0.023692941293120384
p mean is: tensor(-1.2143, device='cuda:3')
epoch:  47000 quantization_loss:  0.02366904728114605
p mean is: tensor(-1.2196, device='cuda:3')
epoch:  48000 quantization_loss:  0.02363792434334755
p mean is: tensor(-1.2245, device='cuda:3')
epoch:  49000 quantization_loss:  0.023625046014785767
p mean is: tensor(-1.2291, device='cuda:3')
epoch:  50000 quantization_loss:  0.0236215740442276
p mean is: tensor(-1.2333, device='cuda:3')
epoch:  51000 quantization_loss:  0.023713279515504837
p mean is: tensor(-1.2373, device='cuda:3')
epoch:  52000 quantization_loss:  0.02358909137547016
p mean is: tensor(-1.2409, device='cuda:3')
epoch:  53000 quantization_loss:  0.023558655753731728
p mean is: tensor(-1.2443, device='cuda:3')
epoch:  54000 quantization_loss:  0.02355787716805935
p mean is: tensor(-1.2475, device='cuda:3')
epoch:  55000 quantization_loss:  0.023549705743789673
p mean is: tensor(-1.2505, device='cuda:3')
epoch:  56000 quantization_loss:  0.023569902405142784
p mean is: tensor(-1.2533, device='cuda:3')
epoch:  57000 quantization_loss:  0.02354411594569683
p mean is: tensor(-1.2559, device='cuda:3')
epoch:  58000 quantization_loss:  0.02351815067231655
p mean is: tensor(-1.2584, device='cuda:3')
epoch:  59000 quantization_loss:  0.02352084033191204
p mean is: tensor(-1.2608, device='cuda:3')
epoch:  60000 quantization_loss:  0.023507244884967804
p mean is: tensor(-1.2630, device='cuda:3')
epoch:  61000 quantization_loss:  0.023509163409471512
p mean is: tensor(-1.2651, device='cuda:3')
epoch:  62000 quantization_loss:  0.023496394976973534
p mean is: tensor(-1.2672, device='cuda:3')
epoch:  63000 quantization_loss:  0.02348203770816326
p mean is: tensor(-1.2691, device='cuda:3')
epoch:  64000 quantization_loss:  0.023482659831643105
p mean is: tensor(-1.2709, device='cuda:3')
epoch:  65000 quantization_loss:  0.023472147062420845
p mean is: tensor(-1.2727, device='cuda:3')
epoch:  66000 quantization_loss:  0.02347910962998867
p mean is: tensor(-1.2743, device='cuda:3')
epoch:  67000 quantization_loss:  0.023470064625144005
p mean is: tensor(-1.2760, device='cuda:3')
epoch:  68000 quantization_loss:  0.02345990389585495
p mean is: tensor(-1.2775, device='cuda:3')
epoch:  69000 quantization_loss:  0.023456044495105743
p mean is: tensor(-1.2790, device='cuda:3')
epoch:  70000 quantization_loss:  0.023448199033737183
p mean is: tensor(-1.2805, device='cuda:3')
epoch:  71000 quantization_loss:  0.023446274921298027
p mean is: tensor(-1.2818, device='cuda:3')
epoch:  72000 quantization_loss:  0.023445075377821922
p mean is: tensor(-1.2831, device='cuda:3')
epoch:  73000 quantization_loss:  0.02344103716313839
p mean is: tensor(-1.2844, device='cuda:3')
epoch:  74000 quantization_loss:  0.023434892296791077
p mean is: tensor(-1.2856, device='cuda:3')
epoch:  75000 quantization_loss:  0.023429585620760918
p mean is: tensor(-1.2869, device='cuda:3')
epoch:  76000 quantization_loss:  0.023430639877915382
p mean is: tensor(-1.2880, device='cuda:3')
epoch:  77000 quantization_loss:  0.023429187014698982
p mean is: tensor(-1.2892, device='cuda:3')
epoch:  78000 quantization_loss:  0.02342715859413147
p mean is: tensor(-1.2903, device='cuda:3')
epoch:  79000 quantization_loss:  0.023418698459863663
p mean is: tensor(-1.2914, device='cuda:3')
here
1.1.1.weight         | nonzeros =    1135 /   12800             (  8.87%) | total_pruned =   11665 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     128 /    6400             (  2.00%) | total_pruned =    6272 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       5 /      16             ( 31.25%) | total_pruned =      11 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      86 /   12800             (  0.67%) | total_pruned =   12714 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =       8 /      32             ( 25.00%) | total_pruned =      24 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     132 /   25600             (  0.52%) | total_pruned =   25468 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      13 /      32             ( 40.62%) | total_pruned =      19 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =      86 /   51200             (  0.17%) | total_pruned =   51114 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     132 /  102400             (  0.13%) | total_pruned =  102268 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =       4 /  204800             (  0.00%) | total_pruned =  204796 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =      49 /  409600             (  0.01%) | total_pruned =  409551 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     140 /  409600             (  0.03%) | total_pruned =  409460 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    2137 /  409600             (  0.52%) | total_pruned =  407463 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    7926 /  409600             (  1.94%) | total_pruned =  401674 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   29495 /  409600             (  7.20%) | total_pruned =  380105 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   26638 /  147456             ( 18.07%) | total_pruned =  120818 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   24063 /  147456             ( 16.32%) | total_pruned =  123393 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   23022 /  147456             ( 15.61%) | total_pruned =  124434 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   12507 /   73728             ( 16.96%) | total_pruned =   61221 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2564 /   18432             ( 13.91%) | total_pruned =   15868 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1030 /    4608             ( 22.35%) | total_pruned =    3578 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      30 /      48             ( 62.50%) | total_pruned =      18 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 132610, pruned : 2876257, total: 3008867, Compression rate :      22.69x  ( 95.59% pruned)
PSNR of output image is:  17.200857017441137
Experiment done
(3, 512, 512)
Starting vanilla DIP on 0 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '19.68052219172393'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/0/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/clean_img/-1.3/1e-09
epoch:  0 quantization_loss:  0.07721176743507385
p mean is: tensor(-0.0002, device='cuda:1')
epoch:  1000 quantization_loss:  0.060123227536678314
p mean is: tensor(-0.0098, device='cuda:1')
epoch:  2000 quantization_loss:  0.061528511345386505
p mean is: tensor(-0.0171, device='cuda:1')
epoch:  3000 quantization_loss:  0.05987474322319031
p mean is: tensor(-0.0244, device='cuda:1')
epoch:  4000 quantization_loss:  0.05831392854452133
p mean is: tensor(-0.0320, device='cuda:1')
epoch:  5000 quantization_loss:  0.058519601821899414
p mean is: tensor(-0.0395, device='cuda:1')
epoch:  6000 quantization_loss:  0.0580131895840168
p mean is: tensor(-0.0474, device='cuda:1')
epoch:  7000 quantization_loss:  0.057836055755615234
p mean is: tensor(-0.0559, device='cuda:1')
epoch:  8000 quantization_loss:  0.05708712711930275
p mean is: tensor(-0.0647, device='cuda:1')
epoch:  9000 quantization_loss:  0.057320550084114075
p mean is: tensor(-0.0741, device='cuda:1')
epoch:  10000 quantization_loss:  0.04709547758102417
p mean is: tensor(-0.0845, device='cuda:1')
epoch:  11000 quantization_loss:  0.04276418685913086
p mean is: tensor(-0.0974, device='cuda:1')
epoch:  12000 quantization_loss:  0.03753441199660301
p mean is: tensor(-0.1146, device='cuda:1')
epoch:  13000 quantization_loss:  0.0320669524371624
p mean is: tensor(-0.1373, device='cuda:1')
epoch:  14000 quantization_loss:  0.029021376743912697
p mean is: tensor(-0.1662, device='cuda:1')
epoch:  15000 quantization_loss:  0.0278543122112751
p mean is: tensor(-0.2025, device='cuda:1')
epoch:  16000 quantization_loss:  0.02638336643576622
p mean is: tensor(-0.2476, device='cuda:1')
epoch:  17000 quantization_loss:  0.025766266509890556
p mean is: tensor(-0.3018, device='cuda:1')
epoch:  18000 quantization_loss:  0.025417644530534744
p mean is: tensor(-0.3644, device='cuda:1')
epoch:  19000 quantization_loss:  0.02493147738277912
p mean is: tensor(-0.4337, device='cuda:1')
epoch:  20000 quantization_loss:  0.022854331880807877
p mean is: tensor(-0.5067, device='cuda:1')
epoch:  21000 quantization_loss:  0.022559329867362976
p mean is: tensor(-0.5793, device='cuda:1')
epoch:  22000 quantization_loss:  0.022184358909726143
p mean is: tensor(-0.6489, device='cuda:1')
epoch:  23000 quantization_loss:  0.0219656303524971
p mean is: tensor(-0.7136, device='cuda:1')
epoch:  24000 quantization_loss:  0.0217585451900959
p mean is: tensor(-0.7728, device='cuda:1')
epoch:  25000 quantization_loss:  0.021616777405142784
p mean is: tensor(-0.8260, device='cuda:1')
epoch:  26000 quantization_loss:  0.021508194506168365
p mean is: tensor(-0.8735, device='cuda:1')
epoch:  27000 quantization_loss:  0.02142058126628399
p mean is: tensor(-0.9156, device='cuda:1')
epoch:  28000 quantization_loss:  0.021299825981259346
p mean is: tensor(-0.9528, device='cuda:1')
epoch:  29000 quantization_loss:  0.02132185734808445
p mean is: tensor(-0.9857, device='cuda:1')
epoch:  30000 quantization_loss:  0.02116457372903824
p mean is: tensor(-1.0148, device='cuda:1')
epoch:  31000 quantization_loss:  0.021126115694642067
p mean is: tensor(-1.0405, device='cuda:1')
epoch:  32000 quantization_loss:  0.021017098799347878
p mean is: tensor(-1.0634, device='cuda:1')
epoch:  33000 quantization_loss:  0.020970715209841728
p mean is: tensor(-1.0836, device='cuda:1')
epoch:  34000 quantization_loss:  0.02090909704566002
p mean is: tensor(-1.1017, device='cuda:1')
epoch:  35000 quantization_loss:  0.02090277522802353
p mean is: tensor(-1.1177, device='cuda:1')
epoch:  36000 quantization_loss:  0.020840493962168694
p mean is: tensor(-1.1319, device='cuda:1')
epoch:  37000 quantization_loss:  0.02079172432422638
p mean is: tensor(-1.1448, device='cuda:1')
epoch:  38000 quantization_loss:  0.020746173337101936
p mean is: tensor(-1.1564, device='cuda:1')
epoch:  39000 quantization_loss:  0.02075481228530407
p mean is: tensor(-1.1667, device='cuda:1')
epoch:  40000 quantization_loss:  0.020739052444696426
p mean is: tensor(-1.1761, device='cuda:1')
epoch:  41000 quantization_loss:  0.020706064999103546
p mean is: tensor(-1.1846, device='cuda:1')
epoch:  42000 quantization_loss:  0.02068365179002285
p mean is: tensor(-1.1923, device='cuda:1')
epoch:  43000 quantization_loss:  0.020761558786034584
p mean is: tensor(-1.1992, device='cuda:1')
epoch:  44000 quantization_loss:  0.020454896613955498
p mean is: tensor(-1.2055, device='cuda:1')
epoch:  45000 quantization_loss:  0.020314795896410942
p mean is: tensor(-1.2112, device='cuda:1')
epoch:  46000 quantization_loss:  0.020234111696481705
p mean is: tensor(-1.2165, device='cuda:1')
epoch:  47000 quantization_loss:  0.020260456949472427
p mean is: tensor(-1.2212, device='cuda:1')
epoch:  48000 quantization_loss:  0.020200271159410477
p mean is: tensor(-1.2257, device='cuda:1')
epoch:  49000 quantization_loss:  0.020167121663689613
p mean is: tensor(-1.2299, device='cuda:1')
epoch:  50000 quantization_loss:  0.020152103155851364
p mean is: tensor(-1.2339, device='cuda:1')
epoch:  51000 quantization_loss:  0.019981440156698227
p mean is: tensor(-1.2375, device='cuda:1')
epoch:  52000 quantization_loss:  0.019910311326384544
p mean is: tensor(-1.2408, device='cuda:1')
epoch:  53000 quantization_loss:  0.019900694489479065
p mean is: tensor(-1.2440, device='cuda:1')
epoch:  54000 quantization_loss:  0.019875407218933105
p mean is: tensor(-1.2469, device='cuda:1')
epoch:  55000 quantization_loss:  0.01985122263431549
p mean is: tensor(-1.2498, device='cuda:1')
epoch:  56000 quantization_loss:  0.01986529864370823
p mean is: tensor(-1.2525, device='cuda:1')
epoch:  57000 quantization_loss:  0.019838515669107437
p mean is: tensor(-1.2550, device='cuda:1')
epoch:  58000 quantization_loss:  0.01980953849852085
p mean is: tensor(-1.2574, device='cuda:1')
epoch:  59000 quantization_loss:  0.019815990701317787
p mean is: tensor(-1.2596, device='cuda:1')
epoch:  60000 quantization_loss:  0.01979098841547966
p mean is: tensor(-1.2618, device='cuda:1')
epoch:  61000 quantization_loss:  0.01978587545454502
p mean is: tensor(-1.2639, device='cuda:1')
epoch:  62000 quantization_loss:  0.019779281690716743
p mean is: tensor(-1.2659, device='cuda:1')
epoch:  63000 quantization_loss:  0.01976674422621727
p mean is: tensor(-1.2678, device='cuda:1')
epoch:  64000 quantization_loss:  0.01975935697555542
p mean is: tensor(-1.2696, device='cuda:1')
epoch:  65000 quantization_loss:  0.019759085029363632
p mean is: tensor(-1.2714, device='cuda:1')
epoch:  66000 quantization_loss:  0.01974782906472683
p mean is: tensor(-1.2732, device='cuda:1')
epoch:  67000 quantization_loss:  0.01973743550479412
p mean is: tensor(-1.2748, device='cuda:1')
epoch:  68000 quantization_loss:  0.019624745473265648
p mean is: tensor(-1.2763, device='cuda:1')
epoch:  69000 quantization_loss:  0.019624225795269012
p mean is: tensor(-1.2778, device='cuda:1')
epoch:  70000 quantization_loss:  0.019604280591011047
p mean is: tensor(-1.2793, device='cuda:1')
epoch:  71000 quantization_loss:  0.019597001373767853
p mean is: tensor(-1.2807, device='cuda:1')
epoch:  72000 quantization_loss:  0.01959584653377533
p mean is: tensor(-1.2821, device='cuda:1')
epoch:  73000 quantization_loss:  0.019595732912421227
p mean is: tensor(-1.2834, device='cuda:1')
epoch:  74000 quantization_loss:  0.019587287679314613
p mean is: tensor(-1.2847, device='cuda:1')
epoch:  75000 quantization_loss:  0.019583581015467644
p mean is: tensor(-1.2858, device='cuda:1')
epoch:  76000 quantization_loss:  0.019575174897909164
p mean is: tensor(-1.2870, device='cuda:1')
epoch:  77000 quantization_loss:  0.01955617405474186
p mean is: tensor(-1.2882, device='cuda:1')
epoch:  78000 quantization_loss:  0.01954943686723709
p mean is: tensor(-1.2893, device='cuda:1')
epoch:  79000 quantization_loss:  0.01955069974064827
p mean is: tensor(-1.2905, device='cuda:1')
here
1.1.1.weight         | nonzeros =     795 /   12800             (  6.21%) | total_pruned =   12005 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     148 /    6400             (  2.31%) | total_pruned =    6252 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      96 /   12800             (  0.75%) | total_pruned =   12704 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     129 /   25600             (  0.50%) | total_pruned =   25471 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =      92 /   51200             (  0.18%) | total_pruned =   51108 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     167 /  102400             (  0.16%) | total_pruned =  102233 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =      38 /  204800             (  0.02%) | total_pruned =  204762 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     186 /  409600             (  0.05%) | total_pruned =  409414 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     257 /  409600             (  0.06%) | total_pruned =  409343 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    2002 /  409600             (  0.49%) | total_pruned =  407598 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    7180 /  409600             (  1.75%) | total_pruned =  402420 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   31209 /  409600             (  7.62%) | total_pruned =  378391 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   27169 /  147456             ( 18.43%) | total_pruned =  120287 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   25296 /  147456             ( 17.15%) | total_pruned =  122160 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   21883 /  147456             ( 14.84%) | total_pruned =  125573 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   10593 /   73728             ( 14.37%) | total_pruned =   63135 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    3049 /   18432             ( 16.54%) | total_pruned =   15383 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1192 /    4608             ( 25.87%) | total_pruned =    3416 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      29 /      48             ( 60.42%) | total_pruned =      19 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 132742, pruned : 2876125, total: 3008867, Compression rate :      22.67x  ( 95.59% pruned)
PSNR of output image is:  16.451568056770093
Experiment done
