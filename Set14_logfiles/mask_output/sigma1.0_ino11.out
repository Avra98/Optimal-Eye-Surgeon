(3, 512, 512)
Noisy PSNR is '20.32740395633736'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/11/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/1.0/1e-09
epoch:  0 quantization_loss:  0.065324567258358
p mean is: tensor(0.0002, device='cuda:2')
epoch:  1000 quantization_loss:  0.05584130808711052
p mean is: tensor(0.0093, device='cuda:2')
epoch:  2000 quantization_loss:  0.05588972195982933
p mean is: tensor(0.0174, device='cuda:2')
epoch:  3000 quantization_loss:  0.05457020550966263
p mean is: tensor(0.0257, device='cuda:2')
epoch:  4000 quantization_loss:  0.05393631383776665
p mean is: tensor(0.0344, device='cuda:2')
epoch:  5000 quantization_loss:  0.05272417888045311
p mean is: tensor(0.0435, device='cuda:2')
epoch:  6000 quantization_loss:  0.049657732248306274
p mean is: tensor(0.0528, device='cuda:2')
epoch:  7000 quantization_loss:  0.04529443010687828
p mean is: tensor(0.0639, device='cuda:2')
epoch:  8000 quantization_loss:  0.040356602519750595
p mean is: tensor(0.0782, device='cuda:2')
epoch:  9000 quantization_loss:  0.037227239459753036
p mean is: tensor(0.0961, device='cuda:2')
epoch:  10000 quantization_loss:  0.03550801798701286
p mean is: tensor(0.1190, device='cuda:2')
epoch:  11000 quantization_loss:  0.033785708248615265
p mean is: tensor(0.1484, device='cuda:2')
epoch:  12000 quantization_loss:  0.03201776742935181
p mean is: tensor(0.1848, device='cuda:2')
epoch:  13000 quantization_loss:  0.030469033867120743
p mean is: tensor(0.2282, device='cuda:2')
epoch:  14000 quantization_loss:  0.029995115473866463
p mean is: tensor(0.2782, device='cuda:2')
epoch:  15000 quantization_loss:  0.028322778642177582
p mean is: tensor(0.3330, device='cuda:2')
epoch:  16000 quantization_loss:  0.02764611877501011
p mean is: tensor(0.3906, device='cuda:2')
epoch:  17000 quantization_loss:  0.026372315362095833
p mean is: tensor(0.4487, device='cuda:2')
epoch:  18000 quantization_loss:  0.0259871669113636
p mean is: tensor(0.5051, device='cuda:2')
epoch:  19000 quantization_loss:  0.025634529069066048
p mean is: tensor(0.5577, device='cuda:2')
epoch:  20000 quantization_loss:  0.025349991396069527
p mean is: tensor(0.6059, device='cuda:2')
epoch:  21000 quantization_loss:  0.025154486298561096
p mean is: tensor(0.6490, device='cuda:2')
epoch:  22000 quantization_loss:  0.024860365316271782
p mean is: tensor(0.6872, device='cuda:2')
epoch:  23000 quantization_loss:  0.024611985310912132
p mean is: tensor(0.7209, device='cuda:2')
epoch:  24000 quantization_loss:  0.02294474095106125
p mean is: tensor(0.7502, device='cuda:2')
epoch:  25000 quantization_loss:  0.02135903388261795
p mean is: tensor(0.7753, device='cuda:2')
epoch:  26000 quantization_loss:  0.02124144695699215
p mean is: tensor(0.7971, device='cuda:2')
epoch:  27000 quantization_loss:  0.02101334184408188
p mean is: tensor(0.8163, device='cuda:2')
epoch:  28000 quantization_loss:  0.02085506170988083
p mean is: tensor(0.8332, device='cuda:2')
epoch:  29000 quantization_loss:  0.020670076832175255
p mean is: tensor(0.8481, device='cuda:2')
epoch:  30000 quantization_loss:  0.020663611590862274
p mean is: tensor(0.8612, device='cuda:2')
epoch:  31000 quantization_loss:  0.02052626758813858
p mean is: tensor(0.8726, device='cuda:2')
epoch:  32000 quantization_loss:  0.020347032696008682
p mean is: tensor(0.8828, device='cuda:2')
epoch:  33000 quantization_loss:  0.020068060606718063
p mean is: tensor(0.8918, device='cuda:2')
epoch:  34000 quantization_loss:  0.019929977133870125
p mean is: tensor(0.8998, device='cuda:2')
epoch:  35000 quantization_loss:  0.019816353917121887
p mean is: tensor(0.9069, device='cuda:2')
epoch:  36000 quantization_loss:  0.019744977355003357
p mean is: tensor(0.9135, device='cuda:2')
epoch:  37000 quantization_loss:  0.019666286185383797
p mean is: tensor(0.9193, device='cuda:2')
epoch:  38000 quantization_loss:  0.019615773111581802
p mean is: tensor(0.9245, device='cuda:2')
epoch:  39000 quantization_loss:  0.019548499956727028
p mean is: tensor(0.9293, device='cuda:2')
epoch:  40000 quantization_loss:  0.019490158185362816
p mean is: tensor(0.9337, device='cuda:2')
epoch:  41000 quantization_loss:  0.01946333982050419
p mean is: tensor(0.9376, device='cuda:2')
epoch:  42000 quantization_loss:  0.019401632249355316
p mean is: tensor(0.9413, device='cuda:2')
epoch:  43000 quantization_loss:  0.019376108422875404
p mean is: tensor(0.9447, device='cuda:2')
epoch:  44000 quantization_loss:  0.019336922094225883
p mean is: tensor(0.9478, device='cuda:2')
epoch:  45000 quantization_loss:  0.01932903565466404
p mean is: tensor(0.9507, device='cuda:2')
epoch:  46000 quantization_loss:  0.0193362757563591
p mean is: tensor(0.9534, device='cuda:2')
epoch:  47000 quantization_loss:  0.019253097474575043
p mean is: tensor(0.9559, device='cuda:2')
epoch:  48000 quantization_loss:  0.019235603511333466
p mean is: tensor(0.9583, device='cuda:2')
epoch:  49000 quantization_loss:  0.019227897748351097
p mean is: tensor(0.9605, device='cuda:2')
epoch:  50000 quantization_loss:  0.019195696339011192
p mean is: tensor(0.9625, device='cuda:2')
epoch:  51000 quantization_loss:  0.01918461173772812
p mean is: tensor(0.9644, device='cuda:2')
epoch:  52000 quantization_loss:  0.019159188494086266
p mean is: tensor(0.9663, device='cuda:2')
epoch:  53000 quantization_loss:  0.01915869675576687
p mean is: tensor(0.9681, device='cuda:2')
epoch:  54000 quantization_loss:  0.01913902722299099
p mean is: tensor(0.9698, device='cuda:2')
epoch:  55000 quantization_loss:  0.019120361655950546
p mean is: tensor(0.9714, device='cuda:2')
epoch:  56000 quantization_loss:  0.01911954954266548
p mean is: tensor(0.9729, device='cuda:2')
epoch:  57000 quantization_loss:  0.019104288890957832
p mean is: tensor(0.9743, device='cuda:2')
epoch:  58000 quantization_loss:  0.019106967374682426
p mean is: tensor(0.9757, device='cuda:2')
epoch:  59000 quantization_loss:  0.01909366436302662
p mean is: tensor(0.9770, device='cuda:2')
epoch:  60000 quantization_loss:  0.019083725288510323
p mean is: tensor(0.9782, device='cuda:2')
epoch:  61000 quantization_loss:  0.019079895690083504
p mean is: tensor(0.9794, device='cuda:2')
epoch:  62000 quantization_loss:  0.019065698608756065
p mean is: tensor(0.9806, device='cuda:2')
epoch:  63000 quantization_loss:  0.019065793603658676
p mean is: tensor(0.9817, device='cuda:2')
epoch:  64000 quantization_loss:  0.019056284800171852
p mean is: tensor(0.9829, device='cuda:2')
epoch:  65000 quantization_loss:  0.01904633268713951
p mean is: tensor(0.9840, device='cuda:2')
epoch:  66000 quantization_loss:  0.01905493065714836
p mean is: tensor(0.9851, device='cuda:2')
epoch:  67000 quantization_loss:  0.019053369760513306
p mean is: tensor(0.9861, device='cuda:2')
epoch:  68000 quantization_loss:  0.019046571105718613
p mean is: tensor(0.9871, device='cuda:2')
epoch:  69000 quantization_loss:  0.01903376914560795
p mean is: tensor(0.9881, device='cuda:2')
epoch:  70000 quantization_loss:  0.019033974036574364
p mean is: tensor(0.9890, device='cuda:2')
epoch:  71000 quantization_loss:  0.01902550645172596
p mean is: tensor(0.9900, device='cuda:2')
epoch:  72000 quantization_loss:  0.019019154831767082
p mean is: tensor(0.9909, device='cuda:2')
epoch:  73000 quantization_loss:  0.019024543464183807
p mean is: tensor(0.9918, device='cuda:2')
epoch:  74000 quantization_loss:  0.019010530784726143
p mean is: tensor(0.9926, device='cuda:2')
epoch:  75000 quantization_loss:  0.019018050283193588
p mean is: tensor(0.9934, device='cuda:2')
epoch:  76000 quantization_loss:  0.01901128515601158
p mean is: tensor(0.9943, device='cuda:2')
epoch:  77000 quantization_loss:  0.01901036687195301
p mean is: tensor(0.9951, device='cuda:2')
epoch:  78000 quantization_loss:  0.019004864618182182
p mean is: tensor(0.9958, device='cuda:2')
epoch:  79000 quantization_loss:  0.019008643925189972
p mean is: tensor(0.9966, device='cuda:2')
1.1.1.weight         | nonzeros =   11464 /   12800             ( 89.56%) | total_pruned =    1336 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.2.weight           | nonzeros =      12 /      16             ( 75.00%) | total_pruned =       4 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =    6135 /    6400             ( 95.86%) | total_pruned =     265 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.5.weight           | nonzeros =      12 /      16             ( 75.00%) | total_pruned =       4 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =   12704 /   12800             ( 99.25%) | total_pruned =      96 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =   25449 /   25600             ( 99.41%) | total_pruned =     151 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =   51034 /   51200             ( 99.68%) | total_pruned =     166 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =  102165 /  102400             ( 99.77%) | total_pruned =     235 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =  204555 /  204800             ( 99.88%) | total_pruned =     245 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =  409098 /  409600             ( 99.88%) | total_pruned =     502 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  408824 /  409600             ( 99.81%) | total_pruned =     776 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  403937 /  409600             ( 98.62%) | total_pruned =    5663 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  394697 /  409600             ( 96.36%) | total_pruned =   14903 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  363133 /  409600             ( 88.66%) | total_pruned =   46467 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  109036 /  147456             ( 73.94%) | total_pruned =   38420 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  115023 /  147456             ( 78.00%) | total_pruned =   32433 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =  122851 /  147456             ( 83.31%) | total_pruned =   24605 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   63242 /   73728             ( 85.78%) | total_pruned =   10486 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =   15283 /   18432             ( 82.92%) | total_pruned =    3149 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      25 /      32             ( 78.12%) | total_pruned =       7 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    3003 /    4608             ( 65.17%) | total_pruned =    1605 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      31 /      48             ( 64.58%) | total_pruned =      17 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 2824601, pruned : 184266, total: 3008867, Compression rate :       1.07x  (  6.12% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  19.503392212299893
Experiment done
