Starting vanilla DIP on 6 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.103655366526695'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/6/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-0.4/1e-09
epoch:  0 quantization_loss:  0.0727589875459671
p mean is: tensor(-7.4215e-05, device='cuda:4')
epoch:  1000 quantization_loss:  0.05710767209529877
p mean is: tensor(-0.0034, device='cuda:4')
epoch:  2000 quantization_loss:  0.05203019455075264
p mean is: tensor(-0.0060, device='cuda:4')
epoch:  3000 quantization_loss:  0.050966277718544006
p mean is: tensor(-0.0087, device='cuda:4')
epoch:  4000 quantization_loss:  0.05027279630303383
p mean is: tensor(-0.0115, device='cuda:4')
epoch:  5000 quantization_loss:  0.050105370581150055
p mean is: tensor(-0.0145, device='cuda:4')
epoch:  6000 quantization_loss:  0.04834168404340744
p mean is: tensor(-0.0183, device='cuda:4')
epoch:  7000 quantization_loss:  0.046077486127614975
p mean is: tensor(-0.0221, device='cuda:4')
epoch:  8000 quantization_loss:  0.043713945895433426
p mean is: tensor(-0.0267, device='cuda:4')
epoch:  9000 quantization_loss:  0.04198278486728668
p mean is: tensor(-0.0326, device='cuda:4')
epoch:  10000 quantization_loss:  0.039931610226631165
p mean is: tensor(-0.0399, device='cuda:4')
epoch:  11000 quantization_loss:  0.03854801133275032
p mean is: tensor(-0.0492, device='cuda:4')
epoch:  12000 quantization_loss:  0.03719577193260193
p mean is: tensor(-0.0607, device='cuda:4')
epoch:  13000 quantization_loss:  0.035220611840486526
p mean is: tensor(-0.0747, device='cuda:4')
epoch:  14000 quantization_loss:  0.033753011375665665
p mean is: tensor(-0.0912, device='cuda:4')
epoch:  15000 quantization_loss:  0.03204925358295441
p mean is: tensor(-0.1101, device='cuda:4')
epoch:  16000 quantization_loss:  0.030621608719229698
p mean is: tensor(-0.1311, device='cuda:4')
epoch:  17000 quantization_loss:  0.02959810383617878
p mean is: tensor(-0.1535, device='cuda:4')
epoch:  18000 quantization_loss:  0.02841973304748535
p mean is: tensor(-0.1765, device='cuda:4')
epoch:  19000 quantization_loss:  0.027835842221975327
p mean is: tensor(-0.1990, device='cuda:4')
epoch:  20000 quantization_loss:  0.02740640379488468
p mean is: tensor(-0.2202, device='cuda:4')
epoch:  21000 quantization_loss:  0.027029672637581825
p mean is: tensor(-0.2398, device='cuda:4')
epoch:  22000 quantization_loss:  0.026453789323568344
p mean is: tensor(-0.2578, device='cuda:4')
epoch:  23000 quantization_loss:  0.026338420808315277
p mean is: tensor(-0.2738, device='cuda:4')
epoch:  24000 quantization_loss:  0.025972146540880203
p mean is: tensor(-0.2879, device='cuda:4')
epoch:  25000 quantization_loss:  0.02578166499733925
p mean is: tensor(-0.3001, device='cuda:4')
epoch:  26000 quantization_loss:  0.025147035717964172
p mean is: tensor(-0.3107, device='cuda:4')
epoch:  27000 quantization_loss:  0.024890149012207985
p mean is: tensor(-0.3198, device='cuda:4')
epoch:  28000 quantization_loss:  0.024752698838710785
p mean is: tensor(-0.3277, device='cuda:4')
epoch:  29000 quantization_loss:  0.024675004184246063
p mean is: tensor(-0.3347, device='cuda:4')
epoch:  30000 quantization_loss:  0.024495385587215424
p mean is: tensor(-0.3407, device='cuda:4')
epoch:  31000 quantization_loss:  0.024398190900683403
p mean is: tensor(-0.3459, device='cuda:4')
epoch:  32000 quantization_loss:  0.024291466921567917
p mean is: tensor(-0.3506, device='cuda:4')
epoch:  33000 quantization_loss:  0.024220841005444527
p mean is: tensor(-0.3546, device='cuda:4')
epoch:  34000 quantization_loss:  0.024134164676070213
p mean is: tensor(-0.3582, device='cuda:4')
epoch:  35000 quantization_loss:  0.024056199938058853
p mean is: tensor(-0.3614, device='cuda:4')
epoch:  36000 quantization_loss:  0.02403976581990719
p mean is: tensor(-0.3644, device='cuda:4')
epoch:  37000 quantization_loss:  0.023945514112710953
p mean is: tensor(-0.3669, device='cuda:4')
epoch:  38000 quantization_loss:  0.023916395381093025
p mean is: tensor(-0.3692, device='cuda:4')
epoch:  39000 quantization_loss:  0.024248091503977776
p mean is: tensor(-0.3713, device='cuda:4')
epoch:  40000 quantization_loss:  0.02378951385617256
p mean is: tensor(-0.3733, device='cuda:4')
epoch:  41000 quantization_loss:  0.023766448721289635
p mean is: tensor(-0.3749, device='cuda:4')
epoch:  42000 quantization_loss:  0.023826342076063156
p mean is: tensor(-0.3765, device='cuda:4')
epoch:  43000 quantization_loss:  0.023712744936347008
p mean is: tensor(-0.3780, device='cuda:4')
epoch:  44000 quantization_loss:  0.023684993386268616
p mean is: tensor(-0.3793, device='cuda:4')
epoch:  45000 quantization_loss:  0.023680174723267555
p mean is: tensor(-0.3805, device='cuda:4')
epoch:  46000 quantization_loss:  0.023665638640522957
p mean is: tensor(-0.3816, device='cuda:4')
epoch:  47000 quantization_loss:  0.02368146739900112
p mean is: tensor(-0.3828, device='cuda:4')
epoch:  48000 quantization_loss:  0.02361285872757435
p mean is: tensor(-0.3839, device='cuda:4')
epoch:  49000 quantization_loss:  0.023597748950123787
p mean is: tensor(-0.3848, device='cuda:4')
epoch:  50000 quantization_loss:  0.02358848787844181
p mean is: tensor(-0.3857, device='cuda:4')
epoch:  51000 quantization_loss:  0.0235604215413332
p mean is: tensor(-0.3867, device='cuda:4')
epoch:  52000 quantization_loss:  0.023552870377898216
p mean is: tensor(-0.3875, device='cuda:4')
epoch:  53000 quantization_loss:  0.02354416623711586
p mean is: tensor(-0.3884, device='cuda:4')
epoch:  54000 quantization_loss:  0.02352956309914589
p mean is: tensor(-0.3891, device='cuda:4')
epoch:  55000 quantization_loss:  0.023642584681510925
p mean is: tensor(-0.3899, device='cuda:4')
epoch:  56000 quantization_loss:  0.023512400686740875
p mean is: tensor(-0.3906, device='cuda:4')
epoch:  57000 quantization_loss:  0.023519005626440048
p mean is: tensor(-0.3913, device='cuda:4')
epoch:  58000 quantization_loss:  0.02350616455078125
p mean is: tensor(-0.3919, device='cuda:4')
epoch:  59000 quantization_loss:  0.023496180772781372
p mean is: tensor(-0.3925, device='cuda:4')
epoch:  60000 quantization_loss:  0.023489031940698624
p mean is: tensor(-0.3931, device='cuda:4')
epoch:  61000 quantization_loss:  0.02348267287015915
p mean is: tensor(-0.3937, device='cuda:4')
epoch:  62000 quantization_loss:  0.0234830379486084
p mean is: tensor(-0.3943, device='cuda:4')
epoch:  63000 quantization_loss:  0.023465825244784355
p mean is: tensor(-0.3947, device='cuda:4')
epoch:  64000 quantization_loss:  0.02346566691994667
p mean is: tensor(-0.3953, device='cuda:4')
epoch:  65000 quantization_loss:  0.023468445986509323
p mean is: tensor(-0.3958, device='cuda:4')
epoch:  66000 quantization_loss:  0.02345859259366989
p mean is: tensor(-0.3963, device='cuda:4')
epoch:  67000 quantization_loss:  0.023473449051380157
p mean is: tensor(-0.3968, device='cuda:4')
epoch:  68000 quantization_loss:  0.023452257737517357
p mean is: tensor(-0.3973, device='cuda:4')
epoch:  69000 quantization_loss:  0.023448599502444267
p mean is: tensor(-0.3978, device='cuda:4')
epoch:  70000 quantization_loss:  0.023448390886187553
p mean is: tensor(-0.3982, device='cuda:4')
epoch:  71000 quantization_loss:  0.02346125803887844
p mean is: tensor(-0.3987, device='cuda:4')
epoch:  72000 quantization_loss:  0.023432724177837372
p mean is: tensor(-0.3990, device='cuda:4')
epoch:  73000 quantization_loss:  0.023427369073033333
p mean is: tensor(-0.3995, device='cuda:4')
epoch:  74000 quantization_loss:  0.02343020774424076
p mean is: tensor(-0.3998, device='cuda:4')
epoch:  75000 quantization_loss:  0.02342599630355835
p mean is: tensor(-0.4003, device='cuda:4')
epoch:  76000 quantization_loss:  0.023417670279741287
p mean is: tensor(-0.4006, device='cuda:4')
epoch:  77000 quantization_loss:  0.023426705971360207
p mean is: tensor(-0.4010, device='cuda:4')
epoch:  78000 quantization_loss:  0.02341654524207115
p mean is: tensor(-0.4014, device='cuda:4')
epoch:  79000 quantization_loss:  0.023425564169883728
p mean is: tensor(-0.4017, device='cuda:4')
here
1.1.1.weight         | nonzeros =    1843 /   12800             ( 14.40%) | total_pruned =   10957 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     388 /    6400             (  6.06%) | total_pruned =    6012 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     455 /   12800             (  3.55%) | total_pruned =   12345 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     776 /   25600             (  3.03%) | total_pruned =   24824 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =    1188 /   51200             (  2.32%) | total_pruned =   50012 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =    2134 /  102400             (  2.08%) | total_pruned =  100266 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =    2909 /  204800             (  1.42%) | total_pruned =  201891 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =    6298 /  409600             (  1.54%) | total_pruned =  403302 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    9453 /  409600             (  2.31%) | total_pruned =  400147 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   21111 /  409600             (  5.15%) | total_pruned =  388489 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   41827 /  409600             ( 10.21%) | total_pruned =  367773 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   70859 /  409600             ( 17.30%) | total_pruned =  338741 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   34678 /  147456             ( 23.52%) | total_pruned =  112778 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   25014 /  147456             ( 16.96%) | total_pruned =  122442 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   21805 /  147456             ( 14.79%) | total_pruned =  125651 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   10966 /   73728             ( 14.87%) | total_pruned =   62762 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    3429 /   18432             ( 18.60%) | total_pruned =   15003 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1587 /    4608             ( 34.44%) | total_pruned =    3021 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      30 /      48             ( 62.50%) | total_pruned =      18 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 258048, pruned : 2750819, total: 3008867, Compression rate :      11.66x  ( 91.42% pruned)
PSNR of output image is:  18.427561664769595
Experiment done
