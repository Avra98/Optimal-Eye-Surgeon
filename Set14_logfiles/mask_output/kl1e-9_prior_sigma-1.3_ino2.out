(3, 512, 512)
Starting vanilla DIP on 2 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.43989273166735'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/2/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-1.3/1e-09
epoch:  0 quantization_loss:  0.10008830577135086
p mean is: tensor(-0.0002, device='cuda:1')
epoch:  1000 quantization_loss:  0.0817607194185257
p mean is: tensor(-0.0091, device='cuda:1')
epoch:  2000 quantization_loss:  0.07972212135791779
p mean is: tensor(-0.0157, device='cuda:1')
epoch:  3000 quantization_loss:  0.07853375375270844
p mean is: tensor(-0.0221, device='cuda:1')
epoch:  4000 quantization_loss:  0.07729438692331314
p mean is: tensor(-0.0284, device='cuda:1')
epoch:  5000 quantization_loss:  0.07272660732269287
p mean is: tensor(-0.0351, device='cuda:1')
epoch:  6000 quantization_loss:  0.0713985338807106
p mean is: tensor(-0.0436, device='cuda:1')
epoch:  7000 quantization_loss:  0.06963405013084412
p mean is: tensor(-0.0552, device='cuda:1')
epoch:  8000 quantization_loss:  0.06584227830171585
p mean is: tensor(-0.0704, device='cuda:1')
epoch:  9000 quantization_loss:  0.058447256684303284
p mean is: tensor(-0.0898, device='cuda:1')
epoch:  10000 quantization_loss:  0.05550212040543556
p mean is: tensor(-0.1142, device='cuda:1')
epoch:  11000 quantization_loss:  0.0536162406206131
p mean is: tensor(-0.1453, device='cuda:1')
epoch:  12000 quantization_loss:  0.04993102326989174
p mean is: tensor(-0.1838, device='cuda:1')
epoch:  13000 quantization_loss:  0.04744506999850273
p mean is: tensor(-0.2294, device='cuda:1')
epoch:  14000 quantization_loss:  0.046646296977996826
p mean is: tensor(-0.2830, device='cuda:1')
epoch:  15000 quantization_loss:  0.04531592130661011
p mean is: tensor(-0.3439, device='cuda:1')
epoch:  16000 quantization_loss:  0.04445366933941841
p mean is: tensor(-0.4105, device='cuda:1')
epoch:  17000 quantization_loss:  0.04396548867225647
p mean is: tensor(-0.4801, device='cuda:1')
epoch:  18000 quantization_loss:  0.04335401952266693
p mean is: tensor(-0.5503, device='cuda:1')
epoch:  19000 quantization_loss:  0.04298882558941841
p mean is: tensor(-0.6186, device='cuda:1')
epoch:  20000 quantization_loss:  0.042702432721853256
p mean is: tensor(-0.6832, device='cuda:1')
epoch:  21000 quantization_loss:  0.04258071258664131
p mean is: tensor(-0.7429, device='cuda:1')
epoch:  22000 quantization_loss:  0.042233895510435104
p mean is: tensor(-0.7972, device='cuda:1')
epoch:  23000 quantization_loss:  0.04222961515188217
p mean is: tensor(-0.8460, device='cuda:1')
epoch:  24000 quantization_loss:  0.04196106642484665
p mean is: tensor(-0.8897, device='cuda:1')
epoch:  25000 quantization_loss:  0.04178119823336601
p mean is: tensor(-0.9287, device='cuda:1')
epoch:  26000 quantization_loss:  0.04175450652837753
p mean is: tensor(-0.9634, device='cuda:1')
epoch:  27000 quantization_loss:  0.041669223457574844
p mean is: tensor(-0.9941, device='cuda:1')
epoch:  28000 quantization_loss:  0.04153616726398468
p mean is: tensor(-1.0215, device='cuda:1')
epoch:  29000 quantization_loss:  0.04147843271493912
p mean is: tensor(-1.0458, device='cuda:1')
epoch:  30000 quantization_loss:  0.041420307010412216
p mean is: tensor(-1.0674, device='cuda:1')
epoch:  31000 quantization_loss:  0.041219424456357956
p mean is: tensor(-1.0866, device='cuda:1')
epoch:  32000 quantization_loss:  0.040669482201337814
p mean is: tensor(-1.1036, device='cuda:1')
epoch:  33000 quantization_loss:  0.04051803797483444
p mean is: tensor(-1.1186, device='cuda:1')
epoch:  34000 quantization_loss:  0.040460869669914246
p mean is: tensor(-1.1321, device='cuda:1')
epoch:  35000 quantization_loss:  0.04036290943622589
p mean is: tensor(-1.1443, device='cuda:1')
epoch:  36000 quantization_loss:  0.04032382369041443
p mean is: tensor(-1.1554, device='cuda:1')
epoch:  37000 quantization_loss:  0.04024249687790871
p mean is: tensor(-1.1654, device='cuda:1')
epoch:  38000 quantization_loss:  0.04020996764302254
p mean is: tensor(-1.1745, device='cuda:1')
epoch:  39000 quantization_loss:  0.040160950273275375
p mean is: tensor(-1.1828, device='cuda:1')
epoch:  40000 quantization_loss:  0.04014144465327263
p mean is: tensor(-1.1904, device='cuda:1')
epoch:  41000 quantization_loss:  0.04000925272703171
p mean is: tensor(-1.1972, device='cuda:1')
epoch:  42000 quantization_loss:  0.039938390254974365
p mean is: tensor(-1.2035, device='cuda:1')
epoch:  43000 quantization_loss:  0.039885371923446655
p mean is: tensor(-1.2094, device='cuda:1')
epoch:  44000 quantization_loss:  0.03987407311797142
p mean is: tensor(-1.2148, device='cuda:1')
epoch:  45000 quantization_loss:  0.03980008140206337
p mean is: tensor(-1.2197, device='cuda:1')
epoch:  46000 quantization_loss:  0.03976722061634064
p mean is: tensor(-1.2243, device='cuda:1')
epoch:  47000 quantization_loss:  0.039757195860147476
p mean is: tensor(-1.2286, device='cuda:1')
epoch:  48000 quantization_loss:  0.03973893076181412
p mean is: tensor(-1.2326, device='cuda:1')
epoch:  49000 quantization_loss:  0.03968644142150879
p mean is: tensor(-1.2363, device='cuda:1')
epoch:  50000 quantization_loss:  0.03969244658946991
p mean is: tensor(-1.2399, device='cuda:1')
epoch:  51000 quantization_loss:  0.039659351110458374
p mean is: tensor(-1.2432, device='cuda:1')
epoch:  52000 quantization_loss:  0.03966234251856804
p mean is: tensor(-1.2463, device='cuda:1')
epoch:  53000 quantization_loss:  0.0396379716694355
p mean is: tensor(-1.2491, device='cuda:1')
epoch:  54000 quantization_loss:  0.03962332755327225
p mean is: tensor(-1.2519, device='cuda:1')
epoch:  55000 quantization_loss:  0.03960806503891945
p mean is: tensor(-1.2545, device='cuda:1')
epoch:  56000 quantization_loss:  0.039604537189006805
p mean is: tensor(-1.2569, device='cuda:1')
epoch:  57000 quantization_loss:  0.03959052637219429
p mean is: tensor(-1.2593, device='cuda:1')
epoch:  58000 quantization_loss:  0.03958531841635704
p mean is: tensor(-1.2615, device='cuda:1')
epoch:  59000 quantization_loss:  0.03957643732428551
p mean is: tensor(-1.2636, device='cuda:1')
epoch:  60000 quantization_loss:  0.03956332057714462
p mean is: tensor(-1.2657, device='cuda:1')
epoch:  61000 quantization_loss:  0.03954894468188286
p mean is: tensor(-1.2677, device='cuda:1')
epoch:  62000 quantization_loss:  0.03954723849892616
p mean is: tensor(-1.2695, device='cuda:1')
epoch:  63000 quantization_loss:  0.03954191133379936
p mean is: tensor(-1.2713, device='cuda:1')
epoch:  64000 quantization_loss:  0.03953742980957031
p mean is: tensor(-1.2731, device='cuda:1')
epoch:  65000 quantization_loss:  0.03953276202082634
p mean is: tensor(-1.2747, device='cuda:1')
epoch:  66000 quantization_loss:  0.039533328264951706
p mean is: tensor(-1.2763, device='cuda:1')
epoch:  67000 quantization_loss:  0.03951847925782204
p mean is: tensor(-1.2779, device='cuda:1')
epoch:  68000 quantization_loss:  0.039524391293525696
p mean is: tensor(-1.2794, device='cuda:1')
epoch:  69000 quantization_loss:  0.039510052651166916
p mean is: tensor(-1.2809, device='cuda:1')
epoch:  70000 quantization_loss:  0.03951789811253548
p mean is: tensor(-1.2823, device='cuda:1')
epoch:  71000 quantization_loss:  0.0395052470266819
p mean is: tensor(-1.2837, device='cuda:1')
epoch:  72000 quantization_loss:  0.039525214582681656
p mean is: tensor(-1.2849, device='cuda:1')
epoch:  73000 quantization_loss:  0.03949233889579773
p mean is: tensor(-1.2862, device='cuda:1')
epoch:  74000 quantization_loss:  0.039496295154094696
p mean is: tensor(-1.2875, device='cuda:1')
epoch:  75000 quantization_loss:  0.03948995843529701
p mean is: tensor(-1.2887, device='cuda:1')
epoch:  76000 quantization_loss:  0.03948003053665161
p mean is: tensor(-1.2899, device='cuda:1')
epoch:  77000 quantization_loss:  0.03947944939136505
p mean is: tensor(-1.2910, device='cuda:1')
epoch:  78000 quantization_loss:  0.03948186710476875
p mean is: tensor(-1.2922, device='cuda:1')
epoch:  79000 quantization_loss:  0.03948088735342026
p mean is: tensor(-1.2934, device='cuda:1')
here
1.1.1.weight         | nonzeros =     966 /   12800             (  7.55%) | total_pruned =   11834 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     100 /    6400             (  1.56%) | total_pruned =    6300 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      80 /   12800             (  0.62%) | total_pruned =   12720 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      13 /      32             ( 40.62%) | total_pruned =      19 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     148 /   25600             (  0.58%) | total_pruned =   25452 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =      75 /   51200             (  0.15%) | total_pruned =   51125 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     135 /  102400             (  0.13%) | total_pruned =  102265 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =      19 /  204800             (  0.01%) | total_pruned =  204781 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =      70 /  409600             (  0.02%) | total_pruned =  409530 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =      99 /  409600             (  0.02%) | total_pruned =  409501 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    2061 /  409600             (  0.50%) | total_pruned =  407539 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    8020 /  409600             (  1.96%) | total_pruned =  401580 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   33033 /  409600             (  8.06%) | total_pruned =  376567 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   29848 /  147456             ( 20.24%) | total_pruned =  117608 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   29948 /  147456             ( 20.31%) | total_pruned =  117508 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   27010 /  147456             ( 18.32%) | total_pruned =  120446 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   12697 /   73728             ( 17.22%) | total_pruned =   61031 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2471 /   18432             ( 13.41%) | total_pruned =   15961 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =     977 /    4608             ( 21.20%) | total_pruned =    3631 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      27 /      48             ( 56.25%) | total_pruned =      21 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 149105, pruned : 2859762, total: 3008867, Compression rate :      20.18x  ( 95.04% pruned)
PSNR of output image is:  14.878726486888617
Experiment done
