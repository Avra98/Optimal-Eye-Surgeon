Starting vanilla DIP on 4 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '19.740588408493604'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/4/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-0.5/1e-09
epoch:  0 quantization_loss:  0.06544280052185059
p mean is: tensor(-9.1333e-05, device='cuda:1')
epoch:  1000 quantization_loss:  0.05071859434247017
p mean is: tensor(-0.0040, device='cuda:1')
epoch:  2000 quantization_loss:  0.04877160117030144
p mean is: tensor(-0.0070, device='cuda:1')
epoch:  3000 quantization_loss:  0.04658115282654762
p mean is: tensor(-0.0106, device='cuda:1')
epoch:  4000 quantization_loss:  0.04639098793268204
p mean is: tensor(-0.0140, device='cuda:1')
epoch:  5000 quantization_loss:  0.04539083316922188
p mean is: tensor(-0.0181, device='cuda:1')
epoch:  6000 quantization_loss:  0.042096130549907684
p mean is: tensor(-0.0227, device='cuda:1')
epoch:  7000 quantization_loss:  0.03970929607748985
p mean is: tensor(-0.0277, device='cuda:1')
epoch:  8000 quantization_loss:  0.03838317096233368
p mean is: tensor(-0.0340, device='cuda:1')
epoch:  9000 quantization_loss:  0.03671194240450859
p mean is: tensor(-0.0426, device='cuda:1')
epoch:  10000 quantization_loss:  0.030740924179553986
p mean is: tensor(-0.0528, device='cuda:1')
epoch:  11000 quantization_loss:  0.027747705578804016
p mean is: tensor(-0.0648, device='cuda:1')
epoch:  12000 quantization_loss:  0.02675808034837246
p mean is: tensor(-0.0792, device='cuda:1')
epoch:  13000 quantization_loss:  0.024940716102719307
p mean is: tensor(-0.0968, device='cuda:1')
epoch:  14000 quantization_loss:  0.02400282584130764
p mean is: tensor(-0.1177, device='cuda:1')
epoch:  15000 quantization_loss:  0.02348428964614868
p mean is: tensor(-0.1417, device='cuda:1')
epoch:  16000 quantization_loss:  0.023142777383327484
p mean is: tensor(-0.1682, device='cuda:1')
epoch:  17000 quantization_loss:  0.022770030423998833
p mean is: tensor(-0.1965, device='cuda:1')
epoch:  18000 quantization_loss:  0.022467950358986855
p mean is: tensor(-0.2253, device='cuda:1')
epoch:  19000 quantization_loss:  0.022220714017748833
p mean is: tensor(-0.2536, device='cuda:1')
epoch:  20000 quantization_loss:  0.02221541851758957
p mean is: tensor(-0.2803, device='cuda:1')
epoch:  21000 quantization_loss:  0.02202112227678299
p mean is: tensor(-0.3049, device='cuda:1')
epoch:  22000 quantization_loss:  0.02186330407857895
p mean is: tensor(-0.3272, device='cuda:1')
epoch:  23000 quantization_loss:  0.021792953833937645
p mean is: tensor(-0.3470, device='cuda:1')
epoch:  24000 quantization_loss:  0.021698694676160812
p mean is: tensor(-0.3645, device='cuda:1')
epoch:  25000 quantization_loss:  0.02165639027953148
p mean is: tensor(-0.3797, device='cuda:1')
epoch:  26000 quantization_loss:  0.02168266661465168
p mean is: tensor(-0.3930, device='cuda:1')
epoch:  27000 quantization_loss:  0.021479247137904167
p mean is: tensor(-0.4044, device='cuda:1')
epoch:  28000 quantization_loss:  0.021349970251321793
p mean is: tensor(-0.4145, device='cuda:1')
epoch:  29000 quantization_loss:  0.021326690912246704
p mean is: tensor(-0.4232, device='cuda:1')
epoch:  30000 quantization_loss:  0.022669538855552673
p mean is: tensor(-0.4306, device='cuda:1')
epoch:  31000 quantization_loss:  0.02120899222791195
p mean is: tensor(-0.4370, device='cuda:1')
epoch:  32000 quantization_loss:  0.021232664585113525
p mean is: tensor(-0.4427, device='cuda:1')
epoch:  33000 quantization_loss:  0.021133258938789368
p mean is: tensor(-0.4477, device='cuda:1')
epoch:  34000 quantization_loss:  0.02110815793275833
p mean is: tensor(-0.4520, device='cuda:1')
epoch:  35000 quantization_loss:  0.021072350442409515
p mean is: tensor(-0.4558, device='cuda:1')
epoch:  36000 quantization_loss:  0.021067271009087563
p mean is: tensor(-0.4592, device='cuda:1')
epoch:  37000 quantization_loss:  0.021045822650194168
p mean is: tensor(-0.4622, device='cuda:1')
epoch:  38000 quantization_loss:  0.021029217168688774
p mean is: tensor(-0.4648, device='cuda:1')
epoch:  39000 quantization_loss:  0.02095346711575985
p mean is: tensor(-0.4672, device='cuda:1')
epoch:  40000 quantization_loss:  0.02092871069908142
p mean is: tensor(-0.4694, device='cuda:1')
epoch:  41000 quantization_loss:  0.020901883020997047
p mean is: tensor(-0.4713, device='cuda:1')
epoch:  42000 quantization_loss:  0.0209184642881155
p mean is: tensor(-0.4730, device='cuda:1')
epoch:  43000 quantization_loss:  0.020891694352030754
p mean is: tensor(-0.4747, device='cuda:1')
epoch:  44000 quantization_loss:  0.020866122096776962
p mean is: tensor(-0.4761, device='cuda:1')
epoch:  45000 quantization_loss:  0.020854605361819267
p mean is: tensor(-0.4774, device='cuda:1')
epoch:  46000 quantization_loss:  0.02080528996884823
p mean is: tensor(-0.4787, device='cuda:1')
epoch:  47000 quantization_loss:  0.020764712244272232
p mean is: tensor(-0.4798, device='cuda:1')
epoch:  48000 quantization_loss:  0.020754555240273476
p mean is: tensor(-0.4808, device='cuda:1')
epoch:  49000 quantization_loss:  0.02075665257871151
p mean is: tensor(-0.4818, device='cuda:1')
epoch:  50000 quantization_loss:  0.020733032375574112
p mean is: tensor(-0.4828, device='cuda:1')
epoch:  51000 quantization_loss:  0.020721064880490303
p mean is: tensor(-0.4837, device='cuda:1')
epoch:  52000 quantization_loss:  0.020714636892080307
p mean is: tensor(-0.4846, device='cuda:1')
epoch:  53000 quantization_loss:  0.02072427235543728
p mean is: tensor(-0.4853, device='cuda:1')
epoch:  54000 quantization_loss:  0.020686466246843338
p mean is: tensor(-0.4860, device='cuda:1')
epoch:  55000 quantization_loss:  0.020680109038949013
p mean is: tensor(-0.4867, device='cuda:1')
epoch:  56000 quantization_loss:  0.02067510224878788
p mean is: tensor(-0.4874, device='cuda:1')
epoch:  57000 quantization_loss:  0.020670918747782707
p mean is: tensor(-0.4880, device='cuda:1')
epoch:  58000 quantization_loss:  0.020648475736379623
p mean is: tensor(-0.4887, device='cuda:1')
epoch:  59000 quantization_loss:  0.020641567185521126
p mean is: tensor(-0.4892, device='cuda:1')
epoch:  60000 quantization_loss:  0.020643124356865883
p mean is: tensor(-0.4898, device='cuda:1')
epoch:  61000 quantization_loss:  0.020632494240999222
p mean is: tensor(-0.4904, device='cuda:1')
epoch:  62000 quantization_loss:  0.02062894217669964
p mean is: tensor(-0.4909, device='cuda:1')
epoch:  63000 quantization_loss:  0.020617306232452393
p mean is: tensor(-0.4914, device='cuda:1')
epoch:  64000 quantization_loss:  0.020626084879040718
p mean is: tensor(-0.4918, device='cuda:1')
epoch:  65000 quantization_loss:  0.020613577216863632
p mean is: tensor(-0.4923, device='cuda:1')
epoch:  66000 quantization_loss:  0.020620819181203842
p mean is: tensor(-0.4927, device='cuda:1')
epoch:  67000 quantization_loss:  0.020605893805623055
p mean is: tensor(-0.4932, device='cuda:1')
epoch:  68000 quantization_loss:  0.020602209493517876
p mean is: tensor(-0.4936, device='cuda:1')
epoch:  69000 quantization_loss:  0.020589714869856834
p mean is: tensor(-0.4941, device='cuda:1')
epoch:  70000 quantization_loss:  0.020601458847522736
p mean is: tensor(-0.4944, device='cuda:1')
epoch:  71000 quantization_loss:  0.020587490871548653
p mean is: tensor(-0.4948, device='cuda:1')
epoch:  72000 quantization_loss:  0.020598575472831726
p mean is: tensor(-0.4952, device='cuda:1')
epoch:  73000 quantization_loss:  0.02058286778628826
p mean is: tensor(-0.4955, device='cuda:1')
epoch:  74000 quantization_loss:  0.020582668483257294
p mean is: tensor(-0.4959, device='cuda:1')
epoch:  75000 quantization_loss:  0.020575854927301407
p mean is: tensor(-0.4963, device='cuda:1')
epoch:  76000 quantization_loss:  0.02057371847331524
p mean is: tensor(-0.4966, device='cuda:1')
epoch:  77000 quantization_loss:  0.020570283755660057
p mean is: tensor(-0.4970, device='cuda:1')
epoch:  78000 quantization_loss:  0.02057490311563015
p mean is: tensor(-0.4973, device='cuda:1')
epoch:  79000 quantization_loss:  0.020570242777466774
p mean is: tensor(-0.4976, device='cuda:1')
here
1.1.1.weight         | nonzeros =    1161 /   12800             (  9.07%) | total_pruned =   11639 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     158 /    6400             (  2.47%) | total_pruned =    6242 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       5 /      16             ( 31.25%) | total_pruned =      11 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     211 /   12800             (  1.65%) | total_pruned =   12589 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     484 /   25600             (  1.89%) | total_pruned =   25116 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     610 /   51200             (  1.19%) | total_pruned =   50590 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =    1016 /  102400             (  0.99%) | total_pruned =  101384 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     939 /  204800             (  0.46%) | total_pruned =  203861 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =    2116 /  409600             (  0.52%) | total_pruned =  407484 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    3666 /  409600             (  0.90%) | total_pruned =  405934 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   11758 /  409600             (  2.87%) | total_pruned =  397842 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   27030 /  409600             (  6.60%) | total_pruned =  382570 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   45206 /  409600             ( 11.04%) | total_pruned =  364394 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   25724 /  147456             ( 17.45%) | total_pruned =  121732 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   30173 /  147456             ( 20.46%) | total_pruned =  117283 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   23779 /  147456             ( 16.13%) | total_pruned =  123677 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    7720 /   73728             ( 10.47%) | total_pruned =   66008 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2413 /   18432             ( 13.09%) | total_pruned =   16019 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1288 /    4608             ( 27.95%) | total_pruned =    3320 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      31 /      48             ( 64.58%) | total_pruned =      17 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 186739, pruned : 2822128, total: 3008867, Compression rate :      16.11x  ( 93.79% pruned)
PSNR of output image is:  18.92001381052809
Experiment done
