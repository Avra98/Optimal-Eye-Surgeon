(3, 256, 256)
Noisy PSNR is '20.190572249536707'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/9/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/1.0/1e-09
epoch:  0 quantization_loss:  0.06192486733198166
p mean is: tensor(0.0002, device='cuda:4')
epoch:  1000 quantization_loss:  0.055379170924425125
p mean is: tensor(0.0039, device='cuda:4')
epoch:  2000 quantization_loss:  0.055154621601104736
p mean is: tensor(0.0073, device='cuda:4')
epoch:  3000 quantization_loss:  0.05526028573513031
p mean is: tensor(0.0114, device='cuda:4')
epoch:  4000 quantization_loss:  0.055861081928014755
p mean is: tensor(0.0162, device='cuda:4')
epoch:  5000 quantization_loss:  0.05505392327904701
p mean is: tensor(0.0219, device='cuda:4')
epoch:  6000 quantization_loss:  0.05531257763504982
p mean is: tensor(0.0285, device='cuda:4')
epoch:  7000 quantization_loss:  0.05530892685055733
p mean is: tensor(0.0358, device='cuda:4')
epoch:  8000 quantization_loss:  0.05517159774899483
p mean is: tensor(0.0432, device='cuda:4')
epoch:  9000 quantization_loss:  0.05513949319720268
p mean is: tensor(0.0506, device='cuda:4')
epoch:  10000 quantization_loss:  0.0553908608853817
p mean is: tensor(0.0576, device='cuda:4')
epoch:  11000 quantization_loss:  0.0553487092256546
p mean is: tensor(0.0643, device='cuda:4')
epoch:  12000 quantization_loss:  0.05506215617060661
p mean is: tensor(0.0711, device='cuda:4')
epoch:  13000 quantization_loss:  0.05602007731795311
p mean is: tensor(0.0777, device='cuda:4')
epoch:  14000 quantization_loss:  0.05601269379258156
p mean is: tensor(0.0845, device='cuda:4')
epoch:  15000 quantization_loss:  0.04901972413063049
p mean is: tensor(0.0904, device='cuda:4')
epoch:  16000 quantization_loss:  0.02765413373708725
p mean is: tensor(0.0983, device='cuda:4')
epoch:  17000 quantization_loss:  0.02487611398100853
p mean is: tensor(0.1089, device='cuda:4')
epoch:  18000 quantization_loss:  0.02025371417403221
p mean is: tensor(0.1220, device='cuda:4')
epoch:  19000 quantization_loss:  0.01926274411380291
p mean is: tensor(0.1385, device='cuda:4')
epoch:  20000 quantization_loss:  0.01884925551712513
p mean is: tensor(0.1605, device='cuda:4')
epoch:  21000 quantization_loss:  0.017260564491152763
p mean is: tensor(0.1891, device='cuda:4')
epoch:  22000 quantization_loss:  0.017078546807169914
p mean is: tensor(0.2254, device='cuda:4')
epoch:  23000 quantization_loss:  0.01650886982679367
p mean is: tensor(0.2697, device='cuda:4')
epoch:  24000 quantization_loss:  0.016120314598083496
p mean is: tensor(0.3212, device='cuda:4')
epoch:  25000 quantization_loss:  0.015520298853516579
p mean is: tensor(0.3776, device='cuda:4')
epoch:  26000 quantization_loss:  0.015417814254760742
p mean is: tensor(0.4374, device='cuda:4')
epoch:  27000 quantization_loss:  0.014940819703042507
p mean is: tensor(0.4974, device='cuda:4')
epoch:  28000 quantization_loss:  0.01465191412717104
p mean is: tensor(0.5552, device='cuda:4')
epoch:  29000 quantization_loss:  0.014381800778210163
p mean is: tensor(0.6093, device='cuda:4')
epoch:  30000 quantization_loss:  0.014258339069783688
p mean is: tensor(0.6585, device='cuda:4')
epoch:  31000 quantization_loss:  0.014158502221107483
p mean is: tensor(0.7024, device='cuda:4')
epoch:  32000 quantization_loss:  0.014009480364620686
p mean is: tensor(0.7412, device='cuda:4')
epoch:  33000 quantization_loss:  0.013805855996906757
p mean is: tensor(0.7749, device='cuda:4')
epoch:  34000 quantization_loss:  0.013707226142287254
p mean is: tensor(0.8040, device='cuda:4')
epoch:  35000 quantization_loss:  0.013420294038951397
p mean is: tensor(0.8289, device='cuda:4')
epoch:  36000 quantization_loss:  0.013263923116028309
p mean is: tensor(0.8502, device='cuda:4')
epoch:  37000 quantization_loss:  0.013133055530488491
p mean is: tensor(0.8684, device='cuda:4')
epoch:  38000 quantization_loss:  0.013046259060502052
p mean is: tensor(0.8841, device='cuda:4')
epoch:  39000 quantization_loss:  0.012976137921214104
p mean is: tensor(0.8974, device='cuda:4')
epoch:  40000 quantization_loss:  0.012859603390097618
p mean is: tensor(0.9089, device='cuda:4')
epoch:  41000 quantization_loss:  0.012800013646483421
p mean is: tensor(0.9187, device='cuda:4')
epoch:  42000 quantization_loss:  0.012728639878332615
p mean is: tensor(0.9271, device='cuda:4')
epoch:  43000 quantization_loss:  0.012690288946032524
p mean is: tensor(0.9344, device='cuda:4')
epoch:  44000 quantization_loss:  0.01266012154519558
p mean is: tensor(0.9407, device='cuda:4')
epoch:  45000 quantization_loss:  0.012591428123414516
p mean is: tensor(0.9461, device='cuda:4')
epoch:  46000 quantization_loss:  0.012534670531749725
p mean is: tensor(0.9509, device='cuda:4')
epoch:  47000 quantization_loss:  0.012533918023109436
p mean is: tensor(0.9551, device='cuda:4')
epoch:  48000 quantization_loss:  0.012456992641091347
p mean is: tensor(0.9587, device='cuda:4')
epoch:  49000 quantization_loss:  0.012397132813930511
p mean is: tensor(0.9618, device='cuda:4')
epoch:  50000 quantization_loss:  0.012128555215895176
p mean is: tensor(0.9646, device='cuda:4')
epoch:  51000 quantization_loss:  0.012121973559260368
p mean is: tensor(0.9670, device='cuda:4')
epoch:  52000 quantization_loss:  0.012119332328438759
p mean is: tensor(0.9691, device='cuda:4')
epoch:  53000 quantization_loss:  0.012049861252307892
p mean is: tensor(0.9711, device='cuda:4')
epoch:  54000 quantization_loss:  0.012005189433693886
p mean is: tensor(0.9728, device='cuda:4')
epoch:  55000 quantization_loss:  0.011982860043644905
p mean is: tensor(0.9744, device='cuda:4')
epoch:  56000 quantization_loss:  0.011962536722421646
p mean is: tensor(0.9759, device='cuda:4')
epoch:  57000 quantization_loss:  0.0119544742628932
p mean is: tensor(0.9773, device='cuda:4')
epoch:  58000 quantization_loss:  0.011932916007936
p mean is: tensor(0.9785, device='cuda:4')
epoch:  59000 quantization_loss:  0.011910785920917988
p mean is: tensor(0.9796, device='cuda:4')
epoch:  60000 quantization_loss:  0.011901792138814926
p mean is: tensor(0.9806, device='cuda:4')
epoch:  61000 quantization_loss:  0.011899133212864399
p mean is: tensor(0.9816, device='cuda:4')
epoch:  62000 quantization_loss:  0.011870667338371277
p mean is: tensor(0.9825, device='cuda:4')
epoch:  63000 quantization_loss:  0.01187223568558693
p mean is: tensor(0.9834, device='cuda:4')
epoch:  64000 quantization_loss:  0.01184752769768238
p mean is: tensor(0.9842, device='cuda:4')
epoch:  65000 quantization_loss:  0.011844010092318058
p mean is: tensor(0.9849, device='cuda:4')
epoch:  66000 quantization_loss:  0.01183787826448679
p mean is: tensor(0.9856, device='cuda:4')
epoch:  67000 quantization_loss:  0.011831900104880333
p mean is: tensor(0.9863, device='cuda:4')
epoch:  68000 quantization_loss:  0.01182187907397747
p mean is: tensor(0.9869, device='cuda:4')
epoch:  69000 quantization_loss:  0.011814875528216362
p mean is: tensor(0.9875, device='cuda:4')
epoch:  70000 quantization_loss:  0.011800982058048248
p mean is: tensor(0.9881, device='cuda:4')
epoch:  71000 quantization_loss:  0.01179757621139288
p mean is: tensor(0.9887, device='cuda:4')
epoch:  72000 quantization_loss:  0.011791453696787357
p mean is: tensor(0.9892, device='cuda:4')
epoch:  73000 quantization_loss:  0.011795710772275925
p mean is: tensor(0.9897, device='cuda:4')
epoch:  74000 quantization_loss:  0.011791476979851723
p mean is: tensor(0.9902, device='cuda:4')
epoch:  75000 quantization_loss:  0.011850138194859028
p mean is: tensor(0.9906, device='cuda:4')
epoch:  76000 quantization_loss:  0.011779765598475933
p mean is: tensor(0.9911, device='cuda:4')
epoch:  77000 quantization_loss:  0.011831419542431831
p mean is: tensor(0.9915, device='cuda:4')
epoch:  78000 quantization_loss:  0.011770932003855705
p mean is: tensor(0.9919, device='cuda:4')
epoch:  79000 quantization_loss:  0.01177146565169096
p mean is: tensor(0.9924, device='cuda:4')
1.1.1.weight         | nonzeros =   12591 /   12800             ( 98.37%) | total_pruned =     209 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.2.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =    6354 /    6400             ( 99.28%) | total_pruned =      46 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.5.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =   12790 /   12800             ( 99.92%) | total_pruned =      10 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      21 /      32             ( 65.62%) | total_pruned =      11 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =   25588 /   25600             ( 99.95%) | total_pruned =      12 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =   51194 /   51200             ( 99.99%) | total_pruned =       6 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =  102399 /  102400             (100.00%) | total_pruned =       1 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =  204800 /  204800             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =  409600 /  409600             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  409585 /  409600             (100.00%) | total_pruned =      15 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  408999 /  409600             ( 99.85%) | total_pruned =     601 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  407012 /  409600             ( 99.37%) | total_pruned =    2588 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  395295 /  409600             ( 96.51%) | total_pruned =   14305 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  126021 /  147456             ( 85.46%) | total_pruned =   21435 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  124604 /  147456             ( 84.50%) | total_pruned =   22852 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =  126799 /  147456             ( 85.99%) | total_pruned =   20657 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   66385 /   73728             ( 90.04%) | total_pruned =    7343 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =   15625 /   18432             ( 84.77%) | total_pruned =    2807 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      27 /      32             ( 84.38%) | total_pruned =       5 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      25 /      32             ( 78.12%) | total_pruned =       7 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    2797 /    4608             ( 60.70%) | total_pruned =    1811 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      32 /      48             ( 66.67%) | total_pruned =      16 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 2911246, pruned : 97621, total: 3008867, Compression rate :       1.03x  (  3.24% pruned)
(3, 256, 256) (3, 256, 256) (3, 256, 256)
PSNR of output image is:  25.158545263094304
Experiment done
