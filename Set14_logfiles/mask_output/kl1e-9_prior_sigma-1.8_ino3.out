(3, 256, 256)
Starting vanilla DIP on 3 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.333653089034748'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/3/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-1.8/1e-09
epoch:  0 quantization_loss:  0.07454863935709
p mean is: tensor(-0.0003, device='cuda:1')
epoch:  1000 quantization_loss:  0.06968103349208832
p mean is: tensor(-0.0101, device='cuda:1')
epoch:  2000 quantization_loss:  0.06972657889127731
p mean is: tensor(-0.0180, device='cuda:1')
epoch:  3000 quantization_loss:  0.07080592960119247
p mean is: tensor(-0.0259, device='cuda:1')
epoch:  4000 quantization_loss:  0.06953310966491699
p mean is: tensor(-0.0338, device='cuda:1')
epoch:  5000 quantization_loss:  0.06927262246608734
p mean is: tensor(-0.0420, device='cuda:1')
epoch:  6000 quantization_loss:  0.06921007484197617
p mean is: tensor(-0.0502, device='cuda:1')
epoch:  7000 quantization_loss:  0.06850921362638474
p mean is: tensor(-0.0587, device='cuda:1')
epoch:  8000 quantization_loss:  0.06939969211816788
p mean is: tensor(-0.0676, device='cuda:1')
epoch:  9000 quantization_loss:  0.0690813735127449
p mean is: tensor(-0.0766, device='cuda:1')
epoch:  10000 quantization_loss:  0.06961635500192642
p mean is: tensor(-0.0857, device='cuda:1')
epoch:  11000 quantization_loss:  0.0705932155251503
p mean is: tensor(-0.0955, device='cuda:1')
epoch:  12000 quantization_loss:  0.06908959150314331
p mean is: tensor(-0.1057, device='cuda:1')
epoch:  13000 quantization_loss:  0.06885814666748047
p mean is: tensor(-0.1165, device='cuda:1')
epoch:  14000 quantization_loss:  0.06948524713516235
p mean is: tensor(-0.1278, device='cuda:1')
epoch:  15000 quantization_loss:  0.06978940963745117
p mean is: tensor(-0.1398, device='cuda:1')
epoch:  16000 quantization_loss:  0.06667723506689072
p mean is: tensor(-0.1520, device='cuda:1')
epoch:  17000 quantization_loss:  0.06568793952465057
p mean is: tensor(-0.1671, device='cuda:1')
epoch:  18000 quantization_loss:  0.053898368030786514
p mean is: tensor(-0.1870, device='cuda:1')
epoch:  19000 quantization_loss:  0.0437421053647995
p mean is: tensor(-0.2122, device='cuda:1')
epoch:  20000 quantization_loss:  0.039339836686849594
p mean is: tensor(-0.2441, device='cuda:1')
epoch:  21000 quantization_loss:  0.0360451303422451
p mean is: tensor(-0.2855, device='cuda:1')
epoch:  22000 quantization_loss:  0.034597959369421005
p mean is: tensor(-0.3386, device='cuda:1')
epoch:  23000 quantization_loss:  0.03286288306117058
p mean is: tensor(-0.4047, device='cuda:1')
epoch:  24000 quantization_loss:  0.03150280937552452
p mean is: tensor(-0.4838, device='cuda:1')
epoch:  25000 quantization_loss:  0.030036894604563713
p mean is: tensor(-0.5742, device='cuda:1')
epoch:  26000 quantization_loss:  0.02924434468150139
p mean is: tensor(-0.6718, device='cuda:1')
epoch:  27000 quantization_loss:  0.028667259961366653
p mean is: tensor(-0.7722, device='cuda:1')
epoch:  28000 quantization_loss:  0.02792257070541382
p mean is: tensor(-0.8703, device='cuda:1')
epoch:  29000 quantization_loss:  0.02738288976252079
p mean is: tensor(-0.9625, device='cuda:1')
epoch:  30000 quantization_loss:  0.026818180456757545
p mean is: tensor(-1.0467, device='cuda:1')
epoch:  31000 quantization_loss:  0.026305610314011574
p mean is: tensor(-1.1217, device='cuda:1')
epoch:  32000 quantization_loss:  0.02606014348566532
p mean is: tensor(-1.1883, device='cuda:1')
epoch:  33000 quantization_loss:  0.025752641260623932
p mean is: tensor(-1.2472, device='cuda:1')
epoch:  34000 quantization_loss:  0.02540825866162777
p mean is: tensor(-1.2990, device='cuda:1')
epoch:  35000 quantization_loss:  0.025178411975502968
p mean is: tensor(-1.3447, device='cuda:1')
epoch:  36000 quantization_loss:  0.025888090953230858
p mean is: tensor(-1.3851, device='cuda:1')
epoch:  37000 quantization_loss:  0.02474355883896351
p mean is: tensor(-1.4206, device='cuda:1')
epoch:  38000 quantization_loss:  0.024478398263454437
p mean is: tensor(-1.4520, device='cuda:1')
epoch:  39000 quantization_loss:  0.023450516164302826
p mean is: tensor(-1.4797, device='cuda:1')
epoch:  40000 quantization_loss:  0.023226648569107056
p mean is: tensor(-1.5041, device='cuda:1')
epoch:  41000 quantization_loss:  0.023089587688446045
p mean is: tensor(-1.5258, device='cuda:1')
epoch:  42000 quantization_loss:  0.022752277553081512
p mean is: tensor(-1.5450, device='cuda:1')
epoch:  43000 quantization_loss:  0.022574637085199356
p mean is: tensor(-1.5622, device='cuda:1')
epoch:  44000 quantization_loss:  0.022448020055890083
p mean is: tensor(-1.5775, device='cuda:1')
epoch:  45000 quantization_loss:  0.02233823575079441
p mean is: tensor(-1.5912, device='cuda:1')
epoch:  46000 quantization_loss:  0.022235263139009476
p mean is: tensor(-1.6036, device='cuda:1')
epoch:  47000 quantization_loss:  0.022139068692922592
p mean is: tensor(-1.6147, device='cuda:1')
epoch:  48000 quantization_loss:  0.02206897921860218
p mean is: tensor(-1.6247, device='cuda:1')
epoch:  49000 quantization_loss:  0.022259285673499107
p mean is: tensor(-1.6338, device='cuda:1')
epoch:  50000 quantization_loss:  0.021925484761595726
p mean is: tensor(-1.6420, device='cuda:1')
epoch:  51000 quantization_loss:  0.021889345720410347
p mean is: tensor(-1.6495, device='cuda:1')
epoch:  52000 quantization_loss:  0.021832821890711784
p mean is: tensor(-1.6562, device='cuda:1')
epoch:  53000 quantization_loss:  0.02193155325949192
p mean is: tensor(-1.6623, device='cuda:1')
epoch:  54000 quantization_loss:  0.021759171038866043
p mean is: tensor(-1.6678, device='cuda:1')
epoch:  55000 quantization_loss:  0.02172585390508175
p mean is: tensor(-1.6729, device='cuda:1')
epoch:  56000 quantization_loss:  0.02167796716094017
p mean is: tensor(-1.6775, device='cuda:1')
epoch:  57000 quantization_loss:  0.02164650708436966
p mean is: tensor(-1.6817, device='cuda:1')
epoch:  58000 quantization_loss:  0.021614214405417442
p mean is: tensor(-1.6855, device='cuda:1')
epoch:  59000 quantization_loss:  0.021594315767288208
p mean is: tensor(-1.6891, device='cuda:1')
epoch:  60000 quantization_loss:  0.02156548574566841
p mean is: tensor(-1.6924, device='cuda:1')
epoch:  61000 quantization_loss:  0.021559765562415123
p mean is: tensor(-1.6954, device='cuda:1')
epoch:  62000 quantization_loss:  0.021559830754995346
p mean is: tensor(-1.6982, device='cuda:1')
epoch:  63000 quantization_loss:  0.02151789702475071
p mean is: tensor(-1.7008, device='cuda:1')
epoch:  64000 quantization_loss:  0.021511279046535492
p mean is: tensor(-1.7031, device='cuda:1')
epoch:  65000 quantization_loss:  0.0214945487678051
p mean is: tensor(-1.7053, device='cuda:1')
epoch:  66000 quantization_loss:  0.021495141088962555
p mean is: tensor(-1.7074, device='cuda:1')
epoch:  67000 quantization_loss:  0.02147972397506237
p mean is: tensor(-1.7094, device='cuda:1')
epoch:  68000 quantization_loss:  0.02146555483341217
p mean is: tensor(-1.7112, device='cuda:1')
epoch:  69000 quantization_loss:  0.021452337503433228
p mean is: tensor(-1.7129, device='cuda:1')
epoch:  70000 quantization_loss:  0.021451231092214584
p mean is: tensor(-1.7145, device='cuda:1')
epoch:  71000 quantization_loss:  0.02144497074186802
p mean is: tensor(-1.7159, device='cuda:1')
epoch:  72000 quantization_loss:  0.021424580365419388
p mean is: tensor(-1.7174, device='cuda:1')
epoch:  73000 quantization_loss:  0.02142181433737278
p mean is: tensor(-1.7187, device='cuda:1')
epoch:  74000 quantization_loss:  0.021416643634438515
p mean is: tensor(-1.7200, device='cuda:1')
epoch:  75000 quantization_loss:  0.021418990567326546
p mean is: tensor(-1.7211, device='cuda:1')
epoch:  76000 quantization_loss:  0.021402960643172264
p mean is: tensor(-1.7222, device='cuda:1')
epoch:  77000 quantization_loss:  0.02139929309487343
p mean is: tensor(-1.7233, device='cuda:1')
epoch:  78000 quantization_loss:  0.021396944299340248
p mean is: tensor(-1.7243, device='cuda:1')
epoch:  79000 quantization_loss:  0.02140200510621071
p mean is: tensor(-1.7251, device='cuda:1')
here
1.1.1.weight         | nonzeros =      53 /   12800             (  0.41%) | total_pruned =   12747 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       5 /      16             ( 31.25%) | total_pruned =      11 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =      15 /    6400             (  0.23%) | total_pruned =    6385 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       4 /      16             ( 25.00%) | total_pruned =      12 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =       9 /   12800             (  0.07%) | total_pruned =   12791 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =       5 /      32             ( 15.62%) | total_pruned =      27 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =       9 /   25600             (  0.04%) | total_pruned =   25591 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =       5 /      32             ( 15.62%) | total_pruned =      27 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =       2 /   51200             (  0.00%) | total_pruned =   51198 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =      10 /  102400             (  0.01%) | total_pruned =  102390 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =       0 /  204800             (  0.00%) | total_pruned =  204800 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =       0 /  409600             (  0.00%) | total_pruned =  409600 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =       0 /  409600             (  0.00%) | total_pruned =  409600 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =     319 /  409600             (  0.08%) | total_pruned =  409281 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    1531 /  409600             (  0.37%) | total_pruned =  408069 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   12416 /  409600             (  3.03%) | total_pruned =  397184 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   20294 /  147456             ( 13.76%) | total_pruned =  127162 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   26290 /  147456             ( 17.83%) | total_pruned =  121166 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   26895 /  147456             ( 18.24%) | total_pruned =  120561 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   13169 /   73728             ( 17.86%) | total_pruned =   60559 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2767 /   18432             ( 15.01%) | total_pruned =   15665 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1023 /    4608             ( 22.20%) | total_pruned =    3585 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      35 /      48             ( 72.92%) | total_pruned =      13 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 105896, pruned : 2902971, total: 3008867, Compression rate :      28.41x  ( 96.48% pruned)
PSNR of output image is:  11.971969617745202
Experiment done
