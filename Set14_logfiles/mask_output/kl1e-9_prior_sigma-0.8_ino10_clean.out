(3, 512, 512)
Starting vanilla DIP on 10 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.167194236247962'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/10/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/clean_img/-0.8/1e-09
epoch:  0 quantization_loss:  0.05443614348769188
p mean is: tensor(-0.0001, device='cuda:3')
epoch:  1000 quantization_loss:  0.04869500920176506
p mean is: tensor(-0.0053, device='cuda:3')
epoch:  2000 quantization_loss:  0.047506991773843765
p mean is: tensor(-0.0096, device='cuda:3')
epoch:  3000 quantization_loss:  0.04666249826550484
p mean is: tensor(-0.0132, device='cuda:3')
epoch:  4000 quantization_loss:  0.04743703454732895
p mean is: tensor(-0.0171, device='cuda:3')
epoch:  5000 quantization_loss:  0.04883719980716705
p mean is: tensor(-0.0209, device='cuda:3')
epoch:  6000 quantization_loss:  0.04669763520359993
p mean is: tensor(-0.0245, device='cuda:3')
epoch:  7000 quantization_loss:  0.047100815922021866
p mean is: tensor(-0.0286, device='cuda:3')
epoch:  8000 quantization_loss:  0.03404390439391136
p mean is: tensor(-0.0324, device='cuda:3')
epoch:  9000 quantization_loss:  0.027613019570708275
p mean is: tensor(-0.0368, device='cuda:3')
epoch:  10000 quantization_loss:  0.025639524683356285
p mean is: tensor(-0.0428, device='cuda:3')
epoch:  11000 quantization_loss:  0.02184699848294258
p mean is: tensor(-0.0511, device='cuda:3')
epoch:  12000 quantization_loss:  0.019320501014590263
p mean is: tensor(-0.0622, device='cuda:3')
epoch:  13000 quantization_loss:  0.016864599660038948
p mean is: tensor(-0.0770, device='cuda:3')
epoch:  14000 quantization_loss:  0.015533546917140484
p mean is: tensor(-0.0963, device='cuda:3')
epoch:  15000 quantization_loss:  0.014676723629236221
p mean is: tensor(-0.1207, device='cuda:3')
epoch:  16000 quantization_loss:  0.013742965646088123
p mean is: tensor(-0.1502, device='cuda:3')
epoch:  17000 quantization_loss:  0.013545223511755466
p mean is: tensor(-0.1851, device='cuda:3')
epoch:  18000 quantization_loss:  0.012751913629472256
p mean is: tensor(-0.2244, device='cuda:3')
epoch:  19000 quantization_loss:  0.012204168364405632
p mean is: tensor(-0.2673, device='cuda:3')
epoch:  20000 quantization_loss:  0.011751786805689335
p mean is: tensor(-0.3119, device='cuda:3')
epoch:  21000 quantization_loss:  0.011464283801615238
p mean is: tensor(-0.3564, device='cuda:3')
epoch:  22000 quantization_loss:  0.01119145192205906
p mean is: tensor(-0.3991, device='cuda:3')
epoch:  23000 quantization_loss:  0.010869774967432022
p mean is: tensor(-0.4392, device='cuda:3')
epoch:  24000 quantization_loss:  0.010688446462154388
p mean is: tensor(-0.4758, device='cuda:3')
epoch:  25000 quantization_loss:  0.010489649139344692
p mean is: tensor(-0.5091, device='cuda:3')
epoch:  26000 quantization_loss:  0.010336882434785366
p mean is: tensor(-0.5388, device='cuda:3')
epoch:  27000 quantization_loss:  0.010145826265215874
p mean is: tensor(-0.5650, device='cuda:3')
epoch:  28000 quantization_loss:  0.009952300228178501
p mean is: tensor(-0.5882, device='cuda:3')
epoch:  29000 quantization_loss:  0.009857133030891418
p mean is: tensor(-0.6086, device='cuda:3')
epoch:  30000 quantization_loss:  0.00973186083137989
p mean is: tensor(-0.6265, device='cuda:3')
epoch:  31000 quantization_loss:  0.009639822877943516
p mean is: tensor(-0.6423, device='cuda:3')
epoch:  32000 quantization_loss:  0.009518531151115894
p mean is: tensor(-0.6562, device='cuda:3')
epoch:  33000 quantization_loss:  0.009469629265367985
p mean is: tensor(-0.6684, device='cuda:3')
epoch:  34000 quantization_loss:  0.009402940049767494
p mean is: tensor(-0.6790, device='cuda:3')
epoch:  35000 quantization_loss:  0.009278373792767525
p mean is: tensor(-0.6885, device='cuda:3')
epoch:  36000 quantization_loss:  0.009237890131771564
p mean is: tensor(-0.6968, device='cuda:3')
epoch:  37000 quantization_loss:  0.009155084379017353
p mean is: tensor(-0.7042, device='cuda:3')
epoch:  38000 quantization_loss:  0.009063070639967918
p mean is: tensor(-0.7109, device='cuda:3')
epoch:  39000 quantization_loss:  0.009047663770616055
p mean is: tensor(-0.7169, device='cuda:3')
epoch:  40000 quantization_loss:  0.00901503674685955
p mean is: tensor(-0.7223, device='cuda:3')
epoch:  41000 quantization_loss:  0.009005401283502579
p mean is: tensor(-0.7271, device='cuda:3')
epoch:  42000 quantization_loss:  0.008928385563194752
p mean is: tensor(-0.7315, device='cuda:3')
epoch:  43000 quantization_loss:  0.008902963250875473
p mean is: tensor(-0.7355, device='cuda:3')
epoch:  44000 quantization_loss:  0.008827170357108116
p mean is: tensor(-0.7390, device='cuda:3')
epoch:  45000 quantization_loss:  0.008836491964757442
p mean is: tensor(-0.7424, device='cuda:3')
epoch:  46000 quantization_loss:  0.008790085092186928
p mean is: tensor(-0.7455, device='cuda:3')
epoch:  47000 quantization_loss:  0.008772604167461395
p mean is: tensor(-0.7484, device='cuda:3')
epoch:  48000 quantization_loss:  0.00871005654335022
p mean is: tensor(-0.7511, device='cuda:3')
epoch:  49000 quantization_loss:  0.00870415847748518
p mean is: tensor(-0.7535, device='cuda:3')
epoch:  50000 quantization_loss:  0.008697274141013622
p mean is: tensor(-0.7558, device='cuda:3')
epoch:  51000 quantization_loss:  0.008675353601574898
p mean is: tensor(-0.7580, device='cuda:3')
epoch:  52000 quantization_loss:  0.008660504594445229
p mean is: tensor(-0.7599, device='cuda:3')
epoch:  53000 quantization_loss:  0.008638349361717701
p mean is: tensor(-0.7618, device='cuda:3')
epoch:  54000 quantization_loss:  0.008631862699985504
p mean is: tensor(-0.7636, device='cuda:3')
epoch:  55000 quantization_loss:  0.00861339457333088
p mean is: tensor(-0.7653, device='cuda:3')
epoch:  56000 quantization_loss:  0.008608016185462475
p mean is: tensor(-0.7668, device='cuda:3')
epoch:  57000 quantization_loss:  0.008611652068793774
p mean is: tensor(-0.7683, device='cuda:3')
epoch:  58000 quantization_loss:  0.008588067255914211
p mean is: tensor(-0.7697, device='cuda:3')
epoch:  59000 quantization_loss:  0.0086367791518569
p mean is: tensor(-0.7712, device='cuda:3')
epoch:  60000 quantization_loss:  0.008567804470658302
p mean is: tensor(-0.7725, device='cuda:3')
epoch:  61000 quantization_loss:  0.008574013598263264
p mean is: tensor(-0.7738, device='cuda:3')
epoch:  62000 quantization_loss:  0.008559348061680794
p mean is: tensor(-0.7749, device='cuda:3')
epoch:  63000 quantization_loss:  0.008552600629627705
p mean is: tensor(-0.7760, device='cuda:3')
epoch:  64000 quantization_loss:  0.008539975620806217
p mean is: tensor(-0.7772, device='cuda:3')
epoch:  65000 quantization_loss:  0.008535453118383884
p mean is: tensor(-0.7783, device='cuda:3')
epoch:  66000 quantization_loss:  0.008539339527487755
p mean is: tensor(-0.7793, device='cuda:3')
epoch:  67000 quantization_loss:  0.008522847667336464
p mean is: tensor(-0.7804, device='cuda:3')
epoch:  68000 quantization_loss:  0.008530901744961739
p mean is: tensor(-0.7813, device='cuda:3')
epoch:  69000 quantization_loss:  0.008511626161634922
p mean is: tensor(-0.7822, device='cuda:3')
epoch:  70000 quantization_loss:  0.008519180119037628
p mean is: tensor(-0.7832, device='cuda:3')
epoch:  71000 quantization_loss:  0.008510753512382507
p mean is: tensor(-0.7841, device='cuda:3')
epoch:  72000 quantization_loss:  0.008520261384546757
p mean is: tensor(-0.7850, device='cuda:3')
epoch:  73000 quantization_loss:  0.008500933647155762
p mean is: tensor(-0.7858, device='cuda:3')
epoch:  74000 quantization_loss:  0.008508006110787392
p mean is: tensor(-0.7867, device='cuda:3')
epoch:  75000 quantization_loss:  0.008503288961946964
p mean is: tensor(-0.7874, device='cuda:3')
epoch:  76000 quantization_loss:  0.008494033478200436
p mean is: tensor(-0.7882, device='cuda:3')
epoch:  77000 quantization_loss:  0.008487792685627937
p mean is: tensor(-0.7890, device='cuda:3')
epoch:  78000 quantization_loss:  0.008483240380883217
p mean is: tensor(-0.7897, device='cuda:3')
epoch:  79000 quantization_loss:  0.00850708968937397
p mean is: tensor(-0.7904, device='cuda:3')
here
1.1.1.weight         | nonzeros =    1809 /   12800             ( 14.13%) | total_pruned =   10991 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     310 /    6400             (  4.84%) | total_pruned =    6090 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     222 /   12800             (  1.73%) | total_pruned =   12578 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     400 /   25600             (  1.56%) | total_pruned =   25200 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     413 /   51200             (  0.81%) | total_pruned =   50787 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     690 /  102400             (  0.67%) | total_pruned =  101710 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     531 /  204800             (  0.26%) | total_pruned =  204269 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =    1269 /  409600             (  0.31%) | total_pruned =  408331 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    1743 /  409600             (  0.43%) | total_pruned =  407857 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    8085 /  409600             (  1.97%) | total_pruned =  401515 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   23945 /  409600             (  5.85%) | total_pruned =  385655 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   51196 /  409600             ( 12.50%) | total_pruned =  358404 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   30959 /  147456             ( 21.00%) | total_pruned =  116497 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   33479 /  147456             ( 22.70%) | total_pruned =  113977 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   33261 /  147456             ( 22.56%) | total_pruned =  114195 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   12797 /   73728             ( 17.36%) | total_pruned =   60931 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    3424 /   18432             ( 18.58%) | total_pruned =   15008 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1378 /    4608             ( 29.90%) | total_pruned =    3230 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      30 /      48             ( 62.50%) | total_pruned =      18 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 207348, pruned : 2801519, total: 3008867, Compression rate :      14.51x  ( 93.11% pruned)
PSNR of output image is:  20.818389293823756
Experiment done
