Starting vanilla DIP on 0 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '19.677628458921582'
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/0/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-0.7/1e-09
epoch:  0 quantization_loss:  0.08341754227876663
p mean is: tensor(-0.0001, device='cuda:2')
epoch:  1000 quantization_loss:  0.07147110253572464
p mean is: tensor(-0.0049, device='cuda:2')
epoch:  2000 quantization_loss:  0.06761756539344788
p mean is: tensor(-0.0087, device='cuda:2')
epoch:  3000 quantization_loss:  0.06742008775472641
p mean is: tensor(-0.0126, device='cuda:2')
epoch:  4000 quantization_loss:  0.06713015586137772
p mean is: tensor(-0.0169, device='cuda:2')
epoch:  5000 quantization_loss:  0.06767880916595459
p mean is: tensor(-0.0213, device='cuda:2')
epoch:  6000 quantization_loss:  0.06584522128105164
p mean is: tensor(-0.0262, device='cuda:2')
epoch:  7000 quantization_loss:  0.06589677184820175
p mean is: tensor(-0.0318, device='cuda:2')
epoch:  8000 quantization_loss:  0.0657692402601242
p mean is: tensor(-0.0377, device='cuda:2')
epoch:  9000 quantization_loss:  0.06440992653369904
p mean is: tensor(-0.0445, device='cuda:2')
epoch:  10000 quantization_loss:  0.05770876631140709
p mean is: tensor(-0.0524, device='cuda:2')
epoch:  11000 quantization_loss:  0.054937127977609634
p mean is: tensor(-0.0621, device='cuda:2')
epoch:  12000 quantization_loss:  0.049074139446020126
p mean is: tensor(-0.0742, device='cuda:2')
epoch:  13000 quantization_loss:  0.045804254710674286
p mean is: tensor(-0.0895, device='cuda:2')
epoch:  14000 quantization_loss:  0.04468148201704025
p mean is: tensor(-0.1086, device='cuda:2')
epoch:  15000 quantization_loss:  0.04380593076348305
p mean is: tensor(-0.1326, device='cuda:2')
epoch:  16000 quantization_loss:  0.04253411665558815
p mean is: tensor(-0.1619, device='cuda:2')
epoch:  17000 quantization_loss:  0.042136479169130325
p mean is: tensor(-0.1963, device='cuda:2')
epoch:  18000 quantization_loss:  0.03965986892580986
p mean is: tensor(-0.2350, device='cuda:2')
epoch:  19000 quantization_loss:  0.03950997442007065
p mean is: tensor(-0.2759, device='cuda:2')
epoch:  20000 quantization_loss:  0.039179351180791855
p mean is: tensor(-0.3176, device='cuda:2')
epoch:  21000 quantization_loss:  0.03900280222296715
p mean is: tensor(-0.3582, device='cuda:2')
epoch:  22000 quantization_loss:  0.03532999008893967
p mean is: tensor(-0.3962, device='cuda:2')
epoch:  23000 quantization_loss:  0.0350697822868824
p mean is: tensor(-0.4304, device='cuda:2')
epoch:  24000 quantization_loss:  0.03498260676860809
p mean is: tensor(-0.4610, device='cuda:2')
epoch:  25000 quantization_loss:  0.03475474566221237
p mean is: tensor(-0.4881, device='cuda:2')
epoch:  26000 quantization_loss:  0.034678369760513306
p mean is: tensor(-0.5118, device='cuda:2')
epoch:  27000 quantization_loss:  0.034514155238866806
p mean is: tensor(-0.5326, device='cuda:2')
epoch:  28000 quantization_loss:  0.03451335057616234
p mean is: tensor(-0.5507, device='cuda:2')
epoch:  29000 quantization_loss:  0.03437129035592079
p mean is: tensor(-0.5666, device='cuda:2')
epoch:  30000 quantization_loss:  0.034227002412080765
p mean is: tensor(-0.5804, device='cuda:2')
epoch:  31000 quantization_loss:  0.032008096575737
p mean is: tensor(-0.5921, device='cuda:2')
epoch:  32000 quantization_loss:  0.0319092720746994
p mean is: tensor(-0.6023, device='cuda:2')
epoch:  33000 quantization_loss:  0.03182375058531761
p mean is: tensor(-0.6111, device='cuda:2')
epoch:  34000 quantization_loss:  0.031872592866420746
p mean is: tensor(-0.6189, device='cuda:2')
epoch:  35000 quantization_loss:  0.03171316906809807
p mean is: tensor(-0.6257, device='cuda:2')
epoch:  36000 quantization_loss:  0.031693924218416214
p mean is: tensor(-0.6318, device='cuda:2')
epoch:  37000 quantization_loss:  0.03163233771920204
p mean is: tensor(-0.6372, device='cuda:2')
epoch:  38000 quantization_loss:  0.031589120626449585
p mean is: tensor(-0.6421, device='cuda:2')
epoch:  39000 quantization_loss:  0.031577713787555695
p mean is: tensor(-0.6463, device='cuda:2')
epoch:  40000 quantization_loss:  0.030389176681637764
p mean is: tensor(-0.6501, device='cuda:2')
epoch:  41000 quantization_loss:  0.030078038573265076
p mean is: tensor(-0.6534, device='cuda:2')
epoch:  42000 quantization_loss:  0.030001552775502205
p mean is: tensor(-0.6564, device='cuda:2')
epoch:  43000 quantization_loss:  0.02994420751929283
p mean is: tensor(-0.6591, device='cuda:2')
epoch:  44000 quantization_loss:  0.029892129823565483
p mean is: tensor(-0.6616, device='cuda:2')
epoch:  45000 quantization_loss:  0.029887523502111435
p mean is: tensor(-0.6640, device='cuda:2')
epoch:  46000 quantization_loss:  0.02987798862159252
p mean is: tensor(-0.6662, device='cuda:2')
epoch:  47000 quantization_loss:  0.02979317307472229
p mean is: tensor(-0.6682, device='cuda:2')
epoch:  48000 quantization_loss:  0.02977006323635578
p mean is: tensor(-0.6701, device='cuda:2')
epoch:  49000 quantization_loss:  0.029751218855381012
p mean is: tensor(-0.6718, device='cuda:2')
here
1.1.1.weight         | nonzeros =    1958 /   12800             ( 15.30%) | total_pruned =   10842 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     353 /    6400             (  5.52%) | total_pruned =    6047 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     350 /   12800             (  2.73%) | total_pruned =   12450 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     502 /   25600             (  1.96%) | total_pruned =   25098 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     484 /   51200             (  0.95%) | total_pruned =   50716 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     920 /  102400             (  0.90%) | total_pruned =  101480 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     973 /  204800             (  0.48%) | total_pruned =  203827 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =    1706 /  409600             (  0.42%) | total_pruned =  407894 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    2104 /  409600             (  0.51%) | total_pruned =  407496 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    9502 /  409600             (  2.32%) | total_pruned =  400098 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   24156 /  409600             (  5.90%) | total_pruned =  385444 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   56234 /  409600             ( 13.73%) | total_pruned =  353366 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   31442 /  147456             ( 21.32%) | total_pruned =  116014 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   25498 /  147456             ( 17.29%) | total_pruned =  121958 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   16444 /  147456             ( 11.15%) | total_pruned =  131012 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   10506 /   73728             ( 14.25%) | total_pruned =   63222 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    1873 /   18432             ( 10.16%) | total_pruned =   16559 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =       9 /      32             ( 28.12%) | total_pruned =      23 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =       9 /      32             ( 28.12%) | total_pruned =      23 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =     620 /    4608             ( 13.45%) | total_pruned =    3988 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      27 /      48             ( 56.25%) | total_pruned =      21 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 186912, pruned : 2821955, total: 3008867, Compression rate :      16.10x  ( 93.79% pruned)
PSNR of output image is:  15.942741907835751
(3, 512, 512) (1, 3, 512, 512) (3, 512, 512)
Experiment done
(3, 512, 512)
Starting vanilla DIP on 0 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '19.675676039697652'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/0/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-0.7/1e-09
epoch:  0 quantization_loss:  0.08069159090518951
p mean is: tensor(-0.0001, device='cuda:2')
epoch:  1000 quantization_loss:  0.07007285207509995
p mean is: tensor(-0.0049, device='cuda:2')
epoch:  2000 quantization_loss:  0.0699751228094101
p mean is: tensor(-0.0090, device='cuda:2')
epoch:  3000 quantization_loss:  0.06872975081205368
p mean is: tensor(-0.0131, device='cuda:2')
epoch:  4000 quantization_loss:  0.06800105422735214
p mean is: tensor(-0.0178, device='cuda:2')
epoch:  5000 quantization_loss:  0.06777606904506683
p mean is: tensor(-0.0235, device='cuda:2')
epoch:  6000 quantization_loss:  0.06764857470989227
p mean is: tensor(-0.0293, device='cuda:2')
epoch:  7000 quantization_loss:  0.06681513041257858
p mean is: tensor(-0.0356, device='cuda:2')
epoch:  8000 quantization_loss:  0.06661562621593475
p mean is: tensor(-0.0421, device='cuda:2')
epoch:  9000 quantization_loss:  0.06573774665594101
p mean is: tensor(-0.0494, device='cuda:2')
epoch:  10000 quantization_loss:  0.05835948884487152
p mean is: tensor(-0.0581, device='cuda:2')
epoch:  11000 quantization_loss:  0.0516899973154068
p mean is: tensor(-0.0682, device='cuda:2')
epoch:  12000 quantization_loss:  0.050796572118997574
p mean is: tensor(-0.0804, device='cuda:2')
epoch:  13000 quantization_loss:  0.04039765149354935
p mean is: tensor(-0.0959, device='cuda:2')
epoch:  14000 quantization_loss:  0.03805099055171013
p mean is: tensor(-0.1146, device='cuda:2')
epoch:  15000 quantization_loss:  0.03636128827929497
p mean is: tensor(-0.1376, device='cuda:2')
epoch:  16000 quantization_loss:  0.03557555004954338
p mean is: tensor(-0.1653, device='cuda:2')
epoch:  17000 quantization_loss:  0.034507982432842255
p mean is: tensor(-0.1975, device='cuda:2')
epoch:  18000 quantization_loss:  0.03409236669540405
p mean is: tensor(-0.2336, device='cuda:2')
epoch:  19000 quantization_loss:  0.03279136121273041
p mean is: tensor(-0.2721, device='cuda:2')
epoch:  20000 quantization_loss:  0.03230461850762367
p mean is: tensor(-0.3112, device='cuda:2')
epoch:  21000 quantization_loss:  0.032077606767416
p mean is: tensor(-0.3496, device='cuda:2')
epoch:  22000 quantization_loss:  0.031851910054683685
p mean is: tensor(-0.3861, device='cuda:2')
epoch:  23000 quantization_loss:  0.03174488991498947
p mean is: tensor(-0.4201, device='cuda:2')
epoch:  24000 quantization_loss:  0.03159106522798538
p mean is: tensor(-0.4509, device='cuda:2')
epoch:  25000 quantization_loss:  0.031473834067583084
p mean is: tensor(-0.4784, device='cuda:2')
epoch:  26000 quantization_loss:  0.03140535205602646
p mean is: tensor(-0.5027, device='cuda:2')
epoch:  27000 quantization_loss:  0.031230762600898743
p mean is: tensor(-0.5241, device='cuda:2')
epoch:  28000 quantization_loss:  0.03121262788772583
p mean is: tensor(-0.5428, device='cuda:2')
epoch:  29000 quantization_loss:  0.03111189603805542
p mean is: tensor(-0.5592, device='cuda:2')
epoch:  30000 quantization_loss:  0.030917802825570107
p mean is: tensor(-0.5733, device='cuda:2')
epoch:  31000 quantization_loss:  0.030866634100675583
p mean is: tensor(-0.5858, device='cuda:2')
epoch:  32000 quantization_loss:  0.030794810503721237
p mean is: tensor(-0.5968, device='cuda:2')
epoch:  33000 quantization_loss:  0.03075951151549816
p mean is: tensor(-0.6063, device='cuda:2')
epoch:  34000 quantization_loss:  0.030703967437148094
p mean is: tensor(-0.6146, device='cuda:2')
epoch:  35000 quantization_loss:  0.03065003827214241
p mean is: tensor(-0.6220, device='cuda:2')
epoch:  36000 quantization_loss:  0.030634485185146332
p mean is: tensor(-0.6285, device='cuda:2')
epoch:  37000 quantization_loss:  0.03058435767889023
p mean is: tensor(-0.6343, device='cuda:2')
epoch:  38000 quantization_loss:  0.030543120577931404
p mean is: tensor(-0.6395, device='cuda:2')
epoch:  39000 quantization_loss:  0.030543075874447823
p mean is: tensor(-0.6440, device='cuda:2')
epoch:  40000 quantization_loss:  0.030468912795186043
p mean is: tensor(-0.6482, device='cuda:2')
epoch:  41000 quantization_loss:  0.030452772974967957
p mean is: tensor(-0.6518, device='cuda:2')
epoch:  42000 quantization_loss:  0.03044191002845764
p mean is: tensor(-0.6551, device='cuda:2')
epoch:  43000 quantization_loss:  0.030437979847192764
p mean is: tensor(-0.6582, device='cuda:2')
epoch:  44000 quantization_loss:  0.03040987066924572
p mean is: tensor(-0.6609, device='cuda:2')
epoch:  45000 quantization_loss:  0.03039213828742504
p mean is: tensor(-0.6635, device='cuda:2')
epoch:  46000 quantization_loss:  0.030349237844347954
p mean is: tensor(-0.6658, device='cuda:2')
epoch:  47000 quantization_loss:  0.030342459678649902
p mean is: tensor(-0.6679, device='cuda:2')
epoch:  48000 quantization_loss:  0.030343348160386086
p mean is: tensor(-0.6699, device='cuda:2')
epoch:  49000 quantization_loss:  0.030332226306200027
p mean is: tensor(-0.6718, device='cuda:2')
epoch:  50000 quantization_loss:  0.03031884878873825
p mean is: tensor(-0.6734, device='cuda:2')
epoch:  51000 quantization_loss:  0.030310407280921936
p mean is: tensor(-0.6750, device='cuda:2')
epoch:  52000 quantization_loss:  0.030299510806798935
p mean is: tensor(-0.6765, device='cuda:2')
epoch:  53000 quantization_loss:  0.030293554067611694
p mean is: tensor(-0.6778, device='cuda:2')
epoch:  54000 quantization_loss:  0.030286749824881554
p mean is: tensor(-0.6791, device='cuda:2')
epoch:  55000 quantization_loss:  0.030266903340816498
p mean is: tensor(-0.6803, device='cuda:2')
epoch:  56000 quantization_loss:  0.030276361852884293
p mean is: tensor(-0.6815, device='cuda:2')
epoch:  57000 quantization_loss:  0.030273038893938065
p mean is: tensor(-0.6825, device='cuda:2')
epoch:  58000 quantization_loss:  0.030263330787420273
p mean is: tensor(-0.6835, device='cuda:2')
epoch:  59000 quantization_loss:  0.030249977484345436
p mean is: tensor(-0.6845, device='cuda:2')
epoch:  60000 quantization_loss:  0.030246172100305557
p mean is: tensor(-0.6854, device='cuda:2')
epoch:  61000 quantization_loss:  0.030241582542657852
p mean is: tensor(-0.6863, device='cuda:2')
epoch:  62000 quantization_loss:  0.030246801674365997
p mean is: tensor(-0.6871, device='cuda:2')
epoch:  63000 quantization_loss:  0.030234534293413162
p mean is: tensor(-0.6880, device='cuda:2')
epoch:  64000 quantization_loss:  0.030243543907999992
p mean is: tensor(-0.6887, device='cuda:2')
epoch:  65000 quantization_loss:  0.030243966728448868
p mean is: tensor(-0.6894, device='cuda:2')
epoch:  66000 quantization_loss:  0.030229410156607628
p mean is: tensor(-0.6901, device='cuda:2')
epoch:  67000 quantization_loss:  0.030222749337553978
p mean is: tensor(-0.6909, device='cuda:2')
epoch:  68000 quantization_loss:  0.030219312757253647
p mean is: tensor(-0.6915, device='cuda:2')
epoch:  69000 quantization_loss:  0.030211549252271652
p mean is: tensor(-0.6921, device='cuda:2')
epoch:  70000 quantization_loss:  0.030205633491277695
p mean is: tensor(-0.6927, device='cuda:2')
epoch:  71000 quantization_loss:  0.03020700253546238
p mean is: tensor(-0.6933, device='cuda:2')
epoch:  72000 quantization_loss:  0.030199291184544563
p mean is: tensor(-0.6938, device='cuda:2')
epoch:  73000 quantization_loss:  0.03029201179742813
p mean is: tensor(-0.6944, device='cuda:2')
epoch:  74000 quantization_loss:  0.030198484659194946
p mean is: tensor(-0.6950, device='cuda:2')
epoch:  75000 quantization_loss:  0.030196569859981537
p mean is: tensor(-0.6955, device='cuda:2')
epoch:  76000 quantization_loss:  0.03019755519926548
p mean is: tensor(-0.6960, device='cuda:2')
epoch:  77000 quantization_loss:  0.030195603147149086
p mean is: tensor(-0.6965, device='cuda:2')
epoch:  78000 quantization_loss:  0.030227532610297203
p mean is: tensor(-0.6970, device='cuda:2')
epoch:  79000 quantization_loss:  0.030189847573637962
p mean is: tensor(-0.6974, device='cuda:2')
here
1.1.1.weight         | nonzeros =    1625 /   12800             ( 12.70%) | total_pruned =   11175 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     204 /    6400             (  3.19%) | total_pruned =    6196 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     177 /   12800             (  1.38%) | total_pruned =   12623 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     295 /   25600             (  1.15%) | total_pruned =   25305 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     395 /   51200             (  0.77%) | total_pruned =   50805 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     661 /  102400             (  0.65%) | total_pruned =  101739 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     410 /  204800             (  0.20%) | total_pruned =  204390 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      49 /     128             ( 38.28%) | total_pruned =      79 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =    1116 /  409600             (  0.27%) | total_pruned =  408484 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    1805 /  409600             (  0.44%) | total_pruned =  407795 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    6020 /  409600             (  1.47%) | total_pruned =  403580 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   17110 /  409600             (  4.18%) | total_pruned =  392490 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   45289 /  409600             ( 11.06%) | total_pruned =  364311 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   31026 /  147456             ( 21.04%) | total_pruned =  116430 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   30931 /  147456             ( 20.98%) | total_pruned =  116525 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   20105 /  147456             ( 13.63%) | total_pruned =  127351 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    5917 /   73728             (  8.03%) | total_pruned =   67811 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    1400 /   18432             (  7.60%) | total_pruned =   17032 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =     918 /    4608             ( 19.92%) | total_pruned =    3690 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      27 /      48             ( 56.25%) | total_pruned =      21 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 166634, pruned : 2842233, total: 3008867, Compression rate :      18.06x  ( 94.46% pruned)
PSNR of output image is:  15.847650744902149
Experiment done
