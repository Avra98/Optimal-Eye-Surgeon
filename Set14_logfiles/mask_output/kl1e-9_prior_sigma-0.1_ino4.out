Starting vanilla DIP on 4 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '19.759531163659908'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/4/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/-0.1/1e-09
epoch:  0 quantization_loss:  0.07042154669761658
p mean is: tensor(-1.7115e-05, device='cuda:4')
epoch:  1000 quantization_loss:  0.04858188331127167
p mean is: tensor(-0.0005, device='cuda:4')
epoch:  2000 quantization_loss:  0.04761885106563568
p mean is: tensor(-0.0012, device='cuda:4')
epoch:  3000 quantization_loss:  0.04661247506737709
p mean is: tensor(-0.0018, device='cuda:4')
epoch:  4000 quantization_loss:  0.04694704711437225
p mean is: tensor(-0.0026, device='cuda:4')
epoch:  5000 quantization_loss:  0.04688270017504692
p mean is: tensor(-0.0034, device='cuda:4')
epoch:  6000 quantization_loss:  0.045455243438482285
p mean is: tensor(-0.0045, device='cuda:4')
epoch:  7000 quantization_loss:  0.04491565003991127
p mean is: tensor(-0.0057, device='cuda:4')
epoch:  8000 quantization_loss:  0.043473586440086365
p mean is: tensor(-0.0073, device='cuda:4')
epoch:  9000 quantization_loss:  0.039813894778490067
p mean is: tensor(-0.0088, device='cuda:4')
epoch:  10000 quantization_loss:  0.03268442675471306
p mean is: tensor(-0.0107, device='cuda:4')
epoch:  11000 quantization_loss:  0.029426228255033493
p mean is: tensor(-0.0129, device='cuda:4')
epoch:  12000 quantization_loss:  0.02850515767931938
p mean is: tensor(-0.0156, device='cuda:4')
epoch:  13000 quantization_loss:  0.027530096471309662
p mean is: tensor(-0.0187, device='cuda:4')
epoch:  14000 quantization_loss:  0.02533338963985443
p mean is: tensor(-0.0226, device='cuda:4')
epoch:  15000 quantization_loss:  0.024222388863563538
p mean is: tensor(-0.0269, device='cuda:4')
epoch:  16000 quantization_loss:  0.02361958473920822
p mean is: tensor(-0.0318, device='cuda:4')
epoch:  17000 quantization_loss:  0.02310258150100708
p mean is: tensor(-0.0369, device='cuda:4')
epoch:  18000 quantization_loss:  0.022869307547807693
p mean is: tensor(-0.0422, device='cuda:4')
epoch:  19000 quantization_loss:  0.022545335814356804
p mean is: tensor(-0.0476, device='cuda:4')
epoch:  20000 quantization_loss:  0.022278612479567528
p mean is: tensor(-0.0530, device='cuda:4')
epoch:  21000 quantization_loss:  0.022329915314912796
p mean is: tensor(-0.0580, device='cuda:4')
epoch:  22000 quantization_loss:  0.022052248939871788
p mean is: tensor(-0.0625, device='cuda:4')
epoch:  23000 quantization_loss:  0.021887117996811867
p mean is: tensor(-0.0667, device='cuda:4')
epoch:  24000 quantization_loss:  0.021728824824094772
p mean is: tensor(-0.0705, device='cuda:4')
epoch:  25000 quantization_loss:  0.021733025088906288
p mean is: tensor(-0.0737, device='cuda:4')
epoch:  26000 quantization_loss:  0.021673444658517838
p mean is: tensor(-0.0764, device='cuda:4')
epoch:  27000 quantization_loss:  0.021560916677117348
p mean is: tensor(-0.0786, device='cuda:4')
epoch:  28000 quantization_loss:  0.021534273400902748
p mean is: tensor(-0.0805, device='cuda:4')
epoch:  29000 quantization_loss:  0.021423934027552605
p mean is: tensor(-0.0822, device='cuda:4')
epoch:  30000 quantization_loss:  0.02143828198313713
p mean is: tensor(-0.0836, device='cuda:4')
epoch:  31000 quantization_loss:  0.021339919418096542
p mean is: tensor(-0.0847, device='cuda:4')
epoch:  32000 quantization_loss:  0.021277382969856262
p mean is: tensor(-0.0857, device='cuda:4')
epoch:  33000 quantization_loss:  0.02124118059873581
p mean is: tensor(-0.0865, device='cuda:4')
epoch:  34000 quantization_loss:  0.021212201565504074
p mean is: tensor(-0.0873, device='cuda:4')
epoch:  35000 quantization_loss:  0.02116258256137371
p mean is: tensor(-0.0880, device='cuda:4')
epoch:  36000 quantization_loss:  0.02114100754261017
p mean is: tensor(-0.0886, device='cuda:4')
epoch:  37000 quantization_loss:  0.02117239497601986
p mean is: tensor(-0.0891, device='cuda:4')
epoch:  38000 quantization_loss:  0.021109456196427345
p mean is: tensor(-0.0895, device='cuda:4')
epoch:  39000 quantization_loss:  0.021091632544994354
p mean is: tensor(-0.0899, device='cuda:4')
epoch:  40000 quantization_loss:  0.021057482808828354
p mean is: tensor(-0.0904, device='cuda:4')
epoch:  41000 quantization_loss:  0.021051809191703796
p mean is: tensor(-0.0908, device='cuda:4')
epoch:  42000 quantization_loss:  0.02102307602763176
p mean is: tensor(-0.0911, device='cuda:4')
epoch:  43000 quantization_loss:  0.021013999357819557
p mean is: tensor(-0.0914, device='cuda:4')
epoch:  44000 quantization_loss:  0.020980069413781166
p mean is: tensor(-0.0917, device='cuda:4')
epoch:  45000 quantization_loss:  0.020971836522221565
p mean is: tensor(-0.0920, device='cuda:4')
epoch:  46000 quantization_loss:  0.020967787131667137
p mean is: tensor(-0.0923, device='cuda:4')
epoch:  47000 quantization_loss:  0.02099769189953804
p mean is: tensor(-0.0925, device='cuda:4')
epoch:  48000 quantization_loss:  0.020940018817782402
p mean is: tensor(-0.0928, device='cuda:4')
epoch:  49000 quantization_loss:  0.020921939983963966
p mean is: tensor(-0.0931, device='cuda:4')
epoch:  50000 quantization_loss:  0.020917832851409912
p mean is: tensor(-0.0934, device='cuda:4')
epoch:  51000 quantization_loss:  0.020925045013427734
p mean is: tensor(-0.0936, device='cuda:4')
epoch:  52000 quantization_loss:  0.020895151421427727
p mean is: tensor(-0.0939, device='cuda:4')
epoch:  53000 quantization_loss:  0.02089475654065609
p mean is: tensor(-0.0940, device='cuda:4')
epoch:  54000 quantization_loss:  0.020929329097270966
p mean is: tensor(-0.0942, device='cuda:4')
epoch:  55000 quantization_loss:  0.020873557776212692
p mean is: tensor(-0.0944, device='cuda:4')
epoch:  56000 quantization_loss:  0.020876912400126457
p mean is: tensor(-0.0947, device='cuda:4')
epoch:  57000 quantization_loss:  0.020869383588433266
p mean is: tensor(-0.0948, device='cuda:4')
epoch:  58000 quantization_loss:  0.020861415192484856
p mean is: tensor(-0.0949, device='cuda:4')
epoch:  59000 quantization_loss:  0.020868390798568726
p mean is: tensor(-0.0950, device='cuda:4')
epoch:  60000 quantization_loss:  0.020859327167272568
p mean is: tensor(-0.0953, device='cuda:4')
epoch:  61000 quantization_loss:  0.020854929462075233
p mean is: tensor(-0.0954, device='cuda:4')
epoch:  62000 quantization_loss:  0.02084832638502121
p mean is: tensor(-0.0956, device='cuda:4')
epoch:  63000 quantization_loss:  0.020842041820287704
p mean is: tensor(-0.0958, device='cuda:4')
epoch:  64000 quantization_loss:  0.02083956077694893
p mean is: tensor(-0.0959, device='cuda:4')
epoch:  65000 quantization_loss:  0.020834239199757576
p mean is: tensor(-0.0961, device='cuda:4')
epoch:  66000 quantization_loss:  0.020834224298596382
p mean is: tensor(-0.0962, device='cuda:4')
epoch:  67000 quantization_loss:  0.02084694802761078
p mean is: tensor(-0.0964, device='cuda:4')
epoch:  68000 quantization_loss:  0.020824650302529335
p mean is: tensor(-0.0965, device='cuda:4')
epoch:  69000 quantization_loss:  0.02081621252000332
p mean is: tensor(-0.0966, device='cuda:4')
epoch:  70000 quantization_loss:  0.0208218302577734
p mean is: tensor(-0.0967, device='cuda:4')
epoch:  71000 quantization_loss:  0.020813707262277603
p mean is: tensor(-0.0969, device='cuda:4')
epoch:  72000 quantization_loss:  0.020812472328543663
p mean is: tensor(-0.0970, device='cuda:4')
epoch:  73000 quantization_loss:  0.020809831097722054
p mean is: tensor(-0.0971, device='cuda:4')
epoch:  74000 quantization_loss:  0.020813999697566032
p mean is: tensor(-0.0972, device='cuda:4')
epoch:  75000 quantization_loss:  0.020810047164559364
p mean is: tensor(-0.0973, device='cuda:4')
epoch:  76000 quantization_loss:  0.02080870419740677
p mean is: tensor(-0.0974, device='cuda:4')
epoch:  77000 quantization_loss:  0.02080606110394001
p mean is: tensor(-0.0976, device='cuda:4')
epoch:  78000 quantization_loss:  0.02080363593995571
p mean is: tensor(-0.0976, device='cuda:4')
epoch:  79000 quantization_loss:  0.020802492275834084
p mean is: tensor(-0.0977, device='cuda:4')
here
1.1.1.weight         | nonzeros =    1824 /   12800             ( 14.25%) | total_pruned =   10976 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       5 /      16             ( 31.25%) | total_pruned =      11 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     471 /    6400             (  7.36%) | total_pruned =    5929 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =    1184 /   12800             (  9.25%) | total_pruned =   11616 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =    2736 /   25600             ( 10.69%) | total_pruned =   22864 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =    4615 /   51200             (  9.01%) | total_pruned =   46585 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =    8136 /  102400             (  7.95%) | total_pruned =   94264 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =   16493 /  204800             (  8.05%) | total_pruned =  188307 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =   31989 /  409600             (  7.81%) | total_pruned =  377611 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   44379 /  409600             ( 10.83%) | total_pruned =  365221 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   58741 /  409600             ( 14.34%) | total_pruned =  350859 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   77903 /  409600             ( 19.02%) | total_pruned =  331697 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   90911 /  409600             ( 22.20%) | total_pruned =  318689 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   36294 /  147456             ( 24.61%) | total_pruned =  111162 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   24052 /  147456             ( 16.31%) | total_pruned =  123404 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   17470 /  147456             ( 11.85%) | total_pruned =  129986 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    9617 /   73728             ( 13.04%) | total_pruned =   64111 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    3021 /   18432             ( 16.39%) | total_pruned =   15411 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1247 /    4608             ( 27.06%) | total_pruned =    3361 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      14 /      16             ( 87.50%) | total_pruned =       2 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      31 /      48             ( 64.58%) | total_pruned =      17 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 432385, pruned : 2576482, total: 3008867, Compression rate :       6.96x  ( 85.63% pruned)
PSNR of output image is:  18.800996021334978
Experiment done
