(3, 512, 512)
Starting vanilla DIP on 5 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.105728870333714'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/5/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/clean_img/-1.0/1e-09
(3, 512, 512)
Starting vanilla DIP on 5 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.088307722738683'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/5/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/clean_img/-1.0/1e-09
(3, 512, 512)
Starting vanilla DIP on 5 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.094322580157595'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/5/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/clean_img/-1.0/1e-09
epoch:  0 quantization_loss:  0.07280704379081726
p mean is: tensor(-0.0002, device='cuda:2')
epoch:  1000 quantization_loss:  0.05696987733244896
p mean is: tensor(-0.0077, device='cuda:2')
epoch:  2000 quantization_loss:  0.055725786834955215
p mean is: tensor(-0.0136, device='cuda:2')
epoch:  3000 quantization_loss:  0.055318303406238556
p mean is: tensor(-0.0195, device='cuda:2')
epoch:  4000 quantization_loss:  0.0553019680082798
p mean is: tensor(-0.0256, device='cuda:2')
epoch:  5000 quantization_loss:  0.05597594752907753
p mean is: tensor(-0.0319, device='cuda:2')
epoch:  6000 quantization_loss:  0.054923031479120255
p mean is: tensor(-0.0384, device='cuda:2')
epoch:  7000 quantization_loss:  0.05517715588212013
p mean is: tensor(-0.0450, device='cuda:2')
epoch:  8000 quantization_loss:  0.05482880026102066
p mean is: tensor(-0.0524, device='cuda:2')
epoch:  9000 quantization_loss:  0.05288887768983841
p mean is: tensor(-0.0604, device='cuda:2')
epoch:  10000 quantization_loss:  0.04734468087553978
p mean is: tensor(-0.0695, device='cuda:2')
epoch:  11000 quantization_loss:  0.04288741201162338
p mean is: tensor(-0.0809, device='cuda:2')
epoch:  12000 quantization_loss:  0.03532906249165535
p mean is: tensor(-0.0955, device='cuda:2')
epoch:  13000 quantization_loss:  0.031716007739305496
p mean is: tensor(-0.1142, device='cuda:2')
epoch:  14000 quantization_loss:  0.03019547276198864
p mean is: tensor(-0.1378, device='cuda:2')
epoch:  15000 quantization_loss:  0.02815694361925125
p mean is: tensor(-0.1676, device='cuda:2')
epoch:  16000 quantization_loss:  0.028161192312836647
p mean is: tensor(-0.2042, device='cuda:2')
epoch:  17000 quantization_loss:  0.02562795579433441
p mean is: tensor(-0.2480, device='cuda:2')
epoch:  18000 quantization_loss:  0.02480831928551197
p mean is: tensor(-0.2977, device='cuda:2')
epoch:  19000 quantization_loss:  0.02436170168220997
p mean is: tensor(-0.3518, device='cuda:2')
epoch:  20000 quantization_loss:  0.023914532735943794
p mean is: tensor(-0.4079, device='cuda:2')
epoch:  21000 quantization_loss:  0.02349134534597397
p mean is: tensor(-0.4638, device='cuda:2')
epoch:  22000 quantization_loss:  0.022983962669968605
p mean is: tensor(-0.5167, device='cuda:2')
epoch:  23000 quantization_loss:  0.022717630490660667
p mean is: tensor(-0.5658, device='cuda:2')
epoch:  24000 quantization_loss:  0.02250787988305092
p mean is: tensor(-0.6101, device='cuda:2')
epoch:  25000 quantization_loss:  0.022393209859728813
p mean is: tensor(-0.6499, device='cuda:2')
epoch:  26000 quantization_loss:  0.022069444879889488
p mean is: tensor(-0.6850, device='cuda:2')
epoch:  27000 quantization_loss:  0.022011060267686844
p mean is: tensor(-0.7161, device='cuda:2')
epoch:  28000 quantization_loss:  0.021976087242364883
p mean is: tensor(-0.7435, device='cuda:2')
epoch:  29000 quantization_loss:  0.021837450563907623
p mean is: tensor(-0.7674, device='cuda:2')
epoch:  30000 quantization_loss:  0.021758968010544777
p mean is: tensor(-0.7884, device='cuda:2')
epoch:  31000 quantization_loss:  0.021600104868412018
p mean is: tensor(-0.8068, device='cuda:2')
epoch:  32000 quantization_loss:  0.02147787995636463
p mean is: tensor(-0.8232, device='cuda:2')
epoch:  33000 quantization_loss:  0.021417740732431412
p mean is: tensor(-0.8376, device='cuda:2')
epoch:  34000 quantization_loss:  0.021357102319598198
p mean is: tensor(-0.8503, device='cuda:2')
epoch:  35000 quantization_loss:  0.02129344269633293
p mean is: tensor(-0.8615, device='cuda:2')
epoch:  36000 quantization_loss:  0.02126677706837654
p mean is: tensor(-0.8715, device='cuda:2')
epoch:  37000 quantization_loss:  0.021198222413659096
p mean is: tensor(-0.8804, device='cuda:2')
epoch:  38000 quantization_loss:  0.02115178480744362
p mean is: tensor(-0.8884, device='cuda:2')
epoch:  39000 quantization_loss:  0.021170474588871002
p mean is: tensor(-0.8956, device='cuda:2')
epoch:  40000 quantization_loss:  0.02108863927423954
p mean is: tensor(-0.9020, device='cuda:2')
epoch:  41000 quantization_loss:  0.02104927971959114
p mean is: tensor(-0.9079, device='cuda:2')
epoch:  42000 quantization_loss:  0.021029764786362648
p mean is: tensor(-0.9132, device='cuda:2')
epoch:  43000 quantization_loss:  0.020984074100852013
p mean is: tensor(-0.9181, device='cuda:2')
epoch:  44000 quantization_loss:  0.020955922082066536
p mean is: tensor(-0.9225, device='cuda:2')
epoch:  45000 quantization_loss:  0.02094964310526848
p mean is: tensor(-0.9266, device='cuda:2')
epoch:  46000 quantization_loss:  0.020924672484397888
p mean is: tensor(-0.9303, device='cuda:2')
epoch:  47000 quantization_loss:  0.020896263420581818
p mean is: tensor(-0.9338, device='cuda:2')
epoch:  48000 quantization_loss:  0.020878706127405167
p mean is: tensor(-0.9370, device='cuda:2')
epoch:  49000 quantization_loss:  0.0208535585552454
p mean is: tensor(-0.9399, device='cuda:2')
epoch:  50000 quantization_loss:  0.02085166983306408
p mean is: tensor(-0.9426, device='cuda:2')
epoch:  51000 quantization_loss:  0.020874235779047012
p mean is: tensor(-0.9451, device='cuda:2')
epoch:  52000 quantization_loss:  0.020846348255872726
p mean is: tensor(-0.9475, device='cuda:2')
epoch:  53000 quantization_loss:  0.020805398002266884
p mean is: tensor(-0.9497, device='cuda:2')
epoch:  54000 quantization_loss:  0.02080453746020794
p mean is: tensor(-0.9517, device='cuda:2')
epoch:  55000 quantization_loss:  0.02079450525343418
p mean is: tensor(-0.9536, device='cuda:2')
epoch:  56000 quantization_loss:  0.020792894065380096
p mean is: tensor(-0.9555, device='cuda:2')
epoch:  57000 quantization_loss:  0.020781435072422028
p mean is: tensor(-0.9573, device='cuda:2')
epoch:  58000 quantization_loss:  0.020763592794537544
p mean is: tensor(-0.9589, device='cuda:2')
epoch:  59000 quantization_loss:  0.02076507918536663
p mean is: tensor(-0.9605, device='cuda:2')
epoch:  60000 quantization_loss:  0.020753012970089912
p mean is: tensor(-0.9620, device='cuda:2')
epoch:  61000 quantization_loss:  0.02075125463306904
p mean is: tensor(-0.9634, device='cuda:2')
epoch:  62000 quantization_loss:  0.02074035070836544
p mean is: tensor(-0.9648, device='cuda:2')
epoch:  63000 quantization_loss:  0.02073838748037815
p mean is: tensor(-0.9661, device='cuda:2')
epoch:  64000 quantization_loss:  0.02072904258966446
p mean is: tensor(-0.9674, device='cuda:2')
epoch:  65000 quantization_loss:  0.02073485217988491
p mean is: tensor(-0.9685, device='cuda:2')
epoch:  66000 quantization_loss:  0.02072477899491787
p mean is: tensor(-0.9697, device='cuda:2')
epoch:  67000 quantization_loss:  0.02071652002632618
p mean is: tensor(-0.9708, device='cuda:2')
epoch:  68000 quantization_loss:  0.020716896280646324
p mean is: tensor(-0.9719, device='cuda:2')
epoch:  69000 quantization_loss:  0.020710445940494537
p mean is: tensor(-0.9729, device='cuda:2')
epoch:  70000 quantization_loss:  0.020703133195638657
p mean is: tensor(-0.9739, device='cuda:2')
epoch:  71000 quantization_loss:  0.02071184664964676
p mean is: tensor(-0.9749, device='cuda:2')
epoch:  72000 quantization_loss:  0.020701535046100616
p mean is: tensor(-0.9759, device='cuda:2')
epoch:  73000 quantization_loss:  0.020702317357063293
p mean is: tensor(-0.9768, device='cuda:2')
epoch:  74000 quantization_loss:  0.020694665610790253
p mean is: tensor(-0.9777, device='cuda:2')
epoch:  75000 quantization_loss:  0.02069440670311451
p mean is: tensor(-0.9786, device='cuda:2')
epoch:  76000 quantization_loss:  0.020687997341156006
p mean is: tensor(-0.9794, device='cuda:2')
epoch:  77000 quantization_loss:  0.020687317475676537
p mean is: tensor(-0.9802, device='cuda:2')
epoch:  78000 quantization_loss:  0.020686255767941475
p mean is: tensor(-0.9810, device='cuda:2')
epoch:  79000 quantization_loss:  0.020674362778663635
p mean is: tensor(-0.9818, device='cuda:2')
here
1.1.1.weight         | nonzeros =     990 /   12800             (  7.73%) | total_pruned =   11810 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     133 /    6400             (  2.08%) | total_pruned =    6267 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      89 /   12800             (  0.70%) | total_pruned =   12711 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      10 /      32             ( 31.25%) | total_pruned =      22 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     146 /   25600             (  0.57%) | total_pruned =   25454 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     109 /   51200             (  0.21%) | total_pruned =   51091 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     201 /  102400             (  0.20%) | total_pruned =  102199 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =      65 /  204800             (  0.03%) | total_pruned =  204735 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     372 /  409600             (  0.09%) | total_pruned =  409228 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     434 /  409600             (  0.11%) | total_pruned =  409166 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    3495 /  409600             (  0.85%) | total_pruned =  406105 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   11063 /  409600             (  2.70%) | total_pruned =  398537 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   39040 /  409600             (  9.53%) | total_pruned =  370560 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   32488 /  147456             ( 22.03%) | total_pruned =  114968 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   31986 /  147456             ( 21.69%) | total_pruned =  115470 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   28118 /  147456             ( 19.07%) | total_pruned =  119338 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   12142 /   73728             ( 16.47%) | total_pruned =   61586 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2741 /   18432             ( 14.87%) | total_pruned =   15691 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1153 /    4608             ( 25.02%) | total_pruned =    3455 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      32 /      48             ( 66.67%) | total_pruned =      16 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 166075, pruned : 2842792, total: 3008867, Compression rate :      18.12x  ( 94.48% pruned)
PSNR of output image is:  19.266667661676642
Experiment done
(3, 512, 512)
Starting vanilla DIP on 5 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.09356587680726'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/5/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/clean_img/-1.0/1e-09
epoch:  0 quantization_loss:  0.060218073427677155
p mean is: tensor(-0.0002, device='cuda:4')
epoch:  1000 quantization_loss:  0.04885018244385719
p mean is: tensor(-0.0090, device='cuda:4')
epoch:  2000 quantization_loss:  0.0461704321205616
p mean is: tensor(-0.0161, device='cuda:4')
epoch:  3000 quantization_loss:  0.046250518411397934
p mean is: tensor(-0.0227, device='cuda:4')
epoch:  4000 quantization_loss:  0.045207250863313675
p mean is: tensor(-0.0298, device='cuda:4')
epoch:  5000 quantization_loss:  0.045593615621328354
p mean is: tensor(-0.0370, device='cuda:4')
epoch:  6000 quantization_loss:  0.04495307803153992
p mean is: tensor(-0.0449, device='cuda:4')
epoch:  7000 quantization_loss:  0.04520273581147194
p mean is: tensor(-0.0537, device='cuda:4')
epoch:  8000 quantization_loss:  0.04153446480631828
p mean is: tensor(-0.0630, device='cuda:4')
epoch:  9000 quantization_loss:  0.03573409840464592
p mean is: tensor(-0.0736, device='cuda:4')
epoch:  10000 quantization_loss:  0.029969612136483192
p mean is: tensor(-0.0871, device='cuda:4')
epoch:  11000 quantization_loss:  0.024753285571932793
p mean is: tensor(-0.1038, device='cuda:4')
epoch:  12000 quantization_loss:  0.021236717700958252
p mean is: tensor(-0.1244, device='cuda:4')
epoch:  13000 quantization_loss:  0.019219430163502693
p mean is: tensor(-0.1502, device='cuda:4')
epoch:  14000 quantization_loss:  0.01869726926088333
p mean is: tensor(-0.1827, device='cuda:4')
epoch:  15000 quantization_loss:  0.0167048629373312
p mean is: tensor(-0.2222, device='cuda:4')
epoch:  16000 quantization_loss:  0.01608153060078621
p mean is: tensor(-0.2685, device='cuda:4')
epoch:  17000 quantization_loss:  0.015332787297666073
p mean is: tensor(-0.3206, device='cuda:4')
epoch:  18000 quantization_loss:  0.01407348271459341
p mean is: tensor(-0.3761, device='cuda:4')
epoch:  19000 quantization_loss:  0.01385658048093319
p mean is: tensor(-0.4322, device='cuda:4')
epoch:  20000 quantization_loss:  0.0134950065985322
p mean is: tensor(-0.4870, device='cuda:4')
epoch:  21000 quantization_loss:  0.013289294205605984
p mean is: tensor(-0.5387, device='cuda:4')
epoch:  22000 quantization_loss:  0.013057777658104897
p mean is: tensor(-0.5861, device='cuda:4')
epoch:  23000 quantization_loss:  0.012996366247534752
p mean is: tensor(-0.6287, device='cuda:4')
epoch:  24000 quantization_loss:  0.012748866342008114
p mean is: tensor(-0.6669, device='cuda:4')
epoch:  25000 quantization_loss:  0.012645736336708069
p mean is: tensor(-0.7007, device='cuda:4')
epoch:  26000 quantization_loss:  0.012518253177404404
p mean is: tensor(-0.7305, device='cuda:4')
epoch:  27000 quantization_loss:  0.012443426996469498
p mean is: tensor(-0.7565, device='cuda:4')
epoch:  28000 quantization_loss:  0.011755176819860935
p mean is: tensor(-0.7794, device='cuda:4')
epoch:  29000 quantization_loss:  0.011586878448724747
p mean is: tensor(-0.7992, device='cuda:4')
epoch:  30000 quantization_loss:  0.01148479338735342
p mean is: tensor(-0.8167, device='cuda:4')
epoch:  31000 quantization_loss:  0.011401382274925709
p mean is: tensor(-0.8321, device='cuda:4')
epoch:  32000 quantization_loss:  0.011328822001814842
p mean is: tensor(-0.8456, device='cuda:4')
epoch:  33000 quantization_loss:  0.011353093199431896
p mean is: tensor(-0.8578, device='cuda:4')
epoch:  34000 quantization_loss:  0.011269924230873585
p mean is: tensor(-0.8684, device='cuda:4')
epoch:  35000 quantization_loss:  0.01120370626449585
p mean is: tensor(-0.8781, device='cuda:4')
epoch:  36000 quantization_loss:  0.011181525886058807
p mean is: tensor(-0.8867, device='cuda:4')
epoch:  37000 quantization_loss:  0.011112256906926632
p mean is: tensor(-0.8943, device='cuda:4')
epoch:  38000 quantization_loss:  0.011031185276806355
p mean is: tensor(-0.9013, device='cuda:4')
epoch:  39000 quantization_loss:  0.011008016765117645
p mean is: tensor(-0.9076, device='cuda:4')
epoch:  40000 quantization_loss:  0.010995467193424702
p mean is: tensor(-0.9134, device='cuda:4')
epoch:  41000 quantization_loss:  0.010935276746749878
p mean is: tensor(-0.9185, device='cuda:4')
epoch:  42000 quantization_loss:  0.01092456839978695
p mean is: tensor(-0.9231, device='cuda:4')
epoch:  43000 quantization_loss:  0.010915711522102356
p mean is: tensor(-0.9275, device='cuda:4')
epoch:  44000 quantization_loss:  0.01088847778737545
p mean is: tensor(-0.9314, device='cuda:4')
epoch:  45000 quantization_loss:  0.0108543261885643
p mean is: tensor(-0.9350, device='cuda:4')
epoch:  46000 quantization_loss:  0.010855959728360176
p mean is: tensor(-0.9383, device='cuda:4')
epoch:  47000 quantization_loss:  0.010827646590769291
p mean is: tensor(-0.9414, device='cuda:4')
epoch:  48000 quantization_loss:  0.010819838382303715
p mean is: tensor(-0.9443, device='cuda:4')
epoch:  49000 quantization_loss:  0.010816341266036034
p mean is: tensor(-0.9470, device='cuda:4')
epoch:  50000 quantization_loss:  0.010841067880392075
p mean is: tensor(-0.9496, device='cuda:4')
epoch:  51000 quantization_loss:  0.010787302628159523
p mean is: tensor(-0.9520, device='cuda:4')
epoch:  52000 quantization_loss:  0.010781819932162762
p mean is: tensor(-0.9542, device='cuda:4')
epoch:  53000 quantization_loss:  0.010795414447784424
p mean is: tensor(-0.9562, device='cuda:4')
epoch:  54000 quantization_loss:  0.010754842311143875
p mean is: tensor(-0.9582, device='cuda:4')
epoch:  55000 quantization_loss:  0.010748697444796562
p mean is: tensor(-0.9600, device='cuda:4')
epoch:  56000 quantization_loss:  0.010741505771875381
p mean is: tensor(-0.9617, device='cuda:4')
epoch:  57000 quantization_loss:  0.010737374424934387
p mean is: tensor(-0.9634, device='cuda:4')
epoch:  58000 quantization_loss:  0.010729129426181316
p mean is: tensor(-0.9650, device='cuda:4')
epoch:  59000 quantization_loss:  0.010708916932344437
p mean is: tensor(-0.9666, device='cuda:4')
epoch:  60000 quantization_loss:  0.010763843543827534
p mean is: tensor(-0.9680, device='cuda:4')
epoch:  61000 quantization_loss:  0.010703328996896744
p mean is: tensor(-0.9694, device='cuda:4')
epoch:  62000 quantization_loss:  0.010702312923967838
p mean is: tensor(-0.9707, device='cuda:4')
epoch:  63000 quantization_loss:  0.010701903142035007
p mean is: tensor(-0.9719, device='cuda:4')
epoch:  64000 quantization_loss:  0.010705281980335712
p mean is: tensor(-0.9732, device='cuda:4')
epoch:  65000 quantization_loss:  0.010697342455387115
p mean is: tensor(-0.9744, device='cuda:4')
epoch:  66000 quantization_loss:  0.01068857777863741
p mean is: tensor(-0.9754, device='cuda:4')
epoch:  67000 quantization_loss:  0.010692145675420761
p mean is: tensor(-0.9765, device='cuda:4')
epoch:  68000 quantization_loss:  0.010677695274353027
p mean is: tensor(-0.9775, device='cuda:4')
epoch:  69000 quantization_loss:  0.010678295977413654
p mean is: tensor(-0.9785, device='cuda:4')
epoch:  70000 quantization_loss:  0.010677341371774673
p mean is: tensor(-0.9796, device='cuda:4')
epoch:  71000 quantization_loss:  0.01066883560270071
p mean is: tensor(-0.9806, device='cuda:4')
epoch:  72000 quantization_loss:  0.010675378143787384
p mean is: tensor(-0.9815, device='cuda:4')
epoch:  73000 quantization_loss:  0.01066550426185131
p mean is: tensor(-0.9824, device='cuda:4')
epoch:  74000 quantization_loss:  0.01066602673381567
p mean is: tensor(-0.9832, device='cuda:4')
epoch:  75000 quantization_loss:  0.010700652375817299
p mean is: tensor(-0.9841, device='cuda:4')
epoch:  76000 quantization_loss:  0.010659283958375454
p mean is: tensor(-0.9850, device='cuda:4')
epoch:  77000 quantization_loss:  0.010667052119970322
p mean is: tensor(-0.9858, device='cuda:4')
epoch:  78000 quantization_loss:  0.010662569664418697
p mean is: tensor(-0.9866, device='cuda:4')
epoch:  79000 quantization_loss:  0.01065597403794527
p mean is: tensor(-0.9873, device='cuda:4')
here
1.1.1.weight         | nonzeros =    1258 /   12800             (  9.83%) | total_pruned =   11542 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     198 /    6400             (  3.09%) | total_pruned =    6202 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     143 /   12800             (  1.12%) | total_pruned =   12657 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     244 /   25600             (  0.95%) | total_pruned =   25356 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      13 /      32             ( 40.62%) | total_pruned =      19 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     189 /   51200             (  0.37%) | total_pruned =   51011 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     258 /  102400             (  0.25%) | total_pruned =  102142 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =      41 /  204800             (  0.02%) | total_pruned =  204759 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     263 /  409600             (  0.06%) | total_pruned =  409337 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     505 /  409600             (  0.12%) | total_pruned =  409095 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    3567 /  409600             (  0.87%) | total_pruned =  406033 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   11461 /  409600             (  2.80%) | total_pruned =  398139 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   37637 /  409600             (  9.19%) | total_pruned =  371963 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   32466 /  147456             ( 22.02%) | total_pruned =  114990 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   29718 /  147456             ( 20.15%) | total_pruned =  117738 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   24943 /  147456             ( 16.92%) | total_pruned =  122513 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   13117 /   73728             ( 17.79%) | total_pruned =   60611 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    4454 /   18432             ( 24.16%) | total_pruned =   13978 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      24 /      32             ( 75.00%) | total_pruned =       8 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      24 /      32             ( 75.00%) | total_pruned =       8 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1594 /    4608             ( 34.59%) | total_pruned =    3014 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      25 /      48             ( 52.08%) | total_pruned =      23 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 163409, pruned : 2845458, total: 3008867, Compression rate :      18.41x  ( 94.57% pruned)
PSNR of output image is:  19.701621044779536
Experiment done
