(3, 256, 256)
Noisy PSNR is '20.851734884479303'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/12/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/1.0/1e-09
epoch:  0 quantization_loss:  0.10750066488981247
p mean is: tensor(0.0002, device='cuda:3')
epoch:  1000 quantization_loss:  0.0815269947052002
p mean is: tensor(0.0031, device='cuda:3')
epoch:  2000 quantization_loss:  0.0870441123843193
p mean is: tensor(0.0049, device='cuda:3')
epoch:  3000 quantization_loss:  0.08426423370838165
p mean is: tensor(0.0061, device='cuda:3')
epoch:  4000 quantization_loss:  0.08317051082849503
p mean is: tensor(0.0078, device='cuda:3')
epoch:  5000 quantization_loss:  0.08013070374727249
p mean is: tensor(0.0091, device='cuda:3')
epoch:  6000 quantization_loss:  0.08236425369977951
p mean is: tensor(0.0108, device='cuda:3')
epoch:  7000 quantization_loss:  0.08043447136878967
p mean is: tensor(0.0122, device='cuda:3')
epoch:  8000 quantization_loss:  0.08405543118715286
p mean is: tensor(0.0139, device='cuda:3')
epoch:  9000 quantization_loss:  0.0803411528468132
p mean is: tensor(0.0153, device='cuda:3')
epoch:  10000 quantization_loss:  0.08085168898105621
p mean is: tensor(0.0166, device='cuda:3')
epoch:  11000 quantization_loss:  0.07996903359889984
p mean is: tensor(0.0181, device='cuda:3')
epoch:  12000 quantization_loss:  0.07597197592258453
p mean is: tensor(0.0194, device='cuda:3')
epoch:  13000 quantization_loss:  0.052257005125284195
p mean is: tensor(0.0205, device='cuda:3')
epoch:  14000 quantization_loss:  0.045377641916275024
p mean is: tensor(0.0225, device='cuda:3')
epoch:  15000 quantization_loss:  0.043401893228292465
p mean is: tensor(0.0257, device='cuda:3')
epoch:  16000 quantization_loss:  0.040994253009557724
p mean is: tensor(0.0303, device='cuda:3')
epoch:  17000 quantization_loss:  0.04058777168393135
p mean is: tensor(0.0373, device='cuda:3')
epoch:  18000 quantization_loss:  0.03993761166930199
p mean is: tensor(0.0474, device='cuda:3')
epoch:  19000 quantization_loss:  0.03912278637290001
p mean is: tensor(0.0617, device='cuda:3')
epoch:  20000 quantization_loss:  0.03885922580957413
p mean is: tensor(0.0814, device='cuda:3')
epoch:  21000 quantization_loss:  0.03809869661927223
p mean is: tensor(0.1080, device='cuda:3')
epoch:  22000 quantization_loss:  0.038068339228630066
p mean is: tensor(0.1428, device='cuda:3')
epoch:  23000 quantization_loss:  0.03766772523522377
p mean is: tensor(0.1866, device='cuda:3')
epoch:  24000 quantization_loss:  0.0374915711581707
p mean is: tensor(0.2396, device='cuda:3')
epoch:  25000 quantization_loss:  0.03725761920213699
p mean is: tensor(0.3008, device='cuda:3')
epoch:  26000 quantization_loss:  0.03724104166030884
p mean is: tensor(0.3678, device='cuda:3')
epoch:  27000 quantization_loss:  0.036998964846134186
p mean is: tensor(0.4377, device='cuda:3')
epoch:  28000 quantization_loss:  0.036946699023246765
p mean is: tensor(0.5064, device='cuda:3')
epoch:  29000 quantization_loss:  0.03681757673621178
p mean is: tensor(0.5710, device='cuda:3')
epoch:  30000 quantization_loss:  0.03671170026063919
p mean is: tensor(0.6292, device='cuda:3')
epoch:  31000 quantization_loss:  0.03656391426920891
p mean is: tensor(0.6804, device='cuda:3')
epoch:  32000 quantization_loss:  0.03651147708296776
p mean is: tensor(0.7245, device='cuda:3')
epoch:  33000 quantization_loss:  0.03648855909705162
p mean is: tensor(0.7621, device='cuda:3')
epoch:  34000 quantization_loss:  0.03644028678536415
p mean is: tensor(0.7940, device='cuda:3')
epoch:  35000 quantization_loss:  0.03637752681970596
p mean is: tensor(0.8211, device='cuda:3')
epoch:  36000 quantization_loss:  0.0363449789583683
p mean is: tensor(0.8441, device='cuda:3')
epoch:  37000 quantization_loss:  0.03631521016359329
p mean is: tensor(0.8636, device='cuda:3')
epoch:  38000 quantization_loss:  0.036320023238658905
p mean is: tensor(0.8801, device='cuda:3')
epoch:  39000 quantization_loss:  0.03630395978689194
p mean is: tensor(0.8941, device='cuda:3')
epoch:  40000 quantization_loss:  0.03625352680683136
p mean is: tensor(0.9062, device='cuda:3')
epoch:  41000 quantization_loss:  0.03623450919985771
p mean is: tensor(0.9164, device='cuda:3')
epoch:  42000 quantization_loss:  0.0362020879983902
p mean is: tensor(0.9253, device='cuda:3')
epoch:  43000 quantization_loss:  0.03618449717760086
p mean is: tensor(0.9329, device='cuda:3')
epoch:  44000 quantization_loss:  0.03617663308978081
p mean is: tensor(0.9395, device='cuda:3')
epoch:  45000 quantization_loss:  0.03615212440490723
p mean is: tensor(0.9452, device='cuda:3')
epoch:  46000 quantization_loss:  0.03613303601741791
p mean is: tensor(0.9502, device='cuda:3')
epoch:  47000 quantization_loss:  0.036105927079916
p mean is: tensor(0.9547, device='cuda:3')
epoch:  48000 quantization_loss:  0.036096446216106415
p mean is: tensor(0.9584, device='cuda:3')
epoch:  49000 quantization_loss:  0.036097653210163116
p mean is: tensor(0.9618, device='cuda:3')
epoch:  50000 quantization_loss:  0.03608520328998566
p mean is: tensor(0.9649, device='cuda:3')
epoch:  51000 quantization_loss:  0.036083564162254333
p mean is: tensor(0.9675, device='cuda:3')
epoch:  52000 quantization_loss:  0.036051537841558456
p mean is: tensor(0.9699, device='cuda:3')
epoch:  53000 quantization_loss:  0.03605316951870918
p mean is: tensor(0.9720, device='cuda:3')
epoch:  54000 quantization_loss:  0.03603154793381691
p mean is: tensor(0.9739, device='cuda:3')
epoch:  55000 quantization_loss:  0.036040980368852615
p mean is: tensor(0.9757, device='cuda:3')
epoch:  56000 quantization_loss:  0.03601973131299019
p mean is: tensor(0.9774, device='cuda:3')
epoch:  57000 quantization_loss:  0.0360104963183403
p mean is: tensor(0.9788, device='cuda:3')
epoch:  58000 quantization_loss:  0.03601041063666344
p mean is: tensor(0.9802, device='cuda:3')
epoch:  59000 quantization_loss:  0.03599381074309349
p mean is: tensor(0.9814, device='cuda:3')
epoch:  60000 quantization_loss:  0.03598761186003685
p mean is: tensor(0.9826, device='cuda:3')
epoch:  61000 quantization_loss:  0.03598072752356529
p mean is: tensor(0.9836, device='cuda:3')
epoch:  62000 quantization_loss:  0.03599192574620247
p mean is: tensor(0.9847, device='cuda:3')
epoch:  63000 quantization_loss:  0.0359855554997921
p mean is: tensor(0.9857, device='cuda:3')
epoch:  64000 quantization_loss:  0.035978879779577255
p mean is: tensor(0.9865, device='cuda:3')
epoch:  65000 quantization_loss:  0.03597155585885048
p mean is: tensor(0.9874, device='cuda:3')
epoch:  66000 quantization_loss:  0.03596989065408707
p mean is: tensor(0.9883, device='cuda:3')
epoch:  67000 quantization_loss:  0.035958778113126755
p mean is: tensor(0.9891, device='cuda:3')
epoch:  68000 quantization_loss:  0.035964738577604294
p mean is: tensor(0.9898, device='cuda:3')
epoch:  69000 quantization_loss:  0.035955265164375305
p mean is: tensor(0.9905, device='cuda:3')
epoch:  70000 quantization_loss:  0.03595149517059326
p mean is: tensor(0.9912, device='cuda:3')
epoch:  71000 quantization_loss:  0.03594723343849182
p mean is: tensor(0.9918, device='cuda:3')
epoch:  72000 quantization_loss:  0.035945456475019455
p mean is: tensor(0.9925, device='cuda:3')
epoch:  73000 quantization_loss:  0.03594323247671127
p mean is: tensor(0.9931, device='cuda:3')
epoch:  74000 quantization_loss:  0.03593950718641281
p mean is: tensor(0.9937, device='cuda:3')
epoch:  75000 quantization_loss:  0.03593773394823074
p mean is: tensor(0.9943, device='cuda:3')
epoch:  76000 quantization_loss:  0.0359380729496479
p mean is: tensor(0.9948, device='cuda:3')
epoch:  77000 quantization_loss:  0.03593168780207634
p mean is: tensor(0.9953, device='cuda:3')
epoch:  78000 quantization_loss:  0.03592849150300026
p mean is: tensor(0.9959, device='cuda:3')
epoch:  79000 quantization_loss:  0.03592987731099129
p mean is: tensor(0.9964, device='cuda:3')
1.1.1.weight         | nonzeros =   12730 /   12800             ( 99.45%) | total_pruned =      70 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.2.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =    6383 /    6400             ( 99.73%) | total_pruned =      17 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.5.weight           | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =   12798 /   12800             ( 99.98%) | total_pruned =       2 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =   25589 /   25600             ( 99.96%) | total_pruned =      11 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      21 /      32             ( 65.62%) | total_pruned =      11 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =   51198 /   51200             (100.00%) | total_pruned =       2 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =  102400 /  102400             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =  204800 /  204800             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =  409600 /  409600             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  409595 /  409600             (100.00%) | total_pruned =       5 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  409234 /  409600             ( 99.91%) | total_pruned =     366 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  408341 /  409600             ( 99.69%) | total_pruned =    1259 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  401450 /  409600             ( 98.01%) | total_pruned =    8150 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  130633 /  147456             ( 88.59%) | total_pruned =   16823 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  125875 /  147456             ( 85.36%) | total_pruned =   21581 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =  128943 /  147456             ( 87.45%) | total_pruned =   18513 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   65091 /   73728             ( 88.29%) | total_pruned =    8637 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =   16220 /   18432             ( 88.00%) | total_pruned =    2212 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    3598 /    4608             ( 78.08%) | total_pruned =    1010 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      15 /      16             ( 93.75%) | total_pruned =       1 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      26 /      48             ( 54.17%) | total_pruned =      22 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 2927284, pruned : 81583, total: 3008867, Compression rate :       1.03x  (  2.71% pruned)
(3, 256, 256) (3, 256, 256) (3, 256, 256)
PSNR of output image is:  14.930468727705959
Experiment done
