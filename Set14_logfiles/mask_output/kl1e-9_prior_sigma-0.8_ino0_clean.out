(3, 512, 512)
Starting vanilla DIP on 0 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '19.679783571695427'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/0/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/clean_img/-0.8/1e-09
(3, 512, 512)
Starting vanilla DIP on 0 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '19.68017853073651'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/0/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/clean_img/-0.8/1e-09
(3, 512, 512)
Starting vanilla DIP on 0 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '19.673079100583912'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/0/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/clean_img/-0.8/1e-09
epoch:  0 quantization_loss:  0.09348827600479126
p mean is: tensor(-0.0001, device='cuda:1')
epoch:  1000 quantization_loss:  0.07155357301235199
p mean is: tensor(-0.0057, device='cuda:1')
epoch:  2000 quantization_loss:  0.07441554963588715
p mean is: tensor(-0.0098, device='cuda:1')
epoch:  3000 quantization_loss:  0.07099145650863647
p mean is: tensor(-0.0141, device='cuda:1')
epoch:  4000 quantization_loss:  0.06882435828447342
p mean is: tensor(-0.0186, device='cuda:1')
epoch:  5000 quantization_loss:  0.06891287118196487
p mean is: tensor(-0.0231, device='cuda:1')
epoch:  6000 quantization_loss:  0.06762369722127914
p mean is: tensor(-0.0284, device='cuda:1')
epoch:  7000 quantization_loss:  0.06810743361711502
p mean is: tensor(-0.0340, device='cuda:1')
epoch:  8000 quantization_loss:  0.0673404112458229
p mean is: tensor(-0.0401, device='cuda:1')
epoch:  9000 quantization_loss:  0.06652197986841202
p mean is: tensor(-0.0468, device='cuda:1')
epoch:  10000 quantization_loss:  0.06048422306776047
p mean is: tensor(-0.0550, device='cuda:1')
epoch:  11000 quantization_loss:  0.055169545114040375
p mean is: tensor(-0.0644, device='cuda:1')
epoch:  12000 quantization_loss:  0.04410221055150032
p mean is: tensor(-0.0762, device='cuda:1')
epoch:  13000 quantization_loss:  0.0404515378177166
p mean is: tensor(-0.0906, device='cuda:1')
epoch:  14000 quantization_loss:  0.03907425329089165
p mean is: tensor(-0.1089, device='cuda:1')
epoch:  15000 quantization_loss:  0.03654094412922859
p mean is: tensor(-0.1319, device='cuda:1')
epoch:  16000 quantization_loss:  0.03609596937894821
p mean is: tensor(-0.1600, device='cuda:1')
epoch:  17000 quantization_loss:  0.034571342170238495
p mean is: tensor(-0.1935, device='cuda:1')
epoch:  18000 quantization_loss:  0.033854737877845764
p mean is: tensor(-0.2319, device='cuda:1')
epoch:  19000 quantization_loss:  0.03345327079296112
p mean is: tensor(-0.2740, device='cuda:1')
epoch:  20000 quantization_loss:  0.032866477966308594
p mean is: tensor(-0.3179, device='cuda:1')
epoch:  21000 quantization_loss:  0.032434336841106415
p mean is: tensor(-0.3618, device='cuda:1')
epoch:  22000 quantization_loss:  0.03227905184030533
p mean is: tensor(-0.4041, device='cuda:1')
epoch:  23000 quantization_loss:  0.032042309641838074
p mean is: tensor(-0.4440, device='cuda:1')
epoch:  24000 quantization_loss:  0.03189621493220329
p mean is: tensor(-0.4807, device='cuda:1')
epoch:  25000 quantization_loss:  0.03203338012099266
p mean is: tensor(-0.5141, device='cuda:1')
epoch:  26000 quantization_loss:  0.031574200838804245
p mean is: tensor(-0.5438, device='cuda:1')
epoch:  27000 quantization_loss:  0.031502142548561096
p mean is: tensor(-0.5703, device='cuda:1')
epoch:  28000 quantization_loss:  0.03134147822856903
p mean is: tensor(-0.5939, device='cuda:1')
epoch:  29000 quantization_loss:  0.03134316951036453
p mean is: tensor(-0.6146, device='cuda:1')
epoch:  30000 quantization_loss:  0.031250353902578354
p mean is: tensor(-0.6328, device='cuda:1')
epoch:  31000 quantization_loss:  0.0310972910374403
p mean is: tensor(-0.6489, device='cuda:1')
epoch:  32000 quantization_loss:  0.031046688556671143
p mean is: tensor(-0.6630, device='cuda:1')
epoch:  33000 quantization_loss:  0.031024441123008728
p mean is: tensor(-0.6755, device='cuda:1')
epoch:  34000 quantization_loss:  0.030946604907512665
p mean is: tensor(-0.6865, device='cuda:1')
epoch:  35000 quantization_loss:  0.0308831799775362
p mean is: tensor(-0.6962, device='cuda:1')
epoch:  36000 quantization_loss:  0.030895214527845383
p mean is: tensor(-0.7050, device='cuda:1')
epoch:  37000 quantization_loss:  0.03083239495754242
p mean is: tensor(-0.7126, device='cuda:1')
epoch:  38000 quantization_loss:  0.030902624130249023
p mean is: tensor(-0.7195, device='cuda:1')
epoch:  39000 quantization_loss:  0.030761990696191788
p mean is: tensor(-0.7256, device='cuda:1')
epoch:  40000 quantization_loss:  0.030746890231966972
p mean is: tensor(-0.7311, device='cuda:1')
epoch:  41000 quantization_loss:  0.03068443015217781
p mean is: tensor(-0.7361, device='cuda:1')
epoch:  42000 quantization_loss:  0.030678261071443558
p mean is: tensor(-0.7406, device='cuda:1')
epoch:  43000 quantization_loss:  0.03065679594874382
p mean is: tensor(-0.7447, device='cuda:1')
epoch:  44000 quantization_loss:  0.030633196234703064
p mean is: tensor(-0.7484, device='cuda:1')
epoch:  45000 quantization_loss:  0.030609676614403725
p mean is: tensor(-0.7517, device='cuda:1')
epoch:  46000 quantization_loss:  0.03059186041355133
p mean is: tensor(-0.7548, device='cuda:1')
epoch:  47000 quantization_loss:  0.030569208785891533
p mean is: tensor(-0.7577, device='cuda:1')
epoch:  48000 quantization_loss:  0.0305344071239233
p mean is: tensor(-0.7603, device='cuda:1')
epoch:  49000 quantization_loss:  0.03054567240178585
p mean is: tensor(-0.7627, device='cuda:1')
epoch:  50000 quantization_loss:  0.030525684356689453
p mean is: tensor(-0.7650, device='cuda:1')
epoch:  51000 quantization_loss:  0.03055618517100811
p mean is: tensor(-0.7671, device='cuda:1')
epoch:  52000 quantization_loss:  0.0304870642721653
p mean is: tensor(-0.7691, device='cuda:1')
epoch:  53000 quantization_loss:  0.03050643391907215
p mean is: tensor(-0.7709, device='cuda:1')
epoch:  54000 quantization_loss:  0.030467022210359573
p mean is: tensor(-0.7727, device='cuda:1')
epoch:  55000 quantization_loss:  0.030466685071587563
p mean is: tensor(-0.7743, device='cuda:1')
epoch:  56000 quantization_loss:  0.030462224036455154
p mean is: tensor(-0.7758, device='cuda:1')
epoch:  57000 quantization_loss:  0.03044085018336773
p mean is: tensor(-0.7773, device='cuda:1')
epoch:  58000 quantization_loss:  0.03042948991060257
p mean is: tensor(-0.7786, device='cuda:1')
epoch:  59000 quantization_loss:  0.030436590313911438
p mean is: tensor(-0.7800, device='cuda:1')
epoch:  60000 quantization_loss:  0.030422719195485115
p mean is: tensor(-0.7812, device='cuda:1')
epoch:  61000 quantization_loss:  0.03040531650185585
p mean is: tensor(-0.7824, device='cuda:1')
epoch:  62000 quantization_loss:  0.030400503426790237
p mean is: tensor(-0.7835, device='cuda:1')
epoch:  63000 quantization_loss:  0.03040156327188015
p mean is: tensor(-0.7846, device='cuda:1')
epoch:  64000 quantization_loss:  0.030394580215215683
p mean is: tensor(-0.7856, device='cuda:1')
epoch:  65000 quantization_loss:  0.030388878658413887
p mean is: tensor(-0.7866, device='cuda:1')
epoch:  66000 quantization_loss:  0.030379680916666985
p mean is: tensor(-0.7877, device='cuda:1')
epoch:  67000 quantization_loss:  0.03038083016872406
p mean is: tensor(-0.7886, device='cuda:1')
epoch:  68000 quantization_loss:  0.030390260741114616
p mean is: tensor(-0.7895, device='cuda:1')
epoch:  69000 quantization_loss:  0.03038022667169571
p mean is: tensor(-0.7903, device='cuda:1')
epoch:  70000 quantization_loss:  0.0303691066801548
p mean is: tensor(-0.7912, device='cuda:1')
epoch:  71000 quantization_loss:  0.030369844287633896
p mean is: tensor(-0.7920, device='cuda:1')
epoch:  72000 quantization_loss:  0.030365383252501488
p mean is: tensor(-0.7928, device='cuda:1')
epoch:  73000 quantization_loss:  0.03035525605082512
p mean is: tensor(-0.7935, device='cuda:1')
epoch:  74000 quantization_loss:  0.03034764714539051
p mean is: tensor(-0.7942, device='cuda:1')
epoch:  75000 quantization_loss:  0.030360324308276176
p mean is: tensor(-0.7949, device='cuda:1')
epoch:  76000 quantization_loss:  0.030352426692843437
p mean is: tensor(-0.7955, device='cuda:1')
epoch:  77000 quantization_loss:  0.03036278672516346
p mean is: tensor(-0.7963, device='cuda:1')
epoch:  78000 quantization_loss:  0.030346402898430824
p mean is: tensor(-0.7970, device='cuda:1')
epoch:  79000 quantization_loss:  0.03034066967666149
p mean is: tensor(-0.7976, device='cuda:1')
here
1.1.1.weight         | nonzeros =    1800 /   12800             ( 14.06%) | total_pruned =   11000 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =      13 /      16             ( 81.25%) | total_pruned =       3 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     287 /    6400             (  4.48%) | total_pruned =    6113 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     230 /   12800             (  1.80%) | total_pruned =   12570 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     359 /   25600             (  1.40%) | total_pruned =   25241 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      13 /      32             ( 40.62%) | total_pruned =      19 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     310 /   51200             (  0.61%) | total_pruned =   50890 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     590 /  102400             (  0.58%) | total_pruned =  101810 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     527 /  204800             (  0.26%) | total_pruned =  204273 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     838 /  409600             (  0.20%) | total_pruned =  408762 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    1063 /  409600             (  0.26%) | total_pruned =  408537 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    5197 /  409600             (  1.27%) | total_pruned =  404403 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   16957 /  409600             (  4.14%) | total_pruned =  392643 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   45936 /  409600             ( 11.21%) | total_pruned =  363664 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   28436 /  147456             ( 19.28%) | total_pruned =  119020 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   25387 /  147456             ( 17.22%) | total_pruned =  122069 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   21390 /  147456             ( 14.51%) | total_pruned =  126066 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    9017 /   73728             ( 12.23%) | total_pruned =   64711 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    1924 /   18432             ( 10.44%) | total_pruned =   16508 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =     938 /    4608             ( 20.36%) | total_pruned =    3670 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      32 /      48             ( 66.67%) | total_pruned =      16 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 162488, pruned : 2846379, total: 3008867, Compression rate :      18.52x  ( 94.60% pruned)
PSNR of output image is:  15.818702746435882
Experiment done
(3, 512, 512)
Starting vanilla DIP on 0 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '19.668992653571372'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/0/SAM(sigma=0.1,lr=0.01,decay=0,beta=0)/det/clean_img/-0.8/1e-09
epoch:  0 quantization_loss:  0.08217348158359528
p mean is: tensor(-0.0001, device='cuda:1')
epoch:  1000 quantization_loss:  0.058421541005373
p mean is: tensor(-0.0058, device='cuda:1')
epoch:  2000 quantization_loss:  0.05773952230811119
p mean is: tensor(-0.0097, device='cuda:1')
epoch:  3000 quantization_loss:  0.05570210516452789
p mean is: tensor(-0.0139, device='cuda:1')
epoch:  4000 quantization_loss:  0.055643610656261444
p mean is: tensor(-0.0180, device='cuda:1')
epoch:  5000 quantization_loss:  0.05518599972128868
p mean is: tensor(-0.0225, device='cuda:1')
epoch:  6000 quantization_loss:  0.055078256875276566
p mean is: tensor(-0.0270, device='cuda:1')
epoch:  7000 quantization_loss:  0.05448697879910469
p mean is: tensor(-0.0319, device='cuda:1')
epoch:  8000 quantization_loss:  0.05230187252163887
p mean is: tensor(-0.0376, device='cuda:1')
epoch:  9000 quantization_loss:  0.0435565821826458
p mean is: tensor(-0.0444, device='cuda:1')
epoch:  10000 quantization_loss:  0.03854547441005707
p mean is: tensor(-0.0530, device='cuda:1')
epoch:  11000 quantization_loss:  0.03327608481049538
p mean is: tensor(-0.0640, device='cuda:1')
epoch:  12000 quantization_loss:  0.027996141463518143
p mean is: tensor(-0.0781, device='cuda:1')
epoch:  13000 quantization_loss:  0.02533552795648575
p mean is: tensor(-0.0955, device='cuda:1')
epoch:  14000 quantization_loss:  0.02206822857260704
p mean is: tensor(-0.1176, device='cuda:1')
epoch:  15000 quantization_loss:  0.020388245582580566
p mean is: tensor(-0.1449, device='cuda:1')
epoch:  16000 quantization_loss:  0.019359080120921135
p mean is: tensor(-0.1776, device='cuda:1')
epoch:  17000 quantization_loss:  0.018882956355810165
p mean is: tensor(-0.2157, device='cuda:1')
epoch:  18000 quantization_loss:  0.018812615424394608
p mean is: tensor(-0.2579, device='cuda:1')
epoch:  19000 quantization_loss:  0.01831885054707527
p mean is: tensor(-0.3027, device='cuda:1')
epoch:  20000 quantization_loss:  0.01781393401324749
p mean is: tensor(-0.3481, device='cuda:1')
epoch:  21000 quantization_loss:  0.017714597284793854
p mean is: tensor(-0.3924, device='cuda:1')
epoch:  22000 quantization_loss:  0.017437072470784187
p mean is: tensor(-0.4342, device='cuda:1')
epoch:  23000 quantization_loss:  0.01728837564587593
p mean is: tensor(-0.4725, device='cuda:1')
epoch:  24000 quantization_loss:  0.01713503897190094
p mean is: tensor(-0.5073, device='cuda:1')
epoch:  25000 quantization_loss:  0.017056317999958992
p mean is: tensor(-0.5383, device='cuda:1')
epoch:  26000 quantization_loss:  0.016866330057382584
p mean is: tensor(-0.5658, device='cuda:1')
epoch:  27000 quantization_loss:  0.016818325966596603
p mean is: tensor(-0.5900, device='cuda:1')
epoch:  28000 quantization_loss:  0.016711488366127014
p mean is: tensor(-0.6113, device='cuda:1')
epoch:  29000 quantization_loss:  0.016565660014748573
p mean is: tensor(-0.6300, device='cuda:1')
epoch:  30000 quantization_loss:  0.01650206744670868
p mean is: tensor(-0.6464, device='cuda:1')
epoch:  31000 quantization_loss:  0.016535168513655663
p mean is: tensor(-0.6608, device='cuda:1')
epoch:  32000 quantization_loss:  0.016383638605475426
p mean is: tensor(-0.6735, device='cuda:1')
epoch:  33000 quantization_loss:  0.016348054632544518
p mean is: tensor(-0.6845, device='cuda:1')
epoch:  34000 quantization_loss:  0.01627812162041664
p mean is: tensor(-0.6943, device='cuda:1')
epoch:  35000 quantization_loss:  0.016251008957624435
p mean is: tensor(-0.7030, device='cuda:1')
epoch:  36000 quantization_loss:  0.016200948506593704
p mean is: tensor(-0.7107, device='cuda:1')
epoch:  37000 quantization_loss:  0.016188999637961388
p mean is: tensor(-0.7175, device='cuda:1')
epoch:  38000 quantization_loss:  0.01614578440785408
p mean is: tensor(-0.7236, device='cuda:1')
epoch:  39000 quantization_loss:  0.016063755378127098
p mean is: tensor(-0.7290, device='cuda:1')
epoch:  40000 quantization_loss:  0.015969835221767426
p mean is: tensor(-0.7339, device='cuda:1')
epoch:  41000 quantization_loss:  0.015893377363681793
p mean is: tensor(-0.7382, device='cuda:1')
epoch:  42000 quantization_loss:  0.015867656096816063
p mean is: tensor(-0.7422, device='cuda:1')
epoch:  43000 quantization_loss:  0.015820695087313652
p mean is: tensor(-0.7458, device='cuda:1')
epoch:  44000 quantization_loss:  0.015809616073966026
p mean is: tensor(-0.7490, device='cuda:1')
epoch:  45000 quantization_loss:  0.01577518880367279
p mean is: tensor(-0.7521, device='cuda:1')
epoch:  46000 quantization_loss:  0.015804197639226913
p mean is: tensor(-0.7547, device='cuda:1')
epoch:  47000 quantization_loss:  0.015736594796180725
p mean is: tensor(-0.7572, device='cuda:1')
epoch:  48000 quantization_loss:  0.01577126793563366
p mean is: tensor(-0.7596, device='cuda:1')
epoch:  49000 quantization_loss:  0.015704277902841568
p mean is: tensor(-0.7618, device='cuda:1')
epoch:  50000 quantization_loss:  0.015691954642534256
p mean is: tensor(-0.7638, device='cuda:1')
epoch:  51000 quantization_loss:  0.015684058889746666
p mean is: tensor(-0.7658, device='cuda:1')
epoch:  52000 quantization_loss:  0.015727562829852104
p mean is: tensor(-0.7675, device='cuda:1')
epoch:  53000 quantization_loss:  0.01567663811147213
p mean is: tensor(-0.7691, device='cuda:1')
epoch:  54000 quantization_loss:  0.015654677525162697
p mean is: tensor(-0.7707, device='cuda:1')
epoch:  55000 quantization_loss:  0.015644365921616554
p mean is: tensor(-0.7722, device='cuda:1')
epoch:  56000 quantization_loss:  0.01564599759876728
p mean is: tensor(-0.7737, device='cuda:1')
epoch:  57000 quantization_loss:  0.015639934688806534
p mean is: tensor(-0.7750, device='cuda:1')
epoch:  58000 quantization_loss:  0.015643563121557236
p mean is: tensor(-0.7762, device='cuda:1')
epoch:  59000 quantization_loss:  0.015616367571055889
p mean is: tensor(-0.7775, device='cuda:1')
epoch:  60000 quantization_loss:  0.01561247743666172
p mean is: tensor(-0.7786, device='cuda:1')
epoch:  61000 quantization_loss:  0.015606047585606575
p mean is: tensor(-0.7796, device='cuda:1')
epoch:  62000 quantization_loss:  0.015601669438183308
p mean is: tensor(-0.7807, device='cuda:1')
epoch:  63000 quantization_loss:  0.015603735111653805
p mean is: tensor(-0.7817, device='cuda:1')
epoch:  64000 quantization_loss:  0.015630114823579788
p mean is: tensor(-0.7826, device='cuda:1')
epoch:  65000 quantization_loss:  0.015592427924275398
p mean is: tensor(-0.7835, device='cuda:1')
epoch:  66000 quantization_loss:  0.015582303516566753
p mean is: tensor(-0.7844, device='cuda:1')
epoch:  67000 quantization_loss:  0.015580344945192337
p mean is: tensor(-0.7853, device='cuda:1')
epoch:  68000 quantization_loss:  0.01557976845651865
p mean is: tensor(-0.7861, device='cuda:1')
epoch:  69000 quantization_loss:  0.015583417378365993
p mean is: tensor(-0.7870, device='cuda:1')
epoch:  70000 quantization_loss:  0.015585040673613548
p mean is: tensor(-0.7877, device='cuda:1')
epoch:  71000 quantization_loss:  0.015568061731755733
p mean is: tensor(-0.7884, device='cuda:1')
epoch:  72000 quantization_loss:  0.01557074673473835
p mean is: tensor(-0.7891, device='cuda:1')
epoch:  73000 quantization_loss:  0.015566333197057247
p mean is: tensor(-0.7898, device='cuda:1')
epoch:  74000 quantization_loss:  0.015568755567073822
p mean is: tensor(-0.7905, device='cuda:1')
epoch:  75000 quantization_loss:  0.015555614605545998
p mean is: tensor(-0.7911, device='cuda:1')
epoch:  76000 quantization_loss:  0.015559948980808258
p mean is: tensor(-0.7917, device='cuda:1')
epoch:  77000 quantization_loss:  0.015563080087304115
p mean is: tensor(-0.7923, device='cuda:1')
epoch:  78000 quantization_loss:  0.015555077232420444
p mean is: tensor(-0.7929, device='cuda:1')
epoch:  79000 quantization_loss:  0.015553341247141361
p mean is: tensor(-0.7935, device='cuda:1')
here
1.1.1.weight         | nonzeros =    1378 /   12800             ( 10.77%) | total_pruned =   11422 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     255 /    6400             (  3.98%) | total_pruned =    6145 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     189 /   12800             (  1.48%) | total_pruned =   12611 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     287 /   25600             (  1.12%) | total_pruned =   25313 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      12 /      32             ( 37.50%) | total_pruned =      20 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     210 /   51200             (  0.41%) | total_pruned =   50990 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     504 /  102400             (  0.49%) | total_pruned =  101896 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     313 /  204800             (  0.15%) | total_pruned =  204487 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     937 /  409600             (  0.23%) | total_pruned =  408663 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    1161 /  409600             (  0.28%) | total_pruned =  408439 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    5383 /  409600             (  1.31%) | total_pruned =  404217 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   16819 /  409600             (  4.11%) | total_pruned =  392781 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   44344 /  409600             ( 10.83%) | total_pruned =  365256 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   32606 /  147456             ( 22.11%) | total_pruned =  114850 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   28711 /  147456             ( 19.47%) | total_pruned =  118745 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   20534 /  147456             ( 13.93%) | total_pruned =  126922 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    7409 /   73728             ( 10.05%) | total_pruned =   66319 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2370 /   18432             ( 12.86%) | total_pruned =   16062 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1294 /    4608             ( 28.08%) | total_pruned =    3314 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      33 /      48             ( 68.75%) | total_pruned =      15 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 166042, pruned : 2842825, total: 3008867, Compression rate :      18.12x  ( 94.48% pruned)
PSNR of output image is:  17.502657450233343
Experiment done
