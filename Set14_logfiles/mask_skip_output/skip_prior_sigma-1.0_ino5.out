(3, 512, 512)
Starting vanilla DIP on 5 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.100867129659605'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/5/skip/det/-1.0/1e-09
(3, 512, 512)
Starting vanilla DIP on 5 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.092401031443224'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/5/skip/det/-1.0/1e-09
epoch:  0 quantization_loss:  0.06105825677514076
p mean is: tensor(-0.0002, device='cuda:1')
epoch:  1000 quantization_loss:  0.05426783114671707
p mean is: tensor(-0.0082, device='cuda:1')
epoch:  2000 quantization_loss:  0.052999310195446014
p mean is: tensor(-0.0149, device='cuda:1')
epoch:  3000 quantization_loss:  0.05388401448726654
p mean is: tensor(-0.0211, device='cuda:1')
epoch:  4000 quantization_loss:  0.052760858088731766
p mean is: tensor(-0.0275, device='cuda:1')
epoch:  5000 quantization_loss:  0.05290142819285393
p mean is: tensor(-0.0341, device='cuda:1')
epoch:  6000 quantization_loss:  0.052416909486055374
p mean is: tensor(-0.0410, device='cuda:1')
epoch:  7000 quantization_loss:  0.053079165518283844
p mean is: tensor(-0.0480, device='cuda:1')
epoch:  8000 quantization_loss:  0.04646983742713928
p mean is: tensor(-0.0558, device='cuda:1')
epoch:  9000 quantization_loss:  0.04444710537791252
p mean is: tensor(-0.0655, device='cuda:1')
epoch:  10000 quantization_loss:  0.037776682525873184
p mean is: tensor(-0.0775, device='cuda:1')
epoch:  11000 quantization_loss:  0.03301813453435898
p mean is: tensor(-0.0912, device='cuda:1')
epoch:  12000 quantization_loss:  0.028138579800724983
p mean is: tensor(-0.1068, device='cuda:1')
epoch:  13000 quantization_loss:  0.025865258648991585
p mean is: tensor(-0.1246, device='cuda:1')
epoch:  14000 quantization_loss:  0.024522054940462112
p mean is: tensor(-0.1460, device='cuda:1')
epoch:  15000 quantization_loss:  0.023769591003656387
p mean is: tensor(-0.1716, device='cuda:1')
epoch:  16000 quantization_loss:  0.022236287593841553
p mean is: tensor(-0.2015, device='cuda:1')
epoch:  17000 quantization_loss:  0.021683653816580772
p mean is: tensor(-0.2353, device='cuda:1')
epoch:  18000 quantization_loss:  0.021200140938162804
p mean is: tensor(-0.2725, device='cuda:1')
epoch:  19000 quantization_loss:  0.02075778879225254
p mean is: tensor(-0.3119, device='cuda:1')
epoch:  20000 quantization_loss:  0.02027433179318905
p mean is: tensor(-0.3528, device='cuda:1')
epoch:  21000 quantization_loss:  0.020187173038721085
p mean is: tensor(-0.3938, device='cuda:1')
epoch:  22000 quantization_loss:  0.0199312474578619
p mean is: tensor(-0.4341, device='cuda:1')
epoch:  23000 quantization_loss:  0.019695216789841652
p mean is: tensor(-0.4726, device='cuda:1')
epoch:  24000 quantization_loss:  0.01958177238702774
p mean is: tensor(-0.5085, device='cuda:1')
epoch:  25000 quantization_loss:  0.01942308619618416
p mean is: tensor(-0.5417, device='cuda:1')
epoch:  26000 quantization_loss:  0.019422005861997604
p mean is: tensor(-0.5721, device='cuda:1')
epoch:  27000 quantization_loss:  0.01915561966598034
p mean is: tensor(-0.6000, device='cuda:1')
epoch:  28000 quantization_loss:  0.01901823841035366
p mean is: tensor(-0.6249, device='cuda:1')
epoch:  29000 quantization_loss:  0.018946725875139236
p mean is: tensor(-0.6475, device='cuda:1')
epoch:  30000 quantization_loss:  0.018839828670024872
p mean is: tensor(-0.6682, device='cuda:1')
epoch:  31000 quantization_loss:  0.018796395510435104
p mean is: tensor(-0.6867, device='cuda:1')
epoch:  32000 quantization_loss:  0.01879955269396305
p mean is: tensor(-0.7033, device='cuda:1')
epoch:  33000 quantization_loss:  0.01866895519196987
p mean is: tensor(-0.7186, device='cuda:1')
epoch:  34000 quantization_loss:  0.01862078718841076
p mean is: tensor(-0.7325, device='cuda:1')
epoch:  35000 quantization_loss:  0.018549060449004173
p mean is: tensor(-0.7452, device='cuda:1')
epoch:  36000 quantization_loss:  0.018509266898036003
p mean is: tensor(-0.7568, device='cuda:1')
epoch:  37000 quantization_loss:  0.018456192687153816
p mean is: tensor(-0.7676, device='cuda:1')
epoch:  38000 quantization_loss:  0.01844896748661995
p mean is: tensor(-0.7776, device='cuda:1')
epoch:  39000 quantization_loss:  0.01840166561305523
p mean is: tensor(-0.7867, device='cuda:1')
epoch:  40000 quantization_loss:  0.02175755240023136
p mean is: tensor(-0.7952, device='cuda:1')
epoch:  41000 quantization_loss:  0.018312782049179077
p mean is: tensor(-0.8031, device='cuda:1')
epoch:  42000 quantization_loss:  0.018282227218151093
p mean is: tensor(-0.8108, device='cuda:1')
epoch:  43000 quantization_loss:  0.01824977993965149
p mean is: tensor(-0.8176, device='cuda:1')
epoch:  44000 quantization_loss:  0.01824384182691574
p mean is: tensor(-0.8241, device='cuda:1')
epoch:  45000 quantization_loss:  0.01822212152183056
p mean is: tensor(-0.8303, device='cuda:1')
epoch:  46000 quantization_loss:  0.01818177103996277
p mean is: tensor(-0.8361, device='cuda:1')
epoch:  47000 quantization_loss:  0.01816907711327076
p mean is: tensor(-0.8416, device='cuda:1')
epoch:  48000 quantization_loss:  0.018166467547416687
p mean is: tensor(-0.8466, device='cuda:1')
epoch:  49000 quantization_loss:  0.018135398626327515
p mean is: tensor(-0.8513, device='cuda:1')
epoch:  50000 quantization_loss:  0.018126968294382095
p mean is: tensor(-0.8559, device='cuda:1')
epoch:  51000 quantization_loss:  0.01813688687980175
p mean is: tensor(-0.8603, device='cuda:1')
epoch:  52000 quantization_loss:  0.018101457506418228
p mean is: tensor(-0.8645, device='cuda:1')
epoch:  53000 quantization_loss:  0.018090195953845978
p mean is: tensor(-0.8687, device='cuda:1')
epoch:  54000 quantization_loss:  0.018071332946419716
p mean is: tensor(-0.8724, device='cuda:1')
epoch:  55000 quantization_loss:  0.018072595819830894
p mean is: tensor(-0.8761, device='cuda:1')
epoch:  56000 quantization_loss:  0.01805300824344158
p mean is: tensor(-0.8795, device='cuda:1')
epoch:  57000 quantization_loss:  0.018050208687782288
p mean is: tensor(-0.8829, device='cuda:1')
epoch:  58000 quantization_loss:  0.018038947135210037
p mean is: tensor(-0.8860, device='cuda:1')
epoch:  59000 quantization_loss:  0.018034514039754868
p mean is: tensor(-0.8891, device='cuda:1')
epoch:  60000 quantization_loss:  0.018032096326351166
p mean is: tensor(-0.8920, device='cuda:1')
epoch:  61000 quantization_loss:  0.01801576465368271
p mean is: tensor(-0.8947, device='cuda:1')
epoch:  62000 quantization_loss:  0.01801123097538948
p mean is: tensor(-0.8973, device='cuda:1')
epoch:  63000 quantization_loss:  0.018021926283836365
p mean is: tensor(-0.8999, device='cuda:1')
epoch:  64000 quantization_loss:  0.018003646284341812
p mean is: tensor(-0.9024, device='cuda:1')
epoch:  65000 quantization_loss:  0.01800292171537876
p mean is: tensor(-0.9048, device='cuda:1')
epoch:  66000 quantization_loss:  0.017994007095694542
p mean is: tensor(-0.9071, device='cuda:1')
epoch:  67000 quantization_loss:  0.01800173707306385
p mean is: tensor(-0.9093, device='cuda:1')
epoch:  68000 quantization_loss:  0.017990153282880783
p mean is: tensor(-0.9115, device='cuda:1')
epoch:  69000 quantization_loss:  0.01798086240887642
p mean is: tensor(-0.9137, device='cuda:1')
epoch:  70000 quantization_loss:  0.017974162474274635
p mean is: tensor(-0.9156, device='cuda:1')
epoch:  71000 quantization_loss:  0.017973285168409348
p mean is: tensor(-0.9177, device='cuda:1')
epoch:  72000 quantization_loss:  0.01796974055469036
p mean is: tensor(-0.9195, device='cuda:1')
epoch:  73000 quantization_loss:  0.017965098842978477
p mean is: tensor(-0.9214, device='cuda:1')
epoch:  74000 quantization_loss:  0.017994249239563942
p mean is: tensor(-0.9233, device='cuda:1')
epoch:  75000 quantization_loss:  0.017958592623472214
p mean is: tensor(-0.9251, device='cuda:1')
epoch:  76000 quantization_loss:  0.01795808970928192
p mean is: tensor(-0.9267, device='cuda:1')
epoch:  77000 quantization_loss:  0.01795242726802826
p mean is: tensor(-0.9284, device='cuda:1')
epoch:  78000 quantization_loss:  0.017951752990484238
p mean is: tensor(-0.9300, device='cuda:1')
epoch:  79000 quantization_loss:  0.017946965992450714
p mean is: tensor(-0.9316, device='cuda:1')
here
1.0.1.1.weight       | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =    1485 /    4608             ( 32.23%) | total_pruned =    3123 | shape = torch.Size([16, 32, 3, 3])
1.1.1.1.bias         | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.2.weight         | nonzeros =      11 /      16             ( 68.75%) | total_pruned =       5 | shape = torch.Size([16])
1.1.2.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.4.1.weight       | nonzeros =     695 /    2304             ( 30.16%) | total_pruned =    1609 | shape = torch.Size([16, 16, 3, 3])
1.1.4.1.bias         | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.5.weight         | nonzeros =      14 /      16             ( 87.50%) | total_pruned =       2 | shape = torch.Size([16])
1.1.5.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.7.1.0.1.1.weight | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([4, 16, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =    1551 /    4608             ( 33.66%) | total_pruned =    3057 | shape = torch.Size([32, 16, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.2.weight   | nonzeros =      27 /      32             ( 84.38%) | total_pruned =       5 | shape = torch.Size([32])
1.1.7.1.1.2.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.4.1.weight | nonzeros =    2412 /    9216             ( 26.17%) | total_pruned =    6804 | shape = torch.Size([32, 32, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.5.weight   | nonzeros =      24 /      32             ( 75.00%) | total_pruned =       8 | shape = torch.Size([32])
1.1.7.1.1.5.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([4, 32, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    3786 /   18432             ( 20.54%) | total_pruned =   14646 | shape = torch.Size([64, 32, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    6198 /   36864             ( 16.81%) | total_pruned =   30666 | shape = torch.Size([64, 64, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      58 /     256             ( 22.66%) | total_pruned =     198 | shape = torch.Size([4, 64, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    5463 /   73728             (  7.41%) | total_pruned =   68265 | shape = torch.Size([128, 64, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    7855 /  147456             (  5.33%) | total_pruned =  139601 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     203 /     512             ( 39.65%) | total_pruned =     309 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    2065 /  147456             (  1.40%) | total_pruned =  145391 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    5149 /  147456             (  3.49%) | total_pruned =  142307 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      46 /     512             (  8.98%) | total_pruned =     466 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   10247 /  147456             (  6.95%) | total_pruned =  137209 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   21414 /  147456             ( 14.52%) | total_pruned =  126042 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      88 /     132             ( 66.67%) | total_pruned =      44 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   30455 /  152064             ( 20.03%) | total_pruned =  121609 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      96 /     132             ( 72.73%) | total_pruned =      36 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   36540 /  152064             ( 24.03%) | total_pruned =  115524 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      99 /     132             ( 75.00%) | total_pruned =      33 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   33880 /  152064             ( 22.28%) | total_pruned =  118184 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      89 /     132             ( 67.42%) | total_pruned =      43 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =   15256 /   76032             ( 20.07%) | total_pruned =   60776 | shape = torch.Size([64, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.4.weight | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.2.weight       | nonzeros =      42 /      68             ( 61.76%) | total_pruned =      26 | shape = torch.Size([68])
1.1.7.2.bias         | nonzeros =       0 /      68             (  0.00%) | total_pruned =      68 | shape = torch.Size([68])
1.1.7.3.1.weight     | nonzeros =    4056 /   19584             ( 20.71%) | total_pruned =   15528 | shape = torch.Size([32, 68, 3, 3])
1.1.7.3.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.4.weight       | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
1.1.7.4.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      23 /      36             ( 63.89%) | total_pruned =      13 | shape = torch.Size([36])
2.bias               | nonzeros =       0 /      36             (  0.00%) | total_pruned =      36 | shape = torch.Size([36])
3.1.weight           | nonzeros =    1536 /    5184             ( 29.63%) | total_pruned =    3648 | shape = torch.Size([16, 36, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      28 /      48             ( 58.33%) | total_pruned =      20 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       3 /       3             (100.00%) | total_pruned =       0 | shape = torch.Size([3])
alive: 191956, pruned : 1259527, total: 1451483, Compression rate :       7.56x  ( 86.78% pruned)
PSNR of output image is:  20.546335887893378
Experiment done
