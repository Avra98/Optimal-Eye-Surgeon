(3, 512, 512)
Starting vanilla DIP on 0 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '19.675558713874977'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/0/skip/det/2.0/1e-09
epoch:  0 quantization_loss:  0.07684403657913208
p mean is: tensor(0.0004, device='cuda:4')
epoch:  1000 quantization_loss:  0.06862576305866241
p mean is: tensor(0.0155, device='cuda:4')
epoch:  2000 quantization_loss:  0.06745712459087372
p mean is: tensor(0.0277, device='cuda:4')
epoch:  3000 quantization_loss:  0.06743129342794418
p mean is: tensor(0.0401, device='cuda:4')
epoch:  4000 quantization_loss:  0.06635882705450058
p mean is: tensor(0.0535, device='cuda:4')
epoch:  5000 quantization_loss:  0.06630733609199524
p mean is: tensor(0.0675, device='cuda:4')
epoch:  6000 quantization_loss:  0.06566014885902405
p mean is: tensor(0.0833, device='cuda:4')
epoch:  7000 quantization_loss:  0.06533899903297424
p mean is: tensor(0.1004, device='cuda:4')
epoch:  8000 quantization_loss:  0.06500262767076492
p mean is: tensor(0.1198, device='cuda:4')
epoch:  9000 quantization_loss:  0.06475826352834702
p mean is: tensor(0.1418, device='cuda:4')
epoch:  10000 quantization_loss:  0.06477509438991547
p mean is: tensor(0.1673, device='cuda:4')
epoch:  11000 quantization_loss:  0.0648258626461029
p mean is: tensor(0.1951, device='cuda:4')
epoch:  12000 quantization_loss:  0.05967635288834572
p mean is: tensor(0.2274, device='cuda:4')
epoch:  13000 quantization_loss:  0.05127301812171936
p mean is: tensor(0.2602, device='cuda:4')
epoch:  14000 quantization_loss:  0.049643393605947495
p mean is: tensor(0.2922, device='cuda:4')
epoch:  15000 quantization_loss:  0.04437623918056488
p mean is: tensor(0.3260, device='cuda:4')
epoch:  16000 quantization_loss:  0.040857382118701935
p mean is: tensor(0.3641, device='cuda:4')
epoch:  17000 quantization_loss:  0.039785537868738174
p mean is: tensor(0.4094, device='cuda:4')
epoch:  18000 quantization_loss:  0.037294160574674606
p mean is: tensor(0.4630, device='cuda:4')
epoch:  19000 quantization_loss:  0.035463038831949234
p mean is: tensor(0.5251, device='cuda:4')
epoch:  20000 quantization_loss:  0.034460216760635376
p mean is: tensor(0.5945, device='cuda:4')
epoch:  21000 quantization_loss:  0.0313907116651535
p mean is: tensor(0.6700, device='cuda:4')
epoch:  22000 quantization_loss:  0.0308303814381361
p mean is: tensor(0.7491, device='cuda:4')
epoch:  23000 quantization_loss:  0.030711937695741653
p mean is: tensor(0.8294, device='cuda:4')
epoch:  24000 quantization_loss:  0.030315672978758812
p mean is: tensor(0.9093, device='cuda:4')
epoch:  25000 quantization_loss:  0.03021502122282982
p mean is: tensor(0.9863, device='cuda:4')
epoch:  26000 quantization_loss:  0.028986772522330284
p mean is: tensor(1.0590, device='cuda:4')
epoch:  27000 quantization_loss:  0.02867787331342697
p mean is: tensor(1.1264, device='cuda:4')
epoch:  28000 quantization_loss:  0.02844502031803131
p mean is: tensor(1.1881, device='cuda:4')
epoch:  29000 quantization_loss:  0.028318092226982117
p mean is: tensor(1.2446, device='cuda:4')
epoch:  30000 quantization_loss:  0.028114238753914833
p mean is: tensor(1.2959, device='cuda:4')
epoch:  31000 quantization_loss:  0.028143370524048805
p mean is: tensor(1.3429, device='cuda:4')
epoch:  32000 quantization_loss:  0.027990393340587616
p mean is: tensor(1.3858, device='cuda:4')
epoch:  33000 quantization_loss:  0.027892323210835457
p mean is: tensor(1.4249, device='cuda:4')
epoch:  34000 quantization_loss:  0.027690261602401733
p mean is: tensor(1.4607, device='cuda:4')
epoch:  35000 quantization_loss:  0.027622777968645096
p mean is: tensor(1.4932, device='cuda:4')
epoch:  36000 quantization_loss:  0.027427686378359795
p mean is: tensor(1.5224, device='cuda:4')
epoch:  37000 quantization_loss:  0.02740868180990219
p mean is: tensor(1.5494, device='cuda:4')
epoch:  38000 quantization_loss:  0.027245959267020226
p mean is: tensor(1.5739, device='cuda:4')
epoch:  39000 quantization_loss:  0.027245253324508667
p mean is: tensor(1.5969, device='cuda:4')
epoch:  40000 quantization_loss:  0.02715977653861046
p mean is: tensor(1.6177, device='cuda:4')
epoch:  41000 quantization_loss:  0.027107028290629387
p mean is: tensor(1.6372, device='cuda:4')
epoch:  42000 quantization_loss:  0.027144286781549454
p mean is: tensor(1.6551, device='cuda:4')
epoch:  43000 quantization_loss:  0.027041563764214516
p mean is: tensor(1.6719, device='cuda:4')
epoch:  44000 quantization_loss:  0.027004312723875046
p mean is: tensor(1.6874, device='cuda:4')
epoch:  45000 quantization_loss:  0.02714165486395359
p mean is: tensor(1.7021, device='cuda:4')
epoch:  46000 quantization_loss:  0.026968954131007195
p mean is: tensor(1.7157, device='cuda:4')
epoch:  47000 quantization_loss:  0.026929477229714394
p mean is: tensor(1.7284, device='cuda:4')
epoch:  48000 quantization_loss:  0.026900188997387886
p mean is: tensor(1.7404, device='cuda:4')
epoch:  49000 quantization_loss:  0.026867974549531937
p mean is: tensor(1.7517, device='cuda:4')
epoch:  50000 quantization_loss:  0.026807354763150215
p mean is: tensor(1.7624, device='cuda:4')
epoch:  51000 quantization_loss:  0.026826994493603706
p mean is: tensor(1.7724, device='cuda:4')
epoch:  52000 quantization_loss:  0.026798881590366364
p mean is: tensor(1.7819, device='cuda:4')
epoch:  53000 quantization_loss:  0.02684975042939186
p mean is: tensor(1.7908, device='cuda:4')
epoch:  54000 quantization_loss:  0.02678689733147621
p mean is: tensor(1.7994, device='cuda:4')
epoch:  55000 quantization_loss:  0.026761576533317566
p mean is: tensor(1.8073, device='cuda:4')
epoch:  56000 quantization_loss:  0.02675195410847664
p mean is: tensor(1.8149, device='cuda:4')
epoch:  57000 quantization_loss:  0.026746541261672974
p mean is: tensor(1.8222, device='cuda:4')
epoch:  58000 quantization_loss:  0.026784807443618774
p mean is: tensor(1.8292, device='cuda:4')
epoch:  59000 quantization_loss:  0.026726972311735153
p mean is: tensor(1.8358, device='cuda:4')
epoch:  60000 quantization_loss:  0.026712188497185707
p mean is: tensor(1.8422, device='cuda:4')
epoch:  61000 quantization_loss:  0.02670511044561863
p mean is: tensor(1.8480, device='cuda:4')
epoch:  62000 quantization_loss:  0.02665405347943306
p mean is: tensor(1.8539, device='cuda:4')
epoch:  63000 quantization_loss:  0.02668505534529686
p mean is: tensor(1.8594, device='cuda:4')
epoch:  64000 quantization_loss:  0.026691969484090805
p mean is: tensor(1.8647, device='cuda:4')
epoch:  65000 quantization_loss:  0.026676375418901443
p mean is: tensor(1.8698, device='cuda:4')
epoch:  66000 quantization_loss:  0.02672353945672512
p mean is: tensor(1.8747, device='cuda:4')
epoch:  67000 quantization_loss:  0.02667492814362049
p mean is: tensor(1.8793, device='cuda:4')
epoch:  68000 quantization_loss:  0.026661109179258347
p mean is: tensor(1.8839, device='cuda:4')
epoch:  69000 quantization_loss:  0.02665606699883938
p mean is: tensor(1.8883, device='cuda:4')
epoch:  70000 quantization_loss:  0.026655014604330063
p mean is: tensor(1.8925, device='cuda:4')
epoch:  71000 quantization_loss:  0.026645170524716377
p mean is: tensor(1.8966, device='cuda:4')
epoch:  72000 quantization_loss:  0.026577984914183617
p mean is: tensor(1.9006, device='cuda:4')
epoch:  73000 quantization_loss:  0.026639366522431374
p mean is: tensor(1.9045, device='cuda:4')
epoch:  74000 quantization_loss:  0.02667948044836521
p mean is: tensor(1.9082, device='cuda:4')
epoch:  75000 quantization_loss:  0.02661958895623684
p mean is: tensor(1.9118, device='cuda:4')
epoch:  76000 quantization_loss:  0.02663334272801876
p mean is: tensor(1.9153, device='cuda:4')
epoch:  77000 quantization_loss:  0.026625867933034897
p mean is: tensor(1.9186, device='cuda:4')
epoch:  78000 quantization_loss:  0.026619696989655495
p mean is: tensor(1.9219, device='cuda:4')
epoch:  79000 quantization_loss:  0.026615530252456665
p mean is: tensor(1.9251, device='cuda:4')
here
1.0.1.1.weight       | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =    3442 /    4608             ( 74.70%) | total_pruned =    1166 | shape = torch.Size([16, 32, 3, 3])
1.1.1.1.bias         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.2.weight         | nonzeros =      13 /      16             ( 81.25%) | total_pruned =       3 | shape = torch.Size([16])
1.1.2.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.4.1.weight       | nonzeros =    2105 /    2304             ( 91.36%) | total_pruned =     199 | shape = torch.Size([16, 16, 3, 3])
1.1.4.1.bias         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.5.weight         | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.1.5.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.7.1.0.1.1.weight | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 16, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =    4472 /    4608             ( 97.05%) | total_pruned =     136 | shape = torch.Size([32, 16, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.1.1.2.weight   | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.1.7.1.1.2.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.4.1.weight | nonzeros =    9006 /    9216             ( 97.72%) | total_pruned =     210 | shape = torch.Size([32, 32, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.1.1.5.weight   | nonzeros =      24 /      32             ( 75.00%) | total_pruned =       8 | shape = torch.Size([32])
1.1.7.1.1.5.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 32, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   18112 /   18432             ( 98.26%) | total_pruned =     320 | shape = torch.Size([64, 32, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   36148 /   36864             ( 98.06%) | total_pruned =     716 | shape = torch.Size([64, 64, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 64, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   72546 /   73728             ( 98.40%) | total_pruned =    1182 | shape = torch.Size([128, 64, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  146249 /  147456             ( 99.18%) | total_pruned =    1207 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     481 /     512             ( 93.95%) | total_pruned =      31 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =  146653 /  147456             ( 99.46%) | total_pruned =     803 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  144440 /  147456             ( 97.95%) | total_pruned =    3016 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     415 /     512             ( 81.05%) | total_pruned =      97 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =  141840 /  147456             ( 96.19%) | total_pruned =    5616 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  131875 /  147456             ( 89.43%) | total_pruned =   15581 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      81 /     132             ( 61.36%) | total_pruned =      51 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  126266 /  152064             ( 83.03%) | total_pruned =   25798 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      98 /     132             ( 74.24%) | total_pruned =      34 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  125258 /  152064             ( 82.37%) | total_pruned =   26806 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      78 /     132             ( 59.09%) | total_pruned =      54 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  136108 /  152064             ( 89.51%) | total_pruned =   15956 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      57 /     132             ( 43.18%) | total_pruned =      75 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =   69708 /   76032             ( 91.68%) | total_pruned =    6324 | shape = torch.Size([64, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.4.weight | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.2.weight       | nonzeros =      28 /      68             ( 41.18%) | total_pruned =      40 | shape = torch.Size([68])
1.1.7.2.bias         | nonzeros =       0 /      68             (  0.00%) | total_pruned =      68 | shape = torch.Size([68])
1.1.7.3.1.weight     | nonzeros =   17252 /   19584             ( 88.09%) | total_pruned =    2332 | shape = torch.Size([32, 68, 3, 3])
1.1.7.3.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.4.weight       | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
1.1.7.4.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      19 /      36             ( 52.78%) | total_pruned =      17 | shape = torch.Size([36])
2.bias               | nonzeros =       0 /      36             (  0.00%) | total_pruned =      36 | shape = torch.Size([36])
3.1.weight           | nonzeros =    3810 /    5184             ( 73.50%) | total_pruned =    1374 | shape = torch.Size([16, 36, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      32 /      48             ( 66.67%) | total_pruned =      16 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 1339737, pruned : 111746, total: 1451483, Compression rate :       1.08x  (  7.70% pruned)
PSNR of output image is:  16.632876192136244
Experiment done
