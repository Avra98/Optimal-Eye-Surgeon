(3, 256, 256)
Starting vanilla DIP on 3 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.313246873402456'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/3/skip/det/-1.5/1e-09
(3, 256, 256)
Starting vanilla DIP on 3 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.30857919098676'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/3/skip/det/-1.5/1e-09
epoch:  0 quantization_loss:  0.07587334513664246
p mean is: tensor(-0.0003, device='cuda:4')
epoch:  1000 quantization_loss:  0.07122959941625595
p mean is: tensor(-0.0091, device='cuda:4')
epoch:  2000 quantization_loss:  0.0689534842967987
p mean is: tensor(-0.0160, device='cuda:4')
epoch:  3000 quantization_loss:  0.06892123073339462
p mean is: tensor(-0.0226, device='cuda:4')
epoch:  4000 quantization_loss:  0.06858984380960464
p mean is: tensor(-0.0295, device='cuda:4')
epoch:  5000 quantization_loss:  0.06871826201677322
p mean is: tensor(-0.0364, device='cuda:4')
epoch:  6000 quantization_loss:  0.06835000216960907
p mean is: tensor(-0.0426, device='cuda:4')
epoch:  7000 quantization_loss:  0.06821280717849731
p mean is: tensor(-0.0493, device='cuda:4')
epoch:  8000 quantization_loss:  0.06787358224391937
p mean is: tensor(-0.0561, device='cuda:4')
epoch:  9000 quantization_loss:  0.06816580146551132
p mean is: tensor(-0.0633, device='cuda:4')
epoch:  10000 quantization_loss:  0.06825914233922958
p mean is: tensor(-0.0708, device='cuda:4')
epoch:  11000 quantization_loss:  0.0687716081738472
p mean is: tensor(-0.0788, device='cuda:4')
epoch:  12000 quantization_loss:  0.06848536431789398
p mean is: tensor(-0.0871, device='cuda:4')
epoch:  13000 quantization_loss:  0.0685196965932846
p mean is: tensor(-0.0957, device='cuda:4')
epoch:  14000 quantization_loss:  0.0682026818394661
p mean is: tensor(-0.1047, device='cuda:4')
epoch:  15000 quantization_loss:  0.0686536505818367
p mean is: tensor(-0.1142, device='cuda:4')
epoch:  16000 quantization_loss:  0.06820407509803772
p mean is: tensor(-0.1243, device='cuda:4')
epoch:  17000 quantization_loss:  0.06821200996637344
p mean is: tensor(-0.1348, device='cuda:4')
epoch:  18000 quantization_loss:  0.0664420872926712
p mean is: tensor(-0.1453, device='cuda:4')
epoch:  19000 quantization_loss:  0.06408663094043732
p mean is: tensor(-0.1567, device='cuda:4')
epoch:  20000 quantization_loss:  0.05954304337501526
p mean is: tensor(-0.1694, device='cuda:4')
epoch:  21000 quantization_loss:  0.0573522187769413
p mean is: tensor(-0.1831, device='cuda:4')
epoch:  22000 quantization_loss:  0.05209451913833618
p mean is: tensor(-0.2004, device='cuda:4')
epoch:  23000 quantization_loss:  0.045225560665130615
p mean is: tensor(-0.2218, device='cuda:4')
epoch:  24000 quantization_loss:  0.041574910283088684
p mean is: tensor(-0.2477, device='cuda:4')
epoch:  25000 quantization_loss:  0.03921142965555191
p mean is: tensor(-0.2794, device='cuda:4')
epoch:  26000 quantization_loss:  0.03635333850979805
p mean is: tensor(-0.3178, device='cuda:4')
epoch:  27000 quantization_loss:  0.03599575161933899
p mean is: tensor(-0.3636, device='cuda:4')
epoch:  28000 quantization_loss:  0.03414537012577057
p mean is: tensor(-0.4163, device='cuda:4')
epoch:  29000 quantization_loss:  0.03258185088634491
p mean is: tensor(-0.4750, device='cuda:4')
epoch:  30000 quantization_loss:  0.030041364952921867
p mean is: tensor(-0.5373, device='cuda:4')
epoch:  31000 quantization_loss:  0.02931392379105091
p mean is: tensor(-0.6014, device='cuda:4')
epoch:  32000 quantization_loss:  0.028605038300156593
p mean is: tensor(-0.6653, device='cuda:4')
epoch:  33000 quantization_loss:  0.028238985687494278
p mean is: tensor(-0.7275, device='cuda:4')
epoch:  34000 quantization_loss:  0.027895022183656693
p mean is: tensor(-0.7872, device='cuda:4')
epoch:  35000 quantization_loss:  0.02745012752711773
p mean is: tensor(-0.8437, device='cuda:4')
epoch:  36000 quantization_loss:  0.027226848527789116
p mean is: tensor(-0.8955, device='cuda:4')
epoch:  37000 quantization_loss:  0.026228174567222595
p mean is: tensor(-0.9429, device='cuda:4')
epoch:  38000 quantization_loss:  0.025908689945936203
p mean is: tensor(-0.9857, device='cuda:4')
epoch:  39000 quantization_loss:  0.025730423629283905
p mean is: tensor(-1.0242, device='cuda:4')
epoch:  40000 quantization_loss:  0.025476131588220596
p mean is: tensor(-1.0590, device='cuda:4')
epoch:  41000 quantization_loss:  0.025374548509716988
p mean is: tensor(-1.0901, device='cuda:4')
epoch:  42000 quantization_loss:  0.02518407627940178
p mean is: tensor(-1.1178, device='cuda:4')
epoch:  43000 quantization_loss:  0.025045109912753105
p mean is: tensor(-1.1425, device='cuda:4')
epoch:  44000 quantization_loss:  0.02489469386637211
p mean is: tensor(-1.1644, device='cuda:4')
epoch:  45000 quantization_loss:  0.024869682267308235
p mean is: tensor(-1.1839, device='cuda:4')
epoch:  46000 quantization_loss:  0.024712227284908295
p mean is: tensor(-1.2014, device='cuda:4')
epoch:  47000 quantization_loss:  0.024545956403017044
p mean is: tensor(-1.2169, device='cuda:4')
epoch:  48000 quantization_loss:  0.024479622021317482
p mean is: tensor(-1.2307, device='cuda:4')
epoch:  49000 quantization_loss:  0.02439453825354576
p mean is: tensor(-1.2431, device='cuda:4')
epoch:  50000 quantization_loss:  0.024311352521181107
p mean is: tensor(-1.2543, device='cuda:4')
epoch:  51000 quantization_loss:  0.024249861016869545
p mean is: tensor(-1.2642, device='cuda:4')
epoch:  52000 quantization_loss:  0.02422628551721573
p mean is: tensor(-1.2732, device='cuda:4')
epoch:  53000 quantization_loss:  0.024136805906891823
p mean is: tensor(-1.2812, device='cuda:4')
epoch:  54000 quantization_loss:  0.02409788966178894
p mean is: tensor(-1.2886, device='cuda:4')
epoch:  55000 quantization_loss:  0.024047570303082466
p mean is: tensor(-1.2953, device='cuda:4')
epoch:  56000 quantization_loss:  0.02399277873337269
p mean is: tensor(-1.3014, device='cuda:4')
epoch:  57000 quantization_loss:  0.023988351225852966
p mean is: tensor(-1.3071, device='cuda:4')
epoch:  58000 quantization_loss:  0.02395804040133953
p mean is: tensor(-1.3122, device='cuda:4')
epoch:  59000 quantization_loss:  0.023908818140625954
p mean is: tensor(-1.3170, device='cuda:4')
epoch:  60000 quantization_loss:  0.0238806139677763
p mean is: tensor(-1.3214, device='cuda:4')
epoch:  61000 quantization_loss:  0.02385536953806877
p mean is: tensor(-1.3254, device='cuda:4')
epoch:  62000 quantization_loss:  0.023934610188007355
p mean is: tensor(-1.3293, device='cuda:4')
epoch:  63000 quantization_loss:  0.023818913847208023
p mean is: tensor(-1.3328, device='cuda:4')
epoch:  64000 quantization_loss:  0.023804519325494766
p mean is: tensor(-1.3360, device='cuda:4')
epoch:  65000 quantization_loss:  0.023812945932149887
p mean is: tensor(-1.3390, device='cuda:4')
epoch:  66000 quantization_loss:  0.023773755878210068
p mean is: tensor(-1.3419, device='cuda:4')
epoch:  67000 quantization_loss:  0.023812348023056984
p mean is: tensor(-1.3446, device='cuda:4')
epoch:  68000 quantization_loss:  0.023762891069054604
p mean is: tensor(-1.3471, device='cuda:4')
epoch:  69000 quantization_loss:  0.023727573454380035
p mean is: tensor(-1.3494, device='cuda:4')
epoch:  70000 quantization_loss:  0.023733174428343773
p mean is: tensor(-1.3517, device='cuda:4')
epoch:  71000 quantization_loss:  0.023714058101177216
p mean is: tensor(-1.3539, device='cuda:4')
epoch:  72000 quantization_loss:  0.02371588535606861
p mean is: tensor(-1.3561, device='cuda:4')
epoch:  73000 quantization_loss:  0.023699598386883736
p mean is: tensor(-1.3580, device='cuda:4')
epoch:  74000 quantization_loss:  0.023676704615354538
p mean is: tensor(-1.3599, device='cuda:4')
epoch:  75000 quantization_loss:  0.02367374114692211
p mean is: tensor(-1.3617, device='cuda:4')
epoch:  76000 quantization_loss:  0.02367629110813141
p mean is: tensor(-1.3634, device='cuda:4')
epoch:  77000 quantization_loss:  0.023854002356529236
p mean is: tensor(-1.3650, device='cuda:4')
epoch:  78000 quantization_loss:  0.02365872822701931
p mean is: tensor(-1.3666, device='cuda:4')
epoch:  79000 quantization_loss:  0.023665014654397964
p mean is: tensor(-1.3681, device='cuda:4')
here
1.0.1.1.weight       | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =    1346 /    4608             ( 29.21%) | total_pruned =    3262 | shape = torch.Size([16, 32, 3, 3])
1.1.1.1.bias         | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.2.weight         | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.1.2.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.4.1.weight       | nonzeros =     626 /    2304             ( 27.17%) | total_pruned =    1678 | shape = torch.Size([16, 16, 3, 3])
1.1.4.1.bias         | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.5.weight         | nonzeros =      13 /      16             ( 81.25%) | total_pruned =       3 | shape = torch.Size([16])
1.1.5.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.7.1.0.1.1.weight | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([4, 16, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =    1455 /    4608             ( 31.58%) | total_pruned =    3153 | shape = torch.Size([32, 16, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.2.weight   | nonzeros =      26 /      32             ( 81.25%) | total_pruned =       6 | shape = torch.Size([32])
1.1.7.1.1.2.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.4.1.weight | nonzeros =    2184 /    9216             ( 23.70%) | total_pruned =    7032 | shape = torch.Size([32, 32, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.5.weight   | nonzeros =      21 /      32             ( 65.62%) | total_pruned =      11 | shape = torch.Size([32])
1.1.7.1.1.5.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([4, 32, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    3041 /   18432             ( 16.50%) | total_pruned =   15391 | shape = torch.Size([64, 32, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    3840 /   36864             ( 10.42%) | total_pruned =   33024 | shape = torch.Size([64, 64, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([4, 64, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    2328 /   73728             (  3.16%) | total_pruned =   71400 | shape = torch.Size([128, 64, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    2398 /  147456             (  1.63%) | total_pruned =  145058 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      41 /     512             (  8.01%) | total_pruned =     471 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =     241 /  147456             (  0.16%) | total_pruned =  147215 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    1185 /  147456             (  0.80%) | total_pruned =  146271 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    3717 /  147456             (  2.52%) | total_pruned =  143739 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    8798 /  147456             (  5.97%) | total_pruned =  138658 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      61 /     132             ( 46.21%) | total_pruned =      71 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   16454 /  152064             ( 10.82%) | total_pruned =  135610 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      70 /     132             ( 53.03%) | total_pruned =      62 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   25097 /  152064             ( 16.50%) | total_pruned =  126967 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      88 /     132             ( 66.67%) | total_pruned =      44 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   27270 /  152064             ( 17.93%) | total_pruned =  124794 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      76 /     132             ( 57.58%) | total_pruned =      56 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =   10447 /   76032             ( 13.74%) | total_pruned =   65585 | shape = torch.Size([64, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.4.weight | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.2.weight       | nonzeros =      33 /      68             ( 48.53%) | total_pruned =      35 | shape = torch.Size([68])
1.1.7.2.bias         | nonzeros =       0 /      68             (  0.00%) | total_pruned =      68 | shape = torch.Size([68])
1.1.7.3.1.weight     | nonzeros =    2123 /   19584             ( 10.84%) | total_pruned =   17461 | shape = torch.Size([32, 68, 3, 3])
1.1.7.3.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.4.weight       | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.1.7.4.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      16 /      36             ( 44.44%) | total_pruned =      20 | shape = torch.Size([36])
2.bias               | nonzeros =       0 /      36             (  0.00%) | total_pruned =      36 | shape = torch.Size([36])
3.1.weight           | nonzeros =     882 /    5184             ( 17.01%) | total_pruned =    4302 | shape = torch.Size([16, 36, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      15 /      16             ( 93.75%) | total_pruned =       1 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      32 /      48             ( 66.67%) | total_pruned =      16 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 114816, pruned : 1336667, total: 1451483, Compression rate :      12.64x  ( 92.09% pruned)
PSNR of output image is:  17.98216767502591
Experiment done
