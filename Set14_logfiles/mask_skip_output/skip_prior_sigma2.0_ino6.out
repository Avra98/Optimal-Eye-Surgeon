(3, 512, 512)
Starting vanilla DIP on 6 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.136691385330696'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/6/skip/det/2.0/1e-09
epoch:  0 quantization_loss:  0.06288059800863266
p mean is: tensor(0.0004, device='cuda:4')
epoch:  1000 quantization_loss:  0.046149738132953644
p mean is: tensor(0.0203, device='cuda:4')
epoch:  2000 quantization_loss:  0.04412703588604927
p mean is: tensor(0.0349, device='cuda:4')
epoch:  3000 quantization_loss:  0.043410103768110275
p mean is: tensor(0.0497, device='cuda:4')
epoch:  4000 quantization_loss:  0.0430101603269577
p mean is: tensor(0.0645, device='cuda:4')
epoch:  5000 quantization_loss:  0.043099526315927505
p mean is: tensor(0.0806, device='cuda:4')
epoch:  6000 quantization_loss:  0.042706530541181564
p mean is: tensor(0.0991, device='cuda:4')
epoch:  7000 quantization_loss:  0.04243125393986702
p mean is: tensor(0.1200, device='cuda:4')
epoch:  8000 quantization_loss:  0.04249716177582741
p mean is: tensor(0.1448, device='cuda:4')
epoch:  9000 quantization_loss:  0.042006369680166245
p mean is: tensor(0.1737, device='cuda:4')
epoch:  10000 quantization_loss:  0.04090972617268562
p mean is: tensor(0.2061, device='cuda:4')
epoch:  11000 quantization_loss:  0.038447197526693344
p mean is: tensor(0.2401, device='cuda:4')
epoch:  12000 quantization_loss:  0.03616327419877052
p mean is: tensor(0.2770, device='cuda:4')
epoch:  13000 quantization_loss:  0.03391013294458389
p mean is: tensor(0.3152, device='cuda:4')
epoch:  14000 quantization_loss:  0.03178388252854347
p mean is: tensor(0.3564, device='cuda:4')
epoch:  15000 quantization_loss:  0.0303734689950943
p mean is: tensor(0.4029, device='cuda:4')
epoch:  16000 quantization_loss:  0.02954733744263649
p mean is: tensor(0.4566, device='cuda:4')
epoch:  17000 quantization_loss:  0.02835395745933056
p mean is: tensor(0.5178, device='cuda:4')
epoch:  18000 quantization_loss:  0.02653990313410759
p mean is: tensor(0.5863, device='cuda:4')
epoch:  19000 quantization_loss:  0.02559894323348999
p mean is: tensor(0.6593, device='cuda:4')
epoch:  20000 quantization_loss:  0.024366741999983788
p mean is: tensor(0.7351, device='cuda:4')
epoch:  21000 quantization_loss:  0.02383357472717762
p mean is: tensor(0.8116, device='cuda:4')
epoch:  22000 quantization_loss:  0.023217778652906418
p mean is: tensor(0.8875, device='cuda:4')
epoch:  23000 quantization_loss:  0.022738803178071976
p mean is: tensor(0.9613, device='cuda:4')
epoch:  24000 quantization_loss:  0.02205951325595379
p mean is: tensor(1.0322, device='cuda:4')
epoch:  25000 quantization_loss:  0.021718358621001244
p mean is: tensor(1.0989, device='cuda:4')
epoch:  26000 quantization_loss:  0.021500039845705032
p mean is: tensor(1.1611, device='cuda:4')
epoch:  27000 quantization_loss:  0.021231910213828087
p mean is: tensor(1.2186, device='cuda:4')
epoch:  28000 quantization_loss:  0.021123256534337997
p mean is: tensor(1.2716, device='cuda:4')
epoch:  29000 quantization_loss:  0.02058573067188263
p mean is: tensor(1.3197, device='cuda:4')
epoch:  30000 quantization_loss:  0.02051207609474659
p mean is: tensor(1.3634, device='cuda:4')
epoch:  31000 quantization_loss:  0.02035968191921711
p mean is: tensor(1.4031, device='cuda:4')
epoch:  32000 quantization_loss:  0.02024845778942108
p mean is: tensor(1.4394, device='cuda:4')
epoch:  33000 quantization_loss:  0.020150307565927505
p mean is: tensor(1.4725, device='cuda:4')
epoch:  34000 quantization_loss:  0.0199842881411314
p mean is: tensor(1.5031, device='cuda:4')
epoch:  35000 quantization_loss:  0.019981373101472855
p mean is: tensor(1.5313, device='cuda:4')
epoch:  36000 quantization_loss:  0.019897399470210075
p mean is: tensor(1.5574, device='cuda:4')
epoch:  37000 quantization_loss:  0.019787564873695374
p mean is: tensor(1.5814, device='cuda:4')
epoch:  38000 quantization_loss:  0.01973944716155529
p mean is: tensor(1.6035, device='cuda:4')
epoch:  39000 quantization_loss:  0.019695671275258064
p mean is: tensor(1.6241, device='cuda:4')
epoch:  40000 quantization_loss:  0.01964973658323288
p mean is: tensor(1.6432, device='cuda:4')
epoch:  41000 quantization_loss:  0.019591230899095535
p mean is: tensor(1.6610, device='cuda:4')
epoch:  42000 quantization_loss:  0.01955951750278473
p mean is: tensor(1.6778, device='cuda:4')
epoch:  43000 quantization_loss:  0.0195073913782835
p mean is: tensor(1.6934, device='cuda:4')
epoch:  44000 quantization_loss:  0.018972055986523628
p mean is: tensor(1.7081, device='cuda:4')
epoch:  45000 quantization_loss:  0.018592488020658493
p mean is: tensor(1.7215, device='cuda:4')
epoch:  46000 quantization_loss:  0.018421843647956848
p mean is: tensor(1.7343, device='cuda:4')
epoch:  47000 quantization_loss:  0.018368275836110115
p mean is: tensor(1.7462, device='cuda:4')
epoch:  48000 quantization_loss:  0.01831735111773014
p mean is: tensor(1.7574, device='cuda:4')
epoch:  49000 quantization_loss:  0.018311182036995888
p mean is: tensor(1.7682, device='cuda:4')
epoch:  50000 quantization_loss:  0.01826530136168003
p mean is: tensor(1.7784, device='cuda:4')
epoch:  51000 quantization_loss:  0.018230151385068893
p mean is: tensor(1.7881, device='cuda:4')
epoch:  52000 quantization_loss:  0.018225040286779404
p mean is: tensor(1.7974, device='cuda:4')
epoch:  53000 quantization_loss:  0.018188951537013054
p mean is: tensor(1.8063, device='cuda:4')
epoch:  54000 quantization_loss:  0.018190940842032433
p mean is: tensor(1.8148, device='cuda:4')
epoch:  55000 quantization_loss:  0.018189366906881332
p mean is: tensor(1.8229, device='cuda:4')
epoch:  56000 quantization_loss:  0.018175242468714714
p mean is: tensor(1.8306, device='cuda:4')
epoch:  57000 quantization_loss:  0.018134666606783867
p mean is: tensor(1.8381, device='cuda:4')
epoch:  58000 quantization_loss:  0.01814032718539238
p mean is: tensor(1.8454, device='cuda:4')
epoch:  59000 quantization_loss:  0.018120750784873962
p mean is: tensor(1.8524, device='cuda:4')
epoch:  60000 quantization_loss:  0.018106136471033096
p mean is: tensor(1.8591, device='cuda:4')
epoch:  61000 quantization_loss:  0.018101252615451813
p mean is: tensor(1.8656, device='cuda:4')
epoch:  62000 quantization_loss:  0.018096942454576492
p mean is: tensor(1.8719, device='cuda:4')
epoch:  63000 quantization_loss:  0.018092483282089233
p mean is: tensor(1.8779, device='cuda:4')
epoch:  64000 quantization_loss:  0.018081368878483772
p mean is: tensor(1.8837, device='cuda:4')
epoch:  65000 quantization_loss:  0.01807311922311783
p mean is: tensor(1.8893, device='cuda:4')
epoch:  66000 quantization_loss:  0.01806100830435753
p mean is: tensor(1.8948, device='cuda:4')
epoch:  67000 quantization_loss:  0.01806044764816761
p mean is: tensor(1.9001, device='cuda:4')
epoch:  68000 quantization_loss:  0.018062496557831764
p mean is: tensor(1.9051, device='cuda:4')
epoch:  69000 quantization_loss:  0.018045585602521896
p mean is: tensor(1.9101, device='cuda:4')
epoch:  70000 quantization_loss:  0.018046243116259575
p mean is: tensor(1.9150, device='cuda:4')
epoch:  71000 quantization_loss:  0.018033508211374283
p mean is: tensor(1.9198, device='cuda:4')
epoch:  72000 quantization_loss:  0.018033141270279884
p mean is: tensor(1.9244, device='cuda:4')
epoch:  73000 quantization_loss:  0.018025409430265427
p mean is: tensor(1.9289, device='cuda:4')
epoch:  74000 quantization_loss:  0.01801820658147335
p mean is: tensor(1.9333, device='cuda:4')
epoch:  75000 quantization_loss:  0.018016614019870758
p mean is: tensor(1.9376, device='cuda:4')
epoch:  76000 quantization_loss:  0.018187232315540314
p mean is: tensor(1.9418, device='cuda:4')
epoch:  77000 quantization_loss:  0.018016355112195015
p mean is: tensor(1.9459, device='cuda:4')
epoch:  78000 quantization_loss:  0.018016183748841286
p mean is: tensor(1.9500, device='cuda:4')
epoch:  79000 quantization_loss:  0.018005717545747757
p mean is: tensor(1.9539, device='cuda:4')
here
1.0.1.1.weight       | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =    3560 /    4608             ( 77.26%) | total_pruned =    1048 | shape = torch.Size([16, 32, 3, 3])
1.1.1.1.bias         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.2.weight         | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.1.2.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.4.1.weight       | nonzeros =    2047 /    2304             ( 88.85%) | total_pruned =     257 | shape = torch.Size([16, 16, 3, 3])
1.1.4.1.bias         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.5.weight         | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.1.5.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.7.1.0.1.1.weight | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 16, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =    3953 /    4608             ( 85.79%) | total_pruned =     655 | shape = torch.Size([32, 16, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.1.1.2.weight   | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
1.1.7.1.1.2.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.4.1.weight | nonzeros =    7187 /    9216             ( 77.98%) | total_pruned =    2029 | shape = torch.Size([32, 32, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.1.1.5.weight   | nonzeros =      26 /      32             ( 81.25%) | total_pruned =       6 | shape = torch.Size([32])
1.1.7.1.1.5.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 32, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   14217 /   18432             ( 77.13%) | total_pruned =    4215 | shape = torch.Size([64, 32, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   31796 /   36864             ( 86.25%) | total_pruned =    5068 | shape = torch.Size([64, 64, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     230 /     256             ( 89.84%) | total_pruned =      26 | shape = torch.Size([4, 64, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   69015 /   73728             ( 93.61%) | total_pruned =    4713 | shape = torch.Size([128, 64, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  141023 /  147456             ( 95.64%) | total_pruned =    6433 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     397 /     512             ( 77.54%) | total_pruned =     115 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =  146145 /  147456             ( 99.11%) | total_pruned =    1311 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  144111 /  147456             ( 97.73%) | total_pruned =    3345 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     456 /     512             ( 89.06%) | total_pruned =      56 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =  141654 /  147456             ( 96.07%) | total_pruned =    5802 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  130506 /  147456             ( 88.51%) | total_pruned =   16950 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      93 /     132             ( 70.45%) | total_pruned =      39 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  125145 /  152064             ( 82.30%) | total_pruned =   26919 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      89 /     132             ( 67.42%) | total_pruned =      43 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  130245 /  152064             ( 85.65%) | total_pruned =   21819 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      66 /     132             ( 50.00%) | total_pruned =      66 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  133523 /  152064             ( 87.81%) | total_pruned =   18541 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      73 /     132             ( 55.30%) | total_pruned =      59 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =   65962 /   76032             ( 86.76%) | total_pruned =   10070 | shape = torch.Size([64, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.4.weight | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.2.weight       | nonzeros =      35 /      68             ( 51.47%) | total_pruned =      33 | shape = torch.Size([68])
1.1.7.2.bias         | nonzeros =       0 /      68             (  0.00%) | total_pruned =      68 | shape = torch.Size([68])
1.1.7.3.1.weight     | nonzeros =   16384 /   19584             ( 83.66%) | total_pruned =    3200 | shape = torch.Size([32, 68, 3, 3])
1.1.7.3.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.4.weight       | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
1.1.7.4.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      21 /      36             ( 58.33%) | total_pruned =      15 | shape = torch.Size([36])
2.bias               | nonzeros =       0 /      36             (  0.00%) | total_pruned =      36 | shape = torch.Size([36])
3.1.weight           | nonzeros =    3812 /    5184             ( 73.53%) | total_pruned =    1372 | shape = torch.Size([16, 36, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      15 /      16             ( 93.75%) | total_pruned =       1 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      29 /      48             ( 60.42%) | total_pruned =      19 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 1314744, pruned : 136739, total: 1451483, Compression rate :       1.10x  (  9.42% pruned)
PSNR of output image is:  20.710803562285847
Experiment done
