(3, 512, 512)
Starting vanilla DIP on 7 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.249652167852737'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/7/skip/det/-1.3/1e-09
(3, 512, 512)
Starting vanilla DIP on 7 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.237001501156023'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/7/skip/det/-1.3/1e-09
epoch:  0 quantization_loss:  0.08292519301176071
p mean is: tensor(-0.0002, device='cuda:2')
epoch:  1000 quantization_loss:  0.06973393261432648
p mean is: tensor(-0.0092, device='cuda:2')
epoch:  2000 quantization_loss:  0.06745901703834534
p mean is: tensor(-0.0153, device='cuda:2')
epoch:  3000 quantization_loss:  0.06691020727157593
p mean is: tensor(-0.0212, device='cuda:2')
epoch:  4000 quantization_loss:  0.06589654088020325
p mean is: tensor(-0.0272, device='cuda:2')
epoch:  5000 quantization_loss:  0.06515663862228394
p mean is: tensor(-0.0336, device='cuda:2')
epoch:  6000 quantization_loss:  0.06422813981771469
p mean is: tensor(-0.0402, device='cuda:2')
epoch:  7000 quantization_loss:  0.058521077036857605
p mean is: tensor(-0.0471, device='cuda:2')
epoch:  8000 quantization_loss:  0.051166240125894547
p mean is: tensor(-0.0550, device='cuda:2')
epoch:  9000 quantization_loss:  0.04840578883886337
p mean is: tensor(-0.0646, device='cuda:2')
epoch:  10000 quantization_loss:  0.042443353682756424
p mean is: tensor(-0.0764, device='cuda:2')
epoch:  11000 quantization_loss:  0.040460750460624695
p mean is: tensor(-0.0915, device='cuda:2')
epoch:  12000 quantization_loss:  0.03756064921617508
p mean is: tensor(-0.1107, device='cuda:2')
epoch:  13000 quantization_loss:  0.033833008259534836
p mean is: tensor(-0.1346, device='cuda:2')
epoch:  14000 quantization_loss:  0.0333508662879467
p mean is: tensor(-0.1638, device='cuda:2')
epoch:  15000 quantization_loss:  0.032751601189374924
p mean is: tensor(-0.1989, device='cuda:2')
epoch:  16000 quantization_loss:  0.031874556094408035
p mean is: tensor(-0.2405, device='cuda:2')
epoch:  17000 quantization_loss:  0.031878918409347534
p mean is: tensor(-0.2886, device='cuda:2')
epoch:  18000 quantization_loss:  0.03156857565045357
p mean is: tensor(-0.3423, device='cuda:2')
epoch:  19000 quantization_loss:  0.031144103035330772
p mean is: tensor(-0.4002, device='cuda:2')
epoch:  20000 quantization_loss:  0.03078494407236576
p mean is: tensor(-0.4599, device='cuda:2')
epoch:  21000 quantization_loss:  0.030718956142663956
p mean is: tensor(-0.5191, device='cuda:2')
epoch:  22000 quantization_loss:  0.03051568940281868
p mean is: tensor(-0.5759, device='cuda:2')
epoch:  23000 quantization_loss:  0.030342012643814087
p mean is: tensor(-0.6289, device='cuda:2')
epoch:  24000 quantization_loss:  0.029999002814292908
p mean is: tensor(-0.6778, device='cuda:2')
epoch:  25000 quantization_loss:  0.03003019094467163
p mean is: tensor(-0.7225, device='cuda:2')
epoch:  26000 quantization_loss:  0.029766833409667015
p mean is: tensor(-0.7633, device='cuda:2')
epoch:  27000 quantization_loss:  0.029655274003744125
p mean is: tensor(-0.8002, device='cuda:2')
epoch:  28000 quantization_loss:  0.02951727993786335
p mean is: tensor(-0.8335, device='cuda:2')
epoch:  29000 quantization_loss:  0.029432915151119232
p mean is: tensor(-0.8639, device='cuda:2')
epoch:  30000 quantization_loss:  0.029329542070627213
p mean is: tensor(-0.8911, device='cuda:2')
epoch:  31000 quantization_loss:  0.02919861115515232
p mean is: tensor(-0.9159, device='cuda:2')
epoch:  32000 quantization_loss:  0.029162244871258736
p mean is: tensor(-0.9382, device='cuda:2')
epoch:  33000 quantization_loss:  0.02909325622022152
p mean is: tensor(-0.9586, device='cuda:2')
epoch:  34000 quantization_loss:  0.028978532180190086
p mean is: tensor(-0.9771, device='cuda:2')
epoch:  35000 quantization_loss:  0.028962697833776474
p mean is: tensor(-0.9941, device='cuda:2')
epoch:  36000 quantization_loss:  0.028862088918685913
p mean is: tensor(-1.0097, device='cuda:2')
epoch:  37000 quantization_loss:  0.02881845086812973
p mean is: tensor(-1.0240, device='cuda:2')
epoch:  38000 quantization_loss:  0.028764374554157257
p mean is: tensor(-1.0372, device='cuda:2')
epoch:  39000 quantization_loss:  0.028712276369333267
p mean is: tensor(-1.0493, device='cuda:2')
epoch:  40000 quantization_loss:  0.02867024391889572
p mean is: tensor(-1.0607, device='cuda:2')
epoch:  41000 quantization_loss:  0.028633126989006996
p mean is: tensor(-1.0714, device='cuda:2')
epoch:  42000 quantization_loss:  0.02860359661281109
p mean is: tensor(-1.0813, device='cuda:2')
epoch:  43000 quantization_loss:  0.028528792783617973
p mean is: tensor(-1.0908, device='cuda:2')
epoch:  44000 quantization_loss:  0.028498511761426926
p mean is: tensor(-1.0995, device='cuda:2')
epoch:  45000 quantization_loss:  0.028471877798438072
p mean is: tensor(-1.1077, device='cuda:2')
epoch:  46000 quantization_loss:  0.02843460813164711
p mean is: tensor(-1.1155, device='cuda:2')
epoch:  47000 quantization_loss:  0.028419218957424164
p mean is: tensor(-1.1230, device='cuda:2')
epoch:  48000 quantization_loss:  0.028378311544656754
p mean is: tensor(-1.1299, device='cuda:2')
epoch:  49000 quantization_loss:  0.028349099680781364
p mean is: tensor(-1.1365, device='cuda:2')
epoch:  50000 quantization_loss:  0.028335075825452805
p mean is: tensor(-1.1427, device='cuda:2')
epoch:  51000 quantization_loss:  0.028308117762207985
p mean is: tensor(-1.1487, device='cuda:2')
epoch:  52000 quantization_loss:  0.02830953150987625
p mean is: tensor(-1.1542, device='cuda:2')
epoch:  53000 quantization_loss:  0.02826773375272751
p mean is: tensor(-1.1596, device='cuda:2')
epoch:  54000 quantization_loss:  0.028263630345463753
p mean is: tensor(-1.1649, device='cuda:2')
epoch:  55000 quantization_loss:  0.02823420986533165
p mean is: tensor(-1.1698, device='cuda:2')
epoch:  56000 quantization_loss:  0.028226403519511223
p mean is: tensor(-1.1746, device='cuda:2')
epoch:  57000 quantization_loss:  0.02844252437353134
p mean is: tensor(-1.1792, device='cuda:2')
epoch:  58000 quantization_loss:  0.028197433799505234
p mean is: tensor(-1.1837, device='cuda:2')
epoch:  59000 quantization_loss:  0.02818804420530796
p mean is: tensor(-1.1879, device='cuda:2')
epoch:  60000 quantization_loss:  0.028172414749860764
p mean is: tensor(-1.1920, device='cuda:2')
epoch:  61000 quantization_loss:  0.028165332973003387
p mean is: tensor(-1.1959, device='cuda:2')
epoch:  62000 quantization_loss:  0.02814127691090107
p mean is: tensor(-1.1997, device='cuda:2')
epoch:  63000 quantization_loss:  0.028123585507273674
p mean is: tensor(-1.2034, device='cuda:2')
epoch:  64000 quantization_loss:  0.02811802178621292
p mean is: tensor(-1.2069, device='cuda:2')
epoch:  65000 quantization_loss:  0.028114788234233856
p mean is: tensor(-1.2105, device='cuda:2')
epoch:  66000 quantization_loss:  0.028137659654021263
p mean is: tensor(-1.2140, device='cuda:2')
epoch:  67000 quantization_loss:  0.028097188100218773
p mean is: tensor(-1.2173, device='cuda:2')
epoch:  68000 quantization_loss:  0.02809455618262291
p mean is: tensor(-1.2204, device='cuda:2')
epoch:  69000 quantization_loss:  0.02808290906250477
p mean is: tensor(-1.2235, device='cuda:2')
epoch:  70000 quantization_loss:  0.028077369555830956
p mean is: tensor(-1.2264, device='cuda:2')
epoch:  71000 quantization_loss:  0.02808065339922905
p mean is: tensor(-1.2294, device='cuda:2')
epoch:  72000 quantization_loss:  0.028067143633961678
p mean is: tensor(-1.2323, device='cuda:2')
epoch:  73000 quantization_loss:  0.028068765997886658
p mean is: tensor(-1.2351, device='cuda:2')
epoch:  74000 quantization_loss:  0.028058378025889397
p mean is: tensor(-1.2379, device='cuda:2')
epoch:  75000 quantization_loss:  0.028056057170033455
p mean is: tensor(-1.2406, device='cuda:2')
epoch:  76000 quantization_loss:  0.028044968843460083
p mean is: tensor(-1.2433, device='cuda:2')
epoch:  77000 quantization_loss:  0.028047777712345123
p mean is: tensor(-1.2458, device='cuda:2')
epoch:  78000 quantization_loss:  0.028078410774469376
p mean is: tensor(-1.2484, device='cuda:2')
epoch:  79000 quantization_loss:  0.028075572103261948
p mean is: tensor(-1.2507, device='cuda:2')
here
1.0.1.1.weight       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =    1096 /    4608             ( 23.78%) | total_pruned =    3512 | shape = torch.Size([16, 32, 3, 3])
1.1.1.1.bias         | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.2.weight         | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.1.2.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.4.1.weight       | nonzeros =     317 /    2304             ( 13.76%) | total_pruned =    1987 | shape = torch.Size([16, 16, 3, 3])
1.1.4.1.bias         | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.5.weight         | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.1.5.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.7.1.0.1.1.weight | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([4, 16, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =     764 /    4608             ( 16.58%) | total_pruned =    3844 | shape = torch.Size([32, 16, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.2.weight   | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
1.1.7.1.1.2.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.4.1.weight | nonzeros =    2038 /    9216             ( 22.11%) | total_pruned =    7178 | shape = torch.Size([32, 32, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.5.weight   | nonzeros =      26 /      32             ( 81.25%) | total_pruned =       6 | shape = torch.Size([32])
1.1.7.1.1.5.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([4, 32, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    4488 /   18432             ( 24.35%) | total_pruned =   13944 | shape = torch.Size([64, 32, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    5923 /   36864             ( 16.07%) | total_pruned =   30941 | shape = torch.Size([64, 64, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      26 /     256             ( 10.16%) | total_pruned =     230 | shape = torch.Size([4, 64, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    4568 /   73728             (  6.20%) | total_pruned =   69160 | shape = torch.Size([128, 64, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    5099 /  147456             (  3.46%) | total_pruned =  142357 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      97 /     512             ( 18.95%) | total_pruned =     415 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    1241 /  147456             (  0.84%) | total_pruned =  146215 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    3844 /  147456             (  2.61%) | total_pruned =  143612 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     107 /     512             ( 20.90%) | total_pruned =     405 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    8436 /  147456             (  5.72%) | total_pruned =  139020 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   19601 /  147456             ( 13.29%) | total_pruned =  127855 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      89 /     132             ( 67.42%) | total_pruned =      43 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   30007 /  152064             ( 19.73%) | total_pruned =  122057 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      96 /     132             ( 72.73%) | total_pruned =      36 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   32277 /  152064             ( 21.23%) | total_pruned =  119787 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      90 /     132             ( 68.18%) | total_pruned =      42 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   29948 /  152064             ( 19.69%) | total_pruned =  122116 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      89 /     132             ( 67.42%) | total_pruned =      43 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =   13546 /   76032             ( 17.82%) | total_pruned =   62486 | shape = torch.Size([64, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.4.weight | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.2.weight       | nonzeros =      39 /      68             ( 57.35%) | total_pruned =      29 | shape = torch.Size([68])
1.1.7.2.bias         | nonzeros =       0 /      68             (  0.00%) | total_pruned =      68 | shape = torch.Size([68])
1.1.7.3.1.weight     | nonzeros =    2816 /   19584             ( 14.38%) | total_pruned =   16768 | shape = torch.Size([32, 68, 3, 3])
1.1.7.3.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.4.weight       | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.1.7.4.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      17 /      36             ( 47.22%) | total_pruned =      19 | shape = torch.Size([36])
2.bias               | nonzeros =       0 /      36             (  0.00%) | total_pruned =      36 | shape = torch.Size([36])
3.1.weight           | nonzeros =    1130 /    5184             ( 21.80%) | total_pruned =    4054 | shape = torch.Size([16, 36, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      29 /      48             ( 60.42%) | total_pruned =      19 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 168909, pruned : 1282574, total: 1451483, Compression rate :       8.59x  ( 88.36% pruned)
PSNR of output image is:  16.989407776062897
Experiment done
