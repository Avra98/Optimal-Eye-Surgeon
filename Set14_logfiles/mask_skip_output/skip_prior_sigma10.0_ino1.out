(3, 256, 256)
Starting vanilla DIP on 1 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.517641799391114'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/1/skip/det/10.0/1e-09
epoch:  0 quantization_loss:  0.10929172486066818
p mean is: tensor(0.0014, device='cuda:4')
epoch:  1000 quantization_loss:  0.08283741772174835
p mean is: tensor(0.0388, device='cuda:4')
epoch:  2000 quantization_loss:  0.08441639691591263
p mean is: tensor(0.0593, device='cuda:4')
epoch:  3000 quantization_loss:  0.08200826495885849
p mean is: tensor(0.0785, device='cuda:4')
epoch:  4000 quantization_loss:  0.08374010771512985
p mean is: tensor(0.0968, device='cuda:4')
epoch:  5000 quantization_loss:  0.08277656883001328
p mean is: tensor(0.1153, device='cuda:4')
epoch:  6000 quantization_loss:  0.08076190948486328
p mean is: tensor(0.1331, device='cuda:4')
epoch:  7000 quantization_loss:  0.08238940685987473
p mean is: tensor(0.1516, device='cuda:4')
epoch:  8000 quantization_loss:  0.08424308896064758
p mean is: tensor(0.1704, device='cuda:4')
epoch:  9000 quantization_loss:  0.07940427213907242
p mean is: tensor(0.1900, device='cuda:4')
epoch:  10000 quantization_loss:  0.08138756453990936
p mean is: tensor(0.2108, device='cuda:4')
epoch:  11000 quantization_loss:  0.07512043416500092
p mean is: tensor(0.2316, device='cuda:4')
epoch:  12000 quantization_loss:  0.06555456668138504
p mean is: tensor(0.2554, device='cuda:4')
epoch:  13000 quantization_loss:  0.0587947852909565
p mean is: tensor(0.2865, device='cuda:4')
epoch:  14000 quantization_loss:  0.04997771233320236
p mean is: tensor(0.3224, device='cuda:4')
epoch:  15000 quantization_loss:  0.04852636158466339
p mean is: tensor(0.3694, device='cuda:4')
epoch:  16000 quantization_loss:  0.04512210562825203
p mean is: tensor(0.4313, device='cuda:4')
epoch:  17000 quantization_loss:  0.04292849451303482
p mean is: tensor(0.5103, device='cuda:4')
epoch:  18000 quantization_loss:  0.03984357789158821
p mean is: tensor(0.6085, device='cuda:4')
epoch:  19000 quantization_loss:  0.03759632259607315
p mean is: tensor(0.7296, device='cuda:4')
epoch:  20000 quantization_loss:  0.036884840577840805
p mean is: tensor(0.8766, device='cuda:4')
epoch:  21000 quantization_loss:  0.03470737487077713
p mean is: tensor(1.0492, device='cuda:4')
epoch:  22000 quantization_loss:  0.033836908638477325
p mean is: tensor(1.2453, device='cuda:4')
epoch:  23000 quantization_loss:  0.03242671117186546
p mean is: tensor(1.4605, device='cuda:4')
epoch:  24000 quantization_loss:  0.03174712508916855
p mean is: tensor(1.6876, device='cuda:4')
epoch:  25000 quantization_loss:  0.03106875717639923
p mean is: tensor(1.9172, device='cuda:4')
epoch:  26000 quantization_loss:  0.030406884849071503
p mean is: tensor(2.1412, device='cuda:4')
epoch:  27000 quantization_loss:  0.02996053360402584
p mean is: tensor(2.3520, device='cuda:4')
epoch:  28000 quantization_loss:  0.02955559641122818
p mean is: tensor(2.5466, device='cuda:4')
epoch:  29000 quantization_loss:  0.02921031415462494
p mean is: tensor(2.7244, device='cuda:4')
epoch:  30000 quantization_loss:  0.02944692224264145
p mean is: tensor(2.8863, device='cuda:4')
epoch:  31000 quantization_loss:  0.028736650943756104
p mean is: tensor(3.0333, device='cuda:4')
epoch:  32000 quantization_loss:  0.028596961870789528
p mean is: tensor(3.1672, device='cuda:4')
epoch:  33000 quantization_loss:  0.028418803587555885
p mean is: tensor(3.2894, device='cuda:4')
epoch:  34000 quantization_loss:  0.028334353119134903
p mean is: tensor(3.4009, device='cuda:4')
epoch:  35000 quantization_loss:  0.028324218466877937
p mean is: tensor(3.5033, device='cuda:4')
epoch:  36000 quantization_loss:  0.02817608043551445
p mean is: tensor(3.5976, device='cuda:4')
epoch:  37000 quantization_loss:  0.02802952006459236
p mean is: tensor(3.6849, device='cuda:4')
epoch:  38000 quantization_loss:  0.027919460088014603
p mean is: tensor(3.7660, device='cuda:4')
epoch:  39000 quantization_loss:  0.02788621373474598
p mean is: tensor(3.8416, device='cuda:4')
epoch:  40000 quantization_loss:  0.027830135077238083
p mean is: tensor(3.9126, device='cuda:4')
epoch:  41000 quantization_loss:  0.027795227244496346
p mean is: tensor(3.9792, device='cuda:4')
epoch:  42000 quantization_loss:  0.027694780379533768
p mean is: tensor(4.0418, device='cuda:4')
epoch:  43000 quantization_loss:  0.02769334241747856
p mean is: tensor(4.1010, device='cuda:4')
epoch:  44000 quantization_loss:  0.027653835713863373
p mean is: tensor(4.1572, device='cuda:4')
epoch:  45000 quantization_loss:  0.027601784095168114
p mean is: tensor(4.2107, device='cuda:4')
epoch:  46000 quantization_loss:  0.02756764553487301
p mean is: tensor(4.2617, device='cuda:4')
epoch:  47000 quantization_loss:  0.027547191828489304
p mean is: tensor(4.3102, device='cuda:4')
epoch:  48000 quantization_loss:  0.02754346653819084
p mean is: tensor(4.3568, device='cuda:4')
epoch:  49000 quantization_loss:  0.02747306227684021
p mean is: tensor(4.4013, device='cuda:4')
epoch:  50000 quantization_loss:  0.027467014268040657
p mean is: tensor(4.4440, device='cuda:4')
epoch:  51000 quantization_loss:  0.02742111124098301
p mean is: tensor(4.4850, device='cuda:4')
epoch:  52000 quantization_loss:  0.0274082962423563
p mean is: tensor(4.5244, device='cuda:4')
epoch:  53000 quantization_loss:  0.027372559532523155
p mean is: tensor(4.5626, device='cuda:4')
epoch:  54000 quantization_loss:  0.02735299989581108
p mean is: tensor(4.5993, device='cuda:4')
epoch:  55000 quantization_loss:  0.027346111834049225
p mean is: tensor(4.6347, device='cuda:4')
epoch:  56000 quantization_loss:  0.02731415256857872
p mean is: tensor(4.6691, device='cuda:4')
epoch:  57000 quantization_loss:  0.027298269793391228
p mean is: tensor(4.7023, device='cuda:4')
epoch:  58000 quantization_loss:  0.027286771684885025
p mean is: tensor(4.7345, device='cuda:4')
epoch:  59000 quantization_loss:  0.02727065235376358
p mean is: tensor(4.7656, device='cuda:4')
epoch:  60000 quantization_loss:  0.0272637028247118
p mean is: tensor(4.7959, device='cuda:4')
epoch:  61000 quantization_loss:  0.027246512472629547
p mean is: tensor(4.8252, device='cuda:4')
epoch:  62000 quantization_loss:  0.02725956402719021
p mean is: tensor(4.8537, device='cuda:4')
epoch:  63000 quantization_loss:  0.027222082018852234
p mean is: tensor(4.8814, device='cuda:4')
epoch:  64000 quantization_loss:  0.027219198644161224
p mean is: tensor(4.9082, device='cuda:4')
epoch:  65000 quantization_loss:  0.02721860259771347
p mean is: tensor(4.9345, device='cuda:4')
epoch:  66000 quantization_loss:  0.027329348027706146
p mean is: tensor(4.9599, device='cuda:4')
epoch:  67000 quantization_loss:  0.027193637564778328
p mean is: tensor(4.9848, device='cuda:4')
epoch:  68000 quantization_loss:  0.02718173712491989
p mean is: tensor(5.0091, device='cuda:4')
epoch:  69000 quantization_loss:  0.027180086821317673
p mean is: tensor(5.0328, device='cuda:4')
epoch:  70000 quantization_loss:  0.027221502736210823
p mean is: tensor(5.0559, device='cuda:4')
epoch:  71000 quantization_loss:  0.027160650119185448
p mean is: tensor(5.0784, device='cuda:4')
epoch:  72000 quantization_loss:  0.02715863101184368
p mean is: tensor(5.1004, device='cuda:4')
epoch:  73000 quantization_loss:  0.027155369520187378
p mean is: tensor(5.1219, device='cuda:4')
epoch:  74000 quantization_loss:  0.027141183614730835
p mean is: tensor(5.1429, device='cuda:4')
epoch:  75000 quantization_loss:  0.02714136429131031
p mean is: tensor(5.1636, device='cuda:4')
epoch:  76000 quantization_loss:  0.027134675532579422
p mean is: tensor(5.1837, device='cuda:4')
epoch:  77000 quantization_loss:  0.027158919721841812
p mean is: tensor(5.2034, device='cuda:4')
epoch:  78000 quantization_loss:  0.027122782543301582
p mean is: tensor(5.2227, device='cuda:4')
epoch:  79000 quantization_loss:  0.02715626172721386
p mean is: tensor(5.2416, device='cuda:4')
here
1.0.1.1.weight       | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =    3361 /    4608             ( 72.94%) | total_pruned =    1247 | shape = torch.Size([16, 32, 3, 3])
1.1.1.1.bias         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.2.weight         | nonzeros =      12 /      16             ( 75.00%) | total_pruned =       4 | shape = torch.Size([16])
1.1.2.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.4.1.weight       | nonzeros =    1919 /    2304             ( 83.29%) | total_pruned =     385 | shape = torch.Size([16, 16, 3, 3])
1.1.4.1.bias         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.5.weight         | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.1.5.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.7.1.0.1.1.weight | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 16, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =    4127 /    4608             ( 89.56%) | total_pruned =     481 | shape = torch.Size([32, 16, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.1.1.2.weight   | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
1.1.7.1.1.2.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.4.1.weight | nonzeros =    8322 /    9216             ( 90.30%) | total_pruned =     894 | shape = torch.Size([32, 32, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.1.1.5.weight   | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
1.1.7.1.1.5.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 32, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   17085 /   18432             ( 92.69%) | total_pruned =    1347 | shape = torch.Size([64, 32, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   34516 /   36864             ( 93.63%) | total_pruned =    2348 | shape = torch.Size([64, 64, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     179 /     256             ( 69.92%) | total_pruned =      77 | shape = torch.Size([4, 64, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   73265 /   73728             ( 99.37%) | total_pruned =     463 | shape = torch.Size([128, 64, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  147079 /  147456             ( 99.74%) | total_pruned =     377 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     436 /     512             ( 85.16%) | total_pruned =      76 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =  147333 /  147456             ( 99.92%) | total_pruned =     123 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  147222 /  147456             ( 99.84%) | total_pruned =     234 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     489 /     512             ( 95.51%) | total_pruned =      23 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =  147013 /  147456             ( 99.70%) | total_pruned =     443 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  145662 /  147456             ( 98.78%) | total_pruned =    1794 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      78 /     132             ( 59.09%) | total_pruned =      54 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  145721 /  152064             ( 95.83%) | total_pruned =    6343 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      89 /     132             ( 67.42%) | total_pruned =      43 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  141555 /  152064             ( 93.09%) | total_pruned =   10509 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      77 /     132             ( 58.33%) | total_pruned =      55 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  140779 /  152064             ( 92.58%) | total_pruned =   11285 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      71 /     132             ( 53.79%) | total_pruned =      61 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =   69550 /   76032             ( 91.47%) | total_pruned =    6482 | shape = torch.Size([64, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.4.weight | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.2.weight       | nonzeros =      34 /      68             ( 50.00%) | total_pruned =      34 | shape = torch.Size([68])
1.1.7.2.bias         | nonzeros =       0 /      68             (  0.00%) | total_pruned =      68 | shape = torch.Size([68])
1.1.7.3.1.weight     | nonzeros =   17906 /   19584             ( 91.43%) | total_pruned =    1678 | shape = torch.Size([32, 68, 3, 3])
1.1.7.3.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.4.weight       | nonzeros =      24 /      32             ( 75.00%) | total_pruned =       8 | shape = torch.Size([32])
1.1.7.4.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      14 /      36             ( 38.89%) | total_pruned =      22 | shape = torch.Size([36])
2.bias               | nonzeros =       0 /      36             (  0.00%) | total_pruned =      36 | shape = torch.Size([36])
3.1.weight           | nonzeros =    4161 /    5184             ( 80.27%) | total_pruned =    1023 | shape = torch.Size([16, 36, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      32 /      48             ( 66.67%) | total_pruned =      16 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 1400973, pruned : 50510, total: 1451483, Compression rate :       1.04x  (  3.48% pruned)
PSNR of output image is:  16.98182541100975
Experiment done
