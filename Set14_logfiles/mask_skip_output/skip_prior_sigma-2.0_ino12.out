(3, 256, 256)
Starting vanilla DIP on 12 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.855986829118084'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/12/skip/det/-2.0/1e-09
(3, 256, 256)
Starting vanilla DIP on 12 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.842782925434413'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/12/skip/det/-2.0/1e-09
epoch:  0 quantization_loss:  0.11486892402172089
p mean is: tensor(-0.0003, device='cuda:2')
epoch:  1000 quantization_loss:  0.09159927070140839
p mean is: tensor(-0.0068, device='cuda:2')
epoch:  2000 quantization_loss:  0.08779765665531158
p mean is: tensor(-0.0102, device='cuda:2')
epoch:  3000 quantization_loss:  0.083805151283741
p mean is: tensor(-0.0133, device='cuda:2')
epoch:  4000 quantization_loss:  0.0865740031003952
p mean is: tensor(-0.0165, device='cuda:2')
epoch:  5000 quantization_loss:  0.08837219327688217
p mean is: tensor(-0.0197, device='cuda:2')
epoch:  6000 quantization_loss:  0.08488775044679642
p mean is: tensor(-0.0227, device='cuda:2')
epoch:  7000 quantization_loss:  0.08523339778184891
p mean is: tensor(-0.0254, device='cuda:2')
epoch:  8000 quantization_loss:  0.08693287521600723
p mean is: tensor(-0.0283, device='cuda:2')
epoch:  9000 quantization_loss:  0.08620977401733398
p mean is: tensor(-0.0313, device='cuda:2')
epoch:  10000 quantization_loss:  0.0881640836596489
p mean is: tensor(-0.0343, device='cuda:2')
epoch:  11000 quantization_loss:  0.08606936037540436
p mean is: tensor(-0.0368, device='cuda:2')
epoch:  12000 quantization_loss:  0.08367418497800827
p mean is: tensor(-0.0399, device='cuda:2')
epoch:  13000 quantization_loss:  0.08610972762107849
p mean is: tensor(-0.0432, device='cuda:2')
epoch:  14000 quantization_loss:  0.08450675010681152
p mean is: tensor(-0.0472, device='cuda:2')
epoch:  15000 quantization_loss:  0.08132149279117584
p mean is: tensor(-0.0520, device='cuda:2')
epoch:  16000 quantization_loss:  0.059981826692819595
p mean is: tensor(-0.0572, device='cuda:2')
epoch:  17000 quantization_loss:  0.048345789313316345
p mean is: tensor(-0.0630, device='cuda:2')
epoch:  18000 quantization_loss:  0.04602926969528198
p mean is: tensor(-0.0710, device='cuda:2')
epoch:  19000 quantization_loss:  0.0443594865500927
p mean is: tensor(-0.0820, device='cuda:2')
epoch:  20000 quantization_loss:  0.04282848536968231
p mean is: tensor(-0.0966, device='cuda:2')
epoch:  21000 quantization_loss:  0.042209442704916
p mean is: tensor(-0.1157, device='cuda:2')
epoch:  22000 quantization_loss:  0.0419984832406044
p mean is: tensor(-0.1411, device='cuda:2')
epoch:  23000 quantization_loss:  0.041726965457201004
p mean is: tensor(-0.1741, device='cuda:2')
epoch:  24000 quantization_loss:  0.04100215435028076
p mean is: tensor(-0.2160, device='cuda:2')
epoch:  25000 quantization_loss:  0.04071509465575218
p mean is: tensor(-0.2678, device='cuda:2')
epoch:  26000 quantization_loss:  0.040158528834581375
p mean is: tensor(-0.3298, device='cuda:2')
epoch:  27000 quantization_loss:  0.03992526978254318
p mean is: tensor(-0.4030, device='cuda:2')
epoch:  28000 quantization_loss:  0.039905667304992676
p mean is: tensor(-0.4872, device='cuda:2')
epoch:  29000 quantization_loss:  0.03964872285723686
p mean is: tensor(-0.5812, device='cuda:2')
epoch:  30000 quantization_loss:  0.03947042301297188
p mean is: tensor(-0.6818, device='cuda:2')
epoch:  31000 quantization_loss:  0.039301205426454544
p mean is: tensor(-0.7855, device='cuda:2')
epoch:  32000 quantization_loss:  0.03915894404053688
p mean is: tensor(-0.8883, device='cuda:2')
epoch:  33000 quantization_loss:  0.039088569581508636
p mean is: tensor(-0.9860, device='cuda:2')
epoch:  34000 quantization_loss:  0.03896447271108627
p mean is: tensor(-1.0765, device='cuda:2')
epoch:  35000 quantization_loss:  0.03884994238615036
p mean is: tensor(-1.1587, device='cuda:2')
epoch:  36000 quantization_loss:  0.03875545412302017
p mean is: tensor(-1.2331, device='cuda:2')
epoch:  37000 quantization_loss:  0.03872881829738617
p mean is: tensor(-1.2995, device='cuda:2')
epoch:  38000 quantization_loss:  0.038691043853759766
p mean is: tensor(-1.3586, device='cuda:2')
epoch:  39000 quantization_loss:  0.038600608706474304
p mean is: tensor(-1.4114, device='cuda:2')
epoch:  40000 quantization_loss:  0.03856850787997246
p mean is: tensor(-1.4585, device='cuda:2')
epoch:  41000 quantization_loss:  0.03853936120867729
p mean is: tensor(-1.5007, device='cuda:2')
epoch:  42000 quantization_loss:  0.03836871311068535
p mean is: tensor(-1.5386, device='cuda:2')
epoch:  43000 quantization_loss:  0.03736836463212967
p mean is: tensor(-1.5722, device='cuda:2')
epoch:  44000 quantization_loss:  0.03712727501988411
p mean is: tensor(-1.6013, device='cuda:2')
epoch:  45000 quantization_loss:  0.03689897432923317
p mean is: tensor(-1.6273, device='cuda:2')
epoch:  46000 quantization_loss:  0.03684747591614723
p mean is: tensor(-1.6509, device='cuda:2')
epoch:  47000 quantization_loss:  0.0369652695953846
p mean is: tensor(-1.6728, device='cuda:2')
epoch:  48000 quantization_loss:  0.036793194711208344
p mean is: tensor(-1.6928, device='cuda:2')
epoch:  49000 quantization_loss:  0.03677176684141159
p mean is: tensor(-1.7111, device='cuda:2')
epoch:  50000 quantization_loss:  0.03672413527965546
p mean is: tensor(-1.7281, device='cuda:2')
epoch:  51000 quantization_loss:  0.03670896589756012
p mean is: tensor(-1.7437, device='cuda:2')
epoch:  52000 quantization_loss:  0.036698631942272186
p mean is: tensor(-1.7581, device='cuda:2')
epoch:  53000 quantization_loss:  0.03670106455683708
p mean is: tensor(-1.7715, device='cuda:2')
epoch:  54000 quantization_loss:  0.036650482565164566
p mean is: tensor(-1.7837, device='cuda:2')
epoch:  55000 quantization_loss:  0.03665058687329292
p mean is: tensor(-1.7952, device='cuda:2')
epoch:  56000 quantization_loss:  0.036630433052778244
p mean is: tensor(-1.8057, device='cuda:2')
epoch:  57000 quantization_loss:  0.03669304400682449
p mean is: tensor(-1.8156, device='cuda:2')
epoch:  58000 quantization_loss:  0.036610327661037445
p mean is: tensor(-1.8248, device='cuda:2')
epoch:  59000 quantization_loss:  0.03659805282950401
p mean is: tensor(-1.8334, device='cuda:2')
epoch:  60000 quantization_loss:  0.03658808767795563
p mean is: tensor(-1.8414, device='cuda:2')
epoch:  61000 quantization_loss:  0.03657081723213196
p mean is: tensor(-1.8490, device='cuda:2')
epoch:  62000 quantization_loss:  0.03664437681436539
p mean is: tensor(-1.8560, device='cuda:2')
epoch:  63000 quantization_loss:  0.036556411534547806
p mean is: tensor(-1.8627, device='cuda:2')
epoch:  64000 quantization_loss:  0.03654870018362999
p mean is: tensor(-1.8690, device='cuda:2')
epoch:  65000 quantization_loss:  0.03654813393950462
p mean is: tensor(-1.8748, device='cuda:2')
epoch:  66000 quantization_loss:  0.036545149981975555
p mean is: tensor(-1.8804, device='cuda:2')
epoch:  67000 quantization_loss:  0.03651927039027214
p mean is: tensor(-1.8857, device='cuda:2')
epoch:  68000 quantization_loss:  0.03653520718216896
p mean is: tensor(-1.8906, device='cuda:2')
epoch:  69000 quantization_loss:  0.03651772812008858
p mean is: tensor(-1.8953, device='cuda:2')
epoch:  70000 quantization_loss:  0.03650999441742897
p mean is: tensor(-1.8998, device='cuda:2')
epoch:  71000 quantization_loss:  0.036520082503557205
p mean is: tensor(-1.9040, device='cuda:2')
epoch:  72000 quantization_loss:  0.03650552034378052
p mean is: tensor(-1.9081, device='cuda:2')
epoch:  73000 quantization_loss:  0.03650948405265808
p mean is: tensor(-1.9119, device='cuda:2')
epoch:  74000 quantization_loss:  0.03649401664733887
p mean is: tensor(-1.9155, device='cuda:2')
epoch:  75000 quantization_loss:  0.0364881306886673
p mean is: tensor(-1.9190, device='cuda:2')
epoch:  76000 quantization_loss:  0.036485619843006134
p mean is: tensor(-1.9224, device='cuda:2')
epoch:  77000 quantization_loss:  0.0364970825612545
p mean is: tensor(-1.9256, device='cuda:2')
epoch:  78000 quantization_loss:  0.036479875445365906
p mean is: tensor(-1.9285, device='cuda:2')
epoch:  79000 quantization_loss:  0.03647792711853981
p mean is: tensor(-1.9314, device='cuda:2')
here
1.0.1.1.weight       | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =     661 /    4608             ( 14.34%) | total_pruned =    3947 | shape = torch.Size([16, 32, 3, 3])
1.1.1.1.bias         | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.2.weight         | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.1.2.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.4.1.weight       | nonzeros =     244 /    2304             ( 10.59%) | total_pruned =    2060 | shape = torch.Size([16, 16, 3, 3])
1.1.4.1.bias         | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.5.weight         | nonzeros =      11 /      16             ( 68.75%) | total_pruned =       5 | shape = torch.Size([16])
1.1.5.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.7.1.0.1.1.weight | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([4, 16, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =     350 /    4608             (  7.60%) | total_pruned =    4258 | shape = torch.Size([32, 16, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.2.weight   | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
1.1.7.1.1.2.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.4.1.weight | nonzeros =     538 /    9216             (  5.84%) | total_pruned =    8678 | shape = torch.Size([32, 32, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.5.weight   | nonzeros =      21 /      32             ( 65.62%) | total_pruned =      11 | shape = torch.Size([32])
1.1.7.1.1.5.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([4, 32, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =     776 /   18432             (  4.21%) | total_pruned =   17656 | shape = torch.Size([64, 32, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =     676 /   36864             (  1.83%) | total_pruned =   36188 | shape = torch.Size([64, 64, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([4, 64, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =      13 /   73728             (  0.02%) | total_pruned =   73715 | shape = torch.Size([128, 64, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =       4 /  147456             (  0.00%) | total_pruned =  147452 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =      19 /  147456             (  0.01%) | total_pruned =  147437 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =     268 /  147456             (  0.18%) | total_pruned =  147188 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      27 /     512             (  5.27%) | total_pruned =     485 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =     831 /  147456             (  0.56%) | total_pruned =  146625 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    3915 /  147456             (  2.66%) | total_pruned =  143541 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      70 /     132             ( 53.03%) | total_pruned =      62 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   11242 /  152064             (  7.39%) | total_pruned =  140822 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      72 /     132             ( 54.55%) | total_pruned =      60 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   16370 /  152064             ( 10.77%) | total_pruned =  135694 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      83 /     132             ( 62.88%) | total_pruned =      49 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   15672 /  152064             ( 10.31%) | total_pruned =  136392 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      65 /     132             ( 49.24%) | total_pruned =      67 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =    7786 /   76032             ( 10.24%) | total_pruned =   68246 | shape = torch.Size([64, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.4.weight | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.2.weight       | nonzeros =      34 /      68             ( 50.00%) | total_pruned =      34 | shape = torch.Size([68])
1.1.7.2.bias         | nonzeros =       0 /      68             (  0.00%) | total_pruned =      68 | shape = torch.Size([68])
1.1.7.3.1.weight     | nonzeros =    2216 /   19584             ( 11.32%) | total_pruned =   17368 | shape = torch.Size([32, 68, 3, 3])
1.1.7.3.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.4.weight       | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
1.1.7.4.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      16 /      36             ( 44.44%) | total_pruned =      20 | shape = torch.Size([36])
2.bias               | nonzeros =       0 /      36             (  0.00%) | total_pruned =      36 | shape = torch.Size([36])
3.1.weight           | nonzeros =    1000 /    5184             ( 19.29%) | total_pruned =    4184 | shape = torch.Size([16, 36, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      15 /      16             ( 93.75%) | total_pruned =       1 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      29 /      48             ( 60.42%) | total_pruned =      19 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 63800, pruned : 1387683, total: 1451483, Compression rate :      22.75x  ( 95.60% pruned)
PSNR of output image is:  14.845617184547606
Experiment done
