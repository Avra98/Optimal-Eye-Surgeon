(3, 512, 512)
Starting vanilla DIP on 2 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.4366435986432'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/2/skip/det/-0.5/1e-09
(3, 512, 512)
Starting vanilla DIP on 2 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.4332467340428'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/2/skip/det/-0.5/1e-09
epoch:  0 quantization_loss:  0.1022791862487793
p mean is: tensor(-8.9179e-05, device='cuda:4')
epoch:  1000 quantization_loss:  0.08158626407384872
p mean is: tensor(-0.0036, device='cuda:4')
epoch:  2000 quantization_loss:  0.07504685968160629
p mean is: tensor(-0.0056, device='cuda:4')
epoch:  3000 quantization_loss:  0.0751030445098877
p mean is: tensor(-0.0077, device='cuda:4')
epoch:  4000 quantization_loss:  0.07532813400030136
p mean is: tensor(-0.0098, device='cuda:4')
epoch:  5000 quantization_loss:  0.0741574689745903
p mean is: tensor(-0.0121, device='cuda:4')
epoch:  6000 quantization_loss:  0.073337621986866
p mean is: tensor(-0.0153, device='cuda:4')
epoch:  7000 quantization_loss:  0.06551662087440491
p mean is: tensor(-0.0183, device='cuda:4')
epoch:  8000 quantization_loss:  0.06106794625520706
p mean is: tensor(-0.0221, device='cuda:4')
epoch:  9000 quantization_loss:  0.05634990707039833
p mean is: tensor(-0.0269, device='cuda:4')
epoch:  10000 quantization_loss:  0.050423797219991684
p mean is: tensor(-0.0324, device='cuda:4')
epoch:  11000 quantization_loss:  0.04807248339056969
p mean is: tensor(-0.0390, device='cuda:4')
epoch:  12000 quantization_loss:  0.045917581766843796
p mean is: tensor(-0.0470, device='cuda:4')
epoch:  13000 quantization_loss:  0.04447447508573532
p mean is: tensor(-0.0568, device='cuda:4')
epoch:  14000 quantization_loss:  0.04346699267625809
p mean is: tensor(-0.0689, device='cuda:4')
epoch:  15000 quantization_loss:  0.04271775856614113
p mean is: tensor(-0.0833, device='cuda:4')
epoch:  16000 quantization_loss:  0.03952448442578316
p mean is: tensor(-0.1002, device='cuda:4')
epoch:  17000 quantization_loss:  0.03869355097413063
p mean is: tensor(-0.1193, device='cuda:4')
epoch:  18000 quantization_loss:  0.03792375698685646
p mean is: tensor(-0.1402, device='cuda:4')
epoch:  19000 quantization_loss:  0.037638336420059204
p mean is: tensor(-0.1623, device='cuda:4')
epoch:  20000 quantization_loss:  0.03741374984383583
p mean is: tensor(-0.1849, device='cuda:4')
epoch:  21000 quantization_loss:  0.03715241700410843
p mean is: tensor(-0.2074, device='cuda:4')
epoch:  22000 quantization_loss:  0.03664276376366615
p mean is: tensor(-0.2285, device='cuda:4')
epoch:  23000 quantization_loss:  0.03577733039855957
p mean is: tensor(-0.2482, device='cuda:4')
epoch:  24000 quantization_loss:  0.03551675006747246
p mean is: tensor(-0.2665, device='cuda:4')
epoch:  25000 quantization_loss:  0.03537411987781525
p mean is: tensor(-0.2835, device='cuda:4')
epoch:  26000 quantization_loss:  0.03522943705320358
p mean is: tensor(-0.2988, device='cuda:4')
epoch:  27000 quantization_loss:  0.0350547730922699
p mean is: tensor(-0.3128, device='cuda:4')
epoch:  28000 quantization_loss:  0.03493979945778847
p mean is: tensor(-0.3250, device='cuda:4')
epoch:  29000 quantization_loss:  0.034816574305295944
p mean is: tensor(-0.3362, device='cuda:4')
epoch:  30000 quantization_loss:  0.034688275307416916
p mean is: tensor(-0.3460, device='cuda:4')
epoch:  31000 quantization_loss:  0.034543946385383606
p mean is: tensor(-0.3548, device='cuda:4')
epoch:  32000 quantization_loss:  0.03447267413139343
p mean is: tensor(-0.3628, device='cuda:4')
epoch:  33000 quantization_loss:  0.03438064828515053
p mean is: tensor(-0.3698, device='cuda:4')
epoch:  34000 quantization_loss:  0.034274373203516006
p mean is: tensor(-0.3761, device='cuda:4')
epoch:  35000 quantization_loss:  0.03425351530313492
p mean is: tensor(-0.3818, device='cuda:4')
epoch:  36000 quantization_loss:  0.034186962991952896
p mean is: tensor(-0.3871, device='cuda:4')
epoch:  37000 quantization_loss:  0.03409399837255478
p mean is: tensor(-0.3918, device='cuda:4')
epoch:  38000 quantization_loss:  0.0340767540037632
p mean is: tensor(-0.3961, device='cuda:4')
epoch:  39000 quantization_loss:  0.03406727686524391
p mean is: tensor(-0.4002, device='cuda:4')
epoch:  40000 quantization_loss:  0.03398726508021355
p mean is: tensor(-0.4038, device='cuda:4')
epoch:  41000 quantization_loss:  0.033952534198760986
p mean is: tensor(-0.4074, device='cuda:4')
epoch:  42000 quantization_loss:  0.03390343114733696
p mean is: tensor(-0.4107, device='cuda:4')
epoch:  43000 quantization_loss:  0.033883821219205856
p mean is: tensor(-0.4139, device='cuda:4')
epoch:  44000 quantization_loss:  0.0338662751019001
p mean is: tensor(-0.4169, device='cuda:4')
epoch:  45000 quantization_loss:  0.03382081910967827
p mean is: tensor(-0.4196, device='cuda:4')
epoch:  46000 quantization_loss:  0.033878907561302185
p mean is: tensor(-0.4222, device='cuda:4')
epoch:  47000 quantization_loss:  0.033797189593315125
p mean is: tensor(-0.4246, device='cuda:4')
epoch:  48000 quantization_loss:  0.0337553471326828
p mean is: tensor(-0.4270, device='cuda:4')
epoch:  49000 quantization_loss:  0.03374505415558815
p mean is: tensor(-0.4292, device='cuda:4')
epoch:  50000 quantization_loss:  0.03371821343898773
p mean is: tensor(-0.4313, device='cuda:4')
epoch:  51000 quantization_loss:  0.03370022028684616
p mean is: tensor(-0.4332, device='cuda:4')
epoch:  52000 quantization_loss:  0.03369666635990143
p mean is: tensor(-0.4351, device='cuda:4')
epoch:  53000 quantization_loss:  0.03368763625621796
p mean is: tensor(-0.4368, device='cuda:4')
epoch:  54000 quantization_loss:  0.033689308911561966
p mean is: tensor(-0.4386, device='cuda:4')
epoch:  55000 quantization_loss:  0.033661387860774994
p mean is: tensor(-0.4403, device='cuda:4')
epoch:  56000 quantization_loss:  0.03365132212638855
p mean is: tensor(-0.4417, device='cuda:4')
epoch:  57000 quantization_loss:  0.03365145996212959
p mean is: tensor(-0.4433, device='cuda:4')
epoch:  58000 quantization_loss:  0.03363296389579773
p mean is: tensor(-0.4447, device='cuda:4')
epoch:  59000 quantization_loss:  0.033630356192588806
p mean is: tensor(-0.4462, device='cuda:4')
epoch:  60000 quantization_loss:  0.03362134099006653
p mean is: tensor(-0.4475, device='cuda:4')
epoch:  61000 quantization_loss:  0.03360579535365105
p mean is: tensor(-0.4490, device='cuda:4')
epoch:  62000 quantization_loss:  0.03359970077872276
p mean is: tensor(-0.4502, device='cuda:4')
epoch:  63000 quantization_loss:  0.033600103110075
p mean is: tensor(-0.4515, device='cuda:4')
epoch:  64000 quantization_loss:  0.03359220176935196
p mean is: tensor(-0.4527, device='cuda:4')
epoch:  65000 quantization_loss:  0.03356702998280525
p mean is: tensor(-0.4539, device='cuda:4')
epoch:  66000 quantization_loss:  0.033567022532224655
p mean is: tensor(-0.4550, device='cuda:4')
epoch:  67000 quantization_loss:  0.03356519341468811
p mean is: tensor(-0.4561, device='cuda:4')
epoch:  68000 quantization_loss:  0.033566221594810486
p mean is: tensor(-0.4570, device='cuda:4')
epoch:  69000 quantization_loss:  0.03355659171938896
p mean is: tensor(-0.4581, device='cuda:4')
epoch:  70000 quantization_loss:  0.033549509942531586
p mean is: tensor(-0.4592, device='cuda:4')
epoch:  71000 quantization_loss:  0.033546656370162964
p mean is: tensor(-0.4601, device='cuda:4')
epoch:  72000 quantization_loss:  0.03355199098587036
p mean is: tensor(-0.4611, device='cuda:4')
epoch:  73000 quantization_loss:  0.033543169498443604
p mean is: tensor(-0.4620, device='cuda:4')
epoch:  74000 quantization_loss:  0.03355611860752106
p mean is: tensor(-0.4629, device='cuda:4')
epoch:  75000 quantization_loss:  0.03343658521771431
p mean is: tensor(-0.4636, device='cuda:4')
epoch:  76000 quantization_loss:  0.033405281603336334
p mean is: tensor(-0.4645, device='cuda:4')
epoch:  77000 quantization_loss:  0.033464107662439346
p mean is: tensor(-0.4650, device='cuda:4')
epoch:  78000 quantization_loss:  0.0331813208758831
p mean is: tensor(-0.4656, device='cuda:4')
epoch:  79000 quantization_loss:  0.033100396394729614
p mean is: tensor(-0.4662, device='cuda:4')
here
1.0.1.1.weight       | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =    1409 /    4608             ( 30.58%) | total_pruned =    3199 | shape = torch.Size([16, 32, 3, 3])
1.1.1.1.bias         | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.2.weight         | nonzeros =      11 /      16             ( 68.75%) | total_pruned =       5 | shape = torch.Size([16])
1.1.2.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.4.1.weight       | nonzeros =     323 /    2304             ( 14.02%) | total_pruned =    1981 | shape = torch.Size([16, 16, 3, 3])
1.1.4.1.bias         | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.5.weight         | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.1.5.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.7.1.0.1.1.weight | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([4, 16, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =     333 /    4608             (  7.23%) | total_pruned =    4275 | shape = torch.Size([32, 16, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.2.weight   | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
1.1.7.1.1.2.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.4.1.weight | nonzeros =     836 /    9216             (  9.07%) | total_pruned =    8380 | shape = torch.Size([32, 32, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.5.weight   | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.1.7.1.1.5.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([4, 32, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    2278 /   18432             ( 12.36%) | total_pruned =   16154 | shape = torch.Size([64, 32, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    5517 /   36864             ( 14.97%) | total_pruned =   31347 | shape = torch.Size([64, 64, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([4, 64, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   12325 /   73728             ( 16.72%) | total_pruned =   61403 | shape = torch.Size([128, 64, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   21483 /  147456             ( 14.57%) | total_pruned =  125973 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     157 /     512             ( 30.66%) | total_pruned =     355 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   11834 /  147456             (  8.03%) | total_pruned =  135622 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   18370 /  147456             ( 12.46%) | total_pruned =  129086 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     227 /     512             ( 44.34%) | total_pruned =     285 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   20449 /  147456             ( 13.87%) | total_pruned =  127007 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   26615 /  147456             ( 18.05%) | total_pruned =  120841 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      90 /     132             ( 68.18%) | total_pruned =      42 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   33606 /  152064             ( 22.10%) | total_pruned =  118458 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      91 /     132             ( 68.94%) | total_pruned =      41 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   34743 /  152064             ( 22.85%) | total_pruned =  117321 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      89 /     132             ( 67.42%) | total_pruned =      43 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   27422 /  152064             ( 18.03%) | total_pruned =  124642 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      73 /     132             ( 55.30%) | total_pruned =      59 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =   11299 /   76032             ( 14.86%) | total_pruned =   64733 | shape = torch.Size([64, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.4.weight | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.2.weight       | nonzeros =      36 /      68             ( 52.94%) | total_pruned =      32 | shape = torch.Size([68])
1.1.7.2.bias         | nonzeros =       0 /      68             (  0.00%) | total_pruned =      68 | shape = torch.Size([68])
1.1.7.3.1.weight     | nonzeros =    3171 /   19584             ( 16.19%) | total_pruned =   16413 | shape = torch.Size([32, 68, 3, 3])
1.1.7.3.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.4.weight       | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.1.7.4.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      20 /      36             ( 55.56%) | total_pruned =      16 | shape = torch.Size([36])
2.bias               | nonzeros =       0 /      36             (  0.00%) | total_pruned =      36 | shape = torch.Size([36])
3.1.weight           | nonzeros =    1398 /    5184             ( 26.97%) | total_pruned =    3786 | shape = torch.Size([16, 36, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      28 /      48             ( 58.33%) | total_pruned =      20 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 235278, pruned : 1216205, total: 1451483, Compression rate :       6.17x  ( 83.79% pruned)
PSNR of output image is:  15.910526130904847
Experiment done
