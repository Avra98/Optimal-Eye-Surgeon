(3, 512, 512)
Starting vanilla DIP on 0 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '19.68185010969681'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/0/skip/det/0.0/1e-09
epoch:  0 quantization_loss:  0.08335410803556442
p mean is: tensor(-3.6410e-06, device='cuda:1')
epoch:  1000 quantization_loss:  0.06497789174318314
p mean is: tensor(0.0004, device='cuda:1')
epoch:  2000 quantization_loss:  0.06507870554924011
p mean is: tensor(0.0003, device='cuda:1')
epoch:  3000 quantization_loss:  0.06416047364473343
p mean is: tensor(0.0003, device='cuda:1')
epoch:  4000 quantization_loss:  0.06368464976549149
p mean is: tensor(0.0005, device='cuda:1')
epoch:  5000 quantization_loss:  0.0632634237408638
p mean is: tensor(0.0004, device='cuda:1')
epoch:  6000 quantization_loss:  0.06484570354223251
p mean is: tensor(0.0003, device='cuda:1')
epoch:  7000 quantization_loss:  0.06232425943017006
p mean is: tensor(0.0001, device='cuda:1')
epoch:  8000 quantization_loss:  0.06193218007683754
p mean is: tensor(-0.0008, device='cuda:1')
epoch:  9000 quantization_loss:  0.061034537851810455
p mean is: tensor(-0.0017, device='cuda:1')
epoch:  10000 quantization_loss:  0.05953720957040787
p mean is: tensor(-0.0024, device='cuda:1')
epoch:  11000 quantization_loss:  0.05828232318162918
p mean is: tensor(-0.0028, device='cuda:1')
epoch:  12000 quantization_loss:  0.0518537200987339
p mean is: tensor(-0.0037, device='cuda:1')
epoch:  13000 quantization_loss:  0.047150809317827225
p mean is: tensor(-0.0049, device='cuda:1')
epoch:  14000 quantization_loss:  0.04080130159854889
p mean is: tensor(-0.0058, device='cuda:1')
epoch:  15000 quantization_loss:  0.03393395245075226
p mean is: tensor(-0.0065, device='cuda:1')
epoch:  16000 quantization_loss:  0.03249889612197876
p mean is: tensor(-0.0069, device='cuda:1')
epoch:  17000 quantization_loss:  0.031166069209575653
p mean is: tensor(-0.0071, device='cuda:1')
epoch:  18000 quantization_loss:  0.030088357627391815
p mean is: tensor(-0.0069, device='cuda:1')
epoch:  19000 quantization_loss:  0.027725378051400185
p mean is: tensor(-0.0065, device='cuda:1')
epoch:  20000 quantization_loss:  0.02733718790113926
p mean is: tensor(-0.0059, device='cuda:1')
epoch:  21000 quantization_loss:  0.026857977733016014
p mean is: tensor(-0.0050, device='cuda:1')
epoch:  22000 quantization_loss:  0.026080690324306488
p mean is: tensor(-0.0042, device='cuda:1')
epoch:  23000 quantization_loss:  0.02592375874519348
p mean is: tensor(-0.0032, device='cuda:1')
epoch:  24000 quantization_loss:  0.02500900626182556
p mean is: tensor(-0.0022, device='cuda:1')
epoch:  25000 quantization_loss:  0.02416379377245903
p mean is: tensor(-0.0012, device='cuda:1')
epoch:  26000 quantization_loss:  0.024100372567772865
p mean is: tensor(0.0002, device='cuda:1')
epoch:  27000 quantization_loss:  0.024011436849832535
p mean is: tensor(0.0016, device='cuda:1')
epoch:  28000 quantization_loss:  0.023852597922086716
p mean is: tensor(0.0029, device='cuda:1')
epoch:  29000 quantization_loss:  0.02370193786919117
p mean is: tensor(0.0040, device='cuda:1')
epoch:  30000 quantization_loss:  0.023662563413381577
p mean is: tensor(0.0054, device='cuda:1')
epoch:  31000 quantization_loss:  0.023742932826280594
p mean is: tensor(0.0068, device='cuda:1')
epoch:  32000 quantization_loss:  0.023440532386302948
p mean is: tensor(0.0081, device='cuda:1')
epoch:  33000 quantization_loss:  0.023386197164654732
p mean is: tensor(0.0094, device='cuda:1')
epoch:  34000 quantization_loss:  0.02386583760380745
p mean is: tensor(0.0105, device='cuda:1')
epoch:  35000 quantization_loss:  0.023243004456162453
p mean is: tensor(0.0117, device='cuda:1')
epoch:  36000 quantization_loss:  0.023185012862086296
p mean is: tensor(0.0128, device='cuda:1')
epoch:  37000 quantization_loss:  0.023171691223978996
p mean is: tensor(0.0136, device='cuda:1')
epoch:  38000 quantization_loss:  0.023062655702233315
p mean is: tensor(0.0144, device='cuda:1')
epoch:  39000 quantization_loss:  0.02301475778222084
p mean is: tensor(0.0151, device='cuda:1')
epoch:  40000 quantization_loss:  0.022997617721557617
p mean is: tensor(0.0156, device='cuda:1')
epoch:  41000 quantization_loss:  0.022959815338253975
p mean is: tensor(0.0162, device='cuda:1')
epoch:  42000 quantization_loss:  0.02281920425593853
p mean is: tensor(0.0166, device='cuda:1')
epoch:  43000 quantization_loss:  0.022695301100611687
p mean is: tensor(0.0170, device='cuda:1')
epoch:  44000 quantization_loss:  0.02238302119076252
p mean is: tensor(0.0173, device='cuda:1')
epoch:  45000 quantization_loss:  0.022313864901661873
p mean is: tensor(0.0175, device='cuda:1')
epoch:  46000 quantization_loss:  0.022299300879240036
p mean is: tensor(0.0177, device='cuda:1')
epoch:  47000 quantization_loss:  0.0222630612552166
p mean is: tensor(0.0178, device='cuda:1')
epoch:  48000 quantization_loss:  0.02219255082309246
p mean is: tensor(0.0181, device='cuda:1')
epoch:  49000 quantization_loss:  0.02217761054635048
p mean is: tensor(0.0183, device='cuda:1')
epoch:  50000 quantization_loss:  0.022141356021165848
p mean is: tensor(0.0186, device='cuda:1')
epoch:  51000 quantization_loss:  0.022125137969851494
p mean is: tensor(0.0187, device='cuda:1')
epoch:  52000 quantization_loss:  0.022108590230345726
p mean is: tensor(0.0189, device='cuda:1')
epoch:  53000 quantization_loss:  0.022080468013882637
p mean is: tensor(0.0190, device='cuda:1')
epoch:  54000 quantization_loss:  0.022067198529839516
p mean is: tensor(0.0190, device='cuda:1')
epoch:  55000 quantization_loss:  0.022067271173000336
p mean is: tensor(0.0191, device='cuda:1')
epoch:  56000 quantization_loss:  0.022043278440833092
p mean is: tensor(0.0191, device='cuda:1')
epoch:  57000 quantization_loss:  0.022033073008060455
p mean is: tensor(0.0191, device='cuda:1')
epoch:  58000 quantization_loss:  0.023206287994980812
p mean is: tensor(0.0190, device='cuda:1')
epoch:  59000 quantization_loss:  0.0220071729272604
p mean is: tensor(0.0190, device='cuda:1')
epoch:  60000 quantization_loss:  0.02199457958340645
p mean is: tensor(0.0191, device='cuda:1')
epoch:  61000 quantization_loss:  0.02199089713394642
p mean is: tensor(0.0192, device='cuda:1')
epoch:  62000 quantization_loss:  0.021973788738250732
p mean is: tensor(0.0192, device='cuda:1')
epoch:  63000 quantization_loss:  0.021978190168738365
p mean is: tensor(0.0193, device='cuda:1')
epoch:  64000 quantization_loss:  0.02196461148560047
p mean is: tensor(0.0193, device='cuda:1')
epoch:  65000 quantization_loss:  0.021951165050268173
p mean is: tensor(0.0194, device='cuda:1')
epoch:  66000 quantization_loss:  0.02195132151246071
p mean is: tensor(0.0194, device='cuda:1')
epoch:  67000 quantization_loss:  0.021940745413303375
p mean is: tensor(0.0195, device='cuda:1')
epoch:  68000 quantization_loss:  0.021939467638731003
p mean is: tensor(0.0195, device='cuda:1')
epoch:  69000 quantization_loss:  0.02193458564579487
p mean is: tensor(0.0195, device='cuda:1')
epoch:  70000 quantization_loss:  0.021923895925283432
p mean is: tensor(0.0194, device='cuda:1')
epoch:  71000 quantization_loss:  0.0219368077814579
p mean is: tensor(0.0193, device='cuda:1')
epoch:  72000 quantization_loss:  0.0219122301787138
p mean is: tensor(0.0193, device='cuda:1')
epoch:  73000 quantization_loss:  0.02189847081899643
p mean is: tensor(0.0193, device='cuda:1')
epoch:  74000 quantization_loss:  0.02189420349895954
p mean is: tensor(0.0193, device='cuda:1')
epoch:  75000 quantization_loss:  0.021887723356485367
p mean is: tensor(0.0193, device='cuda:1')
epoch:  76000 quantization_loss:  0.02189384400844574
p mean is: tensor(0.0192, device='cuda:1')
epoch:  77000 quantization_loss:  0.0218820720911026
p mean is: tensor(0.0192, device='cuda:1')
epoch:  78000 quantization_loss:  0.021887904033064842
p mean is: tensor(0.0192, device='cuda:1')
epoch:  79000 quantization_loss:  0.021876826882362366
p mean is: tensor(0.0192, device='cuda:1')
here
1.0.1.1.weight       | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =    2283 /    4608             ( 49.54%) | total_pruned =    2325 | shape = torch.Size([16, 32, 3, 3])
1.1.1.1.bias         | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.1.2.weight         | nonzeros =      11 /      16             ( 68.75%) | total_pruned =       5 | shape = torch.Size([16])
1.1.2.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.4.1.weight       | nonzeros =    1104 /    2304             ( 47.92%) | total_pruned =    1200 | shape = torch.Size([16, 16, 3, 3])
1.1.4.1.bias         | nonzeros =       5 /      16             ( 31.25%) | total_pruned =      11 | shape = torch.Size([16])
1.1.5.weight         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.5.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.7.1.0.1.1.weight | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([4, 16, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =    2336 /    4608             ( 50.69%) | total_pruned =    2272 | shape = torch.Size([32, 16, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =       8 /      32             ( 25.00%) | total_pruned =      24 | shape = torch.Size([32])
1.1.7.1.1.2.weight   | nonzeros =      21 /      32             ( 65.62%) | total_pruned =      11 | shape = torch.Size([32])
1.1.7.1.1.2.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.4.1.weight | nonzeros =    4423 /    9216             ( 47.99%) | total_pruned =    4793 | shape = torch.Size([32, 32, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =       9 /      32             ( 28.12%) | total_pruned =      23 | shape = torch.Size([32])
1.1.7.1.1.5.weight   | nonzeros =      26 /      32             ( 81.25%) | total_pruned =       6 | shape = torch.Size([32])
1.1.7.1.1.5.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([4, 32, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    9148 /   18432             ( 49.63%) | total_pruned =    9284 | shape = torch.Size([64, 32, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   18403 /   36864             ( 49.92%) | total_pruned =   18461 | shape = torch.Size([64, 64, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     101 /     256             ( 39.45%) | total_pruned =     155 | shape = torch.Size([4, 64, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   36726 /   73728             ( 49.81%) | total_pruned =   37002 | shape = torch.Size([128, 64, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   73581 /  147456             ( 49.90%) | total_pruned =   73875 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     231 /     512             ( 45.12%) | total_pruned =     281 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   73682 /  147456             ( 49.97%) | total_pruned =   73774 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   72601 /  147456             ( 49.24%) | total_pruned =   74855 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     231 /     512             ( 45.12%) | total_pruned =     281 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   71783 /  147456             ( 48.68%) | total_pruned =   75673 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   69760 /  147456             ( 47.31%) | total_pruned =   77696 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      84 /     132             ( 63.64%) | total_pruned =      48 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   70149 /  152064             ( 46.13%) | total_pruned =   81915 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =     101 /     132             ( 76.52%) | total_pruned =      31 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   68129 /  152064             ( 44.80%) | total_pruned =   83935 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      70 /     132             ( 53.03%) | total_pruned =      62 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   59783 /  152064             ( 39.31%) | total_pruned =   92281 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =      27 /     128             ( 21.09%) | total_pruned =     101 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      70 /     132             ( 53.03%) | total_pruned =      62 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =   27694 /   76032             ( 36.42%) | total_pruned =   48338 | shape = torch.Size([64, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
1.1.7.1.1.7.4.weight | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.2.weight       | nonzeros =      26 /      68             ( 38.24%) | total_pruned =      42 | shape = torch.Size([68])
1.1.7.2.bias         | nonzeros =       0 /      68             (  0.00%) | total_pruned =      68 | shape = torch.Size([68])
1.1.7.3.1.weight     | nonzeros =    7239 /   19584             ( 36.96%) | total_pruned =   12345 | shape = torch.Size([32, 68, 3, 3])
1.1.7.3.1.bias       | nonzeros =       4 /      32             ( 12.50%) | total_pruned =      28 | shape = torch.Size([32])
1.1.7.4.weight       | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.1.7.4.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      20 /      36             ( 55.56%) | total_pruned =      16 | shape = torch.Size([36])
2.bias               | nonzeros =       0 /      36             (  0.00%) | total_pruned =      36 | shape = torch.Size([36])
3.1.weight           | nonzeros =    2327 /    5184             ( 44.89%) | total_pruned =    2857 | shape = torch.Size([16, 36, 3, 3])
3.1.bias             | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      34 /      48             ( 70.83%) | total_pruned =      14 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 673438, pruned : 778045, total: 1451483, Compression rate :       2.16x  ( 53.60% pruned)
PSNR of output image is:  17.924248784788123
Experiment done
