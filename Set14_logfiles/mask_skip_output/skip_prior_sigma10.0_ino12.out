(3, 256, 256)
Starting vanilla DIP on 12 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.8576486436545'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/12/skip/det/10.0/1e-09
epoch:  0 quantization_loss:  0.12717531621456146
p mean is: tensor(0.0014, device='cuda:2')
epoch:  1000 quantization_loss:  0.10119831562042236
p mean is: tensor(0.0371, device='cuda:2')
epoch:  2000 quantization_loss:  0.09958405047655106
p mean is: tensor(0.0557, device='cuda:2')
epoch:  3000 quantization_loss:  0.09521082788705826
p mean is: tensor(0.0737, device='cuda:2')
epoch:  4000 quantization_loss:  0.09628267586231232
p mean is: tensor(0.0907, device='cuda:2')
epoch:  5000 quantization_loss:  0.09704439342021942
p mean is: tensor(0.1075, device='cuda:2')
epoch:  6000 quantization_loss:  0.0924452617764473
p mean is: tensor(0.1242, device='cuda:2')
epoch:  7000 quantization_loss:  0.09416022896766663
p mean is: tensor(0.1407, device='cuda:2')
epoch:  8000 quantization_loss:  0.09675998240709305
p mean is: tensor(0.1572, device='cuda:2')
epoch:  9000 quantization_loss:  0.09536804258823395
p mean is: tensor(0.1735, device='cuda:2')
epoch:  10000 quantization_loss:  0.09564840793609619
p mean is: tensor(0.1900, device='cuda:2')
epoch:  11000 quantization_loss:  0.09635039418935776
p mean is: tensor(0.2067, device='cuda:2')
epoch:  12000 quantization_loss:  0.08685507625341415
p mean is: tensor(0.2236, device='cuda:2')
epoch:  13000 quantization_loss:  0.07226613909006119
p mean is: tensor(0.2423, device='cuda:2')
epoch:  14000 quantization_loss:  0.07140132039785385
p mean is: tensor(0.2685, device='cuda:2')
epoch:  15000 quantization_loss:  0.06598538160324097
p mean is: tensor(0.3056, device='cuda:2')
epoch:  16000 quantization_loss:  0.0650460347533226
p mean is: tensor(0.3576, device='cuda:2')
epoch:  17000 quantization_loss:  0.06344931572675705
p mean is: tensor(0.4283, device='cuda:2')
epoch:  18000 quantization_loss:  0.06322507560253143
p mean is: tensor(0.5235, device='cuda:2')
epoch:  19000 quantization_loss:  0.062018148601055145
p mean is: tensor(0.6476, device='cuda:2')
epoch:  20000 quantization_loss:  0.06127985194325447
p mean is: tensor(0.8032, device='cuda:2')
epoch:  21000 quantization_loss:  0.06059551611542702
p mean is: tensor(0.9938, device='cuda:2')
epoch:  22000 quantization_loss:  0.05945994704961777
p mean is: tensor(1.2189, device='cuda:2')
epoch:  23000 quantization_loss:  0.05789222568273544
p mean is: tensor(1.4703, device='cuda:2')
epoch:  24000 quantization_loss:  0.057162053883075714
p mean is: tensor(1.7360, device='cuda:2')
epoch:  25000 quantization_loss:  0.055599845945835114
p mean is: tensor(2.0069, device='cuda:2')
epoch:  26000 quantization_loss:  0.05480869114398956
p mean is: tensor(2.2707, device='cuda:2')
epoch:  27000 quantization_loss:  0.05439896881580353
p mean is: tensor(2.5156, device='cuda:2')
epoch:  28000 quantization_loss:  0.0543767511844635
p mean is: tensor(2.7371, device='cuda:2')
epoch:  29000 quantization_loss:  0.05392066389322281
p mean is: tensor(2.9348, device='cuda:2')
epoch:  30000 quantization_loss:  0.05374092236161232
p mean is: tensor(3.1107, device='cuda:2')
epoch:  31000 quantization_loss:  0.05362597480416298
p mean is: tensor(3.2673, device='cuda:2')
epoch:  32000 quantization_loss:  0.05359579622745514
p mean is: tensor(3.4073, device='cuda:2')
epoch:  33000 quantization_loss:  0.053390294313430786
p mean is: tensor(3.5333, device='cuda:2')
epoch:  34000 quantization_loss:  0.05335243046283722
p mean is: tensor(3.6471, device='cuda:2')
epoch:  35000 quantization_loss:  0.05330067500472069
p mean is: tensor(3.7507, device='cuda:2')
epoch:  36000 quantization_loss:  0.05326564237475395
p mean is: tensor(3.8455, device='cuda:2')
epoch:  37000 quantization_loss:  0.0531977117061615
p mean is: tensor(3.9326, device='cuda:2')
epoch:  38000 quantization_loss:  0.053149040788412094
p mean is: tensor(4.0132, device='cuda:2')
epoch:  39000 quantization_loss:  0.0531553216278553
p mean is: tensor(4.0880, device='cuda:2')
epoch:  40000 quantization_loss:  0.053100284188985825
p mean is: tensor(4.1577, device='cuda:2')
epoch:  41000 quantization_loss:  0.05304896458983421
p mean is: tensor(4.2231, device='cuda:2')
epoch:  42000 quantization_loss:  0.053030576556921005
p mean is: tensor(4.2845, device='cuda:2')
epoch:  43000 quantization_loss:  0.05301164463162422
p mean is: tensor(4.3424, device='cuda:2')
epoch:  44000 quantization_loss:  0.05297981947660446
p mean is: tensor(4.3971, device='cuda:2')
epoch:  45000 quantization_loss:  0.052974406629800797
p mean is: tensor(4.4490, device='cuda:2')
epoch:  46000 quantization_loss:  0.05295225977897644
p mean is: tensor(4.4984, device='cuda:2')
epoch:  47000 quantization_loss:  0.05294616147875786
p mean is: tensor(4.5455, device='cuda:2')
epoch:  48000 quantization_loss:  0.05294293910264969
p mean is: tensor(4.5904, device='cuda:2')
epoch:  49000 quantization_loss:  0.05290966480970383
p mean is: tensor(4.6335, device='cuda:2')
epoch:  50000 quantization_loss:  0.05289474502205849
p mean is: tensor(4.6747, device='cuda:2')
epoch:  51000 quantization_loss:  0.05288654565811157
p mean is: tensor(4.7143, device='cuda:2')
epoch:  52000 quantization_loss:  0.05288213491439819
p mean is: tensor(4.7523, device='cuda:2')
epoch:  53000 quantization_loss:  0.05286619812250137
p mean is: tensor(4.7889, device='cuda:2')
epoch:  54000 quantization_loss:  0.05285581201314926
p mean is: tensor(4.8241, device='cuda:2')
epoch:  55000 quantization_loss:  0.05284961313009262
p mean is: tensor(4.8580, device='cuda:2')
epoch:  56000 quantization_loss:  0.05283857136964798
p mean is: tensor(4.8908, device='cuda:2')
epoch:  57000 quantization_loss:  0.05282697081565857
p mean is: tensor(4.9226, device='cuda:2')
epoch:  58000 quantization_loss:  0.05282548815011978
p mean is: tensor(4.9534, device='cuda:2')
epoch:  59000 quantization_loss:  0.05281149223446846
p mean is: tensor(4.9832, device='cuda:2')
epoch:  60000 quantization_loss:  0.05280262604355812
p mean is: tensor(5.0122, device='cuda:2')
epoch:  61000 quantization_loss:  0.052798930555582047
p mean is: tensor(5.0402, device='cuda:2')
epoch:  62000 quantization_loss:  0.052799124270677567
p mean is: tensor(5.0674, device='cuda:2')
epoch:  63000 quantization_loss:  0.05279121175408363
p mean is: tensor(5.0939, device='cuda:2')
epoch:  64000 quantization_loss:  0.05279713496565819
p mean is: tensor(5.1196, device='cuda:2')
epoch:  65000 quantization_loss:  0.05278190225362778
p mean is: tensor(5.1447, device='cuda:2')
epoch:  66000 quantization_loss:  0.05278278887271881
p mean is: tensor(5.1692, device='cuda:2')
epoch:  67000 quantization_loss:  0.05277320742607117
p mean is: tensor(5.1929, device='cuda:2')
epoch:  68000 quantization_loss:  0.05276820436120033
p mean is: tensor(5.2160, device='cuda:2')
epoch:  69000 quantization_loss:  0.05279171094298363
p mean is: tensor(5.2386, device='cuda:2')
epoch:  70000 quantization_loss:  0.05276228487491608
p mean is: tensor(5.2607, device='cuda:2')
epoch:  71000 quantization_loss:  0.05301705002784729
p mean is: tensor(5.2822, device='cuda:2')
epoch:  72000 quantization_loss:  0.05275186523795128
p mean is: tensor(5.3033, device='cuda:2')
epoch:  73000 quantization_loss:  0.052752211689949036
p mean is: tensor(5.3239, device='cuda:2')
epoch:  74000 quantization_loss:  0.052749037742614746
p mean is: tensor(5.3440, device='cuda:2')
epoch:  75000 quantization_loss:  0.052747175097465515
p mean is: tensor(5.3637, device='cuda:2')
epoch:  76000 quantization_loss:  0.05274331197142601
p mean is: tensor(5.3830, device='cuda:2')
epoch:  77000 quantization_loss:  0.05274336040019989
p mean is: tensor(5.4019, device='cuda:2')
epoch:  78000 quantization_loss:  0.05274178460240364
p mean is: tensor(5.4204, device='cuda:2')
epoch:  79000 quantization_loss:  0.05273709446191788
p mean is: tensor(5.4385, device='cuda:2')
here
1.0.1.1.weight       | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =    4218 /    4608             ( 91.54%) | total_pruned =     390 | shape = torch.Size([16, 32, 3, 3])
1.1.1.1.bias         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.2.weight         | nonzeros =      11 /      16             ( 68.75%) | total_pruned =       5 | shape = torch.Size([16])
1.1.2.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.4.1.weight       | nonzeros =    2219 /    2304             ( 96.31%) | total_pruned =      85 | shape = torch.Size([16, 16, 3, 3])
1.1.4.1.bias         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.5.weight         | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.1.5.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.7.1.0.1.1.weight | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 16, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =    4522 /    4608             ( 98.13%) | total_pruned =      86 | shape = torch.Size([32, 16, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.1.1.2.weight   | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.1.7.1.1.2.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.4.1.weight | nonzeros =    9100 /    9216             ( 98.74%) | total_pruned =     116 | shape = torch.Size([32, 32, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.1.1.5.weight   | nonzeros =      26 /      32             ( 81.25%) | total_pruned =       6 | shape = torch.Size([32])
1.1.7.1.1.5.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 32, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   18305 /   18432             ( 99.31%) | total_pruned =     127 | shape = torch.Size([64, 32, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   36664 /   36864             ( 99.46%) | total_pruned =     200 | shape = torch.Size([64, 64, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     244 /     256             ( 95.31%) | total_pruned =      12 | shape = torch.Size([4, 64, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   73617 /   73728             ( 99.85%) | total_pruned =     111 | shape = torch.Size([128, 64, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  147394 /  147456             ( 99.96%) | total_pruned =      62 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     491 /     512             ( 95.90%) | total_pruned =      21 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =  147377 /  147456             ( 99.95%) | total_pruned =      79 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  147253 /  147456             ( 99.86%) | total_pruned =     203 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     495 /     512             ( 96.68%) | total_pruned =      17 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =  147059 /  147456             ( 99.73%) | total_pruned =     397 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  146089 /  147456             ( 99.07%) | total_pruned =    1367 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      79 /     132             ( 59.85%) | total_pruned =      53 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  148046 /  152064             ( 97.36%) | total_pruned =    4018 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     114 /     128             ( 89.06%) | total_pruned =      14 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      80 /     132             ( 60.61%) | total_pruned =      52 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  146956 /  152064             ( 96.64%) | total_pruned =    5108 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      70 /     132             ( 53.03%) | total_pruned =      62 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  147098 /  152064             ( 96.73%) | total_pruned =    4966 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      70 /     132             ( 53.03%) | total_pruned =      62 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =   72245 /   76032             ( 95.02%) | total_pruned =    3787 | shape = torch.Size([64, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.4.weight | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.2.weight       | nonzeros =      38 /      68             ( 55.88%) | total_pruned =      30 | shape = torch.Size([68])
1.1.7.2.bias         | nonzeros =       0 /      68             (  0.00%) | total_pruned =      68 | shape = torch.Size([68])
1.1.7.3.1.weight     | nonzeros =   17988 /   19584             ( 91.85%) | total_pruned =    1596 | shape = torch.Size([32, 68, 3, 3])
1.1.7.3.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.4.weight       | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
1.1.7.4.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      14 /      36             ( 38.89%) | total_pruned =      22 | shape = torch.Size([36])
2.bias               | nonzeros =       0 /      36             (  0.00%) | total_pruned =      36 | shape = torch.Size([36])
3.1.weight           | nonzeros =    4420 /    5184             ( 85.26%) | total_pruned =     764 | shape = torch.Size([16, 36, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      14 /      16             ( 87.50%) | total_pruned =       2 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      32 /      48             ( 66.67%) | total_pruned =      16 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 1425069, pruned : 26414, total: 1451483, Compression rate :       1.02x  (  1.82% pruned)
PSNR of output image is:  13.02425541234523
Experiment done
