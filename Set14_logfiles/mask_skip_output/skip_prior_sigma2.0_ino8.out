(3, 512, 512)
Starting vanilla DIP on 8 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '21.64907508078401'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/8/skip/det/2.0/1e-09
epoch:  0 quantization_loss:  0.1551087498664856
p mean is: tensor(0.0003, device='cuda:2')
epoch:  1000 quantization_loss:  0.12841451168060303
p mean is: tensor(0.0107, device='cuda:2')
epoch:  2000 quantization_loss:  0.12590545415878296
p mean is: tensor(0.0172, device='cuda:2')
epoch:  3000 quantization_loss:  0.12553541362285614
p mean is: tensor(0.0238, device='cuda:2')
epoch:  4000 quantization_loss:  0.12732550501823425
p mean is: tensor(0.0297, device='cuda:2')
epoch:  5000 quantization_loss:  0.1251450777053833
p mean is: tensor(0.0355, device='cuda:2')
epoch:  6000 quantization_loss:  0.12530195713043213
p mean is: tensor(0.0410, device='cuda:2')
epoch:  7000 quantization_loss:  0.12400204688310623
p mean is: tensor(0.0461, device='cuda:2')
epoch:  8000 quantization_loss:  0.11735744774341583
p mean is: tensor(0.0514, device='cuda:2')
epoch:  9000 quantization_loss:  0.10142125189304352
p mean is: tensor(0.0566, device='cuda:2')
epoch:  10000 quantization_loss:  0.09048368781805038
p mean is: tensor(0.0632, device='cuda:2')
epoch:  11000 quantization_loss:  0.08798421919345856
p mean is: tensor(0.0725, device='cuda:2')
epoch:  12000 quantization_loss:  0.08292165398597717
p mean is: tensor(0.0852, device='cuda:2')
epoch:  13000 quantization_loss:  0.08050613850355148
p mean is: tensor(0.1016, device='cuda:2')
epoch:  14000 quantization_loss:  0.07796522974967957
p mean is: tensor(0.1230, device='cuda:2')
epoch:  15000 quantization_loss:  0.07661838084459305
p mean is: tensor(0.1510, device='cuda:2')
epoch:  16000 quantization_loss:  0.0754317119717598
p mean is: tensor(0.1872, device='cuda:2')
epoch:  17000 quantization_loss:  0.07400388270616531
p mean is: tensor(0.2322, device='cuda:2')
epoch:  18000 quantization_loss:  0.07286788523197174
p mean is: tensor(0.2874, device='cuda:2')
epoch:  19000 quantization_loss:  0.07243546098470688
p mean is: tensor(0.3533, device='cuda:2')
epoch:  20000 quantization_loss:  0.0716109350323677
p mean is: tensor(0.4289, device='cuda:2')
epoch:  21000 quantization_loss:  0.07121903449296951
p mean is: tensor(0.5119, device='cuda:2')
epoch:  22000 quantization_loss:  0.06790206581354141
p mean is: tensor(0.5976, device='cuda:2')
epoch:  23000 quantization_loss:  0.06738407164812088
p mean is: tensor(0.6830, device='cuda:2')
epoch:  24000 quantization_loss:  0.06690983474254608
p mean is: tensor(0.7666, device='cuda:2')
epoch:  25000 quantization_loss:  0.06644885987043381
p mean is: tensor(0.8470, device='cuda:2')
epoch:  26000 quantization_loss:  0.06634832173585892
p mean is: tensor(0.9237, device='cuda:2')
epoch:  27000 quantization_loss:  0.06612841784954071
p mean is: tensor(0.9955, device='cuda:2')
epoch:  28000 quantization_loss:  0.06590503454208374
p mean is: tensor(1.0625, device='cuda:2')
epoch:  29000 quantization_loss:  0.0655638575553894
p mean is: tensor(1.1240, device='cuda:2')
epoch:  30000 quantization_loss:  0.06541423499584198
p mean is: tensor(1.1806, device='cuda:2')
epoch:  31000 quantization_loss:  0.06536106020212173
p mean is: tensor(1.2324, device='cuda:2')
epoch:  32000 quantization_loss:  0.06546474993228912
p mean is: tensor(1.2796, device='cuda:2')
epoch:  33000 quantization_loss:  0.0636211708188057
p mean is: tensor(1.3226, device='cuda:2')
epoch:  34000 quantization_loss:  0.06302831321954727
p mean is: tensor(1.3613, device='cuda:2')
epoch:  35000 quantization_loss:  0.06285379081964493
p mean is: tensor(1.3964, device='cuda:2')
epoch:  36000 quantization_loss:  0.06257310509681702
p mean is: tensor(1.4287, device='cuda:2')
epoch:  37000 quantization_loss:  0.06250196695327759
p mean is: tensor(1.4585, device='cuda:2')
epoch:  38000 quantization_loss:  0.06247818097472191
p mean is: tensor(1.4859, device='cuda:2')
epoch:  39000 quantization_loss:  0.06234204024076462
p mean is: tensor(1.5111, device='cuda:2')
epoch:  40000 quantization_loss:  0.062257878482341766
p mean is: tensor(1.5345, device='cuda:2')
epoch:  41000 quantization_loss:  0.062176983803510666
p mean is: tensor(1.5560, device='cuda:2')
epoch:  42000 quantization_loss:  0.06204698979854584
p mean is: tensor(1.5761, device='cuda:2')
epoch:  43000 quantization_loss:  0.062010910362005234
p mean is: tensor(1.5948, device='cuda:2')
epoch:  44000 quantization_loss:  0.061942510306835175
p mean is: tensor(1.6123, device='cuda:2')
epoch:  45000 quantization_loss:  0.06025121361017227
p mean is: tensor(1.6281, device='cuda:2')
epoch:  46000 quantization_loss:  0.05993112921714783
p mean is: tensor(1.6427, device='cuda:2')
epoch:  47000 quantization_loss:  0.05980539321899414
p mean is: tensor(1.6564, device='cuda:2')
epoch:  48000 quantization_loss:  0.059706564992666245
p mean is: tensor(1.6697, device='cuda:2')
epoch:  49000 quantization_loss:  0.05965360626578331
p mean is: tensor(1.6821, device='cuda:2')
epoch:  50000 quantization_loss:  0.059650927782058716
p mean is: tensor(1.6939, device='cuda:2')
epoch:  51000 quantization_loss:  0.059538811445236206
p mean is: tensor(1.7051, device='cuda:2')
epoch:  52000 quantization_loss:  0.05948910862207413
p mean is: tensor(1.7156, device='cuda:2')
epoch:  53000 quantization_loss:  0.05948198214173317
p mean is: tensor(1.7258, device='cuda:2')
epoch:  54000 quantization_loss:  0.059446461498737335
p mean is: tensor(1.7356, device='cuda:2')
epoch:  55000 quantization_loss:  0.05942597612738609
p mean is: tensor(1.7448, device='cuda:2')
epoch:  56000 quantization_loss:  0.05937300622463226
p mean is: tensor(1.7536, device='cuda:2')
epoch:  57000 quantization_loss:  0.05936192721128464
p mean is: tensor(1.7620, device='cuda:2')
epoch:  58000 quantization_loss:  0.05933760479092598
p mean is: tensor(1.7702, device='cuda:2')
epoch:  59000 quantization_loss:  0.059330470860004425
p mean is: tensor(1.7782, device='cuda:2')
epoch:  60000 quantization_loss:  0.05930488929152489
p mean is: tensor(1.7857, device='cuda:2')
epoch:  61000 quantization_loss:  0.05928981676697731
p mean is: tensor(1.7930, device='cuda:2')
epoch:  62000 quantization_loss:  0.059395309537649155
p mean is: tensor(1.8000, device='cuda:2')
epoch:  63000 quantization_loss:  0.05926524102687836
p mean is: tensor(1.8067, device='cuda:2')
epoch:  64000 quantization_loss:  0.05925702303647995
p mean is: tensor(1.8132, device='cuda:2')
epoch:  65000 quantization_loss:  0.0592484287917614
p mean is: tensor(1.8196, device='cuda:2')
epoch:  66000 quantization_loss:  0.05923830717802048
p mean is: tensor(1.8258, device='cuda:2')
epoch:  67000 quantization_loss:  0.059224843978881836
p mean is: tensor(1.8318, device='cuda:2')
epoch:  68000 quantization_loss:  0.05922040715813637
p mean is: tensor(1.8377, device='cuda:2')
epoch:  69000 quantization_loss:  0.05920843034982681
p mean is: tensor(1.8434, device='cuda:2')
epoch:  70000 quantization_loss:  0.05920253321528435
p mean is: tensor(1.8488, device='cuda:2')
epoch:  71000 quantization_loss:  0.059195417910814285
p mean is: tensor(1.8541, device='cuda:2')
epoch:  72000 quantization_loss:  0.059193383902311325
p mean is: tensor(1.8592, device='cuda:2')
epoch:  73000 quantization_loss:  0.05918563902378082
p mean is: tensor(1.8642, device='cuda:2')
epoch:  74000 quantization_loss:  0.05917326733469963
p mean is: tensor(1.8690, device='cuda:2')
epoch:  75000 quantization_loss:  0.059220440685749054
p mean is: tensor(1.8738, device='cuda:2')
epoch:  76000 quantization_loss:  0.059167247265577316
p mean is: tensor(1.8784, device='cuda:2')
epoch:  77000 quantization_loss:  0.05915955454111099
p mean is: tensor(1.8830, device='cuda:2')
epoch:  78000 quantization_loss:  0.059162989258766174
p mean is: tensor(1.8874, device='cuda:2')
epoch:  79000 quantization_loss:  0.05915115028619766
p mean is: tensor(1.8919, device='cuda:2')
here
1.0.1.1.weight       | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =    3355 /    4608             ( 72.81%) | total_pruned =    1253 | shape = torch.Size([16, 32, 3, 3])
1.1.1.1.bias         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.2.weight         | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.1.2.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.4.1.weight       | nonzeros =    1861 /    2304             ( 80.77%) | total_pruned =     443 | shape = torch.Size([16, 16, 3, 3])
1.1.4.1.bias         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.5.weight         | nonzeros =      13 /      16             ( 81.25%) | total_pruned =       3 | shape = torch.Size([16])
1.1.5.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.7.1.0.1.1.weight | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 16, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =    3680 /    4608             ( 79.86%) | total_pruned =     928 | shape = torch.Size([32, 16, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.1.1.2.weight   | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
1.1.7.1.1.2.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.4.1.weight | nonzeros =    7678 /    9216             ( 83.31%) | total_pruned =    1538 | shape = torch.Size([32, 32, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.1.1.5.weight   | nonzeros =      25 /      32             ( 78.12%) | total_pruned =       7 | shape = torch.Size([32])
1.1.7.1.1.5.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 32, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   15469 /   18432             ( 83.92%) | total_pruned =    2963 | shape = torch.Size([64, 32, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   32687 /   36864             ( 88.67%) | total_pruned =    4177 | shape = torch.Size([64, 64, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     234 /     256             ( 91.41%) | total_pruned =      22 | shape = torch.Size([4, 64, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   68865 /   73728             ( 93.40%) | total_pruned =    4863 | shape = torch.Size([128, 64, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  140358 /  147456             ( 95.19%) | total_pruned =    7098 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     360 /     512             ( 70.31%) | total_pruned =     152 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =  146202 /  147456             ( 99.15%) | total_pruned =    1254 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  144381 /  147456             ( 97.91%) | total_pruned =    3075 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     439 /     512             ( 85.74%) | total_pruned =      73 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =  141566 /  147456             ( 96.01%) | total_pruned =    5890 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  131459 /  147456             ( 89.15%) | total_pruned =   15997 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      81 /     132             ( 61.36%) | total_pruned =      51 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  126477 /  152064             ( 83.17%) | total_pruned =   25587 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      95 /     132             ( 71.97%) | total_pruned =      37 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  122805 /  152064             ( 80.76%) | total_pruned =   29259 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      82 /     132             ( 62.12%) | total_pruned =      50 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  128439 /  152064             ( 84.46%) | total_pruned =   23625 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      72 /     132             ( 54.55%) | total_pruned =      60 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =   65540 /   76032             ( 86.20%) | total_pruned =   10492 | shape = torch.Size([64, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.4.weight | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.2.weight       | nonzeros =      35 /      68             ( 51.47%) | total_pruned =      33 | shape = torch.Size([68])
1.1.7.2.bias         | nonzeros =       0 /      68             (  0.00%) | total_pruned =      68 | shape = torch.Size([68])
1.1.7.3.1.weight     | nonzeros =   16879 /   19584             ( 86.19%) | total_pruned =    2705 | shape = torch.Size([32, 68, 3, 3])
1.1.7.3.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.4.weight       | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
1.1.7.4.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      17 /      36             ( 47.22%) | total_pruned =      19 | shape = torch.Size([36])
2.bias               | nonzeros =       0 /      36             (  0.00%) | total_pruned =      36 | shape = torch.Size([36])
3.1.weight           | nonzeros =    3966 /    5184             ( 76.50%) | total_pruned =    1218 | shape = torch.Size([16, 36, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      15 /      16             ( 93.75%) | total_pruned =       1 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      34 /      48             ( 70.83%) | total_pruned =      14 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 1306054, pruned : 145429, total: 1451483, Compression rate :       1.11x  ( 10.02% pruned)
PSNR of output image is:  11.90160167940123
Experiment done
