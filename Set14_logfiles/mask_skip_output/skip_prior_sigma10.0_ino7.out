(3, 512, 512)
Starting vanilla DIP on 7 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.251189566656635'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/7/skip/det/10.0/1e-09
epoch:  0 quantization_loss:  0.07736960798501968
p mean is: tensor(0.0015, device='cuda:4')
epoch:  1000 quantization_loss:  0.07130372524261475
p mean is: tensor(0.0630, device='cuda:4')
epoch:  2000 quantization_loss:  0.07111841440200806
p mean is: tensor(0.1056, device='cuda:4')
epoch:  3000 quantization_loss:  0.06966610252857208
p mean is: tensor(0.1450, device='cuda:4')
epoch:  4000 quantization_loss:  0.0696665346622467
p mean is: tensor(0.1836, device='cuda:4')
epoch:  5000 quantization_loss:  0.06971731781959534
p mean is: tensor(0.2220, device='cuda:4')
epoch:  6000 quantization_loss:  0.06741856783628464
p mean is: tensor(0.2610, device='cuda:4')
epoch:  7000 quantization_loss:  0.06670214980840683
p mean is: tensor(0.3020, device='cuda:4')
epoch:  8000 quantization_loss:  0.06440303474664688
p mean is: tensor(0.3477, device='cuda:4')
epoch:  9000 quantization_loss:  0.0547327846288681
p mean is: tensor(0.4015, device='cuda:4')
epoch:  10000 quantization_loss:  0.04641158506274223
p mean is: tensor(0.4633, device='cuda:4')
epoch:  11000 quantization_loss:  0.042567215859889984
p mean is: tensor(0.5383, device='cuda:4')
epoch:  12000 quantization_loss:  0.03899524360895157
p mean is: tensor(0.6319, device='cuda:4')
epoch:  13000 quantization_loss:  0.037636898458004
p mean is: tensor(0.7488, device='cuda:4')
epoch:  14000 quantization_loss:  0.03407891467213631
p mean is: tensor(0.8902, device='cuda:4')
epoch:  15000 quantization_loss:  0.032685287296772
p mean is: tensor(1.0573, device='cuda:4')
epoch:  16000 quantization_loss:  0.03207128122448921
p mean is: tensor(1.2487, device='cuda:4')
epoch:  17000 quantization_loss:  0.03127329424023628
p mean is: tensor(1.4602, device='cuda:4')
epoch:  18000 quantization_loss:  0.030144456773996353
p mean is: tensor(1.6836, device='cuda:4')
epoch:  19000 quantization_loss:  0.02937229350209236
p mean is: tensor(1.9084, device='cuda:4')
epoch:  20000 quantization_loss:  0.02888854779303074
p mean is: tensor(2.1263, device='cuda:4')
epoch:  21000 quantization_loss:  0.02848123572766781
p mean is: tensor(2.3311, device='cuda:4')
epoch:  22000 quantization_loss:  0.027976233512163162
p mean is: tensor(2.5201, device='cuda:4')
epoch:  23000 quantization_loss:  0.02762955240905285
p mean is: tensor(2.6924, device='cuda:4')
epoch:  24000 quantization_loss:  0.027365203946828842
p mean is: tensor(2.8490, device='cuda:4')
epoch:  25000 quantization_loss:  0.026798320934176445
p mean is: tensor(2.9901, device='cuda:4')
epoch:  26000 quantization_loss:  0.026340395212173462
p mean is: tensor(3.1183, device='cuda:4')
epoch:  27000 quantization_loss:  0.026365797966718674
p mean is: tensor(3.2351, device='cuda:4')
epoch:  28000 quantization_loss:  0.026389101520180702
p mean is: tensor(3.3421, device='cuda:4')
epoch:  29000 quantization_loss:  0.025766393169760704
p mean is: tensor(3.4410, device='cuda:4')
epoch:  30000 quantization_loss:  0.025535324588418007
p mean is: tensor(3.5325, device='cuda:4')
epoch:  31000 quantization_loss:  0.025353465229272842
p mean is: tensor(3.6173, device='cuda:4')
epoch:  32000 quantization_loss:  0.02522912435233593
p mean is: tensor(3.6965, device='cuda:4')
epoch:  33000 quantization_loss:  0.025096306577324867
p mean is: tensor(3.7709, device='cuda:4')
epoch:  34000 quantization_loss:  0.024971231818199158
p mean is: tensor(3.8409, device='cuda:4')
epoch:  35000 quantization_loss:  0.02485022507607937
p mean is: tensor(3.9071, device='cuda:4')
epoch:  36000 quantization_loss:  0.02480083890259266
p mean is: tensor(3.9698, device='cuda:4')
epoch:  37000 quantization_loss:  0.024693040177226067
p mean is: tensor(4.0293, device='cuda:4')
epoch:  38000 quantization_loss:  0.024636007845401764
p mean is: tensor(4.0859, device='cuda:4')
epoch:  39000 quantization_loss:  0.02458123303949833
p mean is: tensor(4.1402, device='cuda:4')
epoch:  40000 quantization_loss:  0.024513233453035355
p mean is: tensor(4.1921, device='cuda:4')
epoch:  41000 quantization_loss:  0.02444886602461338
p mean is: tensor(4.2419, device='cuda:4')
epoch:  42000 quantization_loss:  0.024451788514852524
p mean is: tensor(4.2897, device='cuda:4')
epoch:  43000 quantization_loss:  0.024328581988811493
p mean is: tensor(4.3356, device='cuda:4')
epoch:  44000 quantization_loss:  0.02429228276014328
p mean is: tensor(4.3797, device='cuda:4')
epoch:  45000 quantization_loss:  0.024254318326711655
p mean is: tensor(4.4220, device='cuda:4')
epoch:  46000 quantization_loss:  0.02421298809349537
p mean is: tensor(4.4629, device='cuda:4')
epoch:  47000 quantization_loss:  0.02423153445124626
p mean is: tensor(4.5023, device='cuda:4')
epoch:  48000 quantization_loss:  0.024158822372555733
p mean is: tensor(4.5405, device='cuda:4')
epoch:  49000 quantization_loss:  0.024115733802318573
p mean is: tensor(4.5774, device='cuda:4')
epoch:  50000 quantization_loss:  0.024088814854621887
p mean is: tensor(4.6131, device='cuda:4')
epoch:  51000 quantization_loss:  0.024073470383882523
p mean is: tensor(4.6475, device='cuda:4')
epoch:  52000 quantization_loss:  0.024056853726506233
p mean is: tensor(4.6809, device='cuda:4')
epoch:  53000 quantization_loss:  0.024009527638554573
p mean is: tensor(4.7133, device='cuda:4')
epoch:  54000 quantization_loss:  0.02399897202849388
p mean is: tensor(4.7448, device='cuda:4')
epoch:  55000 quantization_loss:  0.023968806490302086
p mean is: tensor(4.7753, device='cuda:4')
epoch:  56000 quantization_loss:  0.023953795433044434
p mean is: tensor(4.8050, device='cuda:4')
epoch:  57000 quantization_loss:  0.023936020210385323
p mean is: tensor(4.8339, device='cuda:4')
epoch:  58000 quantization_loss:  0.023921458050608635
p mean is: tensor(4.8620, device='cuda:4')
epoch:  59000 quantization_loss:  0.023920118808746338
p mean is: tensor(4.8893, device='cuda:4')
epoch:  60000 quantization_loss:  0.023892251774668694
p mean is: tensor(4.9159, device='cuda:4')
epoch:  61000 quantization_loss:  0.023883065208792686
p mean is: tensor(4.9417, device='cuda:4')
epoch:  62000 quantization_loss:  0.023861965164542198
p mean is: tensor(4.9669, device='cuda:4')
epoch:  63000 quantization_loss:  0.023856904357671738
p mean is: tensor(4.9915, device='cuda:4')
epoch:  64000 quantization_loss:  0.023842373862862587
p mean is: tensor(5.0154, device='cuda:4')
epoch:  65000 quantization_loss:  0.023837095126509666
p mean is: tensor(5.0389, device='cuda:4')
epoch:  66000 quantization_loss:  0.023834306746721268
p mean is: tensor(5.0617, device='cuda:4')
epoch:  67000 quantization_loss:  0.023820823058485985
p mean is: tensor(5.0839, device='cuda:4')
epoch:  68000 quantization_loss:  0.02380872331559658
p mean is: tensor(5.1056, device='cuda:4')
epoch:  69000 quantization_loss:  0.023805372416973114
p mean is: tensor(5.1269, device='cuda:4')
epoch:  70000 quantization_loss:  0.023796888068318367
p mean is: tensor(5.1477, device='cuda:4')
epoch:  71000 quantization_loss:  0.02379126474261284
p mean is: tensor(5.1681, device='cuda:4')
epoch:  72000 quantization_loss:  0.023779073730111122
p mean is: tensor(5.1880, device='cuda:4')
epoch:  73000 quantization_loss:  0.023825546726584435
p mean is: tensor(5.2076, device='cuda:4')
epoch:  74000 quantization_loss:  0.0237711314111948
p mean is: tensor(5.2266, device='cuda:4')
epoch:  75000 quantization_loss:  0.023774031549692154
p mean is: tensor(5.2453, device='cuda:4')
epoch:  76000 quantization_loss:  0.02375599555671215
p mean is: tensor(5.2636, device='cuda:4')
epoch:  77000 quantization_loss:  0.023756247013807297
p mean is: tensor(5.2816, device='cuda:4')
epoch:  78000 quantization_loss:  0.02374672330915928
p mean is: tensor(5.2992, device='cuda:4')
epoch:  79000 quantization_loss:  0.023749202489852905
p mean is: tensor(5.3165, device='cuda:4')
here
1.0.1.1.weight       | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =    3663 /    4608             ( 79.49%) | total_pruned =     945 | shape = torch.Size([16, 32, 3, 3])
1.1.1.1.bias         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.2.weight         | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.1.2.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.4.1.weight       | nonzeros =    2048 /    2304             ( 88.89%) | total_pruned =     256 | shape = torch.Size([16, 16, 3, 3])
1.1.4.1.bias         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.5.weight         | nonzeros =      11 /      16             ( 68.75%) | total_pruned =       5 | shape = torch.Size([16])
1.1.5.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.7.1.0.1.1.weight | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 16, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =    4144 /    4608             ( 89.93%) | total_pruned =     464 | shape = torch.Size([32, 16, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.1.1.2.weight   | nonzeros =      24 /      32             ( 75.00%) | total_pruned =       8 | shape = torch.Size([32])
1.1.7.1.1.2.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.4.1.weight | nonzeros =    8395 /    9216             ( 91.09%) | total_pruned =     821 | shape = torch.Size([32, 32, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.1.1.5.weight   | nonzeros =      25 /      32             ( 78.12%) | total_pruned =       7 | shape = torch.Size([32])
1.1.7.1.1.5.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 32, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   17052 /   18432             ( 92.51%) | total_pruned =    1380 | shape = torch.Size([64, 32, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   35095 /   36864             ( 95.20%) | total_pruned =    1769 | shape = torch.Size([64, 64, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     238 /     256             ( 92.97%) | total_pruned =      18 | shape = torch.Size([4, 64, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   72510 /   73728             ( 98.35%) | total_pruned =    1218 | shape = torch.Size([128, 64, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  145996 /  147456             ( 99.01%) | total_pruned =    1460 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     407 /     512             ( 79.49%) | total_pruned =     105 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =  147002 /  147456             ( 99.69%) | total_pruned =     454 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  146524 /  147456             ( 99.37%) | total_pruned =     932 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     483 /     512             ( 94.34%) | total_pruned =      29 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =  145473 /  147456             ( 98.66%) | total_pruned =    1983 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  140539 /  147456             ( 95.31%) | total_pruned =    6917 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =     117 /     128             ( 91.41%) | total_pruned =      11 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      95 /     132             ( 71.97%) | total_pruned =      37 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  138730 /  152064             ( 91.23%) | total_pruned =   13334 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     114 /     128             ( 89.06%) | total_pruned =      14 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      91 /     132             ( 68.94%) | total_pruned =      41 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  137196 /  152064             ( 90.22%) | total_pruned =   14868 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     114 /     128             ( 89.06%) | total_pruned =      14 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      86 /     132             ( 65.15%) | total_pruned =      46 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  138459 /  152064             ( 91.05%) | total_pruned =   13605 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      86 /     132             ( 65.15%) | total_pruned =      46 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =   67999 /   76032             ( 89.43%) | total_pruned =    8033 | shape = torch.Size([64, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.4.weight | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.2.weight       | nonzeros =      44 /      68             ( 64.71%) | total_pruned =      24 | shape = torch.Size([68])
1.1.7.2.bias         | nonzeros =       0 /      68             (  0.00%) | total_pruned =      68 | shape = torch.Size([68])
1.1.7.3.1.weight     | nonzeros =   17084 /   19584             ( 87.23%) | total_pruned =    2500 | shape = torch.Size([32, 68, 3, 3])
1.1.7.3.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.4.weight       | nonzeros =      24 /      32             ( 75.00%) | total_pruned =       8 | shape = torch.Size([32])
1.1.7.4.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      16 /      36             ( 44.44%) | total_pruned =      20 | shape = torch.Size([36])
2.bias               | nonzeros =       0 /      36             (  0.00%) | total_pruned =      36 | shape = torch.Size([36])
3.1.weight           | nonzeros =    4117 /    5184             ( 79.42%) | total_pruned =    1067 | shape = torch.Size([16, 36, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      34 /      48             ( 70.83%) | total_pruned =      14 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       3 /       3             (100.00%) | total_pruned =       0 | shape = torch.Size([3])
alive: 1376648, pruned : 74835, total: 1451483, Compression rate :       1.05x  (  5.16% pruned)
PSNR of output image is:  18.246921346131128
Experiment done
