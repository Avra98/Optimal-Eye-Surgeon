(3, 512, 512)
Starting vanilla DIP on 2 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.434705209449504'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/2/skip/det/20.0/1e-09
epoch:  0 quantization_loss:  0.10474754869937897
p mean is: tensor(0.0025, device='cuda:4')
epoch:  1000 quantization_loss:  0.09163060039281845
p mean is: tensor(0.1301, device='cuda:4')
epoch:  2000 quantization_loss:  0.08929175138473511
p mean is: tensor(0.2089, device='cuda:4')
epoch:  3000 quantization_loss:  0.08820771425962448
p mean is: tensor(0.2817, device='cuda:4')
epoch:  4000 quantization_loss:  0.08721049875020981
p mean is: tensor(0.3524, device='cuda:4')
epoch:  5000 quantization_loss:  0.08692694455385208
p mean is: tensor(0.4223, device='cuda:4')
epoch:  6000 quantization_loss:  0.08625322580337524
p mean is: tensor(0.4918, device='cuda:4')
epoch:  7000 quantization_loss:  0.08025169372558594
p mean is: tensor(0.5600, device='cuda:4')
epoch:  8000 quantization_loss:  0.07932212948799133
p mean is: tensor(0.6440, device='cuda:4')
epoch:  9000 quantization_loss:  0.0732613354921341
p mean is: tensor(0.7530, device='cuda:4')
epoch:  10000 quantization_loss:  0.06175995245575905
p mean is: tensor(0.8785, device='cuda:4')
epoch:  11000 quantization_loss:  0.057619381695985794
p mean is: tensor(1.0253, device='cuda:4')
epoch:  12000 quantization_loss:  0.05399617925286293
p mean is: tensor(1.1992, device='cuda:4')
epoch:  13000 quantization_loss:  0.05144133418798447
p mean is: tensor(1.4029, device='cuda:4')
epoch:  14000 quantization_loss:  0.04980158433318138
p mean is: tensor(1.6374, device='cuda:4')
epoch:  15000 quantization_loss:  0.04683290794491768
p mean is: tensor(1.8964, device='cuda:4')
epoch:  16000 quantization_loss:  0.046549081802368164
p mean is: tensor(2.1688, device='cuda:4')
epoch:  17000 quantization_loss:  0.044116582721471786
p mean is: tensor(2.4417, device='cuda:4')
epoch:  18000 quantization_loss:  0.04322816804051399
p mean is: tensor(2.7045, device='cuda:4')
epoch:  19000 quantization_loss:  0.04238426685333252
p mean is: tensor(2.9504, device='cuda:4')
epoch:  20000 quantization_loss:  0.04182342067360878
p mean is: tensor(3.1764, device='cuda:4')
epoch:  21000 quantization_loss:  0.041351307183504105
p mean is: tensor(3.3819, device='cuda:4')
epoch:  22000 quantization_loss:  0.041123490780591965
p mean is: tensor(3.5683, device='cuda:4')
epoch:  23000 quantization_loss:  0.04076094180345535
p mean is: tensor(3.7362, device='cuda:4')
epoch:  24000 quantization_loss:  0.04003274068236351
p mean is: tensor(3.8881, device='cuda:4')
epoch:  25000 quantization_loss:  0.03969847410917282
p mean is: tensor(4.0254, device='cuda:4')
epoch:  26000 quantization_loss:  0.03943405672907829
p mean is: tensor(4.1503, device='cuda:4')
epoch:  27000 quantization_loss:  0.0391693115234375
p mean is: tensor(4.2648, device='cuda:4')
epoch:  28000 quantization_loss:  0.03905290365219116
p mean is: tensor(4.3703, device='cuda:4')
epoch:  29000 quantization_loss:  0.03888867422938347
p mean is: tensor(4.4677, device='cuda:4')
epoch:  30000 quantization_loss:  0.038836535066366196
p mean is: tensor(4.5583, device='cuda:4')
epoch:  31000 quantization_loss:  0.038693759590387344
p mean is: tensor(4.6430, device='cuda:4')
epoch:  32000 quantization_loss:  0.03901662677526474
p mean is: tensor(4.7226, device='cuda:4')
epoch:  33000 quantization_loss:  0.03850952163338661
p mean is: tensor(4.7975, device='cuda:4')
epoch:  34000 quantization_loss:  0.038401663303375244
p mean is: tensor(4.8682, device='cuda:4')
epoch:  35000 quantization_loss:  0.038314420729875565
p mean is: tensor(4.9352, device='cuda:4')
epoch:  36000 quantization_loss:  0.038209978491067886
p mean is: tensor(4.9989, device='cuda:4')
epoch:  37000 quantization_loss:  0.038150668144226074
p mean is: tensor(5.0596, device='cuda:4')
epoch:  38000 quantization_loss:  0.03812252730131149
p mean is: tensor(5.1177, device='cuda:4')
epoch:  39000 quantization_loss:  0.03811275586485863
p mean is: tensor(5.1731, device='cuda:4')
epoch:  40000 quantization_loss:  0.038019828498363495
p mean is: tensor(5.2263, device='cuda:4')
epoch:  41000 quantization_loss:  0.038013771176338196
p mean is: tensor(5.2774, device='cuda:4')
epoch:  42000 quantization_loss:  0.03796449676156044
p mean is: tensor(5.3263, device='cuda:4')
epoch:  43000 quantization_loss:  0.037896528840065
p mean is: tensor(5.3734, device='cuda:4')
epoch:  44000 quantization_loss:  0.03785323724150658
p mean is: tensor(5.4188, device='cuda:4')
epoch:  45000 quantization_loss:  0.03781943395733833
p mean is: tensor(5.4623, device='cuda:4')
epoch:  46000 quantization_loss:  0.037804413586854935
p mean is: tensor(5.5043, device='cuda:4')
epoch:  47000 quantization_loss:  0.03788376599550247
p mean is: tensor(5.5449, device='cuda:4')
epoch:  48000 quantization_loss:  0.03776658698916435
p mean is: tensor(5.5842, device='cuda:4')
epoch:  49000 quantization_loss:  0.03774263709783554
p mean is: tensor(5.6222, device='cuda:4')
epoch:  50000 quantization_loss:  0.03772303834557533
p mean is: tensor(5.6590, device='cuda:4')
epoch:  51000 quantization_loss:  0.03770162910223007
p mean is: tensor(5.6945, device='cuda:4')
epoch:  52000 quantization_loss:  0.03770628571510315
p mean is: tensor(5.7289, device='cuda:4')
epoch:  53000 quantization_loss:  0.03768061101436615
p mean is: tensor(5.7621, device='cuda:4')
epoch:  54000 quantization_loss:  0.03767073154449463
p mean is: tensor(5.7944, device='cuda:4')
epoch:  55000 quantization_loss:  0.037648361176252365
p mean is: tensor(5.8257, device='cuda:4')
epoch:  56000 quantization_loss:  0.03765273466706276
p mean is: tensor(5.8562, device='cuda:4')
epoch:  57000 quantization_loss:  0.03762988746166229
p mean is: tensor(5.8858, device='cuda:4')
epoch:  58000 quantization_loss:  0.03762923926115036
p mean is: tensor(5.9147, device='cuda:4')
epoch:  59000 quantization_loss:  0.03764890879392624
p mean is: tensor(5.9426, device='cuda:4')
epoch:  60000 quantization_loss:  0.03760644420981407
p mean is: tensor(5.9700, device='cuda:4')
epoch:  61000 quantization_loss:  0.03759927675127983
p mean is: tensor(5.9966, device='cuda:4')
epoch:  62000 quantization_loss:  0.037596285343170166
p mean is: tensor(6.0225, device='cuda:4')
epoch:  63000 quantization_loss:  0.03758971393108368
p mean is: tensor(6.0476, device='cuda:4')
epoch:  64000 quantization_loss:  0.03757952153682709
p mean is: tensor(6.0722, device='cuda:4')
epoch:  65000 quantization_loss:  0.03758005425333977
p mean is: tensor(6.0962, device='cuda:4')
epoch:  66000 quantization_loss:  0.03756900131702423
p mean is: tensor(6.1197, device='cuda:4')
epoch:  67000 quantization_loss:  0.0375838465988636
p mean is: tensor(6.1425, device='cuda:4')
epoch:  68000 quantization_loss:  0.037564415484666824
p mean is: tensor(6.1648, device='cuda:4')
epoch:  69000 quantization_loss:  0.03755953162908554
p mean is: tensor(6.1867, device='cuda:4')
epoch:  70000 quantization_loss:  0.03756192326545715
p mean is: tensor(6.2080, device='cuda:4')
epoch:  71000 quantization_loss:  0.0375639982521534
p mean is: tensor(6.2288, device='cuda:4')
epoch:  72000 quantization_loss:  0.03754722699522972
p mean is: tensor(6.2492, device='cuda:4')
epoch:  73000 quantization_loss:  0.03763526305556297
p mean is: tensor(6.2692, device='cuda:4')
epoch:  74000 quantization_loss:  0.03753639757633209
p mean is: tensor(6.2887, device='cuda:4')
epoch:  75000 quantization_loss:  0.03753132000565529
p mean is: tensor(6.3079, device='cuda:4')
epoch:  76000 quantization_loss:  0.037524640560150146
p mean is: tensor(6.3267, device='cuda:4')
epoch:  77000 quantization_loss:  0.037534065544605255
p mean is: tensor(6.3452, device='cuda:4')
epoch:  78000 quantization_loss:  0.03752526640892029
p mean is: tensor(6.3633, device='cuda:4')
epoch:  79000 quantization_loss:  0.03752005845308304
p mean is: tensor(6.3811, device='cuda:4')
here
1.0.1.1.weight       | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =    3973 /    4608             ( 86.22%) | total_pruned =     635 | shape = torch.Size([16, 32, 3, 3])
1.1.1.1.bias         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.2.weight         | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.1.2.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.4.1.weight       | nonzeros =    2174 /    2304             ( 94.36%) | total_pruned =     130 | shape = torch.Size([16, 16, 3, 3])
1.1.4.1.bias         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.5.weight         | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.1.5.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.7.1.0.1.1.weight | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 16, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =    4414 /    4608             ( 95.79%) | total_pruned =     194 | shape = torch.Size([32, 16, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.1.1.2.weight   | nonzeros =      24 /      32             ( 75.00%) | total_pruned =       8 | shape = torch.Size([32])
1.1.7.1.1.2.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.4.1.weight | nonzeros =    8976 /    9216             ( 97.40%) | total_pruned =     240 | shape = torch.Size([32, 32, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.1.1.5.weight   | nonzeros =      21 /      32             ( 65.62%) | total_pruned =      11 | shape = torch.Size([32])
1.1.7.1.1.5.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 32, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   18090 /   18432             ( 98.14%) | total_pruned =     342 | shape = torch.Size([64, 32, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   36315 /   36864             ( 98.51%) | total_pruned =     549 | shape = torch.Size([64, 64, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     241 /     256             ( 94.14%) | total_pruned =      15 | shape = torch.Size([4, 64, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   73298 /   73728             ( 99.42%) | total_pruned =     430 | shape = torch.Size([128, 64, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  146954 /  147456             ( 99.66%) | total_pruned =     502 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     456 /     512             ( 89.06%) | total_pruned =      56 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =  147122 /  147456             ( 99.77%) | total_pruned =     334 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  146709 /  147456             ( 99.49%) | total_pruned =     747 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =  145804 /  147456             ( 98.88%) | total_pruned =    1652 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  142487 /  147456             ( 96.63%) | total_pruned =    4969 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      90 /     132             ( 68.18%) | total_pruned =      42 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  142614 /  152064             ( 93.79%) | total_pruned =    9450 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     112 /     128             ( 87.50%) | total_pruned =      16 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      91 /     132             ( 68.94%) | total_pruned =      41 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  140310 /  152064             ( 92.27%) | total_pruned =   11754 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      97 /     132             ( 73.48%) | total_pruned =      35 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  142169 /  152064             ( 93.49%) | total_pruned =    9895 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      81 /     132             ( 61.36%) | total_pruned =      51 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =   70810 /   76032             ( 93.13%) | total_pruned =    5222 | shape = torch.Size([64, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.4.weight | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.2.weight       | nonzeros =      37 /      68             ( 54.41%) | total_pruned =      31 | shape = torch.Size([68])
1.1.7.2.bias         | nonzeros =       0 /      68             (  0.00%) | total_pruned =      68 | shape = torch.Size([68])
1.1.7.3.1.weight     | nonzeros =   17438 /   19584             ( 89.04%) | total_pruned =    2146 | shape = torch.Size([32, 68, 3, 3])
1.1.7.3.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.4.weight       | nonzeros =      27 /      32             ( 84.38%) | total_pruned =       5 | shape = torch.Size([32])
1.1.7.4.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      20 /      36             ( 55.56%) | total_pruned =      16 | shape = torch.Size([36])
2.bias               | nonzeros =       0 /      36             (  0.00%) | total_pruned =      36 | shape = torch.Size([36])
3.1.weight           | nonzeros =    3942 /    5184             ( 76.04%) | total_pruned =    1242 | shape = torch.Size([16, 36, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      29 /      48             ( 60.42%) | total_pruned =      19 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 1398280, pruned : 53203, total: 1451483, Compression rate :       1.04x  (  3.67% pruned)
PSNR of output image is:  15.324434176934806
Experiment done
