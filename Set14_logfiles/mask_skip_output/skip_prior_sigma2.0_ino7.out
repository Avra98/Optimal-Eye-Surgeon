(3, 512, 512)
Starting vanilla DIP on 7 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.231590675814978'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/7/skip/det/2.0/1e-09
epoch:  0 quantization_loss:  0.07755544036626816
p mean is: tensor(0.0003, device='cuda:1')
epoch:  1000 quantization_loss:  0.06746531277894974
p mean is: tensor(0.0140, device='cuda:1')
epoch:  2000 quantization_loss:  0.06702140718698502
p mean is: tensor(0.0243, device='cuda:1')
epoch:  3000 quantization_loss:  0.06532605737447739
p mean is: tensor(0.0352, device='cuda:1')
epoch:  4000 quantization_loss:  0.06638310849666595
p mean is: tensor(0.0464, device='cuda:1')
epoch:  5000 quantization_loss:  0.06471152603626251
p mean is: tensor(0.0578, device='cuda:1')
epoch:  6000 quantization_loss:  0.06436988711357117
p mean is: tensor(0.0700, device='cuda:1')
epoch:  7000 quantization_loss:  0.0643581822514534
p mean is: tensor(0.0824, device='cuda:1')
epoch:  8000 quantization_loss:  0.06415152549743652
p mean is: tensor(0.0955, device='cuda:1')
epoch:  9000 quantization_loss:  0.05861678719520569
p mean is: tensor(0.1093, device='cuda:1')
epoch:  10000 quantization_loss:  0.05474671348929405
p mean is: tensor(0.1247, device='cuda:1')
epoch:  11000 quantization_loss:  0.04449094086885452
p mean is: tensor(0.1417, device='cuda:1')
epoch:  12000 quantization_loss:  0.04294560104608536
p mean is: tensor(0.1639, device='cuda:1')
epoch:  13000 quantization_loss:  0.038349296897649765
p mean is: tensor(0.1932, device='cuda:1')
epoch:  14000 quantization_loss:  0.03619682788848877
p mean is: tensor(0.2302, device='cuda:1')
epoch:  15000 quantization_loss:  0.035302381962537766
p mean is: tensor(0.2753, device='cuda:1')
epoch:  16000 quantization_loss:  0.03495830297470093
p mean is: tensor(0.3298, device='cuda:1')
epoch:  17000 quantization_loss:  0.034530334174633026
p mean is: tensor(0.3941, device='cuda:1')
epoch:  18000 quantization_loss:  0.03392328321933746
p mean is: tensor(0.4681, device='cuda:1')
epoch:  19000 quantization_loss:  0.03370174393057823
p mean is: tensor(0.5498, device='cuda:1')
epoch:  20000 quantization_loss:  0.03346358612179756
p mean is: tensor(0.6365, device='cuda:1')
epoch:  21000 quantization_loss:  0.03385452553629875
p mean is: tensor(0.7252, device='cuda:1')
epoch:  22000 quantization_loss:  0.03292263299226761
p mean is: tensor(0.8133, device='cuda:1')
epoch:  23000 quantization_loss:  0.03276226297020912
p mean is: tensor(0.8980, device='cuda:1')
epoch:  24000 quantization_loss:  0.032506223767995834
p mean is: tensor(0.9776, device='cuda:1')
epoch:  25000 quantization_loss:  0.032399363815784454
p mean is: tensor(1.0514, device='cuda:1')
epoch:  26000 quantization_loss:  0.03224598616361618
p mean is: tensor(1.1195, device='cuda:1')
epoch:  27000 quantization_loss:  0.03205579146742821
p mean is: tensor(1.1815, device='cuda:1')
epoch:  28000 quantization_loss:  0.031961046159267426
p mean is: tensor(1.2382, device='cuda:1')
epoch:  29000 quantization_loss:  0.031506750732660294
p mean is: tensor(1.2897, device='cuda:1')
epoch:  30000 quantization_loss:  0.031245669350028038
p mean is: tensor(1.3363, device='cuda:1')
epoch:  31000 quantization_loss:  0.03114410676062107
p mean is: tensor(1.3786, device='cuda:1')
epoch:  32000 quantization_loss:  0.031064473092556
p mean is: tensor(1.4172, device='cuda:1')
epoch:  33000 quantization_loss:  0.03108510747551918
p mean is: tensor(1.4527, device='cuda:1')
epoch:  34000 quantization_loss:  0.030888337641954422
p mean is: tensor(1.4850, device='cuda:1')
epoch:  35000 quantization_loss:  0.030833745375275612
p mean is: tensor(1.5147, device='cuda:1')
epoch:  36000 quantization_loss:  0.030772339552640915
p mean is: tensor(1.5420, device='cuda:1')
epoch:  37000 quantization_loss:  0.03067827597260475
p mean is: tensor(1.5672, device='cuda:1')
epoch:  38000 quantization_loss:  0.03064386360347271
p mean is: tensor(1.5906, device='cuda:1')
epoch:  39000 quantization_loss:  0.0305806752294302
p mean is: tensor(1.6126, device='cuda:1')
epoch:  40000 quantization_loss:  0.030580362305045128
p mean is: tensor(1.6328, device='cuda:1')
epoch:  41000 quantization_loss:  0.030485114082694054
p mean is: tensor(1.6517, device='cuda:1')
epoch:  42000 quantization_loss:  0.03043658658862114
p mean is: tensor(1.6695, device='cuda:1')
epoch:  43000 quantization_loss:  0.03045486845076084
p mean is: tensor(1.6862, device='cuda:1')
epoch:  44000 quantization_loss:  0.030317671597003937
p mean is: tensor(1.7017, device='cuda:1')
epoch:  45000 quantization_loss:  0.030284663662314415
p mean is: tensor(1.7163, device='cuda:1')
epoch:  46000 quantization_loss:  0.030285317450761795
p mean is: tensor(1.7303, device='cuda:1')
epoch:  47000 quantization_loss:  0.030235229060053825
p mean is: tensor(1.7433, device='cuda:1')
epoch:  48000 quantization_loss:  0.03018837794661522
p mean is: tensor(1.7557, device='cuda:1')
epoch:  49000 quantization_loss:  0.03015534020960331
p mean is: tensor(1.7674, device='cuda:1')
epoch:  50000 quantization_loss:  0.030140139162540436
p mean is: tensor(1.7786, device='cuda:1')
epoch:  51000 quantization_loss:  0.03010556846857071
p mean is: tensor(1.7892, device='cuda:1')
epoch:  52000 quantization_loss:  0.030079791322350502
p mean is: tensor(1.7994, device='cuda:1')
epoch:  53000 quantization_loss:  0.030054869130253792
p mean is: tensor(1.8091, device='cuda:1')
epoch:  54000 quantization_loss:  0.03005371429026127
p mean is: tensor(1.8183, device='cuda:1')
epoch:  55000 quantization_loss:  0.030034378170967102
p mean is: tensor(1.8272, device='cuda:1')
epoch:  56000 quantization_loss:  0.030010642483830452
p mean is: tensor(1.8358, device='cuda:1')
epoch:  57000 quantization_loss:  0.029995022341609
p mean is: tensor(1.8438, device='cuda:1')
epoch:  58000 quantization_loss:  0.029973257333040237
p mean is: tensor(1.8517, device='cuda:1')
epoch:  59000 quantization_loss:  0.029965493828058243
p mean is: tensor(1.8594, device='cuda:1')
epoch:  60000 quantization_loss:  0.02995128184556961
p mean is: tensor(1.8667, device='cuda:1')
epoch:  61000 quantization_loss:  0.029935549944639206
p mean is: tensor(1.8740, device='cuda:1')
epoch:  62000 quantization_loss:  0.029928255826234818
p mean is: tensor(1.8808, device='cuda:1')
epoch:  63000 quantization_loss:  0.029915781691670418
p mean is: tensor(1.8875, device='cuda:1')
epoch:  64000 quantization_loss:  0.029901515692472458
p mean is: tensor(1.8940, device='cuda:1')
epoch:  65000 quantization_loss:  0.029896937310695648
p mean is: tensor(1.9001, device='cuda:1')
epoch:  66000 quantization_loss:  0.02987692877650261
p mean is: tensor(1.9061, device='cuda:1')
epoch:  67000 quantization_loss:  0.02991335466504097
p mean is: tensor(1.9118, device='cuda:1')
epoch:  68000 quantization_loss:  0.02986164577305317
p mean is: tensor(1.9175, device='cuda:1')
epoch:  69000 quantization_loss:  0.0298527330160141
p mean is: tensor(1.9231, device='cuda:1')
epoch:  70000 quantization_loss:  0.02985500358045101
p mean is: tensor(1.9285, device='cuda:1')
epoch:  71000 quantization_loss:  0.02983889915049076
p mean is: tensor(1.9338, device='cuda:1')
epoch:  72000 quantization_loss:  0.029840365052223206
p mean is: tensor(1.9389, device='cuda:1')
epoch:  73000 quantization_loss:  0.029836490750312805
p mean is: tensor(1.9439, device='cuda:1')
epoch:  74000 quantization_loss:  0.029830947518348694
p mean is: tensor(1.9489, device='cuda:1')
epoch:  75000 quantization_loss:  0.02982484921813011
p mean is: tensor(1.9536, device='cuda:1')
epoch:  76000 quantization_loss:  0.029811441898345947
p mean is: tensor(1.9583, device='cuda:1')
epoch:  77000 quantization_loss:  0.029811792075634003
p mean is: tensor(1.9629, device='cuda:1')
epoch:  78000 quantization_loss:  0.029807016253471375
p mean is: tensor(1.9674, device='cuda:1')
epoch:  79000 quantization_loss:  0.02988746017217636
p mean is: tensor(1.9718, device='cuda:1')
here
1.0.1.1.weight       | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =    3708 /    4608             ( 80.47%) | total_pruned =     900 | shape = torch.Size([16, 32, 3, 3])
1.1.1.1.bias         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.2.weight         | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.1.2.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.4.1.weight       | nonzeros =    2085 /    2304             ( 90.49%) | total_pruned =     219 | shape = torch.Size([16, 16, 3, 3])
1.1.4.1.bias         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.5.weight         | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.1.5.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.7.1.0.1.1.weight | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 16, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =    4329 /    4608             ( 93.95%) | total_pruned =     279 | shape = torch.Size([32, 16, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.1.1.2.weight   | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
1.1.7.1.1.2.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.4.1.weight | nonzeros =    8741 /    9216             ( 94.85%) | total_pruned =     475 | shape = torch.Size([32, 32, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.1.1.5.weight   | nonzeros =      24 /      32             ( 75.00%) | total_pruned =       8 | shape = torch.Size([32])
1.1.7.1.1.5.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 32, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   17521 /   18432             ( 95.06%) | total_pruned =     911 | shape = torch.Size([64, 32, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   35158 /   36864             ( 95.37%) | total_pruned =    1706 | shape = torch.Size([64, 64, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 64, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   70529 /   73728             ( 95.66%) | total_pruned =    3199 | shape = torch.Size([128, 64, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  142676 /  147456             ( 96.76%) | total_pruned =    4780 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     430 /     512             ( 83.98%) | total_pruned =      82 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =  146790 /  147456             ( 99.55%) | total_pruned =     666 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  145238 /  147456             ( 98.50%) | total_pruned =    2218 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     485 /     512             ( 94.73%) | total_pruned =      27 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =  142175 /  147456             ( 96.42%) | total_pruned =    5281 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  131237 /  147456             ( 89.00%) | total_pruned =   16219 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      91 /     132             ( 68.94%) | total_pruned =      41 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  126111 /  152064             ( 82.93%) | total_pruned =   25953 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      93 /     132             ( 70.45%) | total_pruned =      39 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  123993 /  152064             ( 81.54%) | total_pruned =   28071 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      87 /     132             ( 65.91%) | total_pruned =      45 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  125613 /  152064             ( 82.61%) | total_pruned =   26451 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      87 /     132             ( 65.91%) | total_pruned =      45 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =   63108 /   76032             ( 83.00%) | total_pruned =   12924 | shape = torch.Size([64, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.4.weight | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.2.weight       | nonzeros =      41 /      68             ( 60.29%) | total_pruned =      27 | shape = torch.Size([68])
1.1.7.2.bias         | nonzeros =       0 /      68             (  0.00%) | total_pruned =      68 | shape = torch.Size([68])
1.1.7.3.1.weight     | nonzeros =   16877 /   19584             ( 86.18%) | total_pruned =    2707 | shape = torch.Size([32, 68, 3, 3])
1.1.7.3.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.4.weight       | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.1.7.4.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      16 /      36             ( 44.44%) | total_pruned =      20 | shape = torch.Size([36])
2.bias               | nonzeros =       0 /      36             (  0.00%) | total_pruned =      36 | shape = torch.Size([36])
3.1.weight           | nonzeros =    4006 /    5184             ( 77.28%) | total_pruned =    1178 | shape = torch.Size([16, 36, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      24 /      48             ( 50.00%) | total_pruned =      24 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 1314453, pruned : 137030, total: 1451483, Compression rate :       1.10x  (  9.44% pruned)
PSNR of output image is:  16.62361078038837
Experiment done
