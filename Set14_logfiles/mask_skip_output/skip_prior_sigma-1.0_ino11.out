(3, 512, 512)
Starting vanilla DIP on 11 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.312747844079997'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/11/skip/det/-1.0/1e-09
(3, 512, 512)
Starting vanilla DIP on 11 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.313910306041127'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/11/skip/det/-1.0/1e-09
epoch:  0 quantization_loss:  0.0654270201921463
p mean is: tensor(-0.0002, device='cuda:1')
epoch:  1000 quantization_loss:  0.056571755558252335
p mean is: tensor(-0.0095, device='cuda:1')
epoch:  2000 quantization_loss:  0.05541336536407471
p mean is: tensor(-0.0163, device='cuda:1')
epoch:  3000 quantization_loss:  0.05421651899814606
p mean is: tensor(-0.0237, device='cuda:1')
epoch:  4000 quantization_loss:  0.05391671136021614
p mean is: tensor(-0.0312, device='cuda:1')
epoch:  5000 quantization_loss:  0.05454094335436821
p mean is: tensor(-0.0396, device='cuda:1')
epoch:  6000 quantization_loss:  0.053197719156742096
p mean is: tensor(-0.0488, device='cuda:1')
epoch:  7000 quantization_loss:  0.04894182085990906
p mean is: tensor(-0.0581, device='cuda:1')
epoch:  8000 quantization_loss:  0.045728567987680435
p mean is: tensor(-0.0688, device='cuda:1')
epoch:  9000 quantization_loss:  0.04155021533370018
p mean is: tensor(-0.0816, device='cuda:1')
epoch:  10000 quantization_loss:  0.03888775780797005
p mean is: tensor(-0.0964, device='cuda:1')
epoch:  11000 quantization_loss:  0.03583995997905731
p mean is: tensor(-0.1134, device='cuda:1')
epoch:  12000 quantization_loss:  0.03257599100470543
p mean is: tensor(-0.1323, device='cuda:1')
epoch:  13000 quantization_loss:  0.030339887365698814
p mean is: tensor(-0.1541, device='cuda:1')
epoch:  14000 quantization_loss:  0.029670586809515953
p mean is: tensor(-0.1788, device='cuda:1')
epoch:  15000 quantization_loss:  0.02677983231842518
p mean is: tensor(-0.2076, device='cuda:1')
epoch:  16000 quantization_loss:  0.025631071999669075
p mean is: tensor(-0.2400, device='cuda:1')
epoch:  17000 quantization_loss:  0.024926502257585526
p mean is: tensor(-0.2761, device='cuda:1')
epoch:  18000 quantization_loss:  0.02425115555524826
p mean is: tensor(-0.3148, device='cuda:1')
epoch:  19000 quantization_loss:  0.023865610361099243
p mean is: tensor(-0.3553, device='cuda:1')
epoch:  20000 quantization_loss:  0.023299777880311012
p mean is: tensor(-0.3964, device='cuda:1')
epoch:  21000 quantization_loss:  0.022818082943558693
p mean is: tensor(-0.4369, device='cuda:1')
epoch:  22000 quantization_loss:  0.022292394191026688
p mean is: tensor(-0.4758, device='cuda:1')
epoch:  23000 quantization_loss:  0.02207529917359352
p mean is: tensor(-0.5121, device='cuda:1')
epoch:  24000 quantization_loss:  0.02152273803949356
p mean is: tensor(-0.5459, device='cuda:1')
epoch:  25000 quantization_loss:  0.021279094740748405
p mean is: tensor(-0.5766, device='cuda:1')
epoch:  26000 quantization_loss:  0.02108682133257389
p mean is: tensor(-0.6050, device='cuda:1')
epoch:  27000 quantization_loss:  0.021255962550640106
p mean is: tensor(-0.6305, device='cuda:1')
epoch:  28000 quantization_loss:  0.021653464064002037
p mean is: tensor(-0.6538, device='cuda:1')
epoch:  29000 quantization_loss:  0.02053138054907322
p mean is: tensor(-0.6748, device='cuda:1')
epoch:  30000 quantization_loss:  0.020475542172789574
p mean is: tensor(-0.6938, device='cuda:1')
epoch:  31000 quantization_loss:  0.02027273178100586
p mean is: tensor(-0.7109, device='cuda:1')
epoch:  32000 quantization_loss:  0.019885966554284096
p mean is: tensor(-0.7264, device='cuda:1')
epoch:  33000 quantization_loss:  0.019641242921352386
p mean is: tensor(-0.7407, device='cuda:1')
epoch:  34000 quantization_loss:  0.019612891599535942
p mean is: tensor(-0.7532, device='cuda:1')
epoch:  35000 quantization_loss:  0.019499095156788826
p mean is: tensor(-0.7648, device='cuda:1')
epoch:  36000 quantization_loss:  0.019373144954442978
p mean is: tensor(-0.7754, device='cuda:1')
epoch:  37000 quantization_loss:  0.01929779164493084
p mean is: tensor(-0.7852, device='cuda:1')
epoch:  38000 quantization_loss:  0.018029354512691498
p mean is: tensor(-0.7941, device='cuda:1')
epoch:  39000 quantization_loss:  0.017915571108460426
p mean is: tensor(-0.8021, device='cuda:1')
epoch:  40000 quantization_loss:  0.017850376665592194
p mean is: tensor(-0.8098, device='cuda:1')
epoch:  41000 quantization_loss:  0.017789160832762718
p mean is: tensor(-0.8168, device='cuda:1')
epoch:  42000 quantization_loss:  0.0176991056650877
p mean is: tensor(-0.8232, device='cuda:1')
epoch:  43000 quantization_loss:  0.01765700802206993
p mean is: tensor(-0.8294, device='cuda:1')
epoch:  44000 quantization_loss:  0.017227714881300926
p mean is: tensor(-0.8352, device='cuda:1')
epoch:  45000 quantization_loss:  0.01714245416224003
p mean is: tensor(-0.8406, device='cuda:1')
epoch:  46000 quantization_loss:  0.017089899629354477
p mean is: tensor(-0.8458, device='cuda:1')
epoch:  47000 quantization_loss:  0.017045721411705017
p mean is: tensor(-0.8506, device='cuda:1')
epoch:  48000 quantization_loss:  0.016988420858979225
p mean is: tensor(-0.8552, device='cuda:1')
epoch:  49000 quantization_loss:  0.01716938428580761
p mean is: tensor(-0.8596, device='cuda:1')
epoch:  50000 quantization_loss:  0.016936475411057472
p mean is: tensor(-0.8640, device='cuda:1')
epoch:  51000 quantization_loss:  0.016924723982810974
p mean is: tensor(-0.8680, device='cuda:1')
epoch:  52000 quantization_loss:  0.01689177006483078
p mean is: tensor(-0.8719, device='cuda:1')
epoch:  53000 quantization_loss:  0.01686292327940464
p mean is: tensor(-0.8756, device='cuda:1')
epoch:  54000 quantization_loss:  0.01685032993555069
p mean is: tensor(-0.8793, device='cuda:1')
epoch:  55000 quantization_loss:  0.01682249829173088
p mean is: tensor(-0.8826, device='cuda:1')
epoch:  56000 quantization_loss:  0.016857804730534554
p mean is: tensor(-0.8859, device='cuda:1')
epoch:  57000 quantization_loss:  0.01679469272494316
p mean is: tensor(-0.8891, device='cuda:1')
epoch:  58000 quantization_loss:  0.016793658956885338
p mean is: tensor(-0.8923, device='cuda:1')
epoch:  59000 quantization_loss:  0.016771573573350906
p mean is: tensor(-0.8953, device='cuda:1')
epoch:  60000 quantization_loss:  0.016752583906054497
p mean is: tensor(-0.8983, device='cuda:1')
epoch:  61000 quantization_loss:  0.016755441203713417
p mean is: tensor(-0.9011, device='cuda:1')
epoch:  62000 quantization_loss:  0.01674412004649639
p mean is: tensor(-0.9038, device='cuda:1')
epoch:  63000 quantization_loss:  0.016745364293456078
p mean is: tensor(-0.9064, device='cuda:1')
epoch:  64000 quantization_loss:  0.01671588234603405
p mean is: tensor(-0.9089, device='cuda:1')
epoch:  65000 quantization_loss:  0.016710665076971054
p mean is: tensor(-0.9113, device='cuda:1')
epoch:  66000 quantization_loss:  0.016716860234737396
p mean is: tensor(-0.9137, device='cuda:1')
epoch:  67000 quantization_loss:  0.01670156605541706
p mean is: tensor(-0.9160, device='cuda:1')
epoch:  68000 quantization_loss:  0.01693713665008545
p mean is: tensor(-0.9182, device='cuda:1')
epoch:  69000 quantization_loss:  0.0166911743581295
p mean is: tensor(-0.9204, device='cuda:1')
epoch:  70000 quantization_loss:  0.016682857647538185
p mean is: tensor(-0.9225, device='cuda:1')
epoch:  71000 quantization_loss:  0.016683315858244896
p mean is: tensor(-0.9247, device='cuda:1')
epoch:  72000 quantization_loss:  0.016681941226124763
p mean is: tensor(-0.9267, device='cuda:1')
epoch:  73000 quantization_loss:  0.01666920818388462
p mean is: tensor(-0.9286, device='cuda:1')
epoch:  74000 quantization_loss:  0.016673170030117035
p mean is: tensor(-0.9304, device='cuda:1')
epoch:  75000 quantization_loss:  0.016655009239912033
p mean is: tensor(-0.9322, device='cuda:1')
epoch:  76000 quantization_loss:  0.01666438765823841
p mean is: tensor(-0.9341, device='cuda:1')
epoch:  77000 quantization_loss:  0.016659244894981384
p mean is: tensor(-0.9359, device='cuda:1')
epoch:  78000 quantization_loss:  0.0166546031832695
p mean is: tensor(-0.9376, device='cuda:1')
epoch:  79000 quantization_loss:  0.016646601259708405
p mean is: tensor(-0.9392, device='cuda:1')
here
1.0.1.1.weight       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =    1555 /    4608             ( 33.75%) | total_pruned =    3053 | shape = torch.Size([16, 32, 3, 3])
1.1.1.1.bias         | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.2.weight         | nonzeros =      11 /      16             ( 68.75%) | total_pruned =       5 | shape = torch.Size([16])
1.1.2.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.4.1.weight       | nonzeros =     756 /    2304             ( 32.81%) | total_pruned =    1548 | shape = torch.Size([16, 16, 3, 3])
1.1.4.1.bias         | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.5.weight         | nonzeros =      15 /      16             ( 93.75%) | total_pruned =       1 | shape = torch.Size([16])
1.1.5.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.7.1.0.1.1.weight | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([4, 16, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =    1423 /    4608             ( 30.88%) | total_pruned =    3185 | shape = torch.Size([32, 16, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.2.weight   | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
1.1.7.1.1.2.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.4.1.weight | nonzeros =    2582 /    9216             ( 28.02%) | total_pruned =    6634 | shape = torch.Size([32, 32, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.5.weight   | nonzeros =      27 /      32             ( 84.38%) | total_pruned =       5 | shape = torch.Size([32])
1.1.7.1.1.5.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([4, 32, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    5679 /   18432             ( 30.81%) | total_pruned =   12753 | shape = torch.Size([64, 32, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    8278 /   36864             ( 22.46%) | total_pruned =   28586 | shape = torch.Size([64, 64, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      47 /     256             ( 18.36%) | total_pruned =     209 | shape = torch.Size([4, 64, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    6491 /   73728             (  8.80%) | total_pruned =   67237 | shape = torch.Size([128, 64, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    7207 /  147456             (  4.89%) | total_pruned =  140249 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      64 /     512             ( 12.50%) | total_pruned =     448 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    3610 /  147456             (  2.45%) | total_pruned =  143846 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    8284 /  147456             (  5.62%) | total_pruned =  139172 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      55 /     512             ( 10.74%) | total_pruned =     457 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   12767 /  147456             (  8.66%) | total_pruned =  134689 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   26609 /  147456             ( 18.05%) | total_pruned =  120847 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =     100 /     132             ( 75.76%) | total_pruned =      32 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   34344 /  152064             ( 22.59%) | total_pruned =  117720 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      89 /     132             ( 67.42%) | total_pruned =      43 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   31722 /  152064             ( 20.86%) | total_pruned =  120342 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      89 /     132             ( 67.42%) | total_pruned =      43 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   31558 /  152064             ( 20.75%) | total_pruned =  120506 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      88 /     132             ( 66.67%) | total_pruned =      44 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =   13359 /   76032             ( 17.57%) | total_pruned =   62673 | shape = torch.Size([64, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.4.weight | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.2.weight       | nonzeros =      37 /      68             ( 54.41%) | total_pruned =      31 | shape = torch.Size([68])
1.1.7.2.bias         | nonzeros =       0 /      68             (  0.00%) | total_pruned =      68 | shape = torch.Size([68])
1.1.7.3.1.weight     | nonzeros =    3408 /   19584             ( 17.40%) | total_pruned =   16176 | shape = torch.Size([32, 68, 3, 3])
1.1.7.3.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.4.weight       | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
1.1.7.4.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      22 /      36             ( 61.11%) | total_pruned =      14 | shape = torch.Size([36])
2.bias               | nonzeros =       0 /      36             (  0.00%) | total_pruned =      36 | shape = torch.Size([36])
3.1.weight           | nonzeros =    1472 /    5184             ( 28.40%) | total_pruned =    3712 | shape = torch.Size([16, 36, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      35 /      48             ( 72.92%) | total_pruned =      13 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 202834, pruned : 1248649, total: 1451483, Compression rate :       7.16x  ( 86.03% pruned)
PSNR of output image is:  20.7867741888103
Experiment done
