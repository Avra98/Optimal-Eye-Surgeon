(3, 256, 256)
Starting vanilla DIP on 1 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.48747767527109'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/1/skip/det/-1.0/1e-09
(3, 256, 256)
Starting vanilla DIP on 1 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.447567951687006'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/1/skip/det/-1.0/1e-09
epoch:  0 quantization_loss:  0.08683892339468002
p mean is: tensor(-0.0002, device='cuda:4')
epoch:  1000 quantization_loss:  0.07847800850868225
p mean is: tensor(-0.0037, device='cuda:4')
epoch:  2000 quantization_loss:  0.07567128539085388
p mean is: tensor(-0.0061, device='cuda:4')
epoch:  3000 quantization_loss:  0.0768112763762474
p mean is: tensor(-0.0087, device='cuda:4')
epoch:  4000 quantization_loss:  0.07423032820224762
p mean is: tensor(-0.0103, device='cuda:4')
epoch:  5000 quantization_loss:  0.0728478655219078
p mean is: tensor(-0.0121, device='cuda:4')
epoch:  6000 quantization_loss:  0.07431593537330627
p mean is: tensor(-0.0137, device='cuda:4')
epoch:  7000 quantization_loss:  0.0720890685915947
p mean is: tensor(-0.0153, device='cuda:4')
epoch:  8000 quantization_loss:  0.07436791062355042
p mean is: tensor(-0.0178, device='cuda:4')
epoch:  9000 quantization_loss:  0.0725315511226654
p mean is: tensor(-0.0195, device='cuda:4')
epoch:  10000 quantization_loss:  0.07468343526124954
p mean is: tensor(-0.0217, device='cuda:4')
epoch:  11000 quantization_loss:  0.07309957593679428
p mean is: tensor(-0.0238, device='cuda:4')
epoch:  12000 quantization_loss:  0.07315468043088913
p mean is: tensor(-0.0259, device='cuda:4')
epoch:  13000 quantization_loss:  0.07543487846851349
p mean is: tensor(-0.0282, device='cuda:4')
epoch:  14000 quantization_loss:  0.07069015502929688
p mean is: tensor(-0.0313, device='cuda:4')
epoch:  15000 quantization_loss:  0.07250852882862091
p mean is: tensor(-0.0342, device='cuda:4')
epoch:  16000 quantization_loss:  0.06352732330560684
p mean is: tensor(-0.0374, device='cuda:4')
epoch:  17000 quantization_loss:  0.05289716273546219
p mean is: tensor(-0.0415, device='cuda:4')
epoch:  18000 quantization_loss:  0.04183082655072212
p mean is: tensor(-0.0464, device='cuda:4')
epoch:  19000 quantization_loss:  0.03966798260807991
p mean is: tensor(-0.0520, device='cuda:4')
epoch:  20000 quantization_loss:  0.03510068729519844
p mean is: tensor(-0.0592, device='cuda:4')
epoch:  21000 quantization_loss:  0.03357132524251938
p mean is: tensor(-0.0688, device='cuda:4')
epoch:  22000 quantization_loss:  0.03189966827630997
p mean is: tensor(-0.0806, device='cuda:4')
epoch:  23000 quantization_loss:  0.03131687641143799
p mean is: tensor(-0.0953, device='cuda:4')
epoch:  24000 quantization_loss:  0.029698766767978668
p mean is: tensor(-0.1141, device='cuda:4')
epoch:  25000 quantization_loss:  0.027567587792873383
p mean is: tensor(-0.1371, device='cuda:4')
epoch:  26000 quantization_loss:  0.026228196918964386
p mean is: tensor(-0.1652, device='cuda:4')
epoch:  27000 quantization_loss:  0.025514865294098854
p mean is: tensor(-0.1982, device='cuda:4')
epoch:  28000 quantization_loss:  0.0253444854170084
p mean is: tensor(-0.2361, device='cuda:4')
epoch:  29000 quantization_loss:  0.024589261040091515
p mean is: tensor(-0.2789, device='cuda:4')
epoch:  30000 quantization_loss:  0.02457307279109955
p mean is: tensor(-0.3254, device='cuda:4')
epoch:  31000 quantization_loss:  0.024019237607717514
p mean is: tensor(-0.3740, device='cuda:4')
epoch:  32000 quantization_loss:  0.023700376972556114
p mean is: tensor(-0.4234, device='cuda:4')
epoch:  33000 quantization_loss:  0.02362489327788353
p mean is: tensor(-0.4719, device='cuda:4')
epoch:  34000 quantization_loss:  0.023253250867128372
p mean is: tensor(-0.5186, device='cuda:4')
epoch:  35000 quantization_loss:  0.023016760125756264
p mean is: tensor(-0.5626, device='cuda:4')
epoch:  36000 quantization_loss:  0.022910522297024727
p mean is: tensor(-0.6033, device='cuda:4')
epoch:  37000 quantization_loss:  0.022796140983700752
p mean is: tensor(-0.6403, device='cuda:4')
epoch:  38000 quantization_loss:  0.022718003019690514
p mean is: tensor(-0.6738, device='cuda:4')
epoch:  39000 quantization_loss:  0.022594425827264786
p mean is: tensor(-0.7037, device='cuda:4')
epoch:  40000 quantization_loss:  0.022627385333180428
p mean is: tensor(-0.7301, device='cuda:4')
epoch:  41000 quantization_loss:  0.022420790046453476
p mean is: tensor(-0.7535, device='cuda:4')
epoch:  42000 quantization_loss:  0.022354163229465485
p mean is: tensor(-0.7743, device='cuda:4')
epoch:  43000 quantization_loss:  0.022332878783345222
p mean is: tensor(-0.7925, device='cuda:4')
epoch:  44000 quantization_loss:  0.022258562967181206
p mean is: tensor(-0.8086, device='cuda:4')
epoch:  45000 quantization_loss:  0.022278685122728348
p mean is: tensor(-0.8225, device='cuda:4')
epoch:  46000 quantization_loss:  0.02244829759001732
p mean is: tensor(-0.8349, device='cuda:4')
epoch:  47000 quantization_loss:  0.02211606130003929
p mean is: tensor(-0.8457, device='cuda:4')
epoch:  48000 quantization_loss:  0.022134656086564064
p mean is: tensor(-0.8551, device='cuda:4')
epoch:  49000 quantization_loss:  0.022038932889699936
p mean is: tensor(-0.8635, device='cuda:4')
epoch:  50000 quantization_loss:  0.022009367123246193
p mean is: tensor(-0.8709, device='cuda:4')
epoch:  51000 quantization_loss:  0.022003838792443275
p mean is: tensor(-0.8775, device='cuda:4')
epoch:  52000 quantization_loss:  0.021956592798233032
p mean is: tensor(-0.8834, device='cuda:4')
epoch:  53000 quantization_loss:  0.02196911722421646
p mean is: tensor(-0.8886, device='cuda:4')
epoch:  54000 quantization_loss:  0.021949658170342445
p mean is: tensor(-0.8934, device='cuda:4')
epoch:  55000 quantization_loss:  0.021909847855567932
p mean is: tensor(-0.8976, device='cuda:4')
epoch:  56000 quantization_loss:  0.02189229428768158
p mean is: tensor(-0.9016, device='cuda:4')
epoch:  57000 quantization_loss:  0.021877920255064964
p mean is: tensor(-0.9050, device='cuda:4')
epoch:  58000 quantization_loss:  0.021848229691386223
p mean is: tensor(-0.9082, device='cuda:4')
epoch:  59000 quantization_loss:  0.021836694329977036
p mean is: tensor(-0.9111, device='cuda:4')
epoch:  60000 quantization_loss:  0.021840719506144524
p mean is: tensor(-0.9138, device='cuda:4')
epoch:  61000 quantization_loss:  0.021810192614793777
p mean is: tensor(-0.9163, device='cuda:4')
epoch:  62000 quantization_loss:  0.021805547177791595
p mean is: tensor(-0.9186, device='cuda:4')
epoch:  63000 quantization_loss:  0.021786896511912346
p mean is: tensor(-0.9209, device='cuda:4')
epoch:  64000 quantization_loss:  0.021770577877759933
p mean is: tensor(-0.9229, device='cuda:4')
epoch:  65000 quantization_loss:  0.021776603534817696
p mean is: tensor(-0.9246, device='cuda:4')
epoch:  66000 quantization_loss:  0.02175132930278778
p mean is: tensor(-0.9265, device='cuda:4')
epoch:  67000 quantization_loss:  0.02176288701593876
p mean is: tensor(-0.9282, device='cuda:4')
epoch:  68000 quantization_loss:  0.021745549514889717
p mean is: tensor(-0.9299, device='cuda:4')
epoch:  69000 quantization_loss:  0.021733446046710014
p mean is: tensor(-0.9314, device='cuda:4')
epoch:  70000 quantization_loss:  0.021734120324254036
p mean is: tensor(-0.9329, device='cuda:4')
epoch:  71000 quantization_loss:  0.02172832190990448
p mean is: tensor(-0.9344, device='cuda:4')
epoch:  72000 quantization_loss:  0.02173919416964054
p mean is: tensor(-0.9356, device='cuda:4')
epoch:  73000 quantization_loss:  0.021724672988057137
p mean is: tensor(-0.9369, device='cuda:4')
epoch:  74000 quantization_loss:  0.021701984107494354
p mean is: tensor(-0.9381, device='cuda:4')
epoch:  75000 quantization_loss:  0.02170560508966446
p mean is: tensor(-0.9393, device='cuda:4')
epoch:  76000 quantization_loss:  0.021700259298086166
p mean is: tensor(-0.9404, device='cuda:4')
epoch:  77000 quantization_loss:  0.021693062037229538
p mean is: tensor(-0.9416, device='cuda:4')
epoch:  78000 quantization_loss:  0.02169080823659897
p mean is: tensor(-0.9427, device='cuda:4')
epoch:  79000 quantization_loss:  0.021684270352125168
p mean is: tensor(-0.9436, device='cuda:4')
here
1.0.1.1.weight       | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =    1645 /    4608             ( 35.70%) | total_pruned =    2963 | shape = torch.Size([16, 32, 3, 3])
1.1.1.1.bias         | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.2.weight         | nonzeros =      12 /      16             ( 75.00%) | total_pruned =       4 | shape = torch.Size([16])
1.1.2.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.4.1.weight       | nonzeros =     553 /    2304             ( 24.00%) | total_pruned =    1751 | shape = torch.Size([16, 16, 3, 3])
1.1.4.1.bias         | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.5.weight         | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.1.5.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.7.1.0.1.1.weight | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([4, 16, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =     815 /    4608             ( 17.69%) | total_pruned =    3793 | shape = torch.Size([32, 16, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.2.weight   | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.1.7.1.1.2.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.4.1.weight | nonzeros =    1803 /    9216             ( 19.56%) | total_pruned =    7413 | shape = torch.Size([32, 32, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.5.weight   | nonzeros =      24 /      32             ( 75.00%) | total_pruned =       8 | shape = torch.Size([32])
1.1.7.1.1.5.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([4, 32, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    3389 /   18432             ( 18.39%) | total_pruned =   15043 | shape = torch.Size([64, 32, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    3941 /   36864             ( 10.69%) | total_pruned =   32923 | shape = torch.Size([64, 64, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      46 /     256             ( 17.97%) | total_pruned =     210 | shape = torch.Size([4, 64, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =     153 /   73728             (  0.21%) | total_pruned =   73575 | shape = torch.Size([128, 64, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      37 /     128             ( 28.91%) | total_pruned =      91 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =     143 /  147456             (  0.10%) | total_pruned =  147313 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =     218 /  147456             (  0.15%) | total_pruned =  147238 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =     725 /  147456             (  0.49%) | total_pruned =  146731 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    2531 /  147456             (  1.72%) | total_pruned =  144925 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    9916 /  147456             (  6.72%) | total_pruned =  137540 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      72 /     132             ( 54.55%) | total_pruned =      60 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   18142 /  152064             ( 11.93%) | total_pruned =  133922 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      74 /     132             ( 56.06%) | total_pruned =      58 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   19391 /  152064             ( 12.75%) | total_pruned =  132673 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      69 /     132             ( 52.27%) | total_pruned =      63 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   16963 /  152064             ( 11.16%) | total_pruned =  135101 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      61 /     132             ( 46.21%) | total_pruned =      71 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =    8215 /   76032             ( 10.80%) | total_pruned =   67817 | shape = torch.Size([64, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.4.weight | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.2.weight       | nonzeros =      33 /      68             ( 48.53%) | total_pruned =      35 | shape = torch.Size([68])
1.1.7.2.bias         | nonzeros =       0 /      68             (  0.00%) | total_pruned =      68 | shape = torch.Size([68])
1.1.7.3.1.weight     | nonzeros =    2292 /   19584             ( 11.70%) | total_pruned =   17292 | shape = torch.Size([32, 68, 3, 3])
1.1.7.3.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.4.weight       | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
1.1.7.4.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      17 /      36             ( 47.22%) | total_pruned =      19 | shape = torch.Size([36])
2.bias               | nonzeros =       0 /      36             (  0.00%) | total_pruned =      36 | shape = torch.Size([36])
3.1.weight           | nonzeros =    1122 /    5184             ( 21.64%) | total_pruned =    4062 | shape = torch.Size([16, 36, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      29 /      48             ( 60.42%) | total_pruned =      19 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 93201, pruned : 1358282, total: 1451483, Compression rate :      15.57x  ( 93.58% pruned)
PSNR of output image is:  18.40171043971947
Experiment done
