(3, 512, 512)
Starting vanilla DIP on 5 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.085541850009253'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/5/skip/det/2.0/1e-09
epoch:  0 quantization_loss:  0.06033032014966011
p mean is: tensor(0.0004, device='cuda:2')
epoch:  1000 quantization_loss:  0.05442943423986435
p mean is: tensor(0.0168, device='cuda:2')
epoch:  2000 quantization_loss:  0.054234057664871216
p mean is: tensor(0.0295, device='cuda:2')
epoch:  3000 quantization_loss:  0.053457994014024734
p mean is: tensor(0.0415, device='cuda:2')
epoch:  4000 quantization_loss:  0.05295277386903763
p mean is: tensor(0.0537, device='cuda:2')
epoch:  5000 quantization_loss:  0.05412248149514198
p mean is: tensor(0.0655, device='cuda:2')
epoch:  6000 quantization_loss:  0.053574129939079285
p mean is: tensor(0.0777, device='cuda:2')
epoch:  7000 quantization_loss:  0.05028050020337105
p mean is: tensor(0.0904, device='cuda:2')
epoch:  8000 quantization_loss:  0.04668376222252846
p mean is: tensor(0.1036, device='cuda:2')
epoch:  9000 quantization_loss:  0.04161496087908745
p mean is: tensor(0.1197, device='cuda:2')
epoch:  10000 quantization_loss:  0.03404461592435837
p mean is: tensor(0.1380, device='cuda:2')
epoch:  11000 quantization_loss:  0.030497781932353973
p mean is: tensor(0.1598, device='cuda:2')
epoch:  12000 quantization_loss:  0.028480257838964462
p mean is: tensor(0.1871, device='cuda:2')
epoch:  13000 quantization_loss:  0.027293264865875244
p mean is: tensor(0.2213, device='cuda:2')
epoch:  14000 quantization_loss:  0.023749535903334618
p mean is: tensor(0.2638, device='cuda:2')
epoch:  15000 quantization_loss:  0.022857114672660828
p mean is: tensor(0.3153, device='cuda:2')
epoch:  16000 quantization_loss:  0.02205348014831543
p mean is: tensor(0.3763, device='cuda:2')
epoch:  17000 quantization_loss:  0.021581947803497314
p mean is: tensor(0.4459, device='cuda:2')
epoch:  18000 quantization_loss:  0.021135468035936356
p mean is: tensor(0.5225, device='cuda:2')
epoch:  19000 quantization_loss:  0.020811669528484344
p mean is: tensor(0.6038, device='cuda:2')
epoch:  20000 quantization_loss:  0.0205460786819458
p mean is: tensor(0.6870, device='cuda:2')
epoch:  21000 quantization_loss:  0.020222706720232964
p mean is: tensor(0.7697, device='cuda:2')
epoch:  22000 quantization_loss:  0.01999594271183014
p mean is: tensor(0.8503, device='cuda:2')
epoch:  23000 quantization_loss:  0.01976381056010723
p mean is: tensor(0.9272, device='cuda:2')
epoch:  24000 quantization_loss:  0.01962265744805336
p mean is: tensor(0.9991, device='cuda:2')
epoch:  25000 quantization_loss:  0.01946742832660675
p mean is: tensor(1.0658, device='cuda:2')
epoch:  26000 quantization_loss:  0.01934497244656086
p mean is: tensor(1.1273, device='cuda:2')
epoch:  27000 quantization_loss:  0.019220009446144104
p mean is: tensor(1.1839, device='cuda:2')
epoch:  28000 quantization_loss:  0.019125141203403473
p mean is: tensor(1.2358, device='cuda:2')
epoch:  29000 quantization_loss:  0.019009649753570557
p mean is: tensor(1.2832, device='cuda:2')
epoch:  30000 quantization_loss:  0.018945006653666496
p mean is: tensor(1.3266, device='cuda:2')
epoch:  31000 quantization_loss:  0.018897688016295433
p mean is: tensor(1.3663, device='cuda:2')
epoch:  32000 quantization_loss:  0.018867958337068558
p mean is: tensor(1.4028, device='cuda:2')
epoch:  33000 quantization_loss:  0.018756069242954254
p mean is: tensor(1.4363, device='cuda:2')
epoch:  34000 quantization_loss:  0.018686719238758087
p mean is: tensor(1.4670, device='cuda:2')
epoch:  35000 quantization_loss:  0.018648244440555573
p mean is: tensor(1.4955, device='cuda:2')
epoch:  36000 quantization_loss:  0.018600977957248688
p mean is: tensor(1.5217, device='cuda:2')
epoch:  37000 quantization_loss:  0.01855490915477276
p mean is: tensor(1.5460, device='cuda:2')
epoch:  38000 quantization_loss:  0.018604718148708344
p mean is: tensor(1.5686, device='cuda:2')
epoch:  39000 quantization_loss:  0.018496958538889885
p mean is: tensor(1.5896, device='cuda:2')
epoch:  40000 quantization_loss:  0.018475214019417763
p mean is: tensor(1.6092, device='cuda:2')
epoch:  41000 quantization_loss:  0.01844104938209057
p mean is: tensor(1.6276, device='cuda:2')
epoch:  42000 quantization_loss:  0.018409065902233124
p mean is: tensor(1.6447, device='cuda:2')
epoch:  43000 quantization_loss:  0.0183909609913826
p mean is: tensor(1.6608, device='cuda:2')
epoch:  44000 quantization_loss:  0.01837807334959507
p mean is: tensor(1.6759, device='cuda:2')
epoch:  45000 quantization_loss:  0.01834423467516899
p mean is: tensor(1.6901, device='cuda:2')
epoch:  46000 quantization_loss:  0.01834706775844097
p mean is: tensor(1.7036, device='cuda:2')
epoch:  47000 quantization_loss:  0.018313298001885414
p mean is: tensor(1.7161, device='cuda:2')
epoch:  48000 quantization_loss:  0.018303895369172096
p mean is: tensor(1.7280, device='cuda:2')
epoch:  49000 quantization_loss:  0.018296154215931892
p mean is: tensor(1.7394, device='cuda:2')
epoch:  50000 quantization_loss:  0.018277721479535103
p mean is: tensor(1.7501, device='cuda:2')
epoch:  51000 quantization_loss:  0.01826639287173748
p mean is: tensor(1.7602, device='cuda:2')
epoch:  52000 quantization_loss:  0.018247777596116066
p mean is: tensor(1.7697, device='cuda:2')
epoch:  53000 quantization_loss:  0.018257880583405495
p mean is: tensor(1.7787, device='cuda:2')
epoch:  54000 quantization_loss:  0.018108323216438293
p mean is: tensor(1.7872, device='cuda:2')
epoch:  55000 quantization_loss:  0.01804586686193943
p mean is: tensor(1.7951, device='cuda:2')
epoch:  56000 quantization_loss:  0.018001584336161613
p mean is: tensor(1.8020, device='cuda:2')
epoch:  57000 quantization_loss:  0.017934350296854973
p mean is: tensor(1.8090, device='cuda:2')
epoch:  58000 quantization_loss:  0.017881255596876144
p mean is: tensor(1.8160, device='cuda:2')
epoch:  59000 quantization_loss:  0.0178136695176363
p mean is: tensor(1.8228, device='cuda:2')
epoch:  60000 quantization_loss:  0.017767449840903282
p mean is: tensor(1.8297, device='cuda:2')
epoch:  61000 quantization_loss:  0.017730241641402245
p mean is: tensor(1.8360, device='cuda:2')
epoch:  62000 quantization_loss:  0.017755305394530296
p mean is: tensor(1.8423, device='cuda:2')
epoch:  63000 quantization_loss:  0.017687074840068817
p mean is: tensor(1.8483, device='cuda:2')
epoch:  64000 quantization_loss:  0.017673954367637634
p mean is: tensor(1.8541, device='cuda:2')
epoch:  65000 quantization_loss:  0.01765596494078636
p mean is: tensor(1.8596, device='cuda:2')
epoch:  66000 quantization_loss:  0.017647597938776016
p mean is: tensor(1.8650, device='cuda:2')
epoch:  67000 quantization_loss:  0.01764237880706787
p mean is: tensor(1.8701, device='cuda:2')
epoch:  68000 quantization_loss:  0.017637502402067184
p mean is: tensor(1.8753, device='cuda:2')
epoch:  69000 quantization_loss:  0.01766483671963215
p mean is: tensor(1.8803, device='cuda:2')
epoch:  70000 quantization_loss:  0.017609307542443275
p mean is: tensor(1.8851, device='cuda:2')
epoch:  71000 quantization_loss:  0.01763506792485714
p mean is: tensor(1.8898, device='cuda:2')
epoch:  72000 quantization_loss:  0.0175915714353323
p mean is: tensor(1.8943, device='cuda:2')
epoch:  73000 quantization_loss:  0.017589513212442398
p mean is: tensor(1.8986, device='cuda:2')
epoch:  74000 quantization_loss:  0.017580697312951088
p mean is: tensor(1.9029, device='cuda:2')
epoch:  75000 quantization_loss:  0.017578953877091408
p mean is: tensor(1.9072, device='cuda:2')
epoch:  76000 quantization_loss:  0.017572395503520966
p mean is: tensor(1.9113, device='cuda:2')
epoch:  77000 quantization_loss:  0.017571579664945602
p mean is: tensor(1.9151, device='cuda:2')
epoch:  78000 quantization_loss:  0.017563270404934883
p mean is: tensor(1.9190, device='cuda:2')
epoch:  79000 quantization_loss:  0.017556747421622276
p mean is: tensor(1.9228, device='cuda:2')
here
1.0.1.1.weight       | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =    3842 /    4608             ( 83.38%) | total_pruned =     766 | shape = torch.Size([16, 32, 3, 3])
1.1.1.1.bias         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.2.weight         | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.1.2.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.4.1.weight       | nonzeros =    2102 /    2304             ( 91.23%) | total_pruned =     202 | shape = torch.Size([16, 16, 3, 3])
1.1.4.1.bias         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.5.weight         | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.1.5.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.7.1.0.1.1.weight | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 16, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =    3895 /    4608             ( 84.53%) | total_pruned =     713 | shape = torch.Size([32, 16, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.1.1.2.weight   | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
1.1.7.1.1.2.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.4.1.weight | nonzeros =    7584 /    9216             ( 82.29%) | total_pruned =    1632 | shape = torch.Size([32, 32, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.1.1.5.weight   | nonzeros =      26 /      32             ( 81.25%) | total_pruned =       6 | shape = torch.Size([32])
1.1.7.1.1.5.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 32, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   15135 /   18432             ( 82.11%) | total_pruned =    3297 | shape = torch.Size([64, 32, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   31397 /   36864             ( 85.17%) | total_pruned =    5467 | shape = torch.Size([64, 64, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     189 /     256             ( 73.83%) | total_pruned =      67 | shape = torch.Size([4, 64, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   70856 /   73728             ( 96.10%) | total_pruned =    2872 | shape = torch.Size([128, 64, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  144194 /  147456             ( 97.79%) | total_pruned =    3262 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     405 /     512             ( 79.10%) | total_pruned =     107 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =  146826 /  147456             ( 99.57%) | total_pruned =     630 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  145454 /  147456             ( 98.64%) | total_pruned =    2002 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     439 /     512             ( 85.74%) | total_pruned =      73 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =  142922 /  147456             ( 96.93%) | total_pruned =    4534 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  132533 /  147456             ( 89.88%) | total_pruned =   14923 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      97 /     132             ( 73.48%) | total_pruned =      35 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  124885 /  152064             ( 82.13%) | total_pruned =   27179 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      95 /     132             ( 71.97%) | total_pruned =      37 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  120980 /  152064             ( 79.56%) | total_pruned =   31084 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      98 /     132             ( 74.24%) | total_pruned =      34 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  121351 /  152064             ( 79.80%) | total_pruned =   30713 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      88 /     132             ( 66.67%) | total_pruned =      44 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =   61815 /   76032             ( 81.30%) | total_pruned =   14217 | shape = torch.Size([64, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.4.weight | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.2.weight       | nonzeros =      43 /      68             ( 63.24%) | total_pruned =      25 | shape = torch.Size([68])
1.1.7.2.bias         | nonzeros =       0 /      68             (  0.00%) | total_pruned =      68 | shape = torch.Size([68])
1.1.7.3.1.weight     | nonzeros =   15790 /   19584             ( 80.63%) | total_pruned =    3794 | shape = torch.Size([32, 68, 3, 3])
1.1.7.3.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.4.weight       | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
1.1.7.4.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      21 /      36             ( 58.33%) | total_pruned =      15 | shape = torch.Size([36])
2.bias               | nonzeros =       0 /      36             (  0.00%) | total_pruned =      36 | shape = torch.Size([36])
3.1.weight           | nonzeros =    3706 /    5184             ( 71.49%) | total_pruned =    1478 | shape = torch.Size([16, 36, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      30 /      48             ( 62.50%) | total_pruned =      18 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 1299811, pruned : 151672, total: 1451483, Compression rate :       1.12x  ( 10.45% pruned)
PSNR of output image is:  20.695854835784694
Experiment done
