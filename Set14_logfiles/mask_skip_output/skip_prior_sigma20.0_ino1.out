(3, 256, 256)
Starting vanilla DIP on 1 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.47496650063234'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/1/skip/det/20.0/1e-09
epoch:  0 quantization_loss:  0.10466265678405762
p mean is: tensor(0.0024, device='cuda:2')
epoch:  1000 quantization_loss:  0.08865116536617279
p mean is: tensor(0.0703, device='cuda:2')
epoch:  2000 quantization_loss:  0.08348049223423004
p mean is: tensor(0.1059, device='cuda:2')
epoch:  3000 quantization_loss:  0.08347845822572708
p mean is: tensor(0.1392, device='cuda:2')
epoch:  4000 quantization_loss:  0.08420570939779282
p mean is: tensor(0.1717, device='cuda:2')
epoch:  5000 quantization_loss:  0.08390777558088303
p mean is: tensor(0.2043, device='cuda:2')
epoch:  6000 quantization_loss:  0.0824781060218811
p mean is: tensor(0.2371, device='cuda:2')
epoch:  7000 quantization_loss:  0.08355679363012314
p mean is: tensor(0.2695, device='cuda:2')
epoch:  8000 quantization_loss:  0.08317359536886215
p mean is: tensor(0.3015, device='cuda:2')
epoch:  9000 quantization_loss:  0.08197721838951111
p mean is: tensor(0.3340, device='cuda:2')
epoch:  10000 quantization_loss:  0.08103983104228973
p mean is: tensor(0.3671, device='cuda:2')
epoch:  11000 quantization_loss:  0.08296389877796173
p mean is: tensor(0.4006, device='cuda:2')
epoch:  12000 quantization_loss:  0.08238212019205093
p mean is: tensor(0.4354, device='cuda:2')
epoch:  13000 quantization_loss:  0.073145292699337
p mean is: tensor(0.4709, device='cuda:2')
epoch:  14000 quantization_loss:  0.06720493733882904
p mean is: tensor(0.5131, device='cuda:2')
epoch:  15000 quantization_loss:  0.0610259547829628
p mean is: tensor(0.5669, device='cuda:2')
epoch:  16000 quantization_loss:  0.05081625282764435
p mean is: tensor(0.6292, device='cuda:2')
epoch:  17000 quantization_loss:  0.04785938188433647
p mean is: tensor(0.7090, device='cuda:2')
epoch:  18000 quantization_loss:  0.045593418180942535
p mean is: tensor(0.8099, device='cuda:2')
epoch:  19000 quantization_loss:  0.04458105191588402
p mean is: tensor(0.9344, device='cuda:2')
epoch:  20000 quantization_loss:  0.040920402854681015
p mean is: tensor(1.0881, device='cuda:2')
epoch:  21000 quantization_loss:  0.039014704525470734
p mean is: tensor(1.2726, device='cuda:2')
epoch:  22000 quantization_loss:  0.03766617551445961
p mean is: tensor(1.4875, device='cuda:2')
epoch:  23000 quantization_loss:  0.03582514077425003
p mean is: tensor(1.7275, device='cuda:2')
epoch:  24000 quantization_loss:  0.033936046063899994
p mean is: tensor(1.9830, device='cuda:2')
epoch:  25000 quantization_loss:  0.03274552896618843
p mean is: tensor(2.2479, device='cuda:2')
epoch:  26000 quantization_loss:  0.03043639473617077
p mean is: tensor(2.5135, device='cuda:2')
epoch:  27000 quantization_loss:  0.030070407316088676
p mean is: tensor(2.7698, device='cuda:2')
epoch:  28000 quantization_loss:  0.029056377708911896
p mean is: tensor(3.0108, device='cuda:2')
epoch:  29000 quantization_loss:  0.028241224586963654
p mean is: tensor(3.2338, device='cuda:2')
epoch:  30000 quantization_loss:  0.027810821309685707
p mean is: tensor(3.4379, device='cuda:2')
epoch:  31000 quantization_loss:  0.02769550494849682
p mean is: tensor(3.6240, device='cuda:2')
epoch:  32000 quantization_loss:  0.027329348027706146
p mean is: tensor(3.7928, device='cuda:2')
epoch:  33000 quantization_loss:  0.027120795100927353
p mean is: tensor(3.9468, device='cuda:2')
epoch:  34000 quantization_loss:  0.02685287967324257
p mean is: tensor(4.0874, device='cuda:2')
epoch:  35000 quantization_loss:  0.026675254106521606
p mean is: tensor(4.2159, device='cuda:2')
epoch:  36000 quantization_loss:  0.026565376669168472
p mean is: tensor(4.3337, device='cuda:2')
epoch:  37000 quantization_loss:  0.026503074914216995
p mean is: tensor(4.4422, device='cuda:2')
epoch:  38000 quantization_loss:  0.02631879597902298
p mean is: tensor(4.5424, device='cuda:2')
epoch:  39000 quantization_loss:  0.026273025199770927
p mean is: tensor(4.6354, device='cuda:2')
epoch:  40000 quantization_loss:  0.026230204850435257
p mean is: tensor(4.7220, device='cuda:2')
epoch:  41000 quantization_loss:  0.02613854967057705
p mean is: tensor(4.8031, device='cuda:2')
epoch:  42000 quantization_loss:  0.02603498473763466
p mean is: tensor(4.8789, device='cuda:2')
epoch:  43000 quantization_loss:  0.026002559810876846
p mean is: tensor(4.9504, device='cuda:2')
epoch:  44000 quantization_loss:  0.02602590247988701
p mean is: tensor(5.0177, device='cuda:2')
epoch:  45000 quantization_loss:  0.025847766548395157
p mean is: tensor(5.0815, device='cuda:2')
epoch:  46000 quantization_loss:  0.02581106685101986
p mean is: tensor(5.1421, device='cuda:2')
epoch:  47000 quantization_loss:  0.02579471468925476
p mean is: tensor(5.1998, device='cuda:2')
epoch:  48000 quantization_loss:  0.025724399834871292
p mean is: tensor(5.2548, device='cuda:2')
epoch:  49000 quantization_loss:  0.025709982961416245
p mean is: tensor(5.3075, device='cuda:2')
epoch:  50000 quantization_loss:  0.025659916922450066
p mean is: tensor(5.3581, device='cuda:2')
epoch:  51000 quantization_loss:  0.025644537061452866
p mean is: tensor(5.4064, device='cuda:2')
epoch:  52000 quantization_loss:  0.025636332109570503
p mean is: tensor(5.4528, device='cuda:2')
epoch:  53000 quantization_loss:  0.025627806782722473
p mean is: tensor(5.4974, device='cuda:2')
epoch:  54000 quantization_loss:  0.025533027946949005
p mean is: tensor(5.5404, device='cuda:2')
epoch:  55000 quantization_loss:  0.025531549006700516
p mean is: tensor(5.5819, device='cuda:2')
epoch:  56000 quantization_loss:  0.025537502020597458
p mean is: tensor(5.6220, device='cuda:2')
epoch:  57000 quantization_loss:  0.025533007457852364
p mean is: tensor(5.6607, device='cuda:2')
epoch:  58000 quantization_loss:  0.025495892390608788
p mean is: tensor(5.6982, device='cuda:2')
epoch:  59000 quantization_loss:  0.02544955164194107
p mean is: tensor(5.7346, device='cuda:2')
epoch:  60000 quantization_loss:  0.02543940395116806
p mean is: tensor(5.7698, device='cuda:2')
epoch:  61000 quantization_loss:  0.02544926479458809
p mean is: tensor(5.8039, device='cuda:2')
epoch:  62000 quantization_loss:  0.025466840714216232
p mean is: tensor(5.8370, device='cuda:2')
epoch:  63000 quantization_loss:  0.02540520392358303
p mean is: tensor(5.8692, device='cuda:2')
epoch:  64000 quantization_loss:  0.0253903865814209
p mean is: tensor(5.9005, device='cuda:2')
epoch:  65000 quantization_loss:  0.02539372257888317
p mean is: tensor(5.9310, device='cuda:2')
epoch:  66000 quantization_loss:  0.025380268692970276
p mean is: tensor(5.9606, device='cuda:2')
epoch:  67000 quantization_loss:  0.025362960994243622
p mean is: tensor(5.9896, device='cuda:2')
epoch:  68000 quantization_loss:  0.025363512337207794
p mean is: tensor(6.0178, device='cuda:2')
epoch:  69000 quantization_loss:  0.025359731167554855
p mean is: tensor(6.0452, device='cuda:2')
epoch:  70000 quantization_loss:  0.02541038952767849
p mean is: tensor(6.0720, device='cuda:2')
epoch:  71000 quantization_loss:  0.025346210226416588
p mean is: tensor(6.0981, device='cuda:2')
epoch:  72000 quantization_loss:  0.025343341752886772
p mean is: tensor(6.1236, device='cuda:2')
epoch:  73000 quantization_loss:  0.025320371612906456
p mean is: tensor(6.1485, device='cuda:2')
epoch:  74000 quantization_loss:  0.025312356650829315
p mean is: tensor(6.1729, device='cuda:2')
epoch:  75000 quantization_loss:  0.02531030774116516
p mean is: tensor(6.1967, device='cuda:2')
epoch:  76000 quantization_loss:  0.02534915693104267
p mean is: tensor(6.2200, device='cuda:2')
epoch:  77000 quantization_loss:  0.025298601016402245
p mean is: tensor(6.2429, device='cuda:2')
epoch:  78000 quantization_loss:  0.025299876928329468
p mean is: tensor(6.2651, device='cuda:2')
epoch:  79000 quantization_loss:  0.025294547900557518
p mean is: tensor(6.2869, device='cuda:2')
here
1.0.1.1.weight       | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =    3380 /    4608             ( 73.35%) | total_pruned =    1228 | shape = torch.Size([16, 32, 3, 3])
1.1.1.1.bias         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.2.weight         | nonzeros =      14 /      16             ( 87.50%) | total_pruned =       2 | shape = torch.Size([16])
1.1.2.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.4.1.weight       | nonzeros =    1976 /    2304             ( 85.76%) | total_pruned =     328 | shape = torch.Size([16, 16, 3, 3])
1.1.4.1.bias         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.5.weight         | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.1.5.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.7.1.0.1.1.weight | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 16, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =    4203 /    4608             ( 91.21%) | total_pruned =     405 | shape = torch.Size([32, 16, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.1.1.2.weight   | nonzeros =      25 /      32             ( 78.12%) | total_pruned =       7 | shape = torch.Size([32])
1.1.7.1.1.2.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.4.1.weight | nonzeros =    8522 /    9216             ( 92.47%) | total_pruned =     694 | shape = torch.Size([32, 32, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.1.1.5.weight   | nonzeros =      25 /      32             ( 78.12%) | total_pruned =       7 | shape = torch.Size([32])
1.1.7.1.1.5.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 32, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   17574 /   18432             ( 95.35%) | total_pruned =     858 | shape = torch.Size([64, 32, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   35686 /   36864             ( 96.80%) | total_pruned =    1178 | shape = torch.Size([64, 64, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     203 /     256             ( 79.30%) | total_pruned =      53 | shape = torch.Size([4, 64, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   73542 /   73728             ( 99.75%) | total_pruned =     186 | shape = torch.Size([128, 64, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  147303 /  147456             ( 99.90%) | total_pruned =     153 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     455 /     512             ( 88.87%) | total_pruned =      57 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =  147380 /  147456             ( 99.95%) | total_pruned =      76 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  147286 /  147456             ( 99.88%) | total_pruned =     170 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     494 /     512             ( 96.48%) | total_pruned =      18 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =  147021 /  147456             ( 99.70%) | total_pruned =     435 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  146265 /  147456             ( 99.19%) | total_pruned =    1191 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      83 /     132             ( 62.88%) | total_pruned =      49 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  148561 /  152064             ( 97.70%) | total_pruned =    3503 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      85 /     132             ( 64.39%) | total_pruned =      47 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  146656 /  152064             ( 96.44%) | total_pruned =    5408 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      76 /     132             ( 57.58%) | total_pruned =      56 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  145866 /  152064             ( 95.92%) | total_pruned =    6198 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      76 /     132             ( 57.58%) | total_pruned =      56 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =   71989 /   76032             ( 94.68%) | total_pruned =    4043 | shape = torch.Size([64, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.4.weight | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.2.weight       | nonzeros =      28 /      68             ( 41.18%) | total_pruned =      40 | shape = torch.Size([68])
1.1.7.2.bias         | nonzeros =       0 /      68             (  0.00%) | total_pruned =      68 | shape = torch.Size([68])
1.1.7.3.1.weight     | nonzeros =   18368 /   19584             ( 93.79%) | total_pruned =    1216 | shape = torch.Size([32, 68, 3, 3])
1.1.7.3.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.4.weight       | nonzeros =      25 /      32             ( 78.12%) | total_pruned =       7 | shape = torch.Size([32])
1.1.7.4.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      13 /      36             ( 36.11%) | total_pruned =      23 | shape = torch.Size([36])
2.bias               | nonzeros =       0 /      36             (  0.00%) | total_pruned =      36 | shape = torch.Size([36])
3.1.weight           | nonzeros =    4399 /    5184             ( 84.86%) | total_pruned =     785 | shape = torch.Size([16, 36, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      26 /      48             ( 54.17%) | total_pruned =      22 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 1420424, pruned : 31059, total: 1451483, Compression rate :       1.02x  (  2.14% pruned)
PSNR of output image is:  17.522720497181325
Experiment done
