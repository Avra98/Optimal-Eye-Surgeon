(3, 512, 512)
Starting vanilla DIP on 0 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '19.68083890592745'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/0/skip/det/-2.0/1e-09
(3, 512, 512)
Starting vanilla DIP on 0 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '19.66515453204088'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/0/skip/det/-2.0/1e-09
epoch:  0 quantization_loss:  0.09430938214063644
p mean is: tensor(-0.0003, device='cuda:2')
epoch:  1000 quantization_loss:  0.07188436388969421
p mean is: tensor(-0.0147, device='cuda:2')
epoch:  2000 quantization_loss:  0.07222703844308853
p mean is: tensor(-0.0268, device='cuda:2')
epoch:  3000 quantization_loss:  0.07421520352363586
p mean is: tensor(-0.0387, device='cuda:2')
epoch:  4000 quantization_loss:  0.07071805000305176
p mean is: tensor(-0.0504, device='cuda:2')
epoch:  5000 quantization_loss:  0.0700075775384903
p mean is: tensor(-0.0631, device='cuda:2')
epoch:  6000 quantization_loss:  0.06938014179468155
p mean is: tensor(-0.0778, device='cuda:2')
epoch:  7000 quantization_loss:  0.06922989338636398
p mean is: tensor(-0.0948, device='cuda:2')
epoch:  8000 quantization_loss:  0.06888312846422195
p mean is: tensor(-0.1146, device='cuda:2')
epoch:  9000 quantization_loss:  0.06926511973142624
p mean is: tensor(-0.1375, device='cuda:2')
epoch:  10000 quantization_loss:  0.06906013190746307
p mean is: tensor(-0.1633, device='cuda:2')
epoch:  11000 quantization_loss:  0.06882304698228836
p mean is: tensor(-0.1927, device='cuda:2')
epoch:  12000 quantization_loss:  0.06702923029661179
p mean is: tensor(-0.2248, device='cuda:2')
epoch:  13000 quantization_loss:  0.05913212150335312
p mean is: tensor(-0.2557, device='cuda:2')
epoch:  14000 quantization_loss:  0.052359212189912796
p mean is: tensor(-0.2864, device='cuda:2')
epoch:  15000 quantization_loss:  0.0459999218583107
p mean is: tensor(-0.3165, device='cuda:2')
epoch:  16000 quantization_loss:  0.044424619525671005
p mean is: tensor(-0.3487, device='cuda:2')
epoch:  17000 quantization_loss:  0.04295707121491432
p mean is: tensor(-0.3854, device='cuda:2')
epoch:  18000 quantization_loss:  0.04099263250827789
p mean is: tensor(-0.4288, device='cuda:2')
epoch:  19000 quantization_loss:  0.03967823088169098
p mean is: tensor(-0.4794, device='cuda:2')
epoch:  20000 quantization_loss:  0.03801596164703369
p mean is: tensor(-0.5378, device='cuda:2')
epoch:  21000 quantization_loss:  0.03745422512292862
p mean is: tensor(-0.6026, device='cuda:2')
epoch:  22000 quantization_loss:  0.036493852734565735
p mean is: tensor(-0.6728, device='cuda:2')
epoch:  23000 quantization_loss:  0.03583412989974022
p mean is: tensor(-0.7462, device='cuda:2')
epoch:  24000 quantization_loss:  0.03544710949063301
p mean is: tensor(-0.8206, device='cuda:2')
epoch:  25000 quantization_loss:  0.035139743238687515
p mean is: tensor(-0.8942, device='cuda:2')
epoch:  26000 quantization_loss:  0.03505786880850792
p mean is: tensor(-0.9655, device='cuda:2')
epoch:  27000 quantization_loss:  0.03479931503534317
p mean is: tensor(-1.0334, device='cuda:2')
epoch:  28000 quantization_loss:  0.034741561859846115
p mean is: tensor(-1.0968, device='cuda:2')
epoch:  29000 quantization_loss:  0.03351285681128502
p mean is: tensor(-1.1553, device='cuda:2')
epoch:  30000 quantization_loss:  0.032316457480192184
p mean is: tensor(-1.2086, device='cuda:2')
epoch:  31000 quantization_loss:  0.03205106034874916
p mean is: tensor(-1.2573, device='cuda:2')
epoch:  32000 quantization_loss:  0.031817443668842316
p mean is: tensor(-1.3013, device='cuda:2')
epoch:  33000 quantization_loss:  0.0325116403400898
p mean is: tensor(-1.3416, device='cuda:2')
epoch:  34000 quantization_loss:  0.03164936974644661
p mean is: tensor(-1.3788, device='cuda:2')
epoch:  35000 quantization_loss:  0.03142257034778595
p mean is: tensor(-1.4131, device='cuda:2')
epoch:  36000 quantization_loss:  0.03134125843644142
p mean is: tensor(-1.4447, device='cuda:2')
epoch:  37000 quantization_loss:  0.03131839632987976
p mean is: tensor(-1.4741, device='cuda:2')
epoch:  38000 quantization_loss:  0.031214291229844093
p mean is: tensor(-1.5013, device='cuda:2')
epoch:  39000 quantization_loss:  0.03119215928018093
p mean is: tensor(-1.5266, device='cuda:2')
epoch:  40000 quantization_loss:  0.031122999265789986
p mean is: tensor(-1.5501, device='cuda:2')
epoch:  41000 quantization_loss:  0.0310768224298954
p mean is: tensor(-1.5722, device='cuda:2')
epoch:  42000 quantization_loss:  0.031075049191713333
p mean is: tensor(-1.5930, device='cuda:2')
epoch:  43000 quantization_loss:  0.03099444881081581
p mean is: tensor(-1.6125, device='cuda:2')
epoch:  44000 quantization_loss:  0.03101266175508499
p mean is: tensor(-1.6307, device='cuda:2')
epoch:  45000 quantization_loss:  0.03093082271516323
p mean is: tensor(-1.6477, device='cuda:2')
epoch:  46000 quantization_loss:  0.030922476202249527
p mean is: tensor(-1.6636, device='cuda:2')
epoch:  47000 quantization_loss:  0.030885260552167892
p mean is: tensor(-1.6788, device='cuda:2')
epoch:  48000 quantization_loss:  0.030913420021533966
p mean is: tensor(-1.6931, device='cuda:2')
epoch:  49000 quantization_loss:  0.03084789589047432
p mean is: tensor(-1.7067, device='cuda:2')
epoch:  50000 quantization_loss:  0.030820349231362343
p mean is: tensor(-1.7195, device='cuda:2')
epoch:  51000 quantization_loss:  0.03089080937206745
p mean is: tensor(-1.7316, device='cuda:2')
epoch:  52000 quantization_loss:  0.030786456540226936
p mean is: tensor(-1.7430, device='cuda:2')
epoch:  53000 quantization_loss:  0.030759308487176895
p mean is: tensor(-1.7539, device='cuda:2')
epoch:  54000 quantization_loss:  0.030741598457098007
p mean is: tensor(-1.7643, device='cuda:2')
epoch:  55000 quantization_loss:  0.030730552971363068
p mean is: tensor(-1.7743, device='cuda:2')
epoch:  56000 quantization_loss:  0.03088419698178768
p mean is: tensor(-1.7837, device='cuda:2')
epoch:  57000 quantization_loss:  0.030713440850377083
p mean is: tensor(-1.7927, device='cuda:2')
epoch:  58000 quantization_loss:  0.030701741576194763
p mean is: tensor(-1.8013, device='cuda:2')
epoch:  59000 quantization_loss:  0.03069061040878296
p mean is: tensor(-1.8094, device='cuda:2')
epoch:  60000 quantization_loss:  0.030674315989017487
p mean is: tensor(-1.8172, device='cuda:2')
epoch:  61000 quantization_loss:  0.030668392777442932
p mean is: tensor(-1.8248, device='cuda:2')
epoch:  62000 quantization_loss:  0.030653750523924828
p mean is: tensor(-1.8320, device='cuda:2')
epoch:  63000 quantization_loss:  0.030649693682789803
p mean is: tensor(-1.8391, device='cuda:2')
epoch:  64000 quantization_loss:  0.03063889406621456
p mean is: tensor(-1.8459, device='cuda:2')
epoch:  65000 quantization_loss:  0.030646134167909622
p mean is: tensor(-1.8524, device='cuda:2')
epoch:  66000 quantization_loss:  0.0306241512298584
p mean is: tensor(-1.8586, device='cuda:2')
epoch:  67000 quantization_loss:  0.030616501346230507
p mean is: tensor(-1.8645, device='cuda:2')
epoch:  68000 quantization_loss:  0.030621837824583054
p mean is: tensor(-1.8703, device='cuda:2')
epoch:  69000 quantization_loss:  0.030607005581259727
p mean is: tensor(-1.8759, device='cuda:2')
epoch:  70000 quantization_loss:  0.030614346265792847
p mean is: tensor(-1.8814, device='cuda:2')
epoch:  71000 quantization_loss:  0.0306011363863945
p mean is: tensor(-1.8866, device='cuda:2')
epoch:  72000 quantization_loss:  0.03059709258377552
p mean is: tensor(-1.8918, device='cuda:2')
epoch:  73000 quantization_loss:  0.03059220314025879
p mean is: tensor(-1.8968, device='cuda:2')
epoch:  74000 quantization_loss:  0.03058202564716339
p mean is: tensor(-1.9016, device='cuda:2')
epoch:  75000 quantization_loss:  0.030581045895814896
p mean is: tensor(-1.9062, device='cuda:2')
epoch:  76000 quantization_loss:  0.030583007261157036
p mean is: tensor(-1.9107, device='cuda:2')
epoch:  77000 quantization_loss:  0.030576912686228752
p mean is: tensor(-1.9152, device='cuda:2')
epoch:  78000 quantization_loss:  0.030577510595321655
p mean is: tensor(-1.9196, device='cuda:2')
epoch:  79000 quantization_loss:  0.030574455857276917
p mean is: tensor(-1.9238, device='cuda:2')
here
1.0.1.1.weight       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =    1324 /    4608             ( 28.73%) | total_pruned =    3284 | shape = torch.Size([16, 32, 3, 3])
1.1.1.1.bias         | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.2.weight         | nonzeros =      11 /      16             ( 68.75%) | total_pruned =       5 | shape = torch.Size([16])
1.1.2.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.4.1.weight       | nonzeros =     338 /    2304             ( 14.67%) | total_pruned =    1966 | shape = torch.Size([16, 16, 3, 3])
1.1.4.1.bias         | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.5.weight         | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.1.5.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.7.1.0.1.1.weight | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([4, 16, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =     393 /    4608             (  8.53%) | total_pruned =    4215 | shape = torch.Size([32, 16, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.2.weight   | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
1.1.7.1.1.2.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.4.1.weight | nonzeros =     982 /    9216             ( 10.66%) | total_pruned =    8234 | shape = torch.Size([32, 32, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.5.weight   | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
1.1.7.1.1.5.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([4, 32, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    2334 /   18432             ( 12.66%) | total_pruned =   16098 | shape = torch.Size([64, 32, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    3086 /   36864             (  8.37%) | total_pruned =   33778 | shape = torch.Size([64, 64, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([4, 64, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    2724 /   73728             (  3.69%) | total_pruned =   71004 | shape = torch.Size([128, 64, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    3945 /  147456             (  2.68%) | total_pruned =  143511 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     129 /     512             ( 25.20%) | total_pruned =     383 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =     734 /  147456             (  0.50%) | total_pruned =  146722 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    2570 /  147456             (  1.74%) | total_pruned =  144886 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     132 /     512             ( 25.78%) | total_pruned =     380 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    5458 /  147456             (  3.70%) | total_pruned =  141998 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   16924 /  147456             ( 11.48%) | total_pruned =  130532 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      99 /     132             ( 75.00%) | total_pruned =      33 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   28103 /  152064             ( 18.48%) | total_pruned =  123961 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      95 /     132             ( 71.97%) | total_pruned =      37 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   23240 /  152064             ( 15.28%) | total_pruned =  128824 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      71 /     132             ( 53.79%) | total_pruned =      61 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   15199 /  152064             ( 10.00%) | total_pruned =  136865 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      61 /     132             ( 46.21%) | total_pruned =      71 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =    7780 /   76032             ( 10.23%) | total_pruned =   68252 | shape = torch.Size([64, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.4.weight | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.2.weight       | nonzeros =      35 /      68             ( 51.47%) | total_pruned =      33 | shape = torch.Size([68])
1.1.7.2.bias         | nonzeros =       0 /      68             (  0.00%) | total_pruned =      68 | shape = torch.Size([68])
1.1.7.3.1.weight     | nonzeros =    3146 /   19584             ( 16.06%) | total_pruned =   16438 | shape = torch.Size([32, 68, 3, 3])
1.1.7.3.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.4.weight       | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
1.1.7.4.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      22 /      36             ( 61.11%) | total_pruned =      14 | shape = torch.Size([36])
2.bias               | nonzeros =       0 /      36             (  0.00%) | total_pruned =      36 | shape = torch.Size([36])
3.1.weight           | nonzeros =    1321 /    5184             ( 25.48%) | total_pruned =    3863 | shape = torch.Size([16, 36, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      15 /      16             ( 93.75%) | total_pruned =       1 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      25 /      48             ( 52.08%) | total_pruned =      23 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 121304, pruned : 1330179, total: 1451483, Compression rate :      11.97x  ( 91.64% pruned)
PSNR of output image is:  15.777439882247135
Experiment done
