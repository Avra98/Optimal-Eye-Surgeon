(3, 256, 256)
Starting vanilla DIP on 3 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.34351030402574'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/3/skip/det/2.0/1e-09
epoch:  0 quantization_loss:  0.07246999442577362
p mean is: tensor(0.0003, device='cuda:4')
epoch:  1000 quantization_loss:  0.0687616616487503
p mean is: tensor(0.0120, device='cuda:4')
epoch:  2000 quantization_loss:  0.0686616376042366
p mean is: tensor(0.0209, device='cuda:4')
epoch:  3000 quantization_loss:  0.06835107505321503
p mean is: tensor(0.0299, device='cuda:4')
epoch:  4000 quantization_loss:  0.06834901869297028
p mean is: tensor(0.0385, device='cuda:4')
epoch:  5000 quantization_loss:  0.06837769597768784
p mean is: tensor(0.0474, device='cuda:4')
epoch:  6000 quantization_loss:  0.06874940544366837
p mean is: tensor(0.0562, device='cuda:4')
epoch:  7000 quantization_loss:  0.06824806332588196
p mean is: tensor(0.0652, device='cuda:4')
epoch:  8000 quantization_loss:  0.06813231855630875
p mean is: tensor(0.0749, device='cuda:4')
epoch:  9000 quantization_loss:  0.06814044713973999
p mean is: tensor(0.0853, device='cuda:4')
epoch:  10000 quantization_loss:  0.06834814697504044
p mean is: tensor(0.0968, device='cuda:4')
epoch:  11000 quantization_loss:  0.06785102933645248
p mean is: tensor(0.1094, device='cuda:4')
epoch:  12000 quantization_loss:  0.06842804700136185
p mean is: tensor(0.1237, device='cuda:4')
epoch:  13000 quantization_loss:  0.06801912188529968
p mean is: tensor(0.1395, device='cuda:4')
epoch:  14000 quantization_loss:  0.06867839395999908
p mean is: tensor(0.1567, device='cuda:4')
epoch:  15000 quantization_loss:  0.06806045770645142
p mean is: tensor(0.1743, device='cuda:4')
epoch:  16000 quantization_loss:  0.06804276257753372
p mean is: tensor(0.1927, device='cuda:4')
epoch:  17000 quantization_loss:  0.06829054653644562
p mean is: tensor(0.2111, device='cuda:4')
epoch:  18000 quantization_loss:  0.0674947127699852
p mean is: tensor(0.2273, device='cuda:4')
epoch:  19000 quantization_loss:  0.06655793637037277
p mean is: tensor(0.2413, device='cuda:4')
epoch:  20000 quantization_loss:  0.06701210141181946
p mean is: tensor(0.2545, device='cuda:4')
epoch:  21000 quantization_loss:  0.05795189365744591
p mean is: tensor(0.2662, device='cuda:4')
epoch:  22000 quantization_loss:  0.05292541906237602
p mean is: tensor(0.2792, device='cuda:4')
epoch:  23000 quantization_loss:  0.04879187047481537
p mean is: tensor(0.2944, device='cuda:4')
epoch:  24000 quantization_loss:  0.04435001686215401
p mean is: tensor(0.3139, device='cuda:4')
epoch:  25000 quantization_loss:  0.042134955525398254
p mean is: tensor(0.3392, device='cuda:4')
epoch:  26000 quantization_loss:  0.03901536762714386
p mean is: tensor(0.3720, device='cuda:4')
epoch:  27000 quantization_loss:  0.03524847328662872
p mean is: tensor(0.4133, device='cuda:4')
epoch:  28000 quantization_loss:  0.0327359102666378
p mean is: tensor(0.4639, device='cuda:4')
epoch:  29000 quantization_loss:  0.031461652368307114
p mean is: tensor(0.5242, device='cuda:4')
epoch:  30000 quantization_loss:  0.030526408925652504
p mean is: tensor(0.5932, device='cuda:4')
epoch:  31000 quantization_loss:  0.029787616804242134
p mean is: tensor(0.6696, device='cuda:4')
epoch:  32000 quantization_loss:  0.02875393256545067
p mean is: tensor(0.7504, device='cuda:4')
epoch:  33000 quantization_loss:  0.02824218012392521
p mean is: tensor(0.8334, device='cuda:4')
epoch:  34000 quantization_loss:  0.02769201621413231
p mean is: tensor(0.9162, device='cuda:4')
epoch:  35000 quantization_loss:  0.027470359578728676
p mean is: tensor(0.9969, device='cuda:4')
epoch:  36000 quantization_loss:  0.026274684816598892
p mean is: tensor(1.0740, device='cuda:4')
epoch:  37000 quantization_loss:  0.025978123769164085
p mean is: tensor(1.1463, device='cuda:4')
epoch:  38000 quantization_loss:  0.025619231164455414
p mean is: tensor(1.2130, device='cuda:4')
epoch:  39000 quantization_loss:  0.025214621797204018
p mean is: tensor(1.2741, device='cuda:4')
epoch:  40000 quantization_loss:  0.024985559284687042
p mean is: tensor(1.3297, device='cuda:4')
epoch:  41000 quantization_loss:  0.024907032027840614
p mean is: tensor(1.3802, device='cuda:4')
epoch:  42000 quantization_loss:  0.02460080198943615
p mean is: tensor(1.4255, device='cuda:4')
epoch:  43000 quantization_loss:  0.024415239691734314
p mean is: tensor(1.4660, device='cuda:4')
epoch:  44000 quantization_loss:  0.02423267252743244
p mean is: tensor(1.5024, device='cuda:4')
epoch:  45000 quantization_loss:  0.02420373074710369
p mean is: tensor(1.5352, device='cuda:4')
epoch:  46000 quantization_loss:  0.02406454272568226
p mean is: tensor(1.5645, device='cuda:4')
epoch:  47000 quantization_loss:  0.023900281637907028
p mean is: tensor(1.5910, device='cuda:4')
epoch:  48000 quantization_loss:  0.023836366832256317
p mean is: tensor(1.6148, device='cuda:4')
epoch:  49000 quantization_loss:  0.023790713399648666
p mean is: tensor(1.6363, device='cuda:4')
epoch:  50000 quantization_loss:  0.023672280833125114
p mean is: tensor(1.6556, device='cuda:4')
epoch:  51000 quantization_loss:  0.023623965680599213
p mean is: tensor(1.6732, device='cuda:4')
epoch:  52000 quantization_loss:  0.023574480786919594
p mean is: tensor(1.6893, device='cuda:4')
epoch:  53000 quantization_loss:  0.023517441004514694
p mean is: tensor(1.7038, device='cuda:4')
epoch:  54000 quantization_loss:  0.023209914565086365
p mean is: tensor(1.7171, device='cuda:4')
epoch:  55000 quantization_loss:  0.02314094826579094
p mean is: tensor(1.7292, device='cuda:4')
epoch:  56000 quantization_loss:  0.023079929873347282
p mean is: tensor(1.7403, device='cuda:4')
epoch:  57000 quantization_loss:  0.023019272834062576
p mean is: tensor(1.7506, device='cuda:4')
epoch:  58000 quantization_loss:  0.023004284128546715
p mean is: tensor(1.7600, device='cuda:4')
epoch:  59000 quantization_loss:  0.02297619916498661
p mean is: tensor(1.7687, device='cuda:4')
epoch:  60000 quantization_loss:  0.022918885573744774
p mean is: tensor(1.7767, device='cuda:4')
epoch:  61000 quantization_loss:  0.02291562408208847
p mean is: tensor(1.7843, device='cuda:4')
epoch:  62000 quantization_loss:  0.022890597581863403
p mean is: tensor(1.7913, device='cuda:4')
epoch:  63000 quantization_loss:  0.02286815270781517
p mean is: tensor(1.7979, device='cuda:4')
epoch:  64000 quantization_loss:  0.022842135280370712
p mean is: tensor(1.8039, device='cuda:4')
epoch:  65000 quantization_loss:  0.022819412872195244
p mean is: tensor(1.8096, device='cuda:4')
epoch:  66000 quantization_loss:  0.022829582914710045
p mean is: tensor(1.8149, device='cuda:4')
epoch:  67000 quantization_loss:  0.022815128788352013
p mean is: tensor(1.8199, device='cuda:4')
epoch:  68000 quantization_loss:  0.022795718163251877
p mean is: tensor(1.8246, device='cuda:4')
epoch:  69000 quantization_loss:  0.022775648161768913
p mean is: tensor(1.8290, device='cuda:4')
epoch:  70000 quantization_loss:  0.02276221662759781
p mean is: tensor(1.8333, device='cuda:4')
epoch:  71000 quantization_loss:  0.022742608562111855
p mean is: tensor(1.8374, device='cuda:4')
epoch:  72000 quantization_loss:  0.02274939976632595
p mean is: tensor(1.8411, device='cuda:4')
epoch:  73000 quantization_loss:  0.02274003066122532
p mean is: tensor(1.8447, device='cuda:4')
epoch:  74000 quantization_loss:  0.02272539772093296
p mean is: tensor(1.8483, device='cuda:4')
epoch:  75000 quantization_loss:  0.022725749760866165
p mean is: tensor(1.8516, device='cuda:4')
epoch:  76000 quantization_loss:  0.022714730352163315
p mean is: tensor(1.8547, device='cuda:4')
epoch:  77000 quantization_loss:  0.022682901471853256
p mean is: tensor(1.8577, device='cuda:4')
epoch:  78000 quantization_loss:  0.022693274542689323
p mean is: tensor(1.8606, device='cuda:4')
epoch:  79000 quantization_loss:  0.02268456667661667
p mean is: tensor(1.8633, device='cuda:4')
here
1.0.1.1.weight       | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =    2861 /    4608             ( 62.09%) | total_pruned =    1747 | shape = torch.Size([16, 32, 3, 3])
1.1.1.1.bias         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.2.weight         | nonzeros =      12 /      16             ( 75.00%) | total_pruned =       4 | shape = torch.Size([16])
1.1.2.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.4.1.weight       | nonzeros =    1819 /    2304             ( 78.95%) | total_pruned =     485 | shape = torch.Size([16, 16, 3, 3])
1.1.4.1.bias         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.5.weight         | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.1.5.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.7.1.0.1.1.weight | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([4, 16, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =    3675 /    4608             ( 79.75%) | total_pruned =     933 | shape = torch.Size([32, 16, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.1.1.2.weight   | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
1.1.7.1.1.2.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.4.1.weight | nonzeros =    7150 /    9216             ( 77.58%) | total_pruned =    2066 | shape = torch.Size([32, 32, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.1.1.5.weight   | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
1.1.7.1.1.5.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([4, 32, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   14086 /   18432             ( 76.42%) | total_pruned =    4346 | shape = torch.Size([64, 32, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   29676 /   36864             ( 80.50%) | total_pruned =    7188 | shape = torch.Size([64, 64, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     201 /     256             ( 78.52%) | total_pruned =      55 | shape = torch.Size([4, 64, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   71005 /   73728             ( 96.31%) | total_pruned =    2723 | shape = torch.Size([128, 64, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  144550 /  147456             ( 98.03%) | total_pruned =    2906 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     442 /     512             ( 86.33%) | total_pruned =      70 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =  147251 /  147456             ( 99.86%) | total_pruned =     205 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  146790 /  147456             ( 99.55%) | total_pruned =     666 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =  145308 /  147456             ( 98.54%) | total_pruned =    2148 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  139504 /  147456             ( 94.61%) | total_pruned =    7952 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      57 /     132             ( 43.18%) | total_pruned =      75 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  137840 /  152064             ( 90.65%) | total_pruned =   14224 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      71 /     132             ( 53.79%) | total_pruned =      61 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  134997 /  152064             ( 88.78%) | total_pruned =   17067 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      63 /     132             ( 47.73%) | total_pruned =      69 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  133414 /  152064             ( 87.74%) | total_pruned =   18650 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      72 /     132             ( 54.55%) | total_pruned =      60 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =   72090 /   76032             ( 94.82%) | total_pruned =    3942 | shape = torch.Size([64, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.4.weight | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.2.weight       | nonzeros =      16 /      68             ( 23.53%) | total_pruned =      52 | shape = torch.Size([68])
1.1.7.2.bias         | nonzeros =       0 /      68             (  0.00%) | total_pruned =      68 | shape = torch.Size([68])
1.1.7.3.1.weight     | nonzeros =   18749 /   19584             ( 95.74%) | total_pruned =     835 | shape = torch.Size([32, 68, 3, 3])
1.1.7.3.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.4.weight       | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.1.7.4.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      12 /      36             ( 33.33%) | total_pruned =      24 | shape = torch.Size([36])
2.bias               | nonzeros =       0 /      36             (  0.00%) | total_pruned =      36 | shape = torch.Size([36])
3.1.weight           | nonzeros =    4057 /    5184             ( 78.26%) | total_pruned =    1127 | shape = torch.Size([16, 36, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      15 /      16             ( 93.75%) | total_pruned =       1 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      34 /      48             ( 70.83%) | total_pruned =      14 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 1358984, pruned : 92499, total: 1451483, Compression rate :       1.07x  (  6.37% pruned)
PSNR of output image is:  18.317786383378987
Experiment done
