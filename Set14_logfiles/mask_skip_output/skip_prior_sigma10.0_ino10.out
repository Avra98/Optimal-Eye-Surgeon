(3, 512, 512)
Starting vanilla DIP on 10 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.175405829744903'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/10/skip/det/10.0/1e-09
epoch:  0 quantization_loss:  0.06867844611406326
p mean is: tensor(0.0015, device='cuda:4')
epoch:  1000 quantization_loss:  0.0620596744120121
p mean is: tensor(0.0649, device='cuda:4')
epoch:  2000 quantization_loss:  0.06085819751024246
p mean is: tensor(0.1077, device='cuda:4')
epoch:  3000 quantization_loss:  0.06317197531461716
p mean is: tensor(0.1477, device='cuda:4')
epoch:  4000 quantization_loss:  0.0618714801967144
p mean is: tensor(0.1871, device='cuda:4')
epoch:  5000 quantization_loss:  0.060815200209617615
p mean is: tensor(0.2264, device='cuda:4')
epoch:  6000 quantization_loss:  0.05998605117201805
p mean is: tensor(0.2658, device='cuda:4')
epoch:  7000 quantization_loss:  0.06004362180829048
p mean is: tensor(0.3068, device='cuda:4')
epoch:  8000 quantization_loss:  0.059901632368564606
p mean is: tensor(0.3488, device='cuda:4')
epoch:  9000 quantization_loss:  0.05989532172679901
p mean is: tensor(0.3926, device='cuda:4')
epoch:  10000 quantization_loss:  0.053449712693691254
p mean is: tensor(0.4357, device='cuda:4')
epoch:  11000 quantization_loss:  0.04674103483557701
p mean is: tensor(0.4854, device='cuda:4')
epoch:  12000 quantization_loss:  0.04100494086742401
p mean is: tensor(0.5456, device='cuda:4')
epoch:  13000 quantization_loss:  0.0357433557510376
p mean is: tensor(0.6213, device='cuda:4')
epoch:  14000 quantization_loss:  0.030617212876677513
p mean is: tensor(0.7144, device='cuda:4')
epoch:  15000 quantization_loss:  0.029447931796312332
p mean is: tensor(0.8276, device='cuda:4')
epoch:  16000 quantization_loss:  0.02657248266041279
p mean is: tensor(0.9638, device='cuda:4')
epoch:  17000 quantization_loss:  0.025181422010064125
p mean is: tensor(1.1260, device='cuda:4')
epoch:  18000 quantization_loss:  0.024062342941761017
p mean is: tensor(1.3130, device='cuda:4')
epoch:  19000 quantization_loss:  0.02295001409947872
p mean is: tensor(1.5192, device='cuda:4')
epoch:  20000 quantization_loss:  0.02188553288578987
p mean is: tensor(1.7362, device='cuda:4')
epoch:  21000 quantization_loss:  0.021093467250466347
p mean is: tensor(1.9554, device='cuda:4')
epoch:  22000 quantization_loss:  0.02029033750295639
p mean is: tensor(2.1683, device='cuda:4')
epoch:  23000 quantization_loss:  0.01958916336297989
p mean is: tensor(2.3694, device='cuda:4')
epoch:  24000 quantization_loss:  0.0192020982503891
p mean is: tensor(2.5554, device='cuda:4')
epoch:  25000 quantization_loss:  0.018800996243953705
p mean is: tensor(2.7254, device='cuda:4')
epoch:  26000 quantization_loss:  0.018423844128847122
p mean is: tensor(2.8802, device='cuda:4')
epoch:  27000 quantization_loss:  0.01821141317486763
p mean is: tensor(3.0210, device='cuda:4')
epoch:  28000 quantization_loss:  0.017823034897446632
p mean is: tensor(3.1491, device='cuda:4')
epoch:  29000 quantization_loss:  0.01763477921485901
p mean is: tensor(3.2658, device='cuda:4')
epoch:  30000 quantization_loss:  0.017350615933537483
p mean is: tensor(3.3727, device='cuda:4')
epoch:  31000 quantization_loss:  0.017361368983983994
p mean is: tensor(3.4711, device='cuda:4')
epoch:  32000 quantization_loss:  0.01708626002073288
p mean is: tensor(3.5618, device='cuda:4')
epoch:  33000 quantization_loss:  0.01687050238251686
p mean is: tensor(3.6461, device='cuda:4')
epoch:  34000 quantization_loss:  0.016823608428239822
p mean is: tensor(3.7248, device='cuda:4')
epoch:  35000 quantization_loss:  0.016703546047210693
p mean is: tensor(3.7983, device='cuda:4')
epoch:  36000 quantization_loss:  0.01660708524286747
p mean is: tensor(3.8674, device='cuda:4')
epoch:  37000 quantization_loss:  0.016482684761285782
p mean is: tensor(3.9326, device='cuda:4')
epoch:  38000 quantization_loss:  0.016435150057077408
p mean is: tensor(3.9942, device='cuda:4')
epoch:  39000 quantization_loss:  0.016340674832463264
p mean is: tensor(4.0526, device='cuda:4')
epoch:  40000 quantization_loss:  0.016296640038490295
p mean is: tensor(4.1080, device='cuda:4')
epoch:  41000 quantization_loss:  0.016250593587756157
p mean is: tensor(4.1610, device='cuda:4')
epoch:  42000 quantization_loss:  0.016179433092474937
p mean is: tensor(4.2115, device='cuda:4')
epoch:  43000 quantization_loss:  0.016112757846713066
p mean is: tensor(4.2597, device='cuda:4')
epoch:  44000 quantization_loss:  0.016080623492598534
p mean is: tensor(4.3057, device='cuda:4')
epoch:  45000 quantization_loss:  0.016028190031647682
p mean is: tensor(4.3499, device='cuda:4')
epoch:  46000 quantization_loss:  0.015957774594426155
p mean is: tensor(4.3923, device='cuda:4')
epoch:  47000 quantization_loss:  0.0159638412296772
p mean is: tensor(4.4329, device='cuda:4')
epoch:  48000 quantization_loss:  0.01592571847140789
p mean is: tensor(4.4721, device='cuda:4')
epoch:  49000 quantization_loss:  0.01593729294836521
p mean is: tensor(4.5098, device='cuda:4')
epoch:  50000 quantization_loss:  0.015864206477999687
p mean is: tensor(4.5462, device='cuda:4')
epoch:  51000 quantization_loss:  0.015840044245123863
p mean is: tensor(4.5813, device='cuda:4')
epoch:  52000 quantization_loss:  0.015824371948838234
p mean is: tensor(4.6153, device='cuda:4')
epoch:  53000 quantization_loss:  0.015806984156370163
p mean is: tensor(4.6479, device='cuda:4')
epoch:  54000 quantization_loss:  0.015781689435243607
p mean is: tensor(4.6795, device='cuda:4')
epoch:  55000 quantization_loss:  0.015768636018037796
p mean is: tensor(4.7101, device='cuda:4')
epoch:  56000 quantization_loss:  0.01574665494263172
p mean is: tensor(4.7397, device='cuda:4')
epoch:  57000 quantization_loss:  0.01573110744357109
p mean is: tensor(4.7685, device='cuda:4')
epoch:  58000 quantization_loss:  0.01571662351489067
p mean is: tensor(4.7964, device='cuda:4')
epoch:  59000 quantization_loss:  0.01570943184196949
p mean is: tensor(4.8234, device='cuda:4')
epoch:  60000 quantization_loss:  0.015701843425631523
p mean is: tensor(4.8498, device='cuda:4')
epoch:  61000 quantization_loss:  0.015694737434387207
p mean is: tensor(4.8753, device='cuda:4')
epoch:  62000 quantization_loss:  0.015683237463235855
p mean is: tensor(4.9001, device='cuda:4')
epoch:  63000 quantization_loss:  0.015659576281905174
p mean is: tensor(4.9244, device='cuda:4')
epoch:  64000 quantization_loss:  0.01566743291914463
p mean is: tensor(4.9481, device='cuda:4')
epoch:  65000 quantization_loss:  0.0156551580876112
p mean is: tensor(4.9712, device='cuda:4')
epoch:  66000 quantization_loss:  0.01564273238182068
p mean is: tensor(4.9937, device='cuda:4')
epoch:  67000 quantization_loss:  0.01563611999154091
p mean is: tensor(5.0156, device='cuda:4')
epoch:  68000 quantization_loss:  0.015625806525349617
p mean is: tensor(5.0369, device='cuda:4')
epoch:  69000 quantization_loss:  0.015617931261658669
p mean is: tensor(5.0579, device='cuda:4')
epoch:  70000 quantization_loss:  0.015614236705005169
p mean is: tensor(5.0783, device='cuda:4')
epoch:  71000 quantization_loss:  0.015616213902831078
p mean is: tensor(5.0983, device='cuda:4')
epoch:  72000 quantization_loss:  0.015599936246871948
p mean is: tensor(5.1178, device='cuda:4')
epoch:  73000 quantization_loss:  0.015600685030221939
p mean is: tensor(5.1368, device='cuda:4')
epoch:  74000 quantization_loss:  0.015594443306326866
p mean is: tensor(5.1554, device='cuda:4')
epoch:  75000 quantization_loss:  0.015588083304464817
p mean is: tensor(5.1736, device='cuda:4')
epoch:  76000 quantization_loss:  0.01556908804923296
p mean is: tensor(5.1914, device='cuda:4')
epoch:  77000 quantization_loss:  0.015576126985251904
p mean is: tensor(5.2089, device='cuda:4')
epoch:  78000 quantization_loss:  0.015586023218929768
p mean is: tensor(5.2259, device='cuda:4')
epoch:  79000 quantization_loss:  0.015559121966362
p mean is: tensor(5.2427, device='cuda:4')
here
1.0.1.1.weight       | nonzeros =     117 /     128             ( 91.41%) | total_pruned =      11 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =    3533 /    4608             ( 76.67%) | total_pruned =    1075 | shape = torch.Size([16, 32, 3, 3])
1.1.1.1.bias         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.2.weight         | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.1.2.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.4.1.weight       | nonzeros =    1970 /    2304             ( 85.50%) | total_pruned =     334 | shape = torch.Size([16, 16, 3, 3])
1.1.4.1.bias         | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.1.5.weight         | nonzeros =      11 /      16             ( 68.75%) | total_pruned =       5 | shape = torch.Size([16])
1.1.5.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.7.1.0.1.1.weight | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 16, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =    4158 /    4608             ( 90.23%) | total_pruned =     450 | shape = torch.Size([32, 16, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.1.1.2.weight   | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
1.1.7.1.1.2.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.4.1.weight | nonzeros =    8473 /    9216             ( 91.94%) | total_pruned =     743 | shape = torch.Size([32, 32, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.1.1.5.weight   | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
1.1.7.1.1.5.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([4, 32, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   17113 /   18432             ( 92.84%) | total_pruned =    1319 | shape = torch.Size([64, 32, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   34820 /   36864             ( 94.46%) | total_pruned =    2044 | shape = torch.Size([64, 64, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     226 /     256             ( 88.28%) | total_pruned =      30 | shape = torch.Size([4, 64, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =   72515 /   73728             ( 98.35%) | total_pruned =    1213 | shape = torch.Size([128, 64, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  145989 /  147456             ( 99.01%) | total_pruned =    1467 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     427 /     512             ( 83.40%) | total_pruned =      85 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =  146988 /  147456             ( 99.68%) | total_pruned =     468 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  146174 /  147456             ( 99.13%) | total_pruned =    1282 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     432 /     512             ( 84.38%) | total_pruned =      80 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =  145012 /  147456             ( 98.34%) | total_pruned =    2444 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =  138938 /  147456             ( 94.22%) | total_pruned =    8518 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      90 /     132             ( 68.18%) | total_pruned =      42 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  136176 /  152064             ( 89.55%) | total_pruned =   15888 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      91 /     132             ( 68.94%) | total_pruned =      41 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  135697 /  152064             ( 89.24%) | total_pruned =   16367 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      79 /     132             ( 59.85%) | total_pruned =      53 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =  136951 /  152064             ( 90.06%) | total_pruned =   15113 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      86 /     132             ( 65.15%) | total_pruned =      46 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =   69341 /   76032             ( 91.20%) | total_pruned =    6691 | shape = torch.Size([64, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.1.7.1.1.7.4.weight | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.2.weight       | nonzeros =      32 /      68             ( 47.06%) | total_pruned =      36 | shape = torch.Size([68])
1.1.7.2.bias         | nonzeros =       0 /      68             (  0.00%) | total_pruned =      68 | shape = torch.Size([68])
1.1.7.3.1.weight     | nonzeros =   17804 /   19584             ( 90.91%) | total_pruned =    1780 | shape = torch.Size([32, 68, 3, 3])
1.1.7.3.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.1.7.4.weight       | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
1.1.7.4.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      18 /      36             ( 50.00%) | total_pruned =      18 | shape = torch.Size([36])
2.bias               | nonzeros =       0 /      36             (  0.00%) | total_pruned =      36 | shape = torch.Size([36])
3.1.weight           | nonzeros =    4218 /    5184             ( 81.37%) | total_pruned =     966 | shape = torch.Size([16, 36, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      33 /      48             ( 68.75%) | total_pruned =      15 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 1370356, pruned : 81127, total: 1451483, Compression rate :       1.06x  (  5.59% pruned)
PSNR of output image is:  22.41580906092324
Experiment done
