(3, 512, 512)
Starting vanilla DIP on 2 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.4306072586291'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/2/skip/det/-1.5/1e-09
(3, 512, 512)
Starting vanilla DIP on 2 using SAM(sigma=0.1,lr=0.01,decay=0,beta=0)
Noisy PSNR is '20.437046140863444'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Set14/mask/2/skip/det/-1.5/1e-09
epoch:  0 quantization_loss:  0.0945432037115097
p mean is: tensor(-0.0003, device='cuda:2')
epoch:  1000 quantization_loss:  0.07892823964357376
p mean is: tensor(-0.0098, device='cuda:2')
epoch:  2000 quantization_loss:  0.07392051070928574
p mean is: tensor(-0.0165, device='cuda:2')
epoch:  3000 quantization_loss:  0.07339225709438324
p mean is: tensor(-0.0227, device='cuda:2')
epoch:  4000 quantization_loss:  0.07241695374250412
p mean is: tensor(-0.0287, device='cuda:2')
epoch:  5000 quantization_loss:  0.06703051179647446
p mean is: tensor(-0.0356, device='cuda:2')
epoch:  6000 quantization_loss:  0.06607665121555328
p mean is: tensor(-0.0434, device='cuda:2')
epoch:  7000 quantization_loss:  0.06240753456950188
p mean is: tensor(-0.0534, device='cuda:2')
epoch:  8000 quantization_loss:  0.05691307410597801
p mean is: tensor(-0.0669, device='cuda:2')
epoch:  9000 quantization_loss:  0.0500965490937233
p mean is: tensor(-0.0824, device='cuda:2')
epoch:  10000 quantization_loss:  0.046948641538619995
p mean is: tensor(-0.1007, device='cuda:2')
epoch:  11000 quantization_loss:  0.04546269401907921
p mean is: tensor(-0.1238, device='cuda:2')
epoch:  12000 quantization_loss:  0.04320546239614487
p mean is: tensor(-0.1527, device='cuda:2')
epoch:  13000 quantization_loss:  0.039322007447481155
p mean is: tensor(-0.1875, device='cuda:2')
epoch:  14000 quantization_loss:  0.03904678672552109
p mean is: tensor(-0.2291, device='cuda:2')
epoch:  15000 quantization_loss:  0.03814805671572685
p mean is: tensor(-0.2774, device='cuda:2')
epoch:  16000 quantization_loss:  0.03635096549987793
p mean is: tensor(-0.3317, device='cuda:2')
epoch:  17000 quantization_loss:  0.035721585154533386
p mean is: tensor(-0.3905, device='cuda:2')
epoch:  18000 quantization_loss:  0.035646069794893265
p mean is: tensor(-0.4523, device='cuda:2')
epoch:  19000 quantization_loss:  0.03513509780168533
p mean is: tensor(-0.5157, device='cuda:2')
epoch:  20000 quantization_loss:  0.034802213311195374
p mean is: tensor(-0.5786, device='cuda:2')
epoch:  21000 quantization_loss:  0.03452663496136665
p mean is: tensor(-0.6393, device='cuda:2')
epoch:  22000 quantization_loss:  0.0342857651412487
p mean is: tensor(-0.6973, device='cuda:2')
epoch:  23000 quantization_loss:  0.034118033945560455
p mean is: tensor(-0.7518, device='cuda:2')
epoch:  24000 quantization_loss:  0.034017741680145264
p mean is: tensor(-0.8024, device='cuda:2')
epoch:  25000 quantization_loss:  0.03377802297472954
p mean is: tensor(-0.8487, device='cuda:2')
epoch:  26000 quantization_loss:  0.03366370126605034
p mean is: tensor(-0.8911, device='cuda:2')
epoch:  27000 quantization_loss:  0.03351897373795509
p mean is: tensor(-0.9298, device='cuda:2')
epoch:  28000 quantization_loss:  0.03345109522342682
p mean is: tensor(-0.9653, device='cuda:2')
epoch:  29000 quantization_loss:  0.03331931680440903
p mean is: tensor(-0.9976, device='cuda:2')
epoch:  30000 quantization_loss:  0.03327193856239319
p mean is: tensor(-1.0271, device='cuda:2')
epoch:  31000 quantization_loss:  0.03321734815835953
p mean is: tensor(-1.0540, device='cuda:2')
epoch:  32000 quantization_loss:  0.033098965883255005
p mean is: tensor(-1.0788, device='cuda:2')
epoch:  33000 quantization_loss:  0.033018629997968674
p mean is: tensor(-1.1012, device='cuda:2')
epoch:  34000 quantization_loss:  0.032962407916784286
p mean is: tensor(-1.1220, device='cuda:2')
epoch:  35000 quantization_loss:  0.03291596099734306
p mean is: tensor(-1.1411, device='cuda:2')
epoch:  36000 quantization_loss:  0.032841067761182785
p mean is: tensor(-1.1587, device='cuda:2')
epoch:  37000 quantization_loss:  0.03281249850988388
p mean is: tensor(-1.1749, device='cuda:2')
epoch:  38000 quantization_loss:  0.03276386857032776
p mean is: tensor(-1.1900, device='cuda:2')
epoch:  39000 quantization_loss:  0.0327354297041893
p mean is: tensor(-1.2041, device='cuda:2')
epoch:  40000 quantization_loss:  0.032693784683942795
p mean is: tensor(-1.2172, device='cuda:2')
epoch:  41000 quantization_loss:  0.03265528753399849
p mean is: tensor(-1.2295, device='cuda:2')
epoch:  42000 quantization_loss:  0.032639481127262115
p mean is: tensor(-1.2408, device='cuda:2')
epoch:  43000 quantization_loss:  0.032594308257102966
p mean is: tensor(-1.2515, device='cuda:2')
epoch:  44000 quantization_loss:  0.031829044222831726
p mean is: tensor(-1.2606, device='cuda:2')
epoch:  45000 quantization_loss:  0.03133208677172661
p mean is: tensor(-1.2690, device='cuda:2')
epoch:  46000 quantization_loss:  0.031196938827633858
p mean is: tensor(-1.2771, device='cuda:2')
epoch:  47000 quantization_loss:  0.03118615597486496
p mean is: tensor(-1.2850, device='cuda:2')
epoch:  48000 quantization_loss:  0.031056495383381844
p mean is: tensor(-1.2926, device='cuda:2')
epoch:  49000 quantization_loss:  0.031014051288366318
p mean is: tensor(-1.3000, device='cuda:2')
epoch:  50000 quantization_loss:  0.030981041491031647
p mean is: tensor(-1.3070, device='cuda:2')
epoch:  51000 quantization_loss:  0.031019050627946854
p mean is: tensor(-1.3138, device='cuda:2')
epoch:  52000 quantization_loss:  0.030904285609722137
p mean is: tensor(-1.3204, device='cuda:2')
epoch:  53000 quantization_loss:  0.03088134154677391
p mean is: tensor(-1.3268, device='cuda:2')
epoch:  54000 quantization_loss:  0.030851460993289948
p mean is: tensor(-1.3329, device='cuda:2')
epoch:  55000 quantization_loss:  0.03084331378340721
p mean is: tensor(-1.3387, device='cuda:2')
epoch:  56000 quantization_loss:  0.030830077826976776
p mean is: tensor(-1.3443, device='cuda:2')
epoch:  57000 quantization_loss:  0.03079943172633648
p mean is: tensor(-1.3496, device='cuda:2')
epoch:  58000 quantization_loss:  0.030789952725172043
p mean is: tensor(-1.3547, device='cuda:2')
epoch:  59000 quantization_loss:  0.03078664094209671
p mean is: tensor(-1.3597, device='cuda:2')
epoch:  60000 quantization_loss:  0.030750224366784096
p mean is: tensor(-1.3647, device='cuda:2')
epoch:  61000 quantization_loss:  0.030736438930034637
p mean is: tensor(-1.3693, device='cuda:2')
epoch:  62000 quantization_loss:  0.030730534344911575
p mean is: tensor(-1.3738, device='cuda:2')
epoch:  63000 quantization_loss:  0.030587203800678253
p mean is: tensor(-1.3781, device='cuda:2')
epoch:  64000 quantization_loss:  0.03057197667658329
p mean is: tensor(-1.3824, device='cuda:2')
epoch:  65000 quantization_loss:  0.03055650182068348
p mean is: tensor(-1.3864, device='cuda:2')
epoch:  66000 quantization_loss:  0.030559591948986053
p mean is: tensor(-1.3906, device='cuda:2')
epoch:  67000 quantization_loss:  0.030538886785507202
p mean is: tensor(-1.3945, device='cuda:2')
epoch:  68000 quantization_loss:  0.030533675104379654
p mean is: tensor(-1.3983, device='cuda:2')
epoch:  69000 quantization_loss:  0.030531305819749832
p mean is: tensor(-1.4021, device='cuda:2')
epoch:  70000 quantization_loss:  0.030523421242833138
p mean is: tensor(-1.4058, device='cuda:2')
epoch:  71000 quantization_loss:  0.030514191836118698
p mean is: tensor(-1.4094, device='cuda:2')
epoch:  72000 quantization_loss:  0.030508127063512802
p mean is: tensor(-1.4129, device='cuda:2')
epoch:  73000 quantization_loss:  0.03050350770354271
p mean is: tensor(-1.4162, device='cuda:2')
epoch:  74000 quantization_loss:  0.03049892745912075
p mean is: tensor(-1.4195, device='cuda:2')
epoch:  75000 quantization_loss:  0.030495164915919304
p mean is: tensor(-1.4227, device='cuda:2')
epoch:  76000 quantization_loss:  0.030485451221466064
p mean is: tensor(-1.4257, device='cuda:2')
epoch:  77000 quantization_loss:  0.030490655452013016
p mean is: tensor(-1.4288, device='cuda:2')
epoch:  78000 quantization_loss:  0.030483733862638474
p mean is: tensor(-1.4318, device='cuda:2')
epoch:  79000 quantization_loss:  0.030532734468579292
p mean is: tensor(-1.4347, device='cuda:2')
here
1.0.1.1.weight       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =    1517 /    4608             ( 32.92%) | total_pruned =    3091 | shape = torch.Size([16, 32, 3, 3])
1.1.1.1.bias         | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.2.weight         | nonzeros =      12 /      16             ( 75.00%) | total_pruned =       4 | shape = torch.Size([16])
1.1.2.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.4.1.weight       | nonzeros =     538 /    2304             ( 23.35%) | total_pruned =    1766 | shape = torch.Size([16, 16, 3, 3])
1.1.4.1.bias         | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.5.weight         | nonzeros =      11 /      16             ( 68.75%) | total_pruned =       5 | shape = torch.Size([16])
1.1.5.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.1.7.1.0.1.1.weight | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([4, 16, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =     914 /    4608             ( 19.84%) | total_pruned =    3694 | shape = torch.Size([32, 16, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.2.weight   | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
1.1.7.1.1.2.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.4.1.weight | nonzeros =    1761 /    9216             ( 19.11%) | total_pruned =    7455 | shape = torch.Size([32, 32, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.5.weight   | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
1.1.7.1.1.5.bias     | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([4, 32, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    3455 /   18432             ( 18.74%) | total_pruned =   14977 | shape = torch.Size([64, 32, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    5275 /   36864             ( 14.31%) | total_pruned =   31589 | shape = torch.Size([64, 64, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([4, 64, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    5275 /   73728             (  7.15%) | total_pruned =   68453 | shape = torch.Size([128, 64, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    7225 /  147456             (  4.90%) | total_pruned =  140231 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     151 /     512             ( 29.49%) | total_pruned =     361 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    1695 /  147456             (  1.15%) | total_pruned =  145761 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    4312 /  147456             (  2.92%) | total_pruned =  143144 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     149 /     512             ( 29.10%) | total_pruned =     363 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    7739 /  147456             (  5.25%) | total_pruned =  139717 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   18352 /  147456             ( 12.45%) | total_pruned =  129104 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      85 /     132             ( 64.39%) | total_pruned =      47 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   28593 /  152064             ( 18.80%) | total_pruned =  123471 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      96 /     132             ( 72.73%) | total_pruned =      36 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   30559 /  152064             ( 20.10%) | total_pruned =  121505 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      84 /     132             ( 63.64%) | total_pruned =      48 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =   29231 /  152064             ( 19.22%) | total_pruned =  122833 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      93 /     132             ( 70.45%) | total_pruned =      39 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =   12589 /   76032             ( 16.56%) | total_pruned =   63443 | shape = torch.Size([64, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.1.1.7.4.weight | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.1.7.2.weight       | nonzeros =      34 /      68             ( 50.00%) | total_pruned =      34 | shape = torch.Size([68])
1.1.7.2.bias         | nonzeros =       0 /      68             (  0.00%) | total_pruned =      68 | shape = torch.Size([68])
1.1.7.3.1.weight     | nonzeros =    2631 /   19584             ( 13.43%) | total_pruned =   16953 | shape = torch.Size([32, 68, 3, 3])
1.1.7.3.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.1.7.4.weight       | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.1.7.4.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      18 /      36             ( 50.00%) | total_pruned =      18 | shape = torch.Size([36])
2.bias               | nonzeros =       0 /      36             (  0.00%) | total_pruned =      36 | shape = torch.Size([36])
3.1.weight           | nonzeros =    1208 /    5184             ( 23.30%) | total_pruned =    3976 | shape = torch.Size([16, 36, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      33 /      48             ( 68.75%) | total_pruned =      15 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 164725, pruned : 1286758, total: 1451483, Compression rate :       8.81x  ( 88.65% pruned)
PSNR of output image is:  16.390365418213303
Experiment done
