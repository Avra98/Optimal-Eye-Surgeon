(3, 512, 512)
(3, 512, 512)
Noisy PSNR is '9.352053608560148'
(3, 512, 512) torch.Size([1, 3, 512, 512]) torch.Size([1, 32, 512, 512])
Output directory: data/inpainting/Set14/mask/12/0.5/det/-0.5/1e-09
epoch:  0 quantization_loss:  0.028806792572140694
p mean is: tensor(-9.4509e-05, device='cuda:4')
epoch:  1000 quantization_loss:  0.02411717362701893
p mean is: tensor(-0.0067, device='cuda:4')
epoch:  2000 quantization_loss:  0.023864563554525375
p mean is: tensor(-0.0115, device='cuda:4')
epoch:  3000 quantization_loss:  0.02284562960267067
p mean is: tensor(-0.0166, device='cuda:4')
epoch:  4000 quantization_loss:  0.022895652800798416
p mean is: tensor(-0.0217, device='cuda:4')
epoch:  5000 quantization_loss:  0.022177059203386307
p mean is: tensor(-0.0268, device='cuda:4')
epoch:  6000 quantization_loss:  0.021422646939754486
p mean is: tensor(-0.0319, device='cuda:4')
epoch:  7000 quantization_loss:  0.019172105938196182
p mean is: tensor(-0.0379, device='cuda:4')
epoch:  8000 quantization_loss:  0.01797022484242916
p mean is: tensor(-0.0450, device='cuda:4')
epoch:  9000 quantization_loss:  0.014694505371153355
p mean is: tensor(-0.0540, device='cuda:4')
epoch:  10000 quantization_loss:  0.01215326227247715
p mean is: tensor(-0.0649, device='cuda:4')
epoch:  11000 quantization_loss:  0.01107810903340578
p mean is: tensor(-0.0785, device='cuda:4')
epoch:  12000 quantization_loss:  0.009997567161917686
p mean is: tensor(-0.0956, device='cuda:4')
epoch:  13000 quantization_loss:  0.008584720082581043
p mean is: tensor(-0.1166, device='cuda:4')
epoch:  14000 quantization_loss:  0.008286560885608196
p mean is: tensor(-0.1409, device='cuda:4')
epoch:  15000 quantization_loss:  0.007596889045089483
p mean is: tensor(-0.1686, device='cuda:4')
epoch:  16000 quantization_loss:  0.007254702039062977
p mean is: tensor(-0.1983, device='cuda:4')
epoch:  17000 quantization_loss:  0.006787678226828575
p mean is: tensor(-0.2286, device='cuda:4')
epoch:  18000 quantization_loss:  0.006589491851627827
p mean is: tensor(-0.2580, device='cuda:4')
epoch:  19000 quantization_loss:  0.006389954127371311
p mean is: tensor(-0.2857, device='cuda:4')
epoch:  20000 quantization_loss:  0.006275581661611795
p mean is: tensor(-0.3109, device='cuda:4')
epoch:  21000 quantization_loss:  0.006143227219581604
p mean is: tensor(-0.3333, device='cuda:4')
epoch:  22000 quantization_loss:  0.006068970542401075
p mean is: tensor(-0.3529, device='cuda:4')
epoch:  23000 quantization_loss:  0.005976193584501743
p mean is: tensor(-0.3701, device='cuda:4')
epoch:  24000 quantization_loss:  0.005905894562602043
p mean is: tensor(-0.3848, device='cuda:4')
epoch:  25000 quantization_loss:  0.005848869681358337
p mean is: tensor(-0.3975, device='cuda:4')
epoch:  26000 quantization_loss:  0.00583675829693675
p mean is: tensor(-0.4084, device='cuda:4')
epoch:  27000 quantization_loss:  0.005744894966483116
p mean is: tensor(-0.4177, device='cuda:4')
epoch:  28000 quantization_loss:  0.00572886411100626
p mean is: tensor(-0.4257, device='cuda:4')
epoch:  29000 quantization_loss:  0.005667680408805609
p mean is: tensor(-0.4327, device='cuda:4')
epoch:  30000 quantization_loss:  0.0056418925523757935
p mean is: tensor(-0.4388, device='cuda:4')
epoch:  31000 quantization_loss:  0.005634123459458351
p mean is: tensor(-0.4440, device='cuda:4')
epoch:  32000 quantization_loss:  0.005599162075668573
p mean is: tensor(-0.4485, device='cuda:4')
epoch:  33000 quantization_loss:  0.005219987127929926
p mean is: tensor(-0.4525, device='cuda:4')
epoch:  34000 quantization_loss:  0.0051293279975652695
p mean is: tensor(-0.4560, device='cuda:4')
epoch:  35000 quantization_loss:  0.005108794663101435
p mean is: tensor(-0.4590, device='cuda:4')
epoch:  36000 quantization_loss:  0.00508738262578845
p mean is: tensor(-0.4616, device='cuda:4')
epoch:  37000 quantization_loss:  0.0050422721542418
p mean is: tensor(-0.4640, device='cuda:4')
epoch:  38000 quantization_loss:  0.005034133326262236
p mean is: tensor(-0.4663, device='cuda:4')
epoch:  39000 quantization_loss:  0.004990818910300732
p mean is: tensor(-0.4682, device='cuda:4')
epoch:  40000 quantization_loss:  0.004960519727319479
p mean is: tensor(-0.4700, device='cuda:4')
epoch:  41000 quantization_loss:  0.004936307668685913
p mean is: tensor(-0.4717, device='cuda:4')
epoch:  42000 quantization_loss:  0.004919005557894707
p mean is: tensor(-0.4733, device='cuda:4')
epoch:  43000 quantization_loss:  0.0049018277786672115
p mean is: tensor(-0.4747, device='cuda:4')
epoch:  44000 quantization_loss:  0.004901123233139515
p mean is: tensor(-0.4759, device='cuda:4')
epoch:  45000 quantization_loss:  0.004875957500189543
p mean is: tensor(-0.4771, device='cuda:4')
epoch:  46000 quantization_loss:  0.004862531088292599
p mean is: tensor(-0.4783, device='cuda:4')
epoch:  47000 quantization_loss:  0.0048552388325333595
p mean is: tensor(-0.4793, device='cuda:4')
epoch:  48000 quantization_loss:  0.004849586170166731
p mean is: tensor(-0.4803, device='cuda:4')
epoch:  49000 quantization_loss:  0.0048293257132172585
p mean is: tensor(-0.4813, device='cuda:4')
epoch:  50000 quantization_loss:  0.004820410627871752
p mean is: tensor(-0.4822, device='cuda:4')
epoch:  51000 quantization_loss:  0.0048125493340194225
p mean is: tensor(-0.4830, device='cuda:4')
epoch:  52000 quantization_loss:  0.004809985868632793
p mean is: tensor(-0.4838, device='cuda:4')
epoch:  53000 quantization_loss:  0.0048041269183158875
p mean is: tensor(-0.4846, device='cuda:4')
epoch:  54000 quantization_loss:  0.004796680994331837
p mean is: tensor(-0.4853, device='cuda:4')
epoch:  55000 quantization_loss:  0.0047951736487448215
p mean is: tensor(-0.4859, device='cuda:4')
epoch:  56000 quantization_loss:  0.00479049002751708
p mean is: tensor(-0.4866, device='cuda:4')
epoch:  57000 quantization_loss:  0.00477985804900527
p mean is: tensor(-0.4872, device='cuda:4')
epoch:  58000 quantization_loss:  0.0047865076921880245
p mean is: tensor(-0.4878, device='cuda:4')
epoch:  59000 quantization_loss:  0.004770897328853607
p mean is: tensor(-0.4884, device='cuda:4')
epoch:  60000 quantization_loss:  0.0047636148519814014
p mean is: tensor(-0.4890, device='cuda:4')
epoch:  61000 quantization_loss:  0.004766643047332764
p mean is: tensor(-0.4895, device='cuda:4')
epoch:  62000 quantization_loss:  0.004762960132211447
p mean is: tensor(-0.4900, device='cuda:4')
epoch:  63000 quantization_loss:  0.004758656956255436
p mean is: tensor(-0.4905, device='cuda:4')
epoch:  64000 quantization_loss:  0.00475998455658555
p mean is: tensor(-0.4910, device='cuda:4')
epoch:  65000 quantization_loss:  0.004757175222039223
p mean is: tensor(-0.4915, device='cuda:4')
epoch:  66000 quantization_loss:  0.004751227796077728
p mean is: tensor(-0.4919, device='cuda:4')
epoch:  67000 quantization_loss:  0.0047806985676288605
p mean is: tensor(-0.4923, device='cuda:4')
epoch:  68000 quantization_loss:  0.0047495667822659016
p mean is: tensor(-0.4927, device='cuda:4')
epoch:  69000 quantization_loss:  0.004743471741676331
p mean is: tensor(-0.4931, device='cuda:4')
epoch:  70000 quantization_loss:  0.0047449213452637196
p mean is: tensor(-0.4935, device='cuda:4')
epoch:  71000 quantization_loss:  0.004736681934446096
p mean is: tensor(-0.4939, device='cuda:4')
epoch:  72000 quantization_loss:  0.004737359471619129
p mean is: tensor(-0.4943, device='cuda:4')
epoch:  73000 quantization_loss:  0.0047362977638840675
p mean is: tensor(-0.4946, device='cuda:4')
epoch:  74000 quantization_loss:  0.004732013680040836
p mean is: tensor(-0.4949, device='cuda:4')
epoch:  75000 quantization_loss:  0.004732961766421795
p mean is: tensor(-0.4953, device='cuda:4')
epoch:  76000 quantization_loss:  0.004730771761387587
p mean is: tensor(-0.4956, device='cuda:4')
epoch:  77000 quantization_loss:  0.004726476967334747
p mean is: tensor(-0.4959, device='cuda:4')
epoch:  78000 quantization_loss:  0.00473026605322957
p mean is: tensor(-0.4962, device='cuda:4')
epoch:  79000 quantization_loss:  0.004720498342067003
p mean is: tensor(-0.4965, device='cuda:4')
here
1.1.1.weight         | nonzeros =    1455 /   12800             ( 11.37%) | total_pruned =   11345 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     224 /    6400             (  3.50%) | total_pruned =    6176 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     193 /   12800             (  1.51%) | total_pruned =   12607 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      12 /      32             ( 37.50%) | total_pruned =      20 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     278 /   25600             (  1.09%) | total_pruned =   25322 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      10 /      32             ( 31.25%) | total_pruned =      22 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     450 /   51200             (  0.88%) | total_pruned =   50750 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     907 /  102400             (  0.89%) | total_pruned =  101493 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =    1211 /  204800             (  0.59%) | total_pruned =  203589 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =    2512 /  409600             (  0.61%) | total_pruned =  407088 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    3370 /  409600             (  0.82%) | total_pruned =  406230 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    9509 /  409600             (  2.32%) | total_pruned =  400091 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   21963 /  409600             (  5.36%) | total_pruned =  387637 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   42608 /  409600             ( 10.40%) | total_pruned =  366992 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   33457 /  147456             ( 22.69%) | total_pruned =  113999 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   32342 /  147456             ( 21.93%) | total_pruned =  115114 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   31509 /  147456             ( 21.37%) | total_pruned =  115947 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   14662 /   73728             ( 19.89%) | total_pruned =   59066 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2591 /   18432             ( 14.06%) | total_pruned =   15841 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1000 /    4608             ( 21.70%) | total_pruned =    3608 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      15 /      16             ( 93.75%) | total_pruned =       1 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      26 /      48             ( 54.17%) | total_pruned =      22 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 201593, pruned : 2807274, total: 3008867, Compression rate :      14.93x  ( 93.30% pruned)
PSNR of output image is:  20.2184899162135
Experiment done
