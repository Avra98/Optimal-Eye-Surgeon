(3, 512, 512)
(3, 512, 512)
Noisy PSNR is '8.732585125972767'
(3, 512, 512) torch.Size([1, 3, 512, 512]) torch.Size([1, 32, 512, 512])
Output directory: data/inpainting/Set14/mask/4/0.5/det/-0.2/1e-09
epoch:  0 quantization_loss:  0.03093240037560463
p mean is: tensor(-3.8630e-05, device='cuda:1')
epoch:  1000 quantization_loss:  0.025734087452292442
p mean is: tensor(-0.0028, device='cuda:1')
epoch:  2000 quantization_loss:  0.02560078725218773
p mean is: tensor(-0.0053, device='cuda:1')
epoch:  3000 quantization_loss:  0.025296451523900032
p mean is: tensor(-0.0080, device='cuda:1')
epoch:  4000 quantization_loss:  0.02515520341694355
p mean is: tensor(-0.0111, device='cuda:1')
epoch:  5000 quantization_loss:  0.025101441890001297
p mean is: tensor(-0.0144, device='cuda:1')
epoch:  6000 quantization_loss:  0.023637834936380386
p mean is: tensor(-0.0182, device='cuda:1')
epoch:  7000 quantization_loss:  0.020788686349987984
p mean is: tensor(-0.0222, device='cuda:1')
epoch:  8000 quantization_loss:  0.018733937293291092
p mean is: tensor(-0.0269, device='cuda:1')
epoch:  9000 quantization_loss:  0.016510657966136932
p mean is: tensor(-0.0325, device='cuda:1')
epoch:  10000 quantization_loss:  0.015458274632692337
p mean is: tensor(-0.0391, device='cuda:1')
epoch:  11000 quantization_loss:  0.01440082211047411
p mean is: tensor(-0.0468, device='cuda:1')
epoch:  12000 quantization_loss:  0.013063518330454826
p mean is: tensor(-0.0560, device='cuda:1')
epoch:  13000 quantization_loss:  0.012204403057694435
p mean is: tensor(-0.0663, device='cuda:1')
epoch:  14000 quantization_loss:  0.010722581297159195
p mean is: tensor(-0.0772, device='cuda:1')
epoch:  15000 quantization_loss:  0.01007009670138359
p mean is: tensor(-0.0886, device='cuda:1')
epoch:  16000 quantization_loss:  0.009618112817406654
p mean is: tensor(-0.0999, device='cuda:1')
epoch:  17000 quantization_loss:  0.009288900531828403
p mean is: tensor(-0.1108, device='cuda:1')
epoch:  18000 quantization_loss:  0.008660964667797089
p mean is: tensor(-0.1209, device='cuda:1')
epoch:  19000 quantization_loss:  0.008308099582791328
p mean is: tensor(-0.1302, device='cuda:1')
epoch:  20000 quantization_loss:  0.008204239420592785
p mean is: tensor(-0.1383, device='cuda:1')
epoch:  21000 quantization_loss:  0.00810123048722744
p mean is: tensor(-0.1453, device='cuda:1')
epoch:  22000 quantization_loss:  0.007849437184631824
p mean is: tensor(-0.1514, device='cuda:1')
epoch:  23000 quantization_loss:  0.007812573574483395
p mean is: tensor(-0.1566, device='cuda:1')
epoch:  24000 quantization_loss:  0.007626219652593136
p mean is: tensor(-0.1613, device='cuda:1')
epoch:  25000 quantization_loss:  0.007564917206764221
p mean is: tensor(-0.1651, device='cuda:1')
epoch:  26000 quantization_loss:  0.007281716912984848
p mean is: tensor(-0.1684, device='cuda:1')
epoch:  27000 quantization_loss:  0.007092671934515238
p mean is: tensor(-0.1712, device='cuda:1')
epoch:  28000 quantization_loss:  0.006982351653277874
p mean is: tensor(-0.1735, device='cuda:1')
epoch:  29000 quantization_loss:  0.006881208159029484
p mean is: tensor(-0.1756, device='cuda:1')
epoch:  30000 quantization_loss:  0.006780586205422878
p mean is: tensor(-0.1774, device='cuda:1')
epoch:  31000 quantization_loss:  0.006755110342055559
p mean is: tensor(-0.1791, device='cuda:1')
epoch:  32000 quantization_loss:  0.006692185066640377
p mean is: tensor(-0.1805, device='cuda:1')
epoch:  33000 quantization_loss:  0.006634107790887356
p mean is: tensor(-0.1817, device='cuda:1')
epoch:  34000 quantization_loss:  0.006525059696286917
p mean is: tensor(-0.1829, device='cuda:1')
epoch:  35000 quantization_loss:  0.006493191700428724
p mean is: tensor(-0.1840, device='cuda:1')
epoch:  36000 quantization_loss:  0.006468489300459623
p mean is: tensor(-0.1850, device='cuda:1')
epoch:  37000 quantization_loss:  0.006425454281270504
p mean is: tensor(-0.1858, device='cuda:1')
epoch:  38000 quantization_loss:  0.00640843203291297
p mean is: tensor(-0.1865, device='cuda:1')
epoch:  39000 quantization_loss:  0.00632466608658433
p mean is: tensor(-0.1872, device='cuda:1')
epoch:  40000 quantization_loss:  0.00632042670622468
p mean is: tensor(-0.1879, device='cuda:1')
epoch:  41000 quantization_loss:  0.006255127489566803
p mean is: tensor(-0.1885, device='cuda:1')
epoch:  42000 quantization_loss:  0.006227863021194935
p mean is: tensor(-0.1891, device='cuda:1')
epoch:  43000 quantization_loss:  0.006265517324209213
p mean is: tensor(-0.1896, device='cuda:1')
epoch:  44000 quantization_loss:  0.006191602908074856
p mean is: tensor(-0.1900, device='cuda:1')
epoch:  45000 quantization_loss:  0.006174461450427771
p mean is: tensor(-0.1905, device='cuda:1')
epoch:  46000 quantization_loss:  0.006167312152683735
p mean is: tensor(-0.1909, device='cuda:1')
epoch:  47000 quantization_loss:  0.006136380601674318
p mean is: tensor(-0.1913, device='cuda:1')
epoch:  48000 quantization_loss:  0.0061299619264900684
p mean is: tensor(-0.1917, device='cuda:1')
epoch:  49000 quantization_loss:  0.006106086075305939
p mean is: tensor(-0.1921, device='cuda:1')
epoch:  50000 quantization_loss:  0.006090142764151096
p mean is: tensor(-0.1925, device='cuda:1')
epoch:  51000 quantization_loss:  0.006089967209845781
p mean is: tensor(-0.1928, device='cuda:1')
epoch:  52000 quantization_loss:  0.006078826729208231
p mean is: tensor(-0.1932, device='cuda:1')
epoch:  53000 quantization_loss:  0.006075466983020306
p mean is: tensor(-0.1936, device='cuda:1')
epoch:  54000 quantization_loss:  0.006063106004148722
p mean is: tensor(-0.1939, device='cuda:1')
epoch:  55000 quantization_loss:  0.006050769705325365
p mean is: tensor(-0.1943, device='cuda:1')
epoch:  56000 quantization_loss:  0.006054970435798168
p mean is: tensor(-0.1946, device='cuda:1')
epoch:  57000 quantization_loss:  0.006033868063241243
p mean is: tensor(-0.1950, device='cuda:1')
epoch:  58000 quantization_loss:  0.006028718780726194
p mean is: tensor(-0.1953, device='cuda:1')
epoch:  59000 quantization_loss:  0.006025759503245354
p mean is: tensor(-0.1955, device='cuda:1')
epoch:  60000 quantization_loss:  0.006020878907293081
p mean is: tensor(-0.1958, device='cuda:1')
epoch:  61000 quantization_loss:  0.006015308666974306
p mean is: tensor(-0.1961, device='cuda:1')
epoch:  62000 quantization_loss:  0.006009390112012625
p mean is: tensor(-0.1964, device='cuda:1')
epoch:  63000 quantization_loss:  0.006004360970109701
p mean is: tensor(-0.1967, device='cuda:1')
epoch:  64000 quantization_loss:  0.006005140021443367
p mean is: tensor(-0.1970, device='cuda:1')
epoch:  65000 quantization_loss:  0.005995739717036486
p mean is: tensor(-0.1973, device='cuda:1')
epoch:  66000 quantization_loss:  0.0059868632815778255
p mean is: tensor(-0.1976, device='cuda:1')
epoch:  67000 quantization_loss:  0.005990683566778898
p mean is: tensor(-0.1978, device='cuda:1')
epoch:  68000 quantization_loss:  0.005983137525618076
p mean is: tensor(-0.1981, device='cuda:1')
epoch:  69000 quantization_loss:  0.0059820907190442085
p mean is: tensor(-0.1983, device='cuda:1')
epoch:  70000 quantization_loss:  0.0059692165814340115
p mean is: tensor(-0.1985, device='cuda:1')
epoch:  71000 quantization_loss:  0.00596761517226696
p mean is: tensor(-0.1987, device='cuda:1')
epoch:  72000 quantization_loss:  0.005972426384687424
p mean is: tensor(-0.1989, device='cuda:1')
epoch:  73000 quantization_loss:  0.0059681120328605175
p mean is: tensor(-0.1991, device='cuda:1')
epoch:  74000 quantization_loss:  0.0059666624292731285
p mean is: tensor(-0.1993, device='cuda:1')
epoch:  75000 quantization_loss:  0.00596613809466362
p mean is: tensor(-0.1995, device='cuda:1')
epoch:  76000 quantization_loss:  0.005965182092040777
p mean is: tensor(-0.1997, device='cuda:1')
epoch:  77000 quantization_loss:  0.005960919428616762
p mean is: tensor(-0.1999, device='cuda:1')
epoch:  78000 quantization_loss:  0.005952091887593269
p mean is: tensor(-0.2001, device='cuda:1')
epoch:  79000 quantization_loss:  0.005956074222922325
p mean is: tensor(-0.2002, device='cuda:1')
here
1.1.1.weight         | nonzeros =    3105 /   12800             ( 24.26%) | total_pruned =    9695 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =      11 /      16             ( 68.75%) | total_pruned =       5 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     789 /    6400             ( 12.33%) | total_pruned =    5611 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     905 /   12800             (  7.07%) | total_pruned =   11895 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =    1617 /   25600             (  6.32%) | total_pruned =   23983 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =    2930 /   51200             (  5.72%) | total_pruned =   48270 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =    5221 /  102400             (  5.10%) | total_pruned =   97179 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =    7101 /  204800             (  3.47%) | total_pruned =  197699 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =   13701 /  409600             (  3.34%) | total_pruned =  395899 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   20443 /  409600             (  4.99%) | total_pruned =  389157 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   39716 /  409600             (  9.70%) | total_pruned =  369884 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   54186 /  409600             ( 13.23%) | total_pruned =  355414 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   67114 /  409600             ( 16.39%) | total_pruned =  342486 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   37154 /  147456             ( 25.20%) | total_pruned =  110302 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   36779 /  147456             ( 24.94%) | total_pruned =  110677 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   27273 /  147456             ( 18.50%) | total_pruned =  120183 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   13885 /   73728             ( 18.83%) | total_pruned =   59843 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    3587 /   18432             ( 19.46%) | total_pruned =   14845 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1327 /    4608             ( 28.80%) | total_pruned =    3281 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      35 /      48             ( 72.92%) | total_pruned =      13 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 338220, pruned : 2670647, total: 3008867, Compression rate :       8.90x  ( 88.76% pruned)
PSNR of output image is:  19.24046982807595
Experiment done
