(3, 512, 512)
(3, 512, 512)
Noisy PSNR is '9.810459425684437'
(3, 512, 512) torch.Size([1, 3, 512, 512]) torch.Size([1, 32, 512, 512])
Output directory: data/inpainting/Set14/mask/11/0.5/det/-0.8/1e-09
epoch:  0 quantization_loss:  0.027764009311795235
p mean is: tensor(-0.0001, device='cuda:2')
epoch:  1000 quantization_loss:  0.019561458379030228
p mean is: tensor(-0.0116, device='cuda:2')
epoch:  2000 quantization_loss:  0.01869148574769497
p mean is: tensor(-0.0208, device='cuda:2')
epoch:  3000 quantization_loss:  0.01880696602165699
p mean is: tensor(-0.0300, device='cuda:2')
epoch:  4000 quantization_loss:  0.01867763325572014
p mean is: tensor(-0.0394, device='cuda:2')
epoch:  5000 quantization_loss:  0.01816832460463047
p mean is: tensor(-0.0489, device='cuda:2')
epoch:  6000 quantization_loss:  0.017936065793037415
p mean is: tensor(-0.0588, device='cuda:2')
epoch:  7000 quantization_loss:  0.017883263528347015
p mean is: tensor(-0.0698, device='cuda:2')
epoch:  8000 quantization_loss:  0.017570823431015015
p mean is: tensor(-0.0815, device='cuda:2')
epoch:  9000 quantization_loss:  0.01679801568388939
p mean is: tensor(-0.0938, device='cuda:2')
epoch:  10000 quantization_loss:  0.01582508161664009
p mean is: tensor(-0.1086, device='cuda:2')
epoch:  11000 quantization_loss:  0.014381779357790947
p mean is: tensor(-0.1266, device='cuda:2')
epoch:  12000 quantization_loss:  0.013211770914494991
p mean is: tensor(-0.1487, device='cuda:2')
epoch:  13000 quantization_loss:  0.012304645031690598
p mean is: tensor(-0.1761, device='cuda:2')
epoch:  14000 quantization_loss:  0.011644681915640831
p mean is: tensor(-0.2090, device='cuda:2')
epoch:  15000 quantization_loss:  0.010786574333906174
p mean is: tensor(-0.2474, device='cuda:2')
epoch:  16000 quantization_loss:  0.01037807296961546
p mean is: tensor(-0.2905, device='cuda:2')
epoch:  17000 quantization_loss:  0.009766903705894947
p mean is: tensor(-0.3371, device='cuda:2')
epoch:  18000 quantization_loss:  0.009287905879318714
p mean is: tensor(-0.3851, device='cuda:2')
epoch:  19000 quantization_loss:  0.00877336598932743
p mean is: tensor(-0.4323, device='cuda:2')
epoch:  20000 quantization_loss:  0.00842361431568861
p mean is: tensor(-0.4767, device='cuda:2')
epoch:  21000 quantization_loss:  0.008170507848262787
p mean is: tensor(-0.5171, device='cuda:2')
epoch:  22000 quantization_loss:  0.007769300136715174
p mean is: tensor(-0.5530, device='cuda:2')
epoch:  23000 quantization_loss:  0.0075523220002651215
p mean is: tensor(-0.5845, device='cuda:2')
epoch:  24000 quantization_loss:  0.007370037492364645
p mean is: tensor(-0.6117, device='cuda:2')
epoch:  25000 quantization_loss:  0.007246674038469791
p mean is: tensor(-0.6353, device='cuda:2')
epoch:  26000 quantization_loss:  0.00743096973747015
p mean is: tensor(-0.6555, device='cuda:2')
epoch:  27000 quantization_loss:  0.007090380415320396
p mean is: tensor(-0.6728, device='cuda:2')
epoch:  28000 quantization_loss:  0.006961285602301359
p mean is: tensor(-0.6877, device='cuda:2')
epoch:  29000 quantization_loss:  0.00682055251672864
p mean is: tensor(-0.7005, device='cuda:2')
epoch:  30000 quantization_loss:  0.006753666326403618
p mean is: tensor(-0.7113, device='cuda:2')
epoch:  31000 quantization_loss:  0.006654274184256792
p mean is: tensor(-0.7210, device='cuda:2')
epoch:  32000 quantization_loss:  0.006642173044383526
p mean is: tensor(-0.7292, device='cuda:2')
epoch:  33000 quantization_loss:  0.006564685143530369
p mean is: tensor(-0.7364, device='cuda:2')
epoch:  34000 quantization_loss:  0.006538864225149155
p mean is: tensor(-0.7427, device='cuda:2')
epoch:  35000 quantization_loss:  0.00655079772695899
p mean is: tensor(-0.7483, device='cuda:2')
epoch:  36000 quantization_loss:  0.0064398604445159435
p mean is: tensor(-0.7531, device='cuda:2')
epoch:  37000 quantization_loss:  0.006410765927284956
p mean is: tensor(-0.7574, device='cuda:2')
epoch:  38000 quantization_loss:  0.006392663344740868
p mean is: tensor(-0.7613, device='cuda:2')
epoch:  39000 quantization_loss:  0.006344578228890896
p mean is: tensor(-0.7647, device='cuda:2')
epoch:  40000 quantization_loss:  0.0063309445977211
p mean is: tensor(-0.7677, device='cuda:2')
epoch:  41000 quantization_loss:  0.006306002382189035
p mean is: tensor(-0.7705, device='cuda:2')
epoch:  42000 quantization_loss:  0.006280203349888325
p mean is: tensor(-0.7730, device='cuda:2')
epoch:  43000 quantization_loss:  0.0062769814394414425
p mean is: tensor(-0.7752, device='cuda:2')
epoch:  44000 quantization_loss:  0.0062674786895513535
p mean is: tensor(-0.7773, device='cuda:2')
epoch:  45000 quantization_loss:  0.0062353601679205894
p mean is: tensor(-0.7792, device='cuda:2')
epoch:  46000 quantization_loss:  0.006247003097087145
p mean is: tensor(-0.7810, device='cuda:2')
epoch:  47000 quantization_loss:  0.006211777683347464
p mean is: tensor(-0.7826, device='cuda:2')
epoch:  48000 quantization_loss:  0.006204971112310886
p mean is: tensor(-0.7841, device='cuda:2')
epoch:  49000 quantization_loss:  0.006199399475008249
p mean is: tensor(-0.7855, device='cuda:2')
epoch:  50000 quantization_loss:  0.006184524856507778
p mean is: tensor(-0.7868, device='cuda:2')
epoch:  51000 quantization_loss:  0.006183484103530645
p mean is: tensor(-0.7879, device='cuda:2')
epoch:  52000 quantization_loss:  0.00617691595107317
p mean is: tensor(-0.7891, device='cuda:2')
epoch:  53000 quantization_loss:  0.006158711388707161
p mean is: tensor(-0.7902, device='cuda:2')
epoch:  54000 quantization_loss:  0.0061556794680655
p mean is: tensor(-0.7912, device='cuda:2')
epoch:  55000 quantization_loss:  0.006143948994576931
p mean is: tensor(-0.7922, device='cuda:2')
epoch:  56000 quantization_loss:  0.006147753447294235
p mean is: tensor(-0.7932, device='cuda:2')
epoch:  57000 quantization_loss:  0.006141446530818939
p mean is: tensor(-0.7941, device='cuda:2')
epoch:  58000 quantization_loss:  0.006129204761236906
p mean is: tensor(-0.7949, device='cuda:2')
epoch:  59000 quantization_loss:  0.006126236170530319
p mean is: tensor(-0.7957, device='cuda:2')
epoch:  60000 quantization_loss:  0.006128198932856321
p mean is: tensor(-0.7965, device='cuda:2')
epoch:  61000 quantization_loss:  0.006121196784079075
p mean is: tensor(-0.7973, device='cuda:2')
epoch:  62000 quantization_loss:  0.006117644719779491
p mean is: tensor(-0.7980, device='cuda:2')
epoch:  63000 quantization_loss:  0.006109265144914389
p mean is: tensor(-0.7987, device='cuda:2')
epoch:  64000 quantization_loss:  0.0061041321605443954
p mean is: tensor(-0.7995, device='cuda:2')
epoch:  65000 quantization_loss:  0.006108371075242758
p mean is: tensor(-0.8001, device='cuda:2')
epoch:  66000 quantization_loss:  0.00611104816198349
p mean is: tensor(-0.8009, device='cuda:2')
epoch:  67000 quantization_loss:  0.006097991019487381
p mean is: tensor(-0.8015, device='cuda:2')
epoch:  68000 quantization_loss:  0.006101512350142002
p mean is: tensor(-0.8021, device='cuda:2')
epoch:  69000 quantization_loss:  0.0060983034782111645
p mean is: tensor(-0.8027, device='cuda:2')
epoch:  70000 quantization_loss:  0.0060960641130805016
p mean is: tensor(-0.8034, device='cuda:2')
epoch:  71000 quantization_loss:  0.006106220651417971
p mean is: tensor(-0.8039, device='cuda:2')
epoch:  72000 quantization_loss:  0.006088551599532366
p mean is: tensor(-0.8045, device='cuda:2')
epoch:  73000 quantization_loss:  0.006082291714847088
p mean is: tensor(-0.8050, device='cuda:2')
epoch:  74000 quantization_loss:  0.0060895588248968124
p mean is: tensor(-0.8056, device='cuda:2')
epoch:  75000 quantization_loss:  0.006084066350013018
p mean is: tensor(-0.8061, device='cuda:2')
epoch:  76000 quantization_loss:  0.006084292195737362
p mean is: tensor(-0.8066, device='cuda:2')
epoch:  77000 quantization_loss:  0.0060854097828269005
p mean is: tensor(-0.8071, device='cuda:2')
epoch:  78000 quantization_loss:  0.0060804616659879684
p mean is: tensor(-0.8077, device='cuda:2')
epoch:  79000 quantization_loss:  0.006083064246922731
p mean is: tensor(-0.8081, device='cuda:2')
here
1.1.1.weight         | nonzeros =     878 /   12800             (  6.86%) | total_pruned =   11922 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     154 /    6400             (  2.41%) | total_pruned =    6246 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     109 /   12800             (  0.85%) | total_pruned =   12691 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      12 /      32             ( 37.50%) | total_pruned =      20 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     169 /   25600             (  0.66%) | total_pruned =   25431 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =       7 /      32             ( 21.88%) | total_pruned =      25 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     229 /   51200             (  0.45%) | total_pruned =   50971 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     303 /  102400             (  0.30%) | total_pruned =  102097 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     114 /  204800             (  0.06%) | total_pruned =  204686 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     508 /  409600             (  0.12%) | total_pruned =  409092 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     714 /  409600             (  0.17%) | total_pruned =  408886 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    4303 /  409600             (  1.05%) | total_pruned =  405297 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   13451 /  409600             (  3.28%) | total_pruned =  396149 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   33677 /  409600             (  8.22%) | total_pruned =  375923 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   28157 /  147456             ( 19.10%) | total_pruned =  119299 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   28912 /  147456             ( 19.61%) | total_pruned =  118544 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   17834 /  147456             ( 12.09%) | total_pruned =  129622 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    8369 /   73728             ( 11.35%) | total_pruned =   65359 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2670 /   18432             ( 14.49%) | total_pruned =   15762 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1099 /    4608             ( 23.85%) | total_pruned =    3509 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      15 /      16             ( 93.75%) | total_pruned =       1 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      28 /      48             ( 58.33%) | total_pruned =      20 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 142865, pruned : 2866002, total: 3008867, Compression rate :      21.06x  ( 95.25% pruned)
PSNR of output image is:  19.162412560011504
Experiment done
