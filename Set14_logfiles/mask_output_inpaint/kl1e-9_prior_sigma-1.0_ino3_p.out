(3, 512, 512)
(3, 512, 512)
Noisy PSNR is '10.624724579730497'
(3, 512, 512) torch.Size([1, 3, 512, 512]) torch.Size([1, 32, 512, 512])
Output directory: data/inpainting/Set14/mask/3/0.5/det/-1.0/1e-09
epoch:  0 quantization_loss:  0.03841305896639824
p mean is: tensor(-0.0002, device='cuda:6')
epoch:  1000 quantization_loss:  0.0328453928232193
p mean is: tensor(-0.0116, device='cuda:6')
epoch:  2000 quantization_loss:  0.030313897877931595
p mean is: tensor(-0.0197, device='cuda:6')
epoch:  3000 quantization_loss:  0.029766198247671127
p mean is: tensor(-0.0268, device='cuda:6')
epoch:  4000 quantization_loss:  0.02962389960885048
p mean is: tensor(-0.0338, device='cuda:6')
epoch:  5000 quantization_loss:  0.029047010466456413
p mean is: tensor(-0.0412, device='cuda:6')
epoch:  6000 quantization_loss:  0.029467804357409477
p mean is: tensor(-0.0487, device='cuda:6')
epoch:  7000 quantization_loss:  0.02518606372177601
p mean is: tensor(-0.0569, device='cuda:6')
epoch:  8000 quantization_loss:  0.020817914977669716
p mean is: tensor(-0.0663, device='cuda:6')
epoch:  9000 quantization_loss:  0.018869323655962944
p mean is: tensor(-0.0777, device='cuda:6')
epoch:  10000 quantization_loss:  0.016180144622921944
p mean is: tensor(-0.0929, device='cuda:6')
epoch:  11000 quantization_loss:  0.015062800608575344
p mean is: tensor(-0.1130, device='cuda:6')
epoch:  12000 quantization_loss:  0.014171377755701542
p mean is: tensor(-0.1392, device='cuda:6')
epoch:  13000 quantization_loss:  0.013232186436653137
p mean is: tensor(-0.1723, device='cuda:6')
epoch:  14000 quantization_loss:  0.012181599624454975
p mean is: tensor(-0.2123, device='cuda:6')
epoch:  15000 quantization_loss:  0.011701351031661034
p mean is: tensor(-0.2592, device='cuda:6')
epoch:  16000 quantization_loss:  0.01121955644339323
p mean is: tensor(-0.3118, device='cuda:6')
epoch:  17000 quantization_loss:  0.010900896973907948
p mean is: tensor(-0.3687, device='cuda:6')
epoch:  18000 quantization_loss:  0.01065062265843153
p mean is: tensor(-0.4274, device='cuda:6')
epoch:  19000 quantization_loss:  0.010412588715553284
p mean is: tensor(-0.4855, device='cuda:6')
epoch:  20000 quantization_loss:  0.010304470546543598
p mean is: tensor(-0.5407, device='cuda:6')
epoch:  21000 quantization_loss:  0.010090523399412632
p mean is: tensor(-0.5919, device='cuda:6')
epoch:  22000 quantization_loss:  0.010028396733105183
p mean is: tensor(-0.6380, device='cuda:6')
epoch:  23000 quantization_loss:  0.009858192875981331
p mean is: tensor(-0.6793, device='cuda:6')
epoch:  24000 quantization_loss:  0.009775249287486076
p mean is: tensor(-0.7157, device='cuda:6')
epoch:  25000 quantization_loss:  0.00966653786599636
p mean is: tensor(-0.7476, device='cuda:6')
epoch:  26000 quantization_loss:  0.009632391855120659
p mean is: tensor(-0.7755, device='cuda:6')
epoch:  27000 quantization_loss:  0.009569353424012661
p mean is: tensor(-0.7998, device='cuda:6')
epoch:  28000 quantization_loss:  0.009477386251091957
p mean is: tensor(-0.8211, device='cuda:6')
epoch:  29000 quantization_loss:  0.009425701573491096
p mean is: tensor(-0.8396, device='cuda:6')
epoch:  30000 quantization_loss:  0.009381596930325031
p mean is: tensor(-0.8558, device='cuda:6')
epoch:  31000 quantization_loss:  0.0093226982280612
p mean is: tensor(-0.8698, device='cuda:6')
epoch:  32000 quantization_loss:  0.009280561469495296
p mean is: tensor(-0.8822, device='cuda:6')
epoch:  33000 quantization_loss:  0.009115892462432384
p mean is: tensor(-0.8929, device='cuda:6')
epoch:  34000 quantization_loss:  0.009033882059156895
p mean is: tensor(-0.9024, device='cuda:6')
epoch:  35000 quantization_loss:  0.008939575403928757
p mean is: tensor(-0.9107, device='cuda:6')
epoch:  36000 quantization_loss:  0.00891098938882351
p mean is: tensor(-0.9181, device='cuda:6')
epoch:  37000 quantization_loss:  0.0088671138510108
p mean is: tensor(-0.9247, device='cuda:6')
epoch:  38000 quantization_loss:  0.008848815225064754
p mean is: tensor(-0.9305, device='cuda:6')
epoch:  39000 quantization_loss:  0.00881648063659668
p mean is: tensor(-0.9358, device='cuda:6')
epoch:  40000 quantization_loss:  0.008809566497802734
p mean is: tensor(-0.9406, device='cuda:6')
epoch:  41000 quantization_loss:  0.008781947195529938
p mean is: tensor(-0.9450, device='cuda:6')
epoch:  42000 quantization_loss:  0.008762278594076633
p mean is: tensor(-0.9489, device='cuda:6')
epoch:  43000 quantization_loss:  0.008736933581531048
p mean is: tensor(-0.9525, device='cuda:6')
epoch:  44000 quantization_loss:  0.008721771650016308
p mean is: tensor(-0.9558, device='cuda:6')
epoch:  45000 quantization_loss:  0.008713934570550919
p mean is: tensor(-0.9588, device='cuda:6')
epoch:  46000 quantization_loss:  0.008695298805832863
p mean is: tensor(-0.9615, device='cuda:6')
epoch:  47000 quantization_loss:  0.008671225979924202
p mean is: tensor(-0.9641, device='cuda:6')
epoch:  48000 quantization_loss:  0.00873368140310049
p mean is: tensor(-0.9664, device='cuda:6')
epoch:  49000 quantization_loss:  0.00864021759480238
p mean is: tensor(-0.9686, device='cuda:6')
epoch:  50000 quantization_loss:  0.00866286363452673
p mean is: tensor(-0.9707, device='cuda:6')
epoch:  51000 quantization_loss:  0.008620080538094044
p mean is: tensor(-0.9727, device='cuda:6')
epoch:  52000 quantization_loss:  0.00861233938485384
p mean is: tensor(-0.9745, device='cuda:6')
epoch:  53000 quantization_loss:  0.008596882224082947
p mean is: tensor(-0.9761, device='cuda:6')
epoch:  54000 quantization_loss:  0.008601606823503971
p mean is: tensor(-0.9777, device='cuda:6')
epoch:  55000 quantization_loss:  0.00858263112604618
p mean is: tensor(-0.9792, device='cuda:6')
epoch:  56000 quantization_loss:  0.008580303750932217
p mean is: tensor(-0.9807, device='cuda:6')
epoch:  57000 quantization_loss:  0.0085880346596241
p mean is: tensor(-0.9820, device='cuda:6')
epoch:  58000 quantization_loss:  0.008573856204748154
p mean is: tensor(-0.9833, device='cuda:6')
epoch:  59000 quantization_loss:  0.008571479469537735
p mean is: tensor(-0.9846, device='cuda:6')
epoch:  60000 quantization_loss:  0.008555885404348373
p mean is: tensor(-0.9857, device='cuda:6')
epoch:  61000 quantization_loss:  0.008553211577236652
p mean is: tensor(-0.9868, device='cuda:6')
epoch:  62000 quantization_loss:  0.008547424338757992
p mean is: tensor(-0.9879, device='cuda:6')
epoch:  63000 quantization_loss:  0.008543184027075768
p mean is: tensor(-0.9889, device='cuda:6')
epoch:  64000 quantization_loss:  0.00854494795203209
p mean is: tensor(-0.9899, device='cuda:6')
epoch:  65000 quantization_loss:  0.008540475741028786
p mean is: tensor(-0.9908, device='cuda:6')
epoch:  66000 quantization_loss:  0.008531374856829643
p mean is: tensor(-0.9917, device='cuda:6')
epoch:  67000 quantization_loss:  0.008532258681952953
p mean is: tensor(-0.9926, device='cuda:6')
epoch:  68000 quantization_loss:  0.008543400093913078
p mean is: tensor(-0.9935, device='cuda:6')
epoch:  69000 quantization_loss:  0.008522155694663525
p mean is: tensor(-0.9943, device='cuda:6')
epoch:  70000 quantization_loss:  0.008518622256815434
p mean is: tensor(-0.9952, device='cuda:6')
epoch:  71000 quantization_loss:  0.008548229932785034
p mean is: tensor(-0.9960, device='cuda:6')
epoch:  72000 quantization_loss:  0.00851383339613676
p mean is: tensor(-0.9967, device='cuda:6')
epoch:  73000 quantization_loss:  0.008505580015480518
p mean is: tensor(-0.9974, device='cuda:6')
epoch:  74000 quantization_loss:  0.00851019099354744
p mean is: tensor(-0.9981, device='cuda:6')
epoch:  75000 quantization_loss:  0.008509561419487
p mean is: tensor(-0.9988, device='cuda:6')
epoch:  76000 quantization_loss:  0.008497904054820538
p mean is: tensor(-0.9994, device='cuda:6')
epoch:  77000 quantization_loss:  0.008500160649418831
p mean is: tensor(-1.0001, device='cuda:6')
epoch:  78000 quantization_loss:  0.008498369716107845
p mean is: tensor(-1.0008, device='cuda:6')
epoch:  79000 quantization_loss:  0.00853224191814661
p mean is: tensor(-1.0015, device='cuda:6')
here
1.1.1.weight         | nonzeros =    1023 /   12800             (  7.99%) | total_pruned =   11777 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     103 /    6400             (  1.61%) | total_pruned =    6297 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       3 /      16             ( 18.75%) | total_pruned =      13 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      88 /   12800             (  0.69%) | total_pruned =   12712 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      10 /      32             ( 31.25%) | total_pruned =      22 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     146 /   25600             (  0.57%) | total_pruned =   25454 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =      47 /   51200             (  0.09%) | total_pruned =   51153 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     215 /  102400             (  0.21%) | total_pruned =  102185 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =      64 /  204800             (  0.03%) | total_pruned =  204736 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     156 /  409600             (  0.04%) | total_pruned =  409444 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     342 /  409600             (  0.08%) | total_pruned =  409258 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    2785 /  409600             (  0.68%) | total_pruned =  406815 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    9017 /  409600             (  2.20%) | total_pruned =  400583 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   30594 /  409600             (  7.47%) | total_pruned =  379006 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   26992 /  147456             ( 18.31%) | total_pruned =  120464 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   25230 /  147456             ( 17.11%) | total_pruned =  122226 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   21054 /  147456             ( 14.28%) | total_pruned =  126402 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    9292 /   73728             ( 12.60%) | total_pruned =   64436 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2803 /   18432             ( 15.21%) | total_pruned =   15629 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1433 /    4608             ( 31.10%) | total_pruned =    3175 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      27 /      48             ( 56.25%) | total_pruned =      21 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 132651, pruned : 2876216, total: 3008867, Compression rate :      22.68x  ( 95.59% pruned)
PSNR of output image is:  17.63601158290789
Experiment done
