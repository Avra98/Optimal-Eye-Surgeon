(3, 512, 512)
(3, 512, 512)
Noisy PSNR is '9.671871251844006'
(3, 512, 512) torch.Size([1, 3, 512, 512]) torch.Size([1, 32, 512, 512])
Output directory: data/inpainting/Set14/mask/1/0.5/det/-0.8/1e-09
epoch:  0 quantization_loss:  0.03810203820466995
p mean is: tensor(-0.0001, device='cuda:6')
epoch:  1000 quantization_loss:  0.030674980953335762
p mean is: tensor(-0.0085, device='cuda:6')
epoch:  2000 quantization_loss:  0.030758114531636238
p mean is: tensor(-0.0153, device='cuda:6')
epoch:  3000 quantization_loss:  0.029745807871222496
p mean is: tensor(-0.0222, device='cuda:6')
epoch:  4000 quantization_loss:  0.029161961749196053
p mean is: tensor(-0.0291, device='cuda:6')
epoch:  5000 quantization_loss:  0.029317589476704597
p mean is: tensor(-0.0363, device='cuda:6')
epoch:  6000 quantization_loss:  0.029290704056620598
p mean is: tensor(-0.0433, device='cuda:6')
epoch:  7000 quantization_loss:  0.02806941792368889
p mean is: tensor(-0.0509, device='cuda:6')
epoch:  8000 quantization_loss:  0.024596359580755234
p mean is: tensor(-0.0592, device='cuda:6')
epoch:  9000 quantization_loss:  0.02170775644481182
p mean is: tensor(-0.0691, device='cuda:6')
epoch:  10000 quantization_loss:  0.018310999497771263
p mean is: tensor(-0.0819, device='cuda:6')
epoch:  11000 quantization_loss:  0.016528954729437828
p mean is: tensor(-0.0984, device='cuda:6')
epoch:  12000 quantization_loss:  0.01620784029364586
p mean is: tensor(-0.1197, device='cuda:6')
epoch:  13000 quantization_loss:  0.01545284315943718
p mean is: tensor(-0.1464, device='cuda:6')
epoch:  14000 quantization_loss:  0.01459397654980421
p mean is: tensor(-0.1791, device='cuda:6')
epoch:  15000 quantization_loss:  0.013906293548643589
p mean is: tensor(-0.2175, device='cuda:6')
epoch:  16000 quantization_loss:  0.013727347366511822
p mean is: tensor(-0.2608, device='cuda:6')
epoch:  17000 quantization_loss:  0.013719337992370129
p mean is: tensor(-0.3077, device='cuda:6')
epoch:  18000 quantization_loss:  0.012490786612033844
p mean is: tensor(-0.3562, device='cuda:6')
epoch:  19000 quantization_loss:  0.012246533297002316
p mean is: tensor(-0.4038, device='cuda:6')
epoch:  20000 quantization_loss:  0.01211010105907917
p mean is: tensor(-0.4488, device='cuda:6')
epoch:  21000 quantization_loss:  0.01195693202316761
p mean is: tensor(-0.4900, device='cuda:6')
epoch:  22000 quantization_loss:  0.011899356730282307
p mean is: tensor(-0.5270, device='cuda:6')
epoch:  23000 quantization_loss:  0.011773718520998955
p mean is: tensor(-0.5597, device='cuda:6')
epoch:  24000 quantization_loss:  0.011717451736330986
p mean is: tensor(-0.5883, device='cuda:6')
epoch:  25000 quantization_loss:  0.011649835854768753
p mean is: tensor(-0.6134, device='cuda:6')
epoch:  26000 quantization_loss:  0.011545429937541485
p mean is: tensor(-0.6351, device='cuda:6')
epoch:  27000 quantization_loss:  0.011484951712191105
p mean is: tensor(-0.6538, device='cuda:6')
epoch:  28000 quantization_loss:  0.011445701122283936
p mean is: tensor(-0.6700, device='cuda:6')
epoch:  29000 quantization_loss:  0.011369367130100727
p mean is: tensor(-0.6840, device='cuda:6')
epoch:  30000 quantization_loss:  0.011335545219480991
p mean is: tensor(-0.6961, device='cuda:6')
epoch:  31000 quantization_loss:  0.011273761279881
p mean is: tensor(-0.7066, device='cuda:6')
epoch:  32000 quantization_loss:  0.011046061292290688
p mean is: tensor(-0.7158, device='cuda:6')
epoch:  33000 quantization_loss:  0.010872483253479004
p mean is: tensor(-0.7237, device='cuda:6')
epoch:  34000 quantization_loss:  0.010850644670426846
p mean is: tensor(-0.7307, device='cuda:6')
epoch:  35000 quantization_loss:  0.01079054456204176
p mean is: tensor(-0.7367, device='cuda:6')
epoch:  36000 quantization_loss:  0.010766342282295227
p mean is: tensor(-0.7421, device='cuda:6')
epoch:  37000 quantization_loss:  0.010717353783547878
p mean is: tensor(-0.7469, device='cuda:6')
epoch:  38000 quantization_loss:  0.01064118929207325
p mean is: tensor(-0.7512, device='cuda:6')
epoch:  39000 quantization_loss:  0.01059950515627861
p mean is: tensor(-0.7551, device='cuda:6')
epoch:  40000 quantization_loss:  0.01058180257678032
p mean is: tensor(-0.7586, device='cuda:6')
epoch:  41000 quantization_loss:  0.010554236359894276
p mean is: tensor(-0.7618, device='cuda:6')
epoch:  42000 quantization_loss:  0.010560432448983192
p mean is: tensor(-0.7647, device='cuda:6')
epoch:  43000 quantization_loss:  0.01052844524383545
p mean is: tensor(-0.7674, device='cuda:6')
epoch:  44000 quantization_loss:  0.010499228723347187
p mean is: tensor(-0.7700, device='cuda:6')
epoch:  45000 quantization_loss:  0.010478210635483265
p mean is: tensor(-0.7723, device='cuda:6')
epoch:  46000 quantization_loss:  0.010454130358994007
p mean is: tensor(-0.7744, device='cuda:6')
epoch:  47000 quantization_loss:  0.010433482937514782
p mean is: tensor(-0.7764, device='cuda:6')
epoch:  48000 quantization_loss:  0.01042951736599207
p mean is: tensor(-0.7782, device='cuda:6')
epoch:  49000 quantization_loss:  0.010407897643744946
p mean is: tensor(-0.7799, device='cuda:6')
epoch:  50000 quantization_loss:  0.01039618905633688
p mean is: tensor(-0.7816, device='cuda:6')
epoch:  51000 quantization_loss:  0.010403110645711422
p mean is: tensor(-0.7832, device='cuda:6')
epoch:  52000 quantization_loss:  0.01037513092160225
p mean is: tensor(-0.7847, device='cuda:6')
epoch:  53000 quantization_loss:  0.01036738883703947
p mean is: tensor(-0.7862, device='cuda:6')
epoch:  54000 quantization_loss:  0.010334313847124577
p mean is: tensor(-0.7875, device='cuda:6')
epoch:  55000 quantization_loss:  0.010323179885745049
p mean is: tensor(-0.7888, device='cuda:6')
epoch:  56000 quantization_loss:  0.010327162221074104
p mean is: tensor(-0.7900, device='cuda:6')
epoch:  57000 quantization_loss:  0.010313627310097218
p mean is: tensor(-0.7912, device='cuda:6')
epoch:  58000 quantization_loss:  0.010301336646080017
p mean is: tensor(-0.7923, device='cuda:6')
epoch:  59000 quantization_loss:  0.010296222753822803
p mean is: tensor(-0.7934, device='cuda:6')
epoch:  60000 quantization_loss:  0.010287248529493809
p mean is: tensor(-0.7945, device='cuda:6')
epoch:  61000 quantization_loss:  0.010329576209187508
p mean is: tensor(-0.7955, device='cuda:6')
epoch:  62000 quantization_loss:  0.010274420492351055
p mean is: tensor(-0.7965, device='cuda:6')
epoch:  63000 quantization_loss:  0.010273369960486889
p mean is: tensor(-0.7975, device='cuda:6')
epoch:  64000 quantization_loss:  0.010272189974784851
p mean is: tensor(-0.7985, device='cuda:6')
epoch:  65000 quantization_loss:  0.010267207399010658
p mean is: tensor(-0.7994, device='cuda:6')
epoch:  66000 quantization_loss:  0.010259934701025486
p mean is: tensor(-0.8003, device='cuda:6')
epoch:  67000 quantization_loss:  0.010244608856737614
p mean is: tensor(-0.8012, device='cuda:6')
epoch:  68000 quantization_loss:  0.010248333215713501
p mean is: tensor(-0.8020, device='cuda:6')
epoch:  69000 quantization_loss:  0.010243610478937626
p mean is: tensor(-0.8028, device='cuda:6')
epoch:  70000 quantization_loss:  0.010239695198833942
p mean is: tensor(-0.8035, device='cuda:6')
epoch:  71000 quantization_loss:  0.01023821346461773
p mean is: tensor(-0.8043, device='cuda:6')
epoch:  72000 quantization_loss:  0.01022517029196024
p mean is: tensor(-0.8050, device='cuda:6')
epoch:  73000 quantization_loss:  0.010220431722700596
p mean is: tensor(-0.8057, device='cuda:6')
epoch:  74000 quantization_loss:  0.010234879329800606
p mean is: tensor(-0.8064, device='cuda:6')
epoch:  75000 quantization_loss:  0.01021937932819128
p mean is: tensor(-0.8071, device='cuda:6')
epoch:  76000 quantization_loss:  0.01021620724350214
p mean is: tensor(-0.8078, device='cuda:6')
epoch:  77000 quantization_loss:  0.010217580012977123
p mean is: tensor(-0.8085, device='cuda:6')
epoch:  78000 quantization_loss:  0.010209786705672741
p mean is: tensor(-0.8092, device='cuda:6')
epoch:  79000 quantization_loss:  0.010208784602582455
p mean is: tensor(-0.8098, device='cuda:6')
here
1.1.1.weight         | nonzeros =     989 /   12800             (  7.73%) | total_pruned =   11811 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     206 /    6400             (  3.22%) | total_pruned =    6194 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     138 /   12800             (  1.08%) | total_pruned =   12662 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     291 /   25600             (  1.14%) | total_pruned =   25309 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     278 /   51200             (  0.54%) | total_pruned =   50922 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     398 /  102400             (  0.39%) | total_pruned =  102002 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     165 /  204800             (  0.08%) | total_pruned =  204635 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     575 /  409600             (  0.14%) | total_pruned =  409025 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     924 /  409600             (  0.23%) | total_pruned =  408676 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    4458 /  409600             (  1.09%) | total_pruned =  405142 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   12665 /  409600             (  3.09%) | total_pruned =  396935 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   34770 /  409600             (  8.49%) | total_pruned =  374830 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   29415 /  147456             ( 19.95%) | total_pruned =  118041 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   32628 /  147456             ( 22.13%) | total_pruned =  114828 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   26806 /  147456             ( 18.18%) | total_pruned =  120650 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   10099 /   73728             ( 13.70%) | total_pruned =   63629 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2000 /   18432             ( 10.85%) | total_pruned =   16432 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =     943 /    4608             ( 20.46%) | total_pruned =    3665 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      27 /      48             ( 56.25%) | total_pruned =      21 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 159059, pruned : 2849808, total: 3008867, Compression rate :      18.92x  ( 94.71% pruned)
PSNR of output image is:  16.80631986830367
Experiment done
