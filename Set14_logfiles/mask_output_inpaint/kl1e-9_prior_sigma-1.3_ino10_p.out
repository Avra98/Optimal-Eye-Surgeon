(3, 256, 256)
(3, 256, 256)
Noisy PSNR is '6.215802884030377'
(3, 256, 256) torch.Size([1, 3, 256, 256]) torch.Size([1, 32, 256, 256])
Output directory: data/inpainting/Set14/mask/10/0.5/det/-1.3/1e-09
epoch:  0 quantization_loss:  0.043388403952121735
p mean is: tensor(-0.0002, device='cuda:1')
epoch:  1000 quantization_loss:  0.03649003058671951
p mean is: tensor(-0.0072, device='cuda:1')
epoch:  2000 quantization_loss:  0.03641510754823685
p mean is: tensor(-0.0122, device='cuda:1')
epoch:  3000 quantization_loss:  0.03538660705089569
p mean is: tensor(-0.0166, device='cuda:1')
epoch:  4000 quantization_loss:  0.03249324485659599
p mean is: tensor(-0.0213, device='cuda:1')
epoch:  5000 quantization_loss:  0.03381780534982681
p mean is: tensor(-0.0259, device='cuda:1')
epoch:  6000 quantization_loss:  0.03322543948888779
p mean is: tensor(-0.0307, device='cuda:1')
epoch:  7000 quantization_loss:  0.034631434828042984
p mean is: tensor(-0.0359, device='cuda:1')
epoch:  8000 quantization_loss:  0.03371609374880791
p mean is: tensor(-0.0409, device='cuda:1')
epoch:  9000 quantization_loss:  0.033454813063144684
p mean is: tensor(-0.0461, device='cuda:1')
epoch:  10000 quantization_loss:  0.029104121029376984
p mean is: tensor(-0.0512, device='cuda:1')
epoch:  11000 quantization_loss:  0.02368166483938694
p mean is: tensor(-0.0568, device='cuda:1')
epoch:  12000 quantization_loss:  0.018970239907503128
p mean is: tensor(-0.0646, device='cuda:1')
epoch:  13000 quantization_loss:  0.017475290223956108
p mean is: tensor(-0.0753, device='cuda:1')
epoch:  14000 quantization_loss:  0.016753865405917168
p mean is: tensor(-0.0903, device='cuda:1')
epoch:  15000 quantization_loss:  0.013984632678329945
p mean is: tensor(-0.1108, device='cuda:1')
epoch:  16000 quantization_loss:  0.013095591217279434
p mean is: tensor(-0.1383, device='cuda:1')
epoch:  17000 quantization_loss:  0.012322400696575642
p mean is: tensor(-0.1741, device='cuda:1')
epoch:  18000 quantization_loss:  0.011594057083129883
p mean is: tensor(-0.2195, device='cuda:1')
epoch:  19000 quantization_loss:  0.010819632560014725
p mean is: tensor(-0.2755, device='cuda:1')
epoch:  20000 quantization_loss:  0.010372034274041653
p mean is: tensor(-0.3418, device='cuda:1')
epoch:  21000 quantization_loss:  0.009882216341793537
p mean is: tensor(-0.4172, device='cuda:1')
epoch:  22000 quantization_loss:  0.009427820332348347
p mean is: tensor(-0.4989, device='cuda:1')
epoch:  23000 quantization_loss:  0.008424671366810799
p mean is: tensor(-0.5822, device='cuda:1')
epoch:  24000 quantization_loss:  0.008286566473543644
p mean is: tensor(-0.6629, device='cuda:1')
epoch:  25000 quantization_loss:  0.008043907582759857
p mean is: tensor(-0.7378, device='cuda:1')
epoch:  26000 quantization_loss:  0.007875903509557247
p mean is: tensor(-0.8055, device='cuda:1')
epoch:  27000 quantization_loss:  0.007682222407311201
p mean is: tensor(-0.8656, device='cuda:1')
epoch:  28000 quantization_loss:  0.007638182025402784
p mean is: tensor(-0.9181, device='cuda:1')
epoch:  29000 quantization_loss:  0.007527349982410669
p mean is: tensor(-0.9637, device='cuda:1')
epoch:  30000 quantization_loss:  0.007465093396604061
p mean is: tensor(-1.0030, device='cuda:1')
epoch:  31000 quantization_loss:  0.007461993023753166
p mean is: tensor(-1.0368, device='cuda:1')
epoch:  32000 quantization_loss:  0.007388275116682053
p mean is: tensor(-1.0660, device='cuda:1')
epoch:  33000 quantization_loss:  0.007301656994968653
p mean is: tensor(-1.0913, device='cuda:1')
epoch:  34000 quantization_loss:  0.007231735158711672
p mean is: tensor(-1.1132, device='cuda:1')
epoch:  35000 quantization_loss:  0.0072668781504035
p mean is: tensor(-1.1321, device='cuda:1')
epoch:  36000 quantization_loss:  0.007195579819381237
p mean is: tensor(-1.1485, device='cuda:1')
epoch:  37000 quantization_loss:  0.007148282136768103
p mean is: tensor(-1.1627, device='cuda:1')
epoch:  38000 quantization_loss:  0.007096057292073965
p mean is: tensor(-1.1751, device='cuda:1')
epoch:  39000 quantization_loss:  0.007097078021615744
p mean is: tensor(-1.1857, device='cuda:1')
epoch:  40000 quantization_loss:  0.007030499167740345
p mean is: tensor(-1.1952, device='cuda:1')
epoch:  41000 quantization_loss:  0.007047958206385374
p mean is: tensor(-1.2035, device='cuda:1')
epoch:  42000 quantization_loss:  0.0069982209242880344
p mean is: tensor(-1.2107, device='cuda:1')
epoch:  43000 quantization_loss:  0.006978608202189207
p mean is: tensor(-1.2171, device='cuda:1')
epoch:  44000 quantization_loss:  0.006967488210648298
p mean is: tensor(-1.2227, device='cuda:1')
epoch:  45000 quantization_loss:  0.006993276532739401
p mean is: tensor(-1.2277, device='cuda:1')
epoch:  46000 quantization_loss:  0.006929437629878521
p mean is: tensor(-1.2321, device='cuda:1')
epoch:  47000 quantization_loss:  0.006865093484520912
p mean is: tensor(-1.2360, device='cuda:1')
epoch:  48000 quantization_loss:  0.006864749360829592
p mean is: tensor(-1.2395, device='cuda:1')
epoch:  49000 quantization_loss:  0.006827118806540966
p mean is: tensor(-1.2426, device='cuda:1')
epoch:  50000 quantization_loss:  0.006803334224969149
p mean is: tensor(-1.2454, device='cuda:1')
epoch:  51000 quantization_loss:  0.006785904988646507
p mean is: tensor(-1.2480, device='cuda:1')
epoch:  52000 quantization_loss:  0.006757998839020729
p mean is: tensor(-1.2503, device='cuda:1')
epoch:  53000 quantization_loss:  0.006249386351555586
p mean is: tensor(-1.2524, device='cuda:1')
epoch:  54000 quantization_loss:  0.006243269890546799
p mean is: tensor(-1.2543, device='cuda:1')
epoch:  55000 quantization_loss:  0.006199053023010492
p mean is: tensor(-1.2560, device='cuda:1')
epoch:  56000 quantization_loss:  0.006209569983184338
p mean is: tensor(-1.2577, device='cuda:1')
epoch:  57000 quantization_loss:  0.0061746444553136826
p mean is: tensor(-1.2592, device='cuda:1')
epoch:  58000 quantization_loss:  0.006160874851047993
p mean is: tensor(-1.2606, device='cuda:1')
epoch:  59000 quantization_loss:  0.006135459057986736
p mean is: tensor(-1.2620, device='cuda:1')
epoch:  60000 quantization_loss:  0.006117789074778557
p mean is: tensor(-1.2632, device='cuda:1')
epoch:  61000 quantization_loss:  0.006110014393925667
p mean is: tensor(-1.2643, device='cuda:1')
epoch:  62000 quantization_loss:  0.006087993737310171
p mean is: tensor(-1.2654, device='cuda:1')
epoch:  63000 quantization_loss:  0.006072619929909706
p mean is: tensor(-1.2664, device='cuda:1')
epoch:  64000 quantization_loss:  0.006090050563216209
p mean is: tensor(-1.2674, device='cuda:1')
epoch:  65000 quantization_loss:  0.006071996409446001
p mean is: tensor(-1.2683, device='cuda:1')
epoch:  66000 quantization_loss:  0.006050304509699345
p mean is: tensor(-1.2692, device='cuda:1')
epoch:  67000 quantization_loss:  0.006054496858268976
p mean is: tensor(-1.2701, device='cuda:1')
epoch:  68000 quantization_loss:  0.006050120107829571
p mean is: tensor(-1.2709, device='cuda:1')
epoch:  69000 quantization_loss:  0.006046559661626816
p mean is: tensor(-1.2716, device='cuda:1')
epoch:  70000 quantization_loss:  0.006082275882363319
p mean is: tensor(-1.2724, device='cuda:1')
epoch:  71000 quantization_loss:  0.006035507656633854
p mean is: tensor(-1.2730, device='cuda:1')
epoch:  72000 quantization_loss:  0.006034848280251026
p mean is: tensor(-1.2737, device='cuda:1')
epoch:  73000 quantization_loss:  0.006025208160281181
p mean is: tensor(-1.2743, device='cuda:1')
epoch:  74000 quantization_loss:  0.006023532245308161
p mean is: tensor(-1.2749, device='cuda:1')
epoch:  75000 quantization_loss:  0.006022147834300995
p mean is: tensor(-1.2755, device='cuda:1')
epoch:  76000 quantization_loss:  0.006013789679855108
p mean is: tensor(-1.2760, device='cuda:1')
epoch:  77000 quantization_loss:  0.006013471633195877
p mean is: tensor(-1.2766, device='cuda:1')
epoch:  78000 quantization_loss:  0.006006782874464989
p mean is: tensor(-1.2771, device='cuda:1')
epoch:  79000 quantization_loss:  0.006012446712702513
p mean is: tensor(-1.2775, device='cuda:1')
here
1.1.1.weight         | nonzeros =      56 /   12800             (  0.44%) | total_pruned =   12744 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       5 /      16             ( 31.25%) | total_pruned =      11 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =      17 /    6400             (  0.27%) | total_pruned =    6383 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       5 /      16             ( 31.25%) | total_pruned =      11 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =       5 /   12800             (  0.04%) | total_pruned =   12795 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =       7 /      32             ( 21.88%) | total_pruned =      25 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =       2 /   25600             (  0.01%) | total_pruned =   25598 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =       6 /      32             ( 18.75%) | total_pruned =      26 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =       3 /   51200             (  0.01%) | total_pruned =   51197 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =       1 /  102400             (  0.00%) | total_pruned =  102399 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =       0 /  204800             (  0.00%) | total_pruned =  204800 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =       1 /  409600             (  0.00%) | total_pruned =  409599 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =       0 /  409600             (  0.00%) | total_pruned =  409600 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =     123 /  409600             (  0.03%) | total_pruned =  409477 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     670 /  409600             (  0.16%) | total_pruned =  408930 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    6513 /  409600             (  1.59%) | total_pruned =  403087 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   15459 /  147456             ( 10.48%) | total_pruned =  131997 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   22010 /  147456             ( 14.93%) | total_pruned =  125446 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   22300 /  147456             ( 15.12%) | total_pruned =  125156 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    9194 /   73728             ( 12.47%) | total_pruned =   64534 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2500 /   18432             ( 13.56%) | total_pruned =   15932 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1228 /    4608             ( 26.65%) | total_pruned =    3380 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      30 /      48             ( 62.50%) | total_pruned =      18 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 81101, pruned : 2927766, total: 3008867, Compression rate :      37.10x  ( 97.30% pruned)
PSNR of output image is:  11.02594286547463
Experiment done
