(3, 512, 512)
(3, 512, 512)
Noisy PSNR is '7.8881288072150895'
(3, 512, 512) torch.Size([1, 3, 512, 512]) torch.Size([1, 32, 512, 512])
Output directory: data/inpainting/Set14/mask/13/0.5/det/-0.7/1e-09
epoch:  0 quantization_loss:  0.02584836632013321
p mean is: tensor(-0.0001, device='cuda:2')
epoch:  1000 quantization_loss:  0.019740629941225052
p mean is: tensor(-0.0091, device='cuda:2')
epoch:  2000 quantization_loss:  0.02054908685386181
p mean is: tensor(-0.0167, device='cuda:2')
epoch:  3000 quantization_loss:  0.019234849140048027
p mean is: tensor(-0.0246, device='cuda:2')
epoch:  4000 quantization_loss:  0.0192400049418211
p mean is: tensor(-0.0325, device='cuda:2')
epoch:  5000 quantization_loss:  0.018566804006695747
p mean is: tensor(-0.0408, device='cuda:2')
epoch:  6000 quantization_loss:  0.018492475152015686
p mean is: tensor(-0.0502, device='cuda:2')
epoch:  7000 quantization_loss:  0.018112000077962875
p mean is: tensor(-0.0605, device='cuda:2')
epoch:  8000 quantization_loss:  0.016555460169911385
p mean is: tensor(-0.0709, device='cuda:2')
epoch:  9000 quantization_loss:  0.013730964623391628
p mean is: tensor(-0.0834, device='cuda:2')
epoch:  10000 quantization_loss:  0.009233932010829449
p mean is: tensor(-0.0980, device='cuda:2')
epoch:  11000 quantization_loss:  0.008352885022759438
p mean is: tensor(-0.1153, device='cuda:2')
epoch:  12000 quantization_loss:  0.00744281429797411
p mean is: tensor(-0.1370, device='cuda:2')
epoch:  13000 quantization_loss:  0.006857993081212044
p mean is: tensor(-0.1639, device='cuda:2')
epoch:  14000 quantization_loss:  0.006239067297428846
p mean is: tensor(-0.1959, device='cuda:2')
epoch:  15000 quantization_loss:  0.005914961453527212
p mean is: tensor(-0.2327, device='cuda:2')
epoch:  16000 quantization_loss:  0.0056739142164587975
p mean is: tensor(-0.2730, device='cuda:2')
epoch:  17000 quantization_loss:  0.005369532387703657
p mean is: tensor(-0.3152, device='cuda:2')
epoch:  18000 quantization_loss:  0.005312178283929825
p mean is: tensor(-0.3575, device='cuda:2')
epoch:  19000 quantization_loss:  0.005222406703978777
p mean is: tensor(-0.3980, device='cuda:2')
epoch:  20000 quantization_loss:  0.005089580547064543
p mean is: tensor(-0.4354, device='cuda:2')
epoch:  21000 quantization_loss:  0.004970021545886993
p mean is: tensor(-0.4690, device='cuda:2')
epoch:  22000 quantization_loss:  0.0048915245570242405
p mean is: tensor(-0.4985, device='cuda:2')
epoch:  23000 quantization_loss:  0.004826096352189779
p mean is: tensor(-0.5242, device='cuda:2')
epoch:  24000 quantization_loss:  0.004723988939076662
p mean is: tensor(-0.5464, device='cuda:2')
epoch:  25000 quantization_loss:  0.004695082549005747
p mean is: tensor(-0.5652, device='cuda:2')
epoch:  26000 quantization_loss:  0.004623003304004669
p mean is: tensor(-0.5814, device='cuda:2')
epoch:  27000 quantization_loss:  0.004607011564075947
p mean is: tensor(-0.5953, device='cuda:2')
epoch:  28000 quantization_loss:  0.004554676357656717
p mean is: tensor(-0.6073, device='cuda:2')
epoch:  29000 quantization_loss:  0.004527909215539694
p mean is: tensor(-0.6175, device='cuda:2')
epoch:  30000 quantization_loss:  0.004515559878200293
p mean is: tensor(-0.6264, device='cuda:2')
epoch:  31000 quantization_loss:  0.004511670675128698
p mean is: tensor(-0.6341, device='cuda:2')
epoch:  32000 quantization_loss:  0.004442782606929541
p mean is: tensor(-0.6408, device='cuda:2')
epoch:  33000 quantization_loss:  0.004443102516233921
p mean is: tensor(-0.6466, device='cuda:2')
epoch:  34000 quantization_loss:  0.004422627855092287
p mean is: tensor(-0.6517, device='cuda:2')
epoch:  35000 quantization_loss:  0.004496085457503796
p mean is: tensor(-0.6562, device='cuda:2')
epoch:  36000 quantization_loss:  0.004398520104587078
p mean is: tensor(-0.6601, device='cuda:2')
epoch:  37000 quantization_loss:  0.004379446618258953
p mean is: tensor(-0.6636, device='cuda:2')
epoch:  38000 quantization_loss:  0.004361176863312721
p mean is: tensor(-0.6668, device='cuda:2')
epoch:  39000 quantization_loss:  0.004358992446213961
p mean is: tensor(-0.6696, device='cuda:2')
epoch:  40000 quantization_loss:  0.004335850011557341
p mean is: tensor(-0.6720, device='cuda:2')
epoch:  41000 quantization_loss:  0.004326156340539455
p mean is: tensor(-0.6743, device='cuda:2')
epoch:  42000 quantization_loss:  0.004315552767366171
p mean is: tensor(-0.6764, device='cuda:2')
epoch:  43000 quantization_loss:  0.004315431695431471
p mean is: tensor(-0.6782, device='cuda:2')
epoch:  44000 quantization_loss:  0.004312459845095873
p mean is: tensor(-0.6799, device='cuda:2')
epoch:  45000 quantization_loss:  0.004302353598177433
p mean is: tensor(-0.6815, device='cuda:2')
epoch:  46000 quantization_loss:  0.004293452948331833
p mean is: tensor(-0.6830, device='cuda:2')
epoch:  47000 quantization_loss:  0.004280101507902145
p mean is: tensor(-0.6843, device='cuda:2')
epoch:  48000 quantization_loss:  0.004263176582753658
p mean is: tensor(-0.6856, device='cuda:2')
epoch:  49000 quantization_loss:  0.004267971962690353
p mean is: tensor(-0.6868, device='cuda:2')
epoch:  50000 quantization_loss:  0.004256328567862511
p mean is: tensor(-0.6879, device='cuda:2')
epoch:  51000 quantization_loss:  0.004246183205395937
p mean is: tensor(-0.6889, device='cuda:2')
epoch:  52000 quantization_loss:  0.004234387073665857
p mean is: tensor(-0.6899, device='cuda:2')
epoch:  53000 quantization_loss:  0.004238200839608908
p mean is: tensor(-0.6908, device='cuda:2')
epoch:  54000 quantization_loss:  0.004234237130731344
p mean is: tensor(-0.6916, device='cuda:2')
epoch:  55000 quantization_loss:  0.004224802833050489
p mean is: tensor(-0.6924, device='cuda:2')
epoch:  56000 quantization_loss:  0.004223200026899576
p mean is: tensor(-0.6932, device='cuda:2')
epoch:  57000 quantization_loss:  0.0042284405790269375
p mean is: tensor(-0.6939, device='cuda:2')
epoch:  58000 quantization_loss:  0.004214226268231869
p mean is: tensor(-0.6946, device='cuda:2')
epoch:  59000 quantization_loss:  0.004222395364195108
p mean is: tensor(-0.6953, device='cuda:2')
epoch:  60000 quantization_loss:  0.004210814367979765
p mean is: tensor(-0.6960, device='cuda:2')
epoch:  61000 quantization_loss:  0.004212363623082638
p mean is: tensor(-0.6966, device='cuda:2')
epoch:  62000 quantization_loss:  0.0042093051597476006
p mean is: tensor(-0.6972, device='cuda:2')
epoch:  63000 quantization_loss:  0.004201841540634632
p mean is: tensor(-0.6977, device='cuda:2')
epoch:  64000 quantization_loss:  0.004196309018880129
p mean is: tensor(-0.6982, device='cuda:2')
epoch:  65000 quantization_loss:  0.00419981824234128
p mean is: tensor(-0.6988, device='cuda:2')
epoch:  66000 quantization_loss:  0.004201374016702175
p mean is: tensor(-0.6993, device='cuda:2')
epoch:  67000 quantization_loss:  0.004198497626930475
p mean is: tensor(-0.6998, device='cuda:2')
epoch:  68000 quantization_loss:  0.004190023522824049
p mean is: tensor(-0.7002, device='cuda:2')
epoch:  69000 quantization_loss:  0.004184555262327194
p mean is: tensor(-0.7007, device='cuda:2')
epoch:  70000 quantization_loss:  0.004184931516647339
p mean is: tensor(-0.7012, device='cuda:2')
epoch:  71000 quantization_loss:  0.0041870493441820145
p mean is: tensor(-0.7016, device='cuda:2')
epoch:  72000 quantization_loss:  0.004184040706604719
p mean is: tensor(-0.7020, device='cuda:2')
epoch:  73000 quantization_loss:  0.004181630443781614
p mean is: tensor(-0.7024, device='cuda:2')
epoch:  74000 quantization_loss:  0.004182922188192606
p mean is: tensor(-0.7028, device='cuda:2')
epoch:  75000 quantization_loss:  0.004180737305432558
p mean is: tensor(-0.7032, device='cuda:2')
epoch:  76000 quantization_loss:  0.004173852037638426
p mean is: tensor(-0.7036, device='cuda:2')
epoch:  77000 quantization_loss:  0.004179808311164379
p mean is: tensor(-0.7040, device='cuda:2')
epoch:  78000 quantization_loss:  0.004172410350292921
p mean is: tensor(-0.7043, device='cuda:2')
epoch:  79000 quantization_loss:  0.004173031076788902
p mean is: tensor(-0.7047, device='cuda:2')
here
1.1.1.weight         | nonzeros =     749 /   12800             (  5.85%) | total_pruned =   12051 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     111 /    6400             (  1.73%) | total_pruned =    6289 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      85 /   12800             (  0.66%) | total_pruned =   12715 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     155 /   25600             (  0.61%) | total_pruned =   25445 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      10 /      32             ( 31.25%) | total_pruned =      22 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     104 /   51200             (  0.20%) | total_pruned =   51096 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     187 /  102400             (  0.18%) | total_pruned =  102213 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =      98 /  204800             (  0.05%) | total_pruned =  204702 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     395 /  409600             (  0.10%) | total_pruned =  409205 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     726 /  409600             (  0.18%) | total_pruned =  408874 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    3762 /  409600             (  0.92%) | total_pruned =  405838 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   11319 /  409600             (  2.76%) | total_pruned =  398281 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   30376 /  409600             (  7.42%) | total_pruned =  379224 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   25795 /  147456             ( 17.49%) | total_pruned =  121661 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   25643 /  147456             ( 17.39%) | total_pruned =  121813 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   21940 /  147456             ( 14.88%) | total_pruned =  125516 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    9172 /   73728             ( 12.44%) | total_pruned =   64556 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2706 /   18432             ( 14.68%) | total_pruned =   15726 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      21 /      32             ( 65.62%) | total_pruned =      11 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      21 /      32             ( 65.62%) | total_pruned =      11 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1349 /    4608             ( 29.28%) | total_pruned =    3259 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      15 /      16             ( 93.75%) | total_pruned =       1 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      27 /      48             ( 56.25%) | total_pruned =      21 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 135934, pruned : 2872933, total: 3008867, Compression rate :      22.13x  ( 95.48% pruned)
PSNR of output image is:  20.441334425444598
Experiment done
