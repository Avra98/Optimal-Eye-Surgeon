(3, 512, 512)
(3, 512, 512)
Noisy PSNR is '9.796142533440973'
(3, 512, 512) torch.Size([1, 3, 512, 512]) torch.Size([1, 32, 512, 512])
Output directory: data/inpainting/Set14/mask/11/0.5/det/-0.7/1e-09
epoch:  0 quantization_loss:  0.02517726831138134
p mean is: tensor(-0.0001, device='cuda:6')
epoch:  1000 quantization_loss:  0.018116649240255356
p mean is: tensor(-0.0118, device='cuda:6')
epoch:  2000 quantization_loss:  0.01770932413637638
p mean is: tensor(-0.0214, device='cuda:6')
epoch:  3000 quantization_loss:  0.018318727612495422
p mean is: tensor(-0.0318, device='cuda:6')
epoch:  4000 quantization_loss:  0.017498232424259186
p mean is: tensor(-0.0433, device='cuda:6')
epoch:  5000 quantization_loss:  0.017173953354358673
p mean is: tensor(-0.0560, device='cuda:6')
epoch:  6000 quantization_loss:  0.017342092469334602
p mean is: tensor(-0.0694, device='cuda:6')
epoch:  7000 quantization_loss:  0.016629468649625778
p mean is: tensor(-0.0840, device='cuda:6')
epoch:  8000 quantization_loss:  0.01545004453510046
p mean is: tensor(-0.1016, device='cuda:6')
epoch:  9000 quantization_loss:  0.01403080765157938
p mean is: tensor(-0.1231, device='cuda:6')
epoch:  10000 quantization_loss:  0.012894849292933941
p mean is: tensor(-0.1486, device='cuda:6')
epoch:  11000 quantization_loss:  0.012184269726276398
p mean is: tensor(-0.1781, device='cuda:6')
epoch:  12000 quantization_loss:  0.011611091904342175
p mean is: tensor(-0.2126, device='cuda:6')
epoch:  13000 quantization_loss:  0.011144459247589111
p mean is: tensor(-0.2515, device='cuda:6')
epoch:  14000 quantization_loss:  0.010884127579629421
p mean is: tensor(-0.2936, device='cuda:6')
epoch:  15000 quantization_loss:  0.01007710862904787
p mean is: tensor(-0.3367, device='cuda:6')
epoch:  16000 quantization_loss:  0.00931051466614008
p mean is: tensor(-0.3788, device='cuda:6')
epoch:  17000 quantization_loss:  0.008995398879051208
p mean is: tensor(-0.4179, device='cuda:6')
epoch:  18000 quantization_loss:  0.008570163510739803
p mean is: tensor(-0.4535, device='cuda:6')
epoch:  19000 quantization_loss:  0.008405202068388462
p mean is: tensor(-0.4852, device='cuda:6')
epoch:  20000 quantization_loss:  0.008047708310186863
p mean is: tensor(-0.5129, device='cuda:6')
epoch:  21000 quantization_loss:  0.007744801230728626
p mean is: tensor(-0.5370, device='cuda:6')
epoch:  22000 quantization_loss:  0.007572654169052839
p mean is: tensor(-0.5578, device='cuda:6')
epoch:  23000 quantization_loss:  0.007367671467363834
p mean is: tensor(-0.5758, device='cuda:6')
epoch:  24000 quantization_loss:  0.007292022462934256
p mean is: tensor(-0.5913, device='cuda:6')
epoch:  25000 quantization_loss:  0.0071889422833919525
p mean is: tensor(-0.6047, device='cuda:6')
epoch:  26000 quantization_loss:  0.007039944641292095
p mean is: tensor(-0.6161, device='cuda:6')
epoch:  27000 quantization_loss:  0.0068415692076087
p mean is: tensor(-0.6258, device='cuda:6')
epoch:  28000 quantization_loss:  0.006767522543668747
p mean is: tensor(-0.6341, device='cuda:6')
epoch:  29000 quantization_loss:  0.0067252544686198235
p mean is: tensor(-0.6414, device='cuda:6')
epoch:  30000 quantization_loss:  0.006637141108512878
p mean is: tensor(-0.6477, device='cuda:6')
epoch:  31000 quantization_loss:  0.006582724861800671
p mean is: tensor(-0.6533, device='cuda:6')
epoch:  32000 quantization_loss:  0.0065291752107441425
p mean is: tensor(-0.6583, device='cuda:6')
epoch:  33000 quantization_loss:  0.00648776488378644
p mean is: tensor(-0.6625, device='cuda:6')
epoch:  34000 quantization_loss:  0.0064679961651563644
p mean is: tensor(-0.6664, device='cuda:6')
epoch:  35000 quantization_loss:  0.006452237721532583
p mean is: tensor(-0.6697, device='cuda:6')
epoch:  36000 quantization_loss:  0.0064057717099785805
p mean is: tensor(-0.6727, device='cuda:6')
epoch:  37000 quantization_loss:  0.006387592293322086
p mean is: tensor(-0.6754, device='cuda:6')
epoch:  38000 quantization_loss:  0.00636119581758976
p mean is: tensor(-0.6779, device='cuda:6')
epoch:  39000 quantization_loss:  0.00635297829285264
p mean is: tensor(-0.6802, device='cuda:6')
epoch:  40000 quantization_loss:  0.006375887896865606
p mean is: tensor(-0.6822, device='cuda:6')
epoch:  41000 quantization_loss:  0.006323685869574547
p mean is: tensor(-0.6839, device='cuda:6')
epoch:  42000 quantization_loss:  0.006298399530351162
p mean is: tensor(-0.6856, device='cuda:6')
epoch:  43000 quantization_loss:  0.006274678744375706
p mean is: tensor(-0.6871, device='cuda:6')
epoch:  44000 quantization_loss:  0.0062674423679709435
p mean is: tensor(-0.6885, device='cuda:6')
epoch:  45000 quantization_loss:  0.006265781819820404
p mean is: tensor(-0.6898, device='cuda:6')
epoch:  46000 quantization_loss:  0.006248438730835915
p mean is: tensor(-0.6911, device='cuda:6')
epoch:  47000 quantization_loss:  0.006230692379176617
p mean is: tensor(-0.6923, device='cuda:6')
epoch:  48000 quantization_loss:  0.0062410603277385235
p mean is: tensor(-0.6934, device='cuda:6')
epoch:  49000 quantization_loss:  0.00622463459149003
p mean is: tensor(-0.6944, device='cuda:6')
epoch:  50000 quantization_loss:  0.006220260635018349
p mean is: tensor(-0.6954, device='cuda:6')
epoch:  51000 quantization_loss:  0.006210641004145145
p mean is: tensor(-0.6963, device='cuda:6')
epoch:  52000 quantization_loss:  0.0062124826945364475
p mean is: tensor(-0.6971, device='cuda:6')
epoch:  53000 quantization_loss:  0.006210720166563988
p mean is: tensor(-0.6979, device='cuda:6')
epoch:  54000 quantization_loss:  0.00619543856009841
p mean is: tensor(-0.6987, device='cuda:6')
epoch:  55000 quantization_loss:  0.006194109562784433
p mean is: tensor(-0.6994, device='cuda:6')
epoch:  56000 quantization_loss:  0.00620926171541214
p mean is: tensor(-0.7002, device='cuda:6')
epoch:  57000 quantization_loss:  0.006185716949403286
p mean is: tensor(-0.7009, device='cuda:6')
epoch:  58000 quantization_loss:  0.006183445919305086
p mean is: tensor(-0.7016, device='cuda:6')
epoch:  59000 quantization_loss:  0.006180205848067999
p mean is: tensor(-0.7022, device='cuda:6')
epoch:  60000 quantization_loss:  0.006181833799928427
p mean is: tensor(-0.7028, device='cuda:6')
epoch:  61000 quantization_loss:  0.006177893839776516
p mean is: tensor(-0.7034, device='cuda:6')
epoch:  62000 quantization_loss:  0.00616857036948204
p mean is: tensor(-0.7040, device='cuda:6')
epoch:  63000 quantization_loss:  0.006170316133648157
p mean is: tensor(-0.7046, device='cuda:6')
epoch:  64000 quantization_loss:  0.006169822998344898
p mean is: tensor(-0.7052, device='cuda:6')
epoch:  65000 quantization_loss:  0.006166025530546904
p mean is: tensor(-0.7057, device='cuda:6')
epoch:  66000 quantization_loss:  0.006170756183564663
p mean is: tensor(-0.7062, device='cuda:6')
epoch:  67000 quantization_loss:  0.006162622477859259
p mean is: tensor(-0.7067, device='cuda:6')
epoch:  68000 quantization_loss:  0.006161381956189871
p mean is: tensor(-0.7073, device='cuda:6')
epoch:  69000 quantization_loss:  0.0061579737812280655
p mean is: tensor(-0.7077, device='cuda:6')
epoch:  70000 quantization_loss:  0.006160781253129244
p mean is: tensor(-0.7082, device='cuda:6')
epoch:  71000 quantization_loss:  0.006163616664707661
p mean is: tensor(-0.7087, device='cuda:6')
epoch:  72000 quantization_loss:  0.006160619203001261
p mean is: tensor(-0.7091, device='cuda:6')
epoch:  73000 quantization_loss:  0.006157266907393932
p mean is: tensor(-0.7095, device='cuda:6')
epoch:  74000 quantization_loss:  0.006157123949378729
p mean is: tensor(-0.7100, device='cuda:6')
epoch:  75000 quantization_loss:  0.006149820983409882
p mean is: tensor(-0.7104, device='cuda:6')
epoch:  76000 quantization_loss:  0.006150653585791588
p mean is: tensor(-0.7108, device='cuda:6')
epoch:  77000 quantization_loss:  0.006146864499896765
p mean is: tensor(-0.7112, device='cuda:6')
epoch:  78000 quantization_loss:  0.006159450393170118
p mean is: tensor(-0.7116, device='cuda:6')
epoch:  79000 quantization_loss:  0.006171158514916897
p mean is: tensor(-0.7120, device='cuda:6')
here
1.1.1.weight         | nonzeros =    1035 /   12800             (  8.09%) | total_pruned =   11765 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     150 /    6400             (  2.34%) | total_pruned =    6250 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       4 /      16             ( 25.00%) | total_pruned =      12 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     101 /   12800             (  0.79%) | total_pruned =   12699 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     169 /   25600             (  0.66%) | total_pruned =   25431 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      12 /      32             ( 37.50%) | total_pruned =      20 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     218 /   51200             (  0.43%) | total_pruned =   50982 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     451 /  102400             (  0.44%) | total_pruned =  101949 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     295 /  204800             (  0.14%) | total_pruned =  204505 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     742 /  409600             (  0.18%) | total_pruned =  408858 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    1067 /  409600             (  0.26%) | total_pruned =  408533 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    4864 /  409600             (  1.19%) | total_pruned =  404736 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   14390 /  409600             (  3.51%) | total_pruned =  395210 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   39151 /  409600             (  9.56%) | total_pruned =  370449 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   28720 /  147456             ( 19.48%) | total_pruned =  118736 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   23013 /  147456             ( 15.61%) | total_pruned =  124443 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   13600 /  147456             (  9.22%) | total_pruned =  133856 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    6227 /   73728             (  8.45%) | total_pruned =   67501 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2163 /   18432             ( 11.74%) | total_pruned =   16269 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =     999 /    4608             ( 21.68%) | total_pruned =    3609 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      15 /      16             ( 93.75%) | total_pruned =       1 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      30 /      48             ( 62.50%) | total_pruned =      18 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       3 /       3             (100.00%) | total_pruned =       0 | shape = torch.Size([3])
alive: 138538, pruned : 2870329, total: 3008867, Compression rate :      21.72x  ( 95.40% pruned)
PSNR of output image is:  19.10327682475234
Experiment done
