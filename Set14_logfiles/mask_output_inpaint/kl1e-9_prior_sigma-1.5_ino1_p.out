(3, 512, 512)
(3, 512, 512)
Noisy PSNR is '9.64880390557409'
(3, 512, 512) torch.Size([1, 3, 512, 512]) torch.Size([1, 32, 512, 512])
Output directory: data/inpainting/Set14/mask/1/0.5/det/-1.5/1e-09
epoch:  0 quantization_loss:  0.034908659756183624
p mean is: tensor(-0.0003, device='cuda:2')
epoch:  1000 quantization_loss:  0.029989629983901978
p mean is: tensor(-0.0156, device='cuda:2')
epoch:  2000 quantization_loss:  0.029132509604096413
p mean is: tensor(-0.0273, device='cuda:2')
epoch:  3000 quantization_loss:  0.029177716001868248
p mean is: tensor(-0.0388, device='cuda:2')
epoch:  4000 quantization_loss:  0.029503732919692993
p mean is: tensor(-0.0504, device='cuda:2')
epoch:  5000 quantization_loss:  0.028616271913051605
p mean is: tensor(-0.0623, device='cuda:2')
epoch:  6000 quantization_loss:  0.028436198830604553
p mean is: tensor(-0.0741, device='cuda:2')
epoch:  7000 quantization_loss:  0.027488911524415016
p mean is: tensor(-0.0867, device='cuda:2')
epoch:  8000 quantization_loss:  0.02354024536907673
p mean is: tensor(-0.0997, device='cuda:2')
epoch:  9000 quantization_loss:  0.018803713843226433
p mean is: tensor(-0.1154, device='cuda:2')
epoch:  10000 quantization_loss:  0.014173036441206932
p mean is: tensor(-0.1363, device='cuda:2')
epoch:  11000 quantization_loss:  0.013596600852906704
p mean is: tensor(-0.1642, device='cuda:2')
epoch:  12000 quantization_loss:  0.01240837387740612
p mean is: tensor(-0.2010, device='cuda:2')
epoch:  13000 quantization_loss:  0.012089728377759457
p mean is: tensor(-0.2482, device='cuda:2')
epoch:  14000 quantization_loss:  0.010323606431484222
p mean is: tensor(-0.3062, device='cuda:2')
epoch:  15000 quantization_loss:  0.00984856579452753
p mean is: tensor(-0.3750, device='cuda:2')
epoch:  16000 quantization_loss:  0.009465949609875679
p mean is: tensor(-0.4530, device='cuda:2')
epoch:  17000 quantization_loss:  0.009239123202860355
p mean is: tensor(-0.5375, device='cuda:2')
epoch:  18000 quantization_loss:  0.009136034175753593
p mean is: tensor(-0.6246, device='cuda:2')
epoch:  19000 quantization_loss:  0.0088696563616395
p mean is: tensor(-0.7102, device='cuda:2')
epoch:  20000 quantization_loss:  0.008669991046190262
p mean is: tensor(-0.7910, device='cuda:2')
epoch:  21000 quantization_loss:  0.008523390628397465
p mean is: tensor(-0.8649, device='cuda:2')
epoch:  22000 quantization_loss:  0.008275547064840794
p mean is: tensor(-0.9312, device='cuda:2')
epoch:  23000 quantization_loss:  0.00820283591747284
p mean is: tensor(-0.9900, device='cuda:2')
epoch:  24000 quantization_loss:  0.008089061826467514
p mean is: tensor(-1.0420, device='cuda:2')
epoch:  25000 quantization_loss:  0.007951080799102783
p mean is: tensor(-1.0877, device='cuda:2')
epoch:  26000 quantization_loss:  0.008021541871130466
p mean is: tensor(-1.1280, device='cuda:2')
epoch:  27000 quantization_loss:  0.00784744881093502
p mean is: tensor(-1.1634, device='cuda:2')
epoch:  28000 quantization_loss:  0.0076831672340631485
p mean is: tensor(-1.1947, device='cuda:2')
epoch:  29000 quantization_loss:  0.007652735337615013
p mean is: tensor(-1.2224, device='cuda:2')
epoch:  30000 quantization_loss:  0.007570917718112469
p mean is: tensor(-1.2471, device='cuda:2')
epoch:  31000 quantization_loss:  0.007510787341743708
p mean is: tensor(-1.2690, device='cuda:2')
epoch:  32000 quantization_loss:  0.00746229337528348
p mean is: tensor(-1.2886, device='cuda:2')
epoch:  33000 quantization_loss:  0.007421123329550028
p mean is: tensor(-1.3061, device='cuda:2')
epoch:  34000 quantization_loss:  0.0073527018539607525
p mean is: tensor(-1.3218, device='cuda:2')
epoch:  35000 quantization_loss:  0.0073449756018817425
p mean is: tensor(-1.3359, device='cuda:2')
epoch:  36000 quantization_loss:  0.007314044050872326
p mean is: tensor(-1.3486, device='cuda:2')
epoch:  37000 quantization_loss:  0.0073138331063091755
p mean is: tensor(-1.3602, device='cuda:2')
epoch:  38000 quantization_loss:  0.0072198789566755295
p mean is: tensor(-1.3706, device='cuda:2')
epoch:  39000 quantization_loss:  0.007210478652268648
p mean is: tensor(-1.3801, device='cuda:2')
epoch:  40000 quantization_loss:  0.007151202764362097
p mean is: tensor(-1.3887, device='cuda:2')
epoch:  41000 quantization_loss:  0.007121735718101263
p mean is: tensor(-1.3967, device='cuda:2')
epoch:  42000 quantization_loss:  0.007093051914125681
p mean is: tensor(-1.4039, device='cuda:2')
epoch:  43000 quantization_loss:  0.007081745192408562
p mean is: tensor(-1.4105, device='cuda:2')
epoch:  44000 quantization_loss:  0.007061151787638664
p mean is: tensor(-1.4166, device='cuda:2')
epoch:  45000 quantization_loss:  0.007037247531116009
p mean is: tensor(-1.4224, device='cuda:2')
epoch:  46000 quantization_loss:  0.0070218276232481
p mean is: tensor(-1.4277, device='cuda:2')
epoch:  47000 quantization_loss:  0.007034582551568747
p mean is: tensor(-1.4326, device='cuda:2')
epoch:  48000 quantization_loss:  0.0069797104224562645
p mean is: tensor(-1.4372, device='cuda:2')
epoch:  49000 quantization_loss:  0.006961599458009005
p mean is: tensor(-1.4414, device='cuda:2')
epoch:  50000 quantization_loss:  0.006947648245841265
p mean is: tensor(-1.4453, device='cuda:2')
epoch:  51000 quantization_loss:  0.006929861847311258
p mean is: tensor(-1.4490, device='cuda:2')
epoch:  52000 quantization_loss:  0.006914081517606974
p mean is: tensor(-1.4525, device='cuda:2')
epoch:  53000 quantization_loss:  0.006914572324603796
p mean is: tensor(-1.4558, device='cuda:2')
epoch:  54000 quantization_loss:  0.0068916878663003445
p mean is: tensor(-1.4589, device='cuda:2')
epoch:  55000 quantization_loss:  0.006882139947265387
p mean is: tensor(-1.4619, device='cuda:2')
epoch:  56000 quantization_loss:  0.0068763731978833675
p mean is: tensor(-1.4646, device='cuda:2')
epoch:  57000 quantization_loss:  0.006862052716314793
p mean is: tensor(-1.4673, device='cuda:2')
epoch:  58000 quantization_loss:  0.006848445162177086
p mean is: tensor(-1.4698, device='cuda:2')
epoch:  59000 quantization_loss:  0.006839037407189608
p mean is: tensor(-1.4722, device='cuda:2')
epoch:  60000 quantization_loss:  0.006846209987998009
p mean is: tensor(-1.4745, device='cuda:2')
epoch:  61000 quantization_loss:  0.006864746101200581
p mean is: tensor(-1.4767, device='cuda:2')
epoch:  62000 quantization_loss:  0.006840009242296219
p mean is: tensor(-1.4788, device='cuda:2')
epoch:  63000 quantization_loss:  0.006813351064920425
p mean is: tensor(-1.4809, device='cuda:2')
epoch:  64000 quantization_loss:  0.0068040709011256695
p mean is: tensor(-1.4828, device='cuda:2')
epoch:  65000 quantization_loss:  0.0068057505413889885
p mean is: tensor(-1.4848, device='cuda:2')
epoch:  66000 quantization_loss:  0.006793001666665077
p mean is: tensor(-1.4867, device='cuda:2')
epoch:  67000 quantization_loss:  0.006782616022974253
p mean is: tensor(-1.4884, device='cuda:2')
epoch:  68000 quantization_loss:  0.006779870949685574
p mean is: tensor(-1.4901, device='cuda:2')
epoch:  69000 quantization_loss:  0.00677401851862669
p mean is: tensor(-1.4918, device='cuda:2')
epoch:  70000 quantization_loss:  0.006769890431314707
p mean is: tensor(-1.4934, device='cuda:2')
epoch:  71000 quantization_loss:  0.006763678975403309
p mean is: tensor(-1.4949, device='cuda:2')
epoch:  72000 quantization_loss:  0.006764216814190149
p mean is: tensor(-1.4965, device='cuda:2')
epoch:  73000 quantization_loss:  0.006753137335181236
p mean is: tensor(-1.4979, device='cuda:2')
epoch:  74000 quantization_loss:  0.006752442102879286
p mean is: tensor(-1.4994, device='cuda:2')
epoch:  75000 quantization_loss:  0.006747565232217312
p mean is: tensor(-1.5009, device='cuda:2')
epoch:  76000 quantization_loss:  0.006745385937392712
p mean is: tensor(-1.5022, device='cuda:2')
epoch:  77000 quantization_loss:  0.006742965430021286
p mean is: tensor(-1.5035, device='cuda:2')
epoch:  78000 quantization_loss:  0.006736932322382927
p mean is: tensor(-1.5048, device='cuda:2')
epoch:  79000 quantization_loss:  0.006746314000338316
p mean is: tensor(-1.5061, device='cuda:2')
here
1.1.1.weight         | nonzeros =     615 /   12800             (  4.80%) | total_pruned =   12185 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =      80 /    6400             (  1.25%) | total_pruned =    6320 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      39 /   12800             (  0.30%) | total_pruned =   12761 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      10 /      32             ( 31.25%) | total_pruned =      22 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =      70 /   25600             (  0.27%) | total_pruned =   25530 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =       9 /      32             ( 28.12%) | total_pruned =      23 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =      30 /   51200             (  0.06%) | total_pruned =   51170 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =      46 /  102400             (  0.04%) | total_pruned =  102354 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =       1 /  204800             (  0.00%) | total_pruned =  204799 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =       8 /  409600             (  0.00%) | total_pruned =  409592 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =      17 /  409600             (  0.00%) | total_pruned =  409583 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    1411 /  409600             (  0.34%) | total_pruned =  408189 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    4827 /  409600             (  1.18%) | total_pruned =  404773 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   20287 /  409600             (  4.95%) | total_pruned =  389313 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   24096 /  147456             ( 16.34%) | total_pruned =  123360 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   29014 /  147456             ( 19.68%) | total_pruned =  118442 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   25693 /  147456             ( 17.42%) | total_pruned =  121763 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   11089 /   73728             ( 15.04%) | total_pruned =   62639 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2794 /   18432             ( 15.16%) | total_pruned =   15638 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1209 /    4608             ( 26.24%) | total_pruned =    3399 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      31 /      48             ( 64.58%) | total_pruned =      17 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 122605, pruned : 2886262, total: 3008867, Compression rate :      24.54x  ( 95.93% pruned)
PSNR of output image is:  12.115649869111731
Experiment done
