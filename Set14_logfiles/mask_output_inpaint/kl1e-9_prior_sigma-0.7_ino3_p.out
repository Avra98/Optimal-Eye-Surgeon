(3, 512, 512)
(3, 512, 512)
Noisy PSNR is '10.632893332619917'
(3, 512, 512) torch.Size([1, 3, 512, 512]) torch.Size([1, 32, 512, 512])
Output directory: data/inpainting/Set14/mask/3/0.5/det/-0.7/1e-09
epoch:  0 quantization_loss:  0.037430841475725174
p mean is: tensor(-0.0001, device='cuda:6')
epoch:  1000 quantization_loss:  0.031249361112713814
p mean is: tensor(-0.0070, device='cuda:6')
epoch:  2000 quantization_loss:  0.027778534218668938
p mean is: tensor(-0.0117, device='cuda:6')
epoch:  3000 quantization_loss:  0.029079217463731766
p mean is: tensor(-0.0164, device='cuda:6')
epoch:  4000 quantization_loss:  0.028106199577450752
p mean is: tensor(-0.0208, device='cuda:6')
epoch:  5000 quantization_loss:  0.02794216200709343
p mean is: tensor(-0.0256, device='cuda:6')
epoch:  6000 quantization_loss:  0.027480999007821083
p mean is: tensor(-0.0304, device='cuda:6')
epoch:  7000 quantization_loss:  0.024404268711805344
p mean is: tensor(-0.0357, device='cuda:6')
epoch:  8000 quantization_loss:  0.01865818351507187
p mean is: tensor(-0.0421, device='cuda:6')
epoch:  9000 quantization_loss:  0.015773868188261986
p mean is: tensor(-0.0506, device='cuda:6')
epoch:  10000 quantization_loss:  0.013942096382379532
p mean is: tensor(-0.0617, device='cuda:6')
epoch:  11000 quantization_loss:  0.012737592682242393
p mean is: tensor(-0.0764, device='cuda:6')
epoch:  12000 quantization_loss:  0.01187452394515276
p mean is: tensor(-0.0953, device='cuda:6')
epoch:  13000 quantization_loss:  0.011312649585306644
p mean is: tensor(-0.1190, device='cuda:6')
epoch:  14000 quantization_loss:  0.010658237151801586
p mean is: tensor(-0.1478, device='cuda:6')
epoch:  15000 quantization_loss:  0.010434786789119244
p mean is: tensor(-0.1818, device='cuda:6')
epoch:  16000 quantization_loss:  0.01018395647406578
p mean is: tensor(-0.2202, device='cuda:6')
epoch:  17000 quantization_loss:  0.009237143211066723
p mean is: tensor(-0.2617, device='cuda:6')
epoch:  18000 quantization_loss:  0.008857648819684982
p mean is: tensor(-0.3043, device='cuda:6')
epoch:  19000 quantization_loss:  0.008616960607469082
p mean is: tensor(-0.3460, device='cuda:6')
epoch:  20000 quantization_loss:  0.008482521399855614
p mean is: tensor(-0.3855, device='cuda:6')
epoch:  21000 quantization_loss:  0.00831618532538414
p mean is: tensor(-0.4220, device='cuda:6')
epoch:  22000 quantization_loss:  0.008167603053152561
p mean is: tensor(-0.4551, device='cuda:6')
epoch:  23000 quantization_loss:  0.008078713901340961
p mean is: tensor(-0.4844, device='cuda:6')
epoch:  24000 quantization_loss:  0.008043022826313972
p mean is: tensor(-0.5101, device='cuda:6')
epoch:  25000 quantization_loss:  0.007962647825479507
p mean is: tensor(-0.5324, device='cuda:6')
epoch:  26000 quantization_loss:  0.007833665236830711
p mean is: tensor(-0.5518, device='cuda:6')
epoch:  27000 quantization_loss:  0.007762787397950888
p mean is: tensor(-0.5685, device='cuda:6')
epoch:  28000 quantization_loss:  0.0077781216241419315
p mean is: tensor(-0.5829, device='cuda:6')
epoch:  29000 quantization_loss:  0.007684205658733845
p mean is: tensor(-0.5954, device='cuda:6')
epoch:  30000 quantization_loss:  0.007659371010959148
p mean is: tensor(-0.6061, device='cuda:6')
epoch:  31000 quantization_loss:  0.007587043568491936
p mean is: tensor(-0.6154, device='cuda:6')
epoch:  32000 quantization_loss:  0.007488055154681206
p mean is: tensor(-0.6236, device='cuda:6')
epoch:  33000 quantization_loss:  0.007343464531004429
p mean is: tensor(-0.6306, device='cuda:6')
epoch:  34000 quantization_loss:  0.007489413022994995
p mean is: tensor(-0.6366, device='cuda:6')
epoch:  35000 quantization_loss:  0.007262672297656536
p mean is: tensor(-0.6421, device='cuda:6')
epoch:  36000 quantization_loss:  0.007235934026539326
p mean is: tensor(-0.6467, device='cuda:6')
epoch:  37000 quantization_loss:  0.007221199572086334
p mean is: tensor(-0.6510, device='cuda:6')
epoch:  38000 quantization_loss:  0.007184324786067009
p mean is: tensor(-0.6547, device='cuda:6')
epoch:  39000 quantization_loss:  0.007157501764595509
p mean is: tensor(-0.6580, device='cuda:6')
epoch:  40000 quantization_loss:  0.007168421521782875
p mean is: tensor(-0.6609, device='cuda:6')
epoch:  41000 quantization_loss:  0.007112320978194475
p mean is: tensor(-0.6636, device='cuda:6')
epoch:  42000 quantization_loss:  0.007089481223374605
p mean is: tensor(-0.6660, device='cuda:6')
epoch:  43000 quantization_loss:  0.007061605341732502
p mean is: tensor(-0.6682, device='cuda:6')
epoch:  44000 quantization_loss:  0.007048641797155142
p mean is: tensor(-0.6702, device='cuda:6')
epoch:  45000 quantization_loss:  0.007040408905595541
p mean is: tensor(-0.6721, device='cuda:6')
epoch:  46000 quantization_loss:  0.007000156678259373
p mean is: tensor(-0.6739, device='cuda:6')
epoch:  47000 quantization_loss:  0.0070454771630465984
p mean is: tensor(-0.6754, device='cuda:6')
epoch:  48000 quantization_loss:  0.006994468625634909
p mean is: tensor(-0.6769, device='cuda:6')
epoch:  49000 quantization_loss:  0.006984923966228962
p mean is: tensor(-0.6783, device='cuda:6')
epoch:  50000 quantization_loss:  0.0069639841094613075
p mean is: tensor(-0.6796, device='cuda:6')
epoch:  51000 quantization_loss:  0.0070215146988630295
p mean is: tensor(-0.6807, device='cuda:6')
epoch:  52000 quantization_loss:  0.006958067417144775
p mean is: tensor(-0.6819, device='cuda:6')
epoch:  53000 quantization_loss:  0.0069426740519702435
p mean is: tensor(-0.6830, device='cuda:6')
epoch:  54000 quantization_loss:  0.006941576488316059
p mean is: tensor(-0.6840, device='cuda:6')
epoch:  55000 quantization_loss:  0.006920856423676014
p mean is: tensor(-0.6849, device='cuda:6')
epoch:  56000 quantization_loss:  0.006926299072802067
p mean is: tensor(-0.6859, device='cuda:6')
epoch:  57000 quantization_loss:  0.006915402133017778
p mean is: tensor(-0.6868, device='cuda:6')
epoch:  58000 quantization_loss:  0.006935254670679569
p mean is: tensor(-0.6876, device='cuda:6')
epoch:  59000 quantization_loss:  0.006906845606863499
p mean is: tensor(-0.6884, device='cuda:6')
epoch:  60000 quantization_loss:  0.00689941318705678
p mean is: tensor(-0.6892, device='cuda:6')
epoch:  61000 quantization_loss:  0.006901556625962257
p mean is: tensor(-0.6899, device='cuda:6')
epoch:  62000 quantization_loss:  0.006899775005877018
p mean is: tensor(-0.6906, device='cuda:6')
epoch:  63000 quantization_loss:  0.006896596867591143
p mean is: tensor(-0.6912, device='cuda:6')
epoch:  64000 quantization_loss:  0.006886472459882498
p mean is: tensor(-0.6919, device='cuda:6')
epoch:  65000 quantization_loss:  0.006883424706757069
p mean is: tensor(-0.6925, device='cuda:6')
epoch:  66000 quantization_loss:  0.006899494677782059
p mean is: tensor(-0.6931, device='cuda:6')
epoch:  67000 quantization_loss:  0.006873901933431625
p mean is: tensor(-0.6937, device='cuda:6')
epoch:  68000 quantization_loss:  0.006876923609524965
p mean is: tensor(-0.6943, device='cuda:6')
epoch:  69000 quantization_loss:  0.006868105847388506
p mean is: tensor(-0.6948, device='cuda:6')
epoch:  70000 quantization_loss:  0.006865587551146746
p mean is: tensor(-0.6954, device='cuda:6')
epoch:  71000 quantization_loss:  0.006866401061415672
p mean is: tensor(-0.6959, device='cuda:6')
epoch:  72000 quantization_loss:  0.006859793793410063
p mean is: tensor(-0.6964, device='cuda:6')
epoch:  73000 quantization_loss:  0.006857473868876696
p mean is: tensor(-0.6968, device='cuda:6')
epoch:  74000 quantization_loss:  0.006856863386929035
p mean is: tensor(-0.6973, device='cuda:6')
epoch:  75000 quantization_loss:  0.006859122309833765
p mean is: tensor(-0.6978, device='cuda:6')
epoch:  76000 quantization_loss:  0.006854513194411993
p mean is: tensor(-0.6982, device='cuda:6')
epoch:  77000 quantization_loss:  0.006850620731711388
p mean is: tensor(-0.6987, device='cuda:6')
epoch:  78000 quantization_loss:  0.006845937576144934
p mean is: tensor(-0.6991, device='cuda:6')
epoch:  79000 quantization_loss:  0.006845598574727774
p mean is: tensor(-0.6995, device='cuda:6')
here
1.1.1.weight         | nonzeros =    1208 /   12800             (  9.44%) | total_pruned =   11592 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     158 /    6400             (  2.47%) | total_pruned =    6242 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     177 /   12800             (  1.38%) | total_pruned =   12623 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     287 /   25600             (  1.12%) | total_pruned =   25313 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     307 /   51200             (  0.60%) | total_pruned =   50893 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     579 /  102400             (  0.57%) | total_pruned =  101821 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     404 /  204800             (  0.20%) | total_pruned =  204396 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =    1015 /  409600             (  0.25%) | total_pruned =  408585 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    1580 /  409600             (  0.39%) | total_pruned =  408020 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    6421 /  409600             (  1.57%) | total_pruned =  403179 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   17173 /  409600             (  4.19%) | total_pruned =  392427 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   39849 /  409600             (  9.73%) | total_pruned =  369751 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   28599 /  147456             ( 19.39%) | total_pruned =  118857 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   27049 /  147456             ( 18.34%) | total_pruned =  120407 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   24522 /  147456             ( 16.63%) | total_pruned =  122934 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   11195 /   73728             ( 15.18%) | total_pruned =   62533 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    1622 /   18432             (  8.80%) | total_pruned =   16810 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =     700 /    4608             ( 15.19%) | total_pruned =    3908 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      26 /      48             ( 54.17%) | total_pruned =      22 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       3 /       3             (100.00%) | total_pruned =       0 | shape = torch.Size([3])
alive: 164133, pruned : 2844734, total: 3008867, Compression rate :      18.33x  ( 94.55% pruned)
PSNR of output image is:  18.55206288144712
Experiment done
