(3, 512, 512)
(3, 512, 512)
Noisy PSNR is '9.1044243422826'
(3, 512, 512) torch.Size([1, 3, 512, 512]) torch.Size([1, 32, 512, 512])
Output directory: data/inpainting/Set14/mask/9/0.5/det/-1.0/1e-09
epoch:  0 quantization_loss:  0.027152350172400475
p mean is: tensor(-0.0002, device='cuda:2')
epoch:  1000 quantization_loss:  0.024088459089398384
p mean is: tensor(-0.0116, device='cuda:2')
epoch:  2000 quantization_loss:  0.02344350516796112
p mean is: tensor(-0.0220, device='cuda:2')
epoch:  3000 quantization_loss:  0.023590819910168648
p mean is: tensor(-0.0330, device='cuda:2')
epoch:  4000 quantization_loss:  0.0241544172167778
p mean is: tensor(-0.0445, device='cuda:2')
epoch:  5000 quantization_loss:  0.02379956841468811
p mean is: tensor(-0.0563, device='cuda:2')
epoch:  6000 quantization_loss:  0.023861069232225418
p mean is: tensor(-0.0686, device='cuda:2')
epoch:  7000 quantization_loss:  0.02367047406733036
p mean is: tensor(-0.0806, device='cuda:2')
epoch:  8000 quantization_loss:  0.02356095053255558
p mean is: tensor(-0.0925, device='cuda:2')
epoch:  9000 quantization_loss:  0.020393531769514084
p mean is: tensor(-0.1039, device='cuda:2')
epoch:  10000 quantization_loss:  0.01447833888232708
p mean is: tensor(-0.1177, device='cuda:2')
epoch:  11000 quantization_loss:  0.012310395948588848
p mean is: tensor(-0.1348, device='cuda:2')
epoch:  12000 quantization_loss:  0.01101687178015709
p mean is: tensor(-0.1571, device='cuda:2')
epoch:  13000 quantization_loss:  0.010525485500693321
p mean is: tensor(-0.1856, device='cuda:2')
epoch:  14000 quantization_loss:  0.009075538255274296
p mean is: tensor(-0.2216, device='cuda:2')
epoch:  15000 quantization_loss:  0.008769181556999683
p mean is: tensor(-0.2650, device='cuda:2')
epoch:  16000 quantization_loss:  0.008273489773273468
p mean is: tensor(-0.3155, device='cuda:2')
epoch:  17000 quantization_loss:  0.007582374382764101
p mean is: tensor(-0.3712, device='cuda:2')
epoch:  18000 quantization_loss:  0.007328681647777557
p mean is: tensor(-0.4296, device='cuda:2')
epoch:  19000 quantization_loss:  0.007042290177196264
p mean is: tensor(-0.4880, device='cuda:2')
epoch:  20000 quantization_loss:  0.006863456219434738
p mean is: tensor(-0.5442, device='cuda:2')
epoch:  21000 quantization_loss:  0.0065176780335605145
p mean is: tensor(-0.5965, device='cuda:2')
epoch:  22000 quantization_loss:  0.006146926432847977
p mean is: tensor(-0.6437, device='cuda:2')
epoch:  23000 quantization_loss:  0.005965459626168013
p mean is: tensor(-0.6855, device='cuda:2')
epoch:  24000 quantization_loss:  0.0058606830425560474
p mean is: tensor(-0.7223, device='cuda:2')
epoch:  25000 quantization_loss:  0.0057933335192501545
p mean is: tensor(-0.7545, device='cuda:2')
epoch:  26000 quantization_loss:  0.005401809234172106
p mean is: tensor(-0.7824, device='cuda:2')
epoch:  27000 quantization_loss:  0.005287863314151764
p mean is: tensor(-0.8066, device='cuda:2')
epoch:  28000 quantization_loss:  0.005195198114961386
p mean is: tensor(-0.8276, device='cuda:2')
epoch:  29000 quantization_loss:  0.005163733847439289
p mean is: tensor(-0.8459, device='cuda:2')
epoch:  30000 quantization_loss:  0.005083827767521143
p mean is: tensor(-0.8619, device='cuda:2')
epoch:  31000 quantization_loss:  0.005075582303106785
p mean is: tensor(-0.8758, device='cuda:2')
epoch:  32000 quantization_loss:  0.004980525001883507
p mean is: tensor(-0.8878, device='cuda:2')
epoch:  33000 quantization_loss:  0.004954627715051174
p mean is: tensor(-0.8984, device='cuda:2')
epoch:  34000 quantization_loss:  0.004907031077891588
p mean is: tensor(-0.9078, device='cuda:2')
epoch:  35000 quantization_loss:  0.004876231774687767
p mean is: tensor(-0.9161, device='cuda:2')
epoch:  36000 quantization_loss:  0.004823370836675167
p mean is: tensor(-0.9235, device='cuda:2')
epoch:  37000 quantization_loss:  0.004842789843678474
p mean is: tensor(-0.9301, device='cuda:2')
epoch:  38000 quantization_loss:  0.004769681021571159
p mean is: tensor(-0.9360, device='cuda:2')
epoch:  39000 quantization_loss:  0.004739937838166952
p mean is: tensor(-0.9412, device='cuda:2')
epoch:  40000 quantization_loss:  0.004740158095955849
p mean is: tensor(-0.9459, device='cuda:2')
epoch:  41000 quantization_loss:  0.0047013661824166775
p mean is: tensor(-0.9502, device='cuda:2')
epoch:  42000 quantization_loss:  0.004689090885221958
p mean is: tensor(-0.9540, device='cuda:2')
epoch:  43000 quantization_loss:  0.004652847535908222
p mean is: tensor(-0.9576, device='cuda:2')
epoch:  44000 quantization_loss:  0.004634555894881487
p mean is: tensor(-0.9608, device='cuda:2')
epoch:  45000 quantization_loss:  0.004626535810530186
p mean is: tensor(-0.9637, device='cuda:2')
epoch:  46000 quantization_loss:  0.004606441128998995
p mean is: tensor(-0.9664, device='cuda:2')
epoch:  47000 quantization_loss:  0.004589176271110773
p mean is: tensor(-0.9689, device='cuda:2')
epoch:  48000 quantization_loss:  0.00457466347143054
p mean is: tensor(-0.9713, device='cuda:2')
epoch:  49000 quantization_loss:  0.004572079982608557
p mean is: tensor(-0.9735, device='cuda:2')
epoch:  50000 quantization_loss:  0.004556895699352026
p mean is: tensor(-0.9755, device='cuda:2')
epoch:  51000 quantization_loss:  0.004542819689959288
p mean is: tensor(-0.9773, device='cuda:2')
epoch:  52000 quantization_loss:  0.004531435668468475
p mean is: tensor(-0.9791, device='cuda:2')
epoch:  53000 quantization_loss:  0.004522859118878841
p mean is: tensor(-0.9808, device='cuda:2')
epoch:  54000 quantization_loss:  0.004510299302637577
p mean is: tensor(-0.9824, device='cuda:2')
epoch:  55000 quantization_loss:  0.004511951468884945
p mean is: tensor(-0.9839, device='cuda:2')
epoch:  56000 quantization_loss:  0.004526512231677771
p mean is: tensor(-0.9854, device='cuda:2')
epoch:  57000 quantization_loss:  0.004496069625020027
p mean is: tensor(-0.9867, device='cuda:2')
epoch:  58000 quantization_loss:  0.004494831431657076
p mean is: tensor(-0.9881, device='cuda:2')
epoch:  59000 quantization_loss:  0.0044867610558867455
p mean is: tensor(-0.9894, device='cuda:2')
epoch:  60000 quantization_loss:  0.00447501428425312
p mean is: tensor(-0.9906, device='cuda:2')
epoch:  61000 quantization_loss:  0.004471557214856148
p mean is: tensor(-0.9918, device='cuda:2')
epoch:  62000 quantization_loss:  0.004466605838388205
p mean is: tensor(-0.9930, device='cuda:2')
epoch:  63000 quantization_loss:  0.004468362312763929
p mean is: tensor(-0.9940, device='cuda:2')
epoch:  64000 quantization_loss:  0.004464566707611084
p mean is: tensor(-0.9951, device='cuda:2')
epoch:  65000 quantization_loss:  0.004460480529814959
p mean is: tensor(-0.9960, device='cuda:2')
epoch:  66000 quantization_loss:  0.004456906579434872
p mean is: tensor(-0.9970, device='cuda:2')
epoch:  67000 quantization_loss:  0.004452121909707785
p mean is: tensor(-0.9980, device='cuda:2')
epoch:  68000 quantization_loss:  0.004444122780114412
p mean is: tensor(-0.9988, device='cuda:2')
epoch:  69000 quantization_loss:  0.004450582433491945
p mean is: tensor(-0.9997, device='cuda:2')
epoch:  70000 quantization_loss:  0.004441645462065935
p mean is: tensor(-1.0005, device='cuda:2')
epoch:  71000 quantization_loss:  0.004438675474375486
p mean is: tensor(-1.0014, device='cuda:2')
epoch:  72000 quantization_loss:  0.004448277875781059
p mean is: tensor(-1.0022, device='cuda:2')
epoch:  73000 quantization_loss:  0.004442110192030668
p mean is: tensor(-1.0030, device='cuda:2')
epoch:  74000 quantization_loss:  0.004430785775184631
p mean is: tensor(-1.0038, device='cuda:2')
epoch:  75000 quantization_loss:  0.004437190014868975
p mean is: tensor(-1.0045, device='cuda:2')
epoch:  76000 quantization_loss:  0.004402128513902426
p mean is: tensor(-1.0053, device='cuda:2')
epoch:  77000 quantization_loss:  0.004426161292940378
p mean is: tensor(-1.0060, device='cuda:2')
epoch:  78000 quantization_loss:  0.004429337102919817
p mean is: tensor(-1.0066, device='cuda:2')
epoch:  79000 quantization_loss:  0.004427414387464523
p mean is: tensor(-1.0073, device='cuda:2')
here
1.1.1.weight         | nonzeros =     987 /   12800             (  7.71%) | total_pruned =   11813 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     214 /    6400             (  3.34%) | total_pruned =    6186 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     129 /   12800             (  1.01%) | total_pruned =   12671 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     162 /   25600             (  0.63%) | total_pruned =   25438 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =      95 /   51200             (  0.19%) | total_pruned =   51105 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     222 /  102400             (  0.22%) | total_pruned =  102178 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     119 /  204800             (  0.06%) | total_pruned =  204681 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     237 /  409600             (  0.06%) | total_pruned =  409363 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     238 /  409600             (  0.06%) | total_pruned =  409362 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    2735 /  409600             (  0.67%) | total_pruned =  406865 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   10403 /  409600             (  2.54%) | total_pruned =  399197 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   31094 /  409600             (  7.59%) | total_pruned =  378506 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   27955 /  147456             ( 18.96%) | total_pruned =  119501 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   26088 /  147456             ( 17.69%) | total_pruned =  121368 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   21794 /  147456             ( 14.78%) | total_pruned =  125662 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   11043 /   73728             ( 14.98%) | total_pruned =   62685 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    3651 /   18432             ( 19.81%) | total_pruned =   14781 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1383 /    4608             ( 30.01%) | total_pruned =    3225 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      31 /      48             ( 64.58%) | total_pruned =      17 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 139921, pruned : 2868946, total: 3008867, Compression rate :      21.50x  ( 95.35% pruned)
PSNR of output image is:  20.276918448695113
Experiment done
