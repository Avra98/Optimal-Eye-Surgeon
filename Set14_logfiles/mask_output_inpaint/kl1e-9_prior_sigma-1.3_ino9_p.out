(3, 512, 512)
(3, 512, 512)
Noisy PSNR is '9.112006796869013'
(3, 512, 512) torch.Size([1, 3, 512, 512]) torch.Size([1, 32, 512, 512])
Output directory: data/inpainting/Set14/mask/9/0.5/det/-1.3/1e-09
epoch:  0 quantization_loss:  0.024785036221146584
p mean is: tensor(-0.0002, device='cuda:6')
epoch:  1000 quantization_loss:  0.0243828222155571
p mean is: tensor(-0.0154, device='cuda:6')
epoch:  2000 quantization_loss:  0.024232570081949234
p mean is: tensor(-0.0282, device='cuda:6')
epoch:  3000 quantization_loss:  0.02428101748228073
p mean is: tensor(-0.0415, device='cuda:6')
epoch:  4000 quantization_loss:  0.02433519996702671
p mean is: tensor(-0.0551, device='cuda:6')
epoch:  5000 quantization_loss:  0.02423335611820221
p mean is: tensor(-0.0689, device='cuda:6')
epoch:  6000 quantization_loss:  0.023827696219086647
p mean is: tensor(-0.0829, device='cuda:6')
epoch:  7000 quantization_loss:  0.02426108717918396
p mean is: tensor(-0.0963, device='cuda:6')
epoch:  8000 quantization_loss:  0.022064857184886932
p mean is: tensor(-0.1101, device='cuda:6')
epoch:  9000 quantization_loss:  0.016703367233276367
p mean is: tensor(-0.1252, device='cuda:6')
epoch:  10000 quantization_loss:  0.013045293278992176
p mean is: tensor(-0.1447, device='cuda:6')
epoch:  11000 quantization_loss:  0.012244143523275852
p mean is: tensor(-0.1701, device='cuda:6')
epoch:  12000 quantization_loss:  0.00953561719506979
p mean is: tensor(-0.2030, device='cuda:6')
epoch:  13000 quantization_loss:  0.008768858388066292
p mean is: tensor(-0.2445, device='cuda:6')
epoch:  14000 quantization_loss:  0.008166137151420116
p mean is: tensor(-0.2959, device='cuda:6')
epoch:  15000 quantization_loss:  0.007276442367583513
p mean is: tensor(-0.3571, device='cuda:6')
epoch:  16000 quantization_loss:  0.006908538285642862
p mean is: tensor(-0.4262, device='cuda:6')
epoch:  17000 quantization_loss:  0.006480477750301361
p mean is: tensor(-0.5004, device='cuda:6')
epoch:  18000 quantization_loss:  0.006264928262680769
p mean is: tensor(-0.5764, device='cuda:6')
epoch:  19000 quantization_loss:  0.006033525802195072
p mean is: tensor(-0.6508, device='cuda:6')
epoch:  20000 quantization_loss:  0.005794580094516277
p mean is: tensor(-0.7208, device='cuda:6')
epoch:  21000 quantization_loss:  0.005609529092907906
p mean is: tensor(-0.7846, device='cuda:6')
epoch:  22000 quantization_loss:  0.005495878867805004
p mean is: tensor(-0.8419, device='cuda:6')
epoch:  23000 quantization_loss:  0.005368261132389307
p mean is: tensor(-0.8925, device='cuda:6')
epoch:  24000 quantization_loss:  0.005262340884655714
p mean is: tensor(-0.9371, device='cuda:6')
epoch:  25000 quantization_loss:  0.0051360162906348705
p mean is: tensor(-0.9761, device='cuda:6')
epoch:  26000 quantization_loss:  0.005046352744102478
p mean is: tensor(-1.0102, device='cuda:6')
epoch:  27000 quantization_loss:  0.004946800880134106
p mean is: tensor(-1.0402, device='cuda:6')
epoch:  28000 quantization_loss:  0.004913193639367819
p mean is: tensor(-1.0665, device='cuda:6')
epoch:  29000 quantization_loss:  0.004808366298675537
p mean is: tensor(-1.0896, device='cuda:6')
epoch:  30000 quantization_loss:  0.004786493256688118
p mean is: tensor(-1.1100, device='cuda:6')
epoch:  31000 quantization_loss:  0.004702738951891661
p mean is: tensor(-1.1280, device='cuda:6')
epoch:  32000 quantization_loss:  0.004677095916122198
p mean is: tensor(-1.1439, device='cuda:6')
epoch:  33000 quantization_loss:  0.004639040678739548
p mean is: tensor(-1.1580, device='cuda:6')
epoch:  34000 quantization_loss:  0.004593782126903534
p mean is: tensor(-1.1706, device='cuda:6')
epoch:  35000 quantization_loss:  0.00455331988632679
p mean is: tensor(-1.1819, device='cuda:6')
epoch:  36000 quantization_loss:  0.004533565137535334
p mean is: tensor(-1.1920, device='cuda:6')
epoch:  37000 quantization_loss:  0.004500474780797958
p mean is: tensor(-1.2010, device='cuda:6')
epoch:  38000 quantization_loss:  0.004469423089176416
p mean is: tensor(-1.2092, device='cuda:6')
epoch:  39000 quantization_loss:  0.0044335569255054
p mean is: tensor(-1.2166, device='cuda:6')
epoch:  40000 quantization_loss:  0.004432884510606527
p mean is: tensor(-1.2232, device='cuda:6')
epoch:  41000 quantization_loss:  0.004409095272421837
p mean is: tensor(-1.2293, device='cuda:6')
epoch:  42000 quantization_loss:  0.004368727095425129
p mean is: tensor(-1.2348, device='cuda:6')
epoch:  43000 quantization_loss:  0.004361492581665516
p mean is: tensor(-1.2398, device='cuda:6')
epoch:  44000 quantization_loss:  0.004351153038442135
p mean is: tensor(-1.2445, device='cuda:6')
epoch:  45000 quantization_loss:  0.004332981072366238
p mean is: tensor(-1.2488, device='cuda:6')
epoch:  46000 quantization_loss:  0.004318453371524811
p mean is: tensor(-1.2527, device='cuda:6')
epoch:  47000 quantization_loss:  0.004297046922147274
p mean is: tensor(-1.2564, device='cuda:6')
epoch:  48000 quantization_loss:  0.0042921556159853935
p mean is: tensor(-1.2598, device='cuda:6')
epoch:  49000 quantization_loss:  0.004275271203368902
p mean is: tensor(-1.2630, device='cuda:6')
epoch:  50000 quantization_loss:  0.0042661624029278755
p mean is: tensor(-1.2660, device='cuda:6')
epoch:  51000 quantization_loss:  0.004255188629031181
p mean is: tensor(-1.2688, device='cuda:6')
epoch:  52000 quantization_loss:  0.0042523667216300964
p mean is: tensor(-1.2715, device='cuda:6')
epoch:  53000 quantization_loss:  0.00425196997821331
p mean is: tensor(-1.2740, device='cuda:6')
epoch:  54000 quantization_loss:  0.00424734503030777
p mean is: tensor(-1.2764, device='cuda:6')
epoch:  55000 quantization_loss:  0.004233884625136852
p mean is: tensor(-1.2786, device='cuda:6')
epoch:  56000 quantization_loss:  0.00421763863414526
p mean is: tensor(-1.2807, device='cuda:6')
epoch:  57000 quantization_loss:  0.004228058271110058
p mean is: tensor(-1.2828, device='cuda:6')
epoch:  58000 quantization_loss:  0.004208783153444529
p mean is: tensor(-1.2847, device='cuda:6')
epoch:  59000 quantization_loss:  0.00420984486117959
p mean is: tensor(-1.2865, device='cuda:6')
epoch:  60000 quantization_loss:  0.004202854819595814
p mean is: tensor(-1.2882, device='cuda:6')
epoch:  61000 quantization_loss:  0.004196744412183762
p mean is: tensor(-1.2899, device='cuda:6')
epoch:  62000 quantization_loss:  0.004192184656858444
p mean is: tensor(-1.2915, device='cuda:6')
epoch:  63000 quantization_loss:  0.004193117842078209
p mean is: tensor(-1.2931, device='cuda:6')
epoch:  64000 quantization_loss:  0.004185481928288937
p mean is: tensor(-1.2946, device='cuda:6')
epoch:  65000 quantization_loss:  0.004190026316791773
p mean is: tensor(-1.2960, device='cuda:6')
epoch:  66000 quantization_loss:  0.004185309633612633
p mean is: tensor(-1.2974, device='cuda:6')
epoch:  67000 quantization_loss:  0.004194995854049921
p mean is: tensor(-1.2987, device='cuda:6')
epoch:  68000 quantization_loss:  0.004174443427473307
p mean is: tensor(-1.3000, device='cuda:6')
epoch:  69000 quantization_loss:  0.004170688800513744
p mean is: tensor(-1.3013, device='cuda:6')
epoch:  70000 quantization_loss:  0.004167831968516111
p mean is: tensor(-1.3025, device='cuda:6')
epoch:  71000 quantization_loss:  0.004169488791376352
p mean is: tensor(-1.3036, device='cuda:6')
epoch:  72000 quantization_loss:  0.004164815880358219
p mean is: tensor(-1.3048, device='cuda:6')
epoch:  73000 quantization_loss:  0.004157440271228552
p mean is: tensor(-1.3059, device='cuda:6')
epoch:  74000 quantization_loss:  0.0041673444211483
p mean is: tensor(-1.3070, device='cuda:6')
epoch:  75000 quantization_loss:  0.004160031676292419
p mean is: tensor(-1.3080, device='cuda:6')
epoch:  76000 quantization_loss:  0.004157308954745531
p mean is: tensor(-1.3090, device='cuda:6')
epoch:  77000 quantization_loss:  0.004151652567088604
p mean is: tensor(-1.3100, device='cuda:6')
epoch:  78000 quantization_loss:  0.004150546155869961
p mean is: tensor(-1.3110, device='cuda:6')
epoch:  79000 quantization_loss:  0.004149447660893202
p mean is: tensor(-1.3120, device='cuda:6')
here
1.1.1.weight         | nonzeros =     851 /   12800             (  6.65%) | total_pruned =   11949 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     110 /    6400             (  1.72%) | total_pruned =    6290 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      67 /   12800             (  0.52%) | total_pruned =   12733 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      10 /      32             ( 31.25%) | total_pruned =      22 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     131 /   25600             (  0.51%) | total_pruned =   25469 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =      80 /   51200             (  0.16%) | total_pruned =   51120 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =      96 /  102400             (  0.09%) | total_pruned =  102304 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =       9 /  204800             (  0.00%) | total_pruned =  204791 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =      92 /  409600             (  0.02%) | total_pruned =  409508 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =      93 /  409600             (  0.02%) | total_pruned =  409507 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    1730 /  409600             (  0.42%) | total_pruned =  407870 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    6693 /  409600             (  1.63%) | total_pruned =  402907 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   24899 /  409600             (  6.08%) | total_pruned =  384701 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   26565 /  147456             ( 18.02%) | total_pruned =  120891 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   27251 /  147456             ( 18.48%) | total_pruned =  120205 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   23458 /  147456             ( 15.91%) | total_pruned =  123998 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   10524 /   73728             ( 14.27%) | total_pruned =   63204 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2706 /   18432             ( 14.68%) | total_pruned =   15726 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1076 /    4608             ( 23.35%) | total_pruned =    3532 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      30 /      48             ( 62.50%) | total_pruned =      18 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 127726, pruned : 2881141, total: 3008867, Compression rate :      23.56x  ( 95.76% pruned)
PSNR of output image is:  20.491467062118005
Experiment done
