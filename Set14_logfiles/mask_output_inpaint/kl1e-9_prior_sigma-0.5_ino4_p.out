(3, 512, 512)
(3, 512, 512)
Noisy PSNR is '8.7279700553647'
(3, 512, 512) torch.Size([1, 3, 512, 512]) torch.Size([1, 32, 512, 512])
Output directory: data/inpainting/Set14/mask/4/0.5/det/-0.5/1e-09
epoch:  0 quantization_loss:  0.03062346763908863
p mean is: tensor(-9.3761e-05, device='cuda:4')
epoch:  1000 quantization_loss:  0.026173913851380348
p mean is: tensor(-0.0073, device='cuda:4')
epoch:  2000 quantization_loss:  0.026161247864365578
p mean is: tensor(-0.0148, device='cuda:4')
epoch:  3000 quantization_loss:  0.02588355354964733
p mean is: tensor(-0.0232, device='cuda:4')
epoch:  4000 quantization_loss:  0.026020025834441185
p mean is: tensor(-0.0329, device='cuda:4')
epoch:  5000 quantization_loss:  0.02599644847214222
p mean is: tensor(-0.0430, device='cuda:4')
epoch:  6000 quantization_loss:  0.025913693010807037
p mean is: tensor(-0.0536, device='cuda:4')
epoch:  7000 quantization_loss:  0.02570958435535431
p mean is: tensor(-0.0641, device='cuda:4')
epoch:  8000 quantization_loss:  0.025594625622034073
p mean is: tensor(-0.0746, device='cuda:4')
epoch:  9000 quantization_loss:  0.025506187230348587
p mean is: tensor(-0.0854, device='cuda:4')
epoch:  10000 quantization_loss:  0.025579208508133888
p mean is: tensor(-0.0965, device='cuda:4')
epoch:  11000 quantization_loss:  0.025524886325001717
p mean is: tensor(-0.1079, device='cuda:4')
epoch:  12000 quantization_loss:  0.025496715679764748
p mean is: tensor(-0.1193, device='cuda:4')
epoch:  13000 quantization_loss:  0.025391848757863045
p mean is: tensor(-0.1311, device='cuda:4')
epoch:  14000 quantization_loss:  0.02517891675233841
p mean is: tensor(-0.1436, device='cuda:4')
epoch:  15000 quantization_loss:  0.023724230006337166
p mean is: tensor(-0.1580, device='cuda:4')
epoch:  16000 quantization_loss:  0.021794138476252556
p mean is: tensor(-0.1735, device='cuda:4')
epoch:  17000 quantization_loss:  0.019043782725930214
p mean is: tensor(-0.1902, device='cuda:4')
epoch:  18000 quantization_loss:  0.017788443714380264
p mean is: tensor(-0.2085, device='cuda:4')
epoch:  19000 quantization_loss:  0.016361815854907036
p mean is: tensor(-0.2285, device='cuda:4')
epoch:  20000 quantization_loss:  0.01531192660331726
p mean is: tensor(-0.2504, device='cuda:4')
epoch:  21000 quantization_loss:  0.012981528416275978
p mean is: tensor(-0.2735, device='cuda:4')
epoch:  22000 quantization_loss:  0.012323794886469841
p mean is: tensor(-0.2970, device='cuda:4')
epoch:  23000 quantization_loss:  0.011903353035449982
p mean is: tensor(-0.3199, device='cuda:4')
epoch:  24000 quantization_loss:  0.011607117019593716
p mean is: tensor(-0.3416, device='cuda:4')
epoch:  25000 quantization_loss:  0.011268493719398975
p mean is: tensor(-0.3619, device='cuda:4')
epoch:  26000 quantization_loss:  0.010597020387649536
p mean is: tensor(-0.3801, device='cuda:4')
epoch:  27000 quantization_loss:  0.01081489585340023
p mean is: tensor(-0.3962, device='cuda:4')
epoch:  28000 quantization_loss:  0.010259074158966541
p mean is: tensor(-0.4101, device='cuda:4')
epoch:  29000 quantization_loss:  0.009977648966014385
p mean is: tensor(-0.4221, device='cuda:4')
epoch:  30000 quantization_loss:  0.009364321827888489
p mean is: tensor(-0.4324, device='cuda:4')
epoch:  31000 quantization_loss:  0.009236413054168224
p mean is: tensor(-0.4411, device='cuda:4')
epoch:  32000 quantization_loss:  0.009136902168393135
p mean is: tensor(-0.4486, device='cuda:4')
epoch:  33000 quantization_loss:  0.00948398932814598
p mean is: tensor(-0.4549, device='cuda:4')
epoch:  34000 quantization_loss:  0.008938404731452465
p mean is: tensor(-0.4605, device='cuda:4')
epoch:  35000 quantization_loss:  0.008870081976056099
p mean is: tensor(-0.4653, device='cuda:4')
epoch:  36000 quantization_loss:  0.008782591670751572
p mean is: tensor(-0.4693, device='cuda:4')
epoch:  37000 quantization_loss:  0.008740877732634544
p mean is: tensor(-0.4729, device='cuda:4')
epoch:  38000 quantization_loss:  0.008743002079427242
p mean is: tensor(-0.4760, device='cuda:4')
epoch:  39000 quantization_loss:  0.00865674577653408
p mean is: tensor(-0.4788, device='cuda:4')
epoch:  40000 quantization_loss:  0.008598471991717815
p mean is: tensor(-0.4812, device='cuda:4')
epoch:  41000 quantization_loss:  0.008561478927731514
p mean is: tensor(-0.4834, device='cuda:4')
epoch:  42000 quantization_loss:  0.007978876121342182
p mean is: tensor(-0.4853, device='cuda:4')
epoch:  43000 quantization_loss:  0.008014073595404625
p mean is: tensor(-0.4870, device='cuda:4')
epoch:  44000 quantization_loss:  0.007920213975012302
p mean is: tensor(-0.4886, device='cuda:4')
epoch:  45000 quantization_loss:  0.007844897918403149
p mean is: tensor(-0.4900, device='cuda:4')
epoch:  46000 quantization_loss:  0.007823548279702663
p mean is: tensor(-0.4912, device='cuda:4')
epoch:  47000 quantization_loss:  0.007792649324983358
p mean is: tensor(-0.4925, device='cuda:4')
epoch:  48000 quantization_loss:  0.007818660698831081
p mean is: tensor(-0.4936, device='cuda:4')
epoch:  49000 quantization_loss:  0.0077706133015453815
p mean is: tensor(-0.4946, device='cuda:4')
epoch:  50000 quantization_loss:  0.0077534751035273075
p mean is: tensor(-0.4956, device='cuda:4')
epoch:  51000 quantization_loss:  0.007735037244856358
p mean is: tensor(-0.4966, device='cuda:4')
epoch:  52000 quantization_loss:  0.007724425755441189
p mean is: tensor(-0.4974, device='cuda:4')
epoch:  53000 quantization_loss:  0.007713363040238619
p mean is: tensor(-0.4982, device='cuda:4')
epoch:  54000 quantization_loss:  0.007711178157478571
p mean is: tensor(-0.4991, device='cuda:4')
epoch:  55000 quantization_loss:  0.007692957762628794
p mean is: tensor(-0.4998, device='cuda:4')
epoch:  56000 quantization_loss:  0.007719126995652914
p mean is: tensor(-0.5005, device='cuda:4')
epoch:  57000 quantization_loss:  0.007677151821553707
p mean is: tensor(-0.5012, device='cuda:4')
epoch:  58000 quantization_loss:  0.007672163657844067
p mean is: tensor(-0.5020, device='cuda:4')
epoch:  59000 quantization_loss:  0.0076740942895412445
p mean is: tensor(-0.5027, device='cuda:4')
epoch:  60000 quantization_loss:  0.007670356892049313
p mean is: tensor(-0.5033, device='cuda:4')
epoch:  61000 quantization_loss:  0.00766411330550909
p mean is: tensor(-0.5039, device='cuda:4')
epoch:  62000 quantization_loss:  0.007657812442630529
p mean is: tensor(-0.5045, device='cuda:4')
epoch:  63000 quantization_loss:  0.00765216676518321
p mean is: tensor(-0.5051, device='cuda:4')
epoch:  64000 quantization_loss:  0.007634936366230249
p mean is: tensor(-0.5057, device='cuda:4')
epoch:  65000 quantization_loss:  0.007633492816239595
p mean is: tensor(-0.5063, device='cuda:4')
epoch:  66000 quantization_loss:  0.007627660408616066
p mean is: tensor(-0.5068, device='cuda:4')
epoch:  67000 quantization_loss:  0.007636391092091799
p mean is: tensor(-0.5073, device='cuda:4')
epoch:  68000 quantization_loss:  0.00763455918058753
p mean is: tensor(-0.5079, device='cuda:4')
epoch:  69000 quantization_loss:  0.007619861513376236
p mean is: tensor(-0.5085, device='cuda:4')
epoch:  70000 quantization_loss:  0.00761320348829031
p mean is: tensor(-0.5090, device='cuda:4')
epoch:  71000 quantization_loss:  0.007609433960169554
p mean is: tensor(-0.5095, device='cuda:4')
epoch:  72000 quantization_loss:  0.007604722864925861
p mean is: tensor(-0.5100, device='cuda:4')
epoch:  73000 quantization_loss:  0.007596712093800306
p mean is: tensor(-0.5104, device='cuda:4')
epoch:  74000 quantization_loss:  0.007599032483994961
p mean is: tensor(-0.5109, device='cuda:4')
epoch:  75000 quantization_loss:  0.007596616633236408
p mean is: tensor(-0.5114, device='cuda:4')
epoch:  76000 quantization_loss:  0.007603055331856012
p mean is: tensor(-0.5119, device='cuda:4')
epoch:  77000 quantization_loss:  0.007594302296638489
p mean is: tensor(-0.5123, device='cuda:4')
epoch:  78000 quantization_loss:  0.00758920144289732
p mean is: tensor(-0.5128, device='cuda:4')
epoch:  79000 quantization_loss:  0.007587372791022062
p mean is: tensor(-0.5132, device='cuda:4')
here
1.1.1.weight         | nonzeros =    1405 /   12800             ( 10.98%) | total_pruned =   11395 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     280 /    6400             (  4.38%) | total_pruned =    6120 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     279 /   12800             (  2.18%) | total_pruned =   12521 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      12 /      32             ( 37.50%) | total_pruned =      20 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     357 /   25600             (  1.39%) | total_pruned =   25243 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =       7 /      32             ( 21.88%) | total_pruned =      25 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     546 /   51200             (  1.07%) | total_pruned =   50654 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =    1333 /  102400             (  1.30%) | total_pruned =  101067 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =    2053 /  204800             (  1.00%) | total_pruned =  202747 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =    3875 /  409600             (  0.95%) | total_pruned =  405725 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    5720 /  409600             (  1.40%) | total_pruned =  403880 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   12643 /  409600             (  3.09%) | total_pruned =  396957 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   30229 /  409600             (  7.38%) | total_pruned =  379371 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   55455 /  409600             ( 13.54%) | total_pruned =  354145 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   27690 /  147456             ( 18.78%) | total_pruned =  119766 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   15759 /  147456             ( 10.69%) | total_pruned =  131697 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =    6865 /  147456             (  4.66%) | total_pruned =  140591 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    2993 /   73728             (  4.06%) | total_pruned =   70735 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    1418 /   18432             (  7.69%) | total_pruned =   17014 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1037 /    4608             ( 22.50%) | total_pruned =    3571 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      32 /      48             ( 66.67%) | total_pruned =      16 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 170987, pruned : 2837880, total: 3008867, Compression rate :      17.60x  ( 94.32% pruned)
PSNR of output image is:  18.20667923271622
Experiment done
