(3, 512, 512)
(3, 512, 512)
Noisy PSNR is '9.815956465159243'
(3, 512, 512) torch.Size([1, 3, 512, 512]) torch.Size([1, 32, 512, 512])
Output directory: data/inpainting/Set14/mask/11/0.5/det/-1.3/1e-09
epoch:  0 quantization_loss:  0.027311239391565323
p mean is: tensor(-0.0002, device='cuda:2')
epoch:  1000 quantization_loss:  0.020915010944008827
p mean is: tensor(-0.0196, device='cuda:2')
epoch:  2000 quantization_loss:  0.019598474726080894
p mean is: tensor(-0.0357, device='cuda:2')
epoch:  3000 quantization_loss:  0.01894683763384819
p mean is: tensor(-0.0522, device='cuda:2')
epoch:  4000 quantization_loss:  0.019062861800193787
p mean is: tensor(-0.0683, device='cuda:2')
epoch:  5000 quantization_loss:  0.018670644611120224
p mean is: tensor(-0.0852, device='cuda:2')
epoch:  6000 quantization_loss:  0.018809540197253227
p mean is: tensor(-0.1033, device='cuda:2')
epoch:  7000 quantization_loss:  0.018608486279845238
p mean is: tensor(-0.1226, device='cuda:2')
epoch:  8000 quantization_loss:  0.01821722462773323
p mean is: tensor(-0.1428, device='cuda:2')
epoch:  9000 quantization_loss:  0.01741531677544117
p mean is: tensor(-0.1658, device='cuda:2')
epoch:  10000 quantization_loss:  0.015975099056959152
p mean is: tensor(-0.1941, device='cuda:2')
epoch:  11000 quantization_loss:  0.015476983040571213
p mean is: tensor(-0.2301, device='cuda:2')
epoch:  12000 quantization_loss:  0.014025080017745495
p mean is: tensor(-0.2738, device='cuda:2')
epoch:  13000 quantization_loss:  0.0134588573127985
p mean is: tensor(-0.3236, device='cuda:2')
epoch:  14000 quantization_loss:  0.01279479917138815
p mean is: tensor(-0.3813, device='cuda:2')
epoch:  15000 quantization_loss:  0.012276951223611832
p mean is: tensor(-0.4469, device='cuda:2')
epoch:  16000 quantization_loss:  0.01174863986670971
p mean is: tensor(-0.5182, device='cuda:2')
epoch:  17000 quantization_loss:  0.011257367208600044
p mean is: tensor(-0.5922, device='cuda:2')
epoch:  18000 quantization_loss:  0.010587659664452076
p mean is: tensor(-0.6650, device='cuda:2')
epoch:  19000 quantization_loss:  0.010126885958015919
p mean is: tensor(-0.7337, device='cuda:2')
epoch:  20000 quantization_loss:  0.009737987071275711
p mean is: tensor(-0.7968, device='cuda:2')
epoch:  21000 quantization_loss:  0.009315534494817257
p mean is: tensor(-0.8535, device='cuda:2')
epoch:  22000 quantization_loss:  0.008988925255835056
p mean is: tensor(-0.9036, device='cuda:2')
epoch:  23000 quantization_loss:  0.008752304129302502
p mean is: tensor(-0.9477, device='cuda:2')
epoch:  24000 quantization_loss:  0.00856596976518631
p mean is: tensor(-0.9863, device='cuda:2')
epoch:  25000 quantization_loss:  0.008401398546993732
p mean is: tensor(-1.0202, device='cuda:2')
epoch:  26000 quantization_loss:  0.008307412266731262
p mean is: tensor(-1.0500, device='cuda:2')
epoch:  27000 quantization_loss:  0.008097322657704353
p mean is: tensor(-1.0761, device='cuda:2')
epoch:  28000 quantization_loss:  0.007996504195034504
p mean is: tensor(-1.0991, device='cuda:2')
epoch:  29000 quantization_loss:  0.007907944731414318
p mean is: tensor(-1.1193, device='cuda:2')
epoch:  30000 quantization_loss:  0.00785459391772747
p mean is: tensor(-1.1373, device='cuda:2')
epoch:  31000 quantization_loss:  0.007720293942838907
p mean is: tensor(-1.1533, device='cuda:2')
epoch:  32000 quantization_loss:  0.007672713603824377
p mean is: tensor(-1.1674, device='cuda:2')
epoch:  33000 quantization_loss:  0.007607852108776569
p mean is: tensor(-1.1799, device='cuda:2')
epoch:  34000 quantization_loss:  0.00757789658382535
p mean is: tensor(-1.1911, device='cuda:2')
epoch:  35000 quantization_loss:  0.007536428980529308
p mean is: tensor(-1.2011, device='cuda:2')
epoch:  36000 quantization_loss:  0.007470432203263044
p mean is: tensor(-1.2101, device='cuda:2')
epoch:  37000 quantization_loss:  0.007434397004544735
p mean is: tensor(-1.2181, device='cuda:2')
epoch:  38000 quantization_loss:  0.007397219073027372
p mean is: tensor(-1.2253, device='cuda:2')
epoch:  39000 quantization_loss:  0.007373712491244078
p mean is: tensor(-1.2318, device='cuda:2')
epoch:  40000 quantization_loss:  0.0073456899262964725
p mean is: tensor(-1.2377, device='cuda:2')
epoch:  41000 quantization_loss:  0.007330664899200201
p mean is: tensor(-1.2430, device='cuda:2')
epoch:  42000 quantization_loss:  0.007295386865735054
p mean is: tensor(-1.2480, device='cuda:2')
epoch:  43000 quantization_loss:  0.007287075277417898
p mean is: tensor(-1.2525, device='cuda:2')
epoch:  44000 quantization_loss:  0.0072721997275948524
p mean is: tensor(-1.2566, device='cuda:2')
epoch:  45000 quantization_loss:  0.007242268417030573
p mean is: tensor(-1.2603, device='cuda:2')
epoch:  46000 quantization_loss:  0.00722765875980258
p mean is: tensor(-1.2637, device='cuda:2')
epoch:  47000 quantization_loss:  0.007217931095510721
p mean is: tensor(-1.2669, device='cuda:2')
epoch:  48000 quantization_loss:  0.007218426093459129
p mean is: tensor(-1.2699, device='cuda:2')
epoch:  49000 quantization_loss:  0.007201988250017166
p mean is: tensor(-1.2727, device='cuda:2')
epoch:  50000 quantization_loss:  0.007186999544501305
p mean is: tensor(-1.2753, device='cuda:2')
epoch:  51000 quantization_loss:  0.007172085344791412
p mean is: tensor(-1.2776, device='cuda:2')
epoch:  52000 quantization_loss:  0.007169100921601057
p mean is: tensor(-1.2798, device='cuda:2')
epoch:  53000 quantization_loss:  0.0071584368124604225
p mean is: tensor(-1.2819, device='cuda:2')
epoch:  54000 quantization_loss:  0.00715389009565115
p mean is: tensor(-1.2839, device='cuda:2')
epoch:  55000 quantization_loss:  0.00714806979522109
p mean is: tensor(-1.2858, device='cuda:2')
epoch:  56000 quantization_loss:  0.007143065333366394
p mean is: tensor(-1.2876, device='cuda:2')
epoch:  57000 quantization_loss:  0.007142519112676382
p mean is: tensor(-1.2893, device='cuda:2')
epoch:  58000 quantization_loss:  0.0071336631663143635
p mean is: tensor(-1.2908, device='cuda:2')
epoch:  59000 quantization_loss:  0.00712835555896163
p mean is: tensor(-1.2924, device='cuda:2')
epoch:  60000 quantization_loss:  0.007127231452614069
p mean is: tensor(-1.2938, device='cuda:2')
epoch:  61000 quantization_loss:  0.0071167116984725
p mean is: tensor(-1.2952, device='cuda:2')
epoch:  62000 quantization_loss:  0.007119492162019014
p mean is: tensor(-1.2966, device='cuda:2')
epoch:  63000 quantization_loss:  0.00711080152541399
p mean is: tensor(-1.2978, device='cuda:2')
epoch:  64000 quantization_loss:  0.0071202716790139675
p mean is: tensor(-1.2991, device='cuda:2')
epoch:  65000 quantization_loss:  0.007114662788808346
p mean is: tensor(-1.3003, device='cuda:2')
epoch:  66000 quantization_loss:  0.007105205673724413
p mean is: tensor(-1.3014, device='cuda:2')
epoch:  67000 quantization_loss:  0.007104062009602785
p mean is: tensor(-1.3025, device='cuda:2')
epoch:  68000 quantization_loss:  0.007099999580532312
p mean is: tensor(-1.3036, device='cuda:2')
epoch:  69000 quantization_loss:  0.007097452878952026
p mean is: tensor(-1.3046, device='cuda:2')
epoch:  70000 quantization_loss:  0.007093407213687897
p mean is: tensor(-1.3056, device='cuda:2')
epoch:  71000 quantization_loss:  0.007097325753420591
p mean is: tensor(-1.3065, device='cuda:2')
epoch:  72000 quantization_loss:  0.007096081506460905
p mean is: tensor(-1.3075, device='cuda:2')
epoch:  73000 quantization_loss:  0.007090336177498102
p mean is: tensor(-1.3084, device='cuda:2')
epoch:  74000 quantization_loss:  0.007092659827321768
p mean is: tensor(-1.3093, device='cuda:2')
epoch:  75000 quantization_loss:  0.00708516500890255
p mean is: tensor(-1.3102, device='cuda:2')
epoch:  76000 quantization_loss:  0.007084976881742477
p mean is: tensor(-1.3111, device='cuda:2')
epoch:  77000 quantization_loss:  0.007085296791046858
p mean is: tensor(-1.3118, device='cuda:2')
epoch:  78000 quantization_loss:  0.00708321388810873
p mean is: tensor(-1.3126, device='cuda:2')
epoch:  79000 quantization_loss:  0.007119812071323395
p mean is: tensor(-1.3134, device='cuda:2')
here
1.1.1.weight         | nonzeros =     838 /   12800             (  6.55%) | total_pruned =   11962 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =      96 /    6400             (  1.50%) | total_pruned =    6304 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      74 /   12800             (  0.58%) | total_pruned =   12726 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =       9 /      32             ( 28.12%) | total_pruned =      23 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     106 /   25600             (  0.41%) | total_pruned =   25494 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =      22 /   51200             (  0.04%) | total_pruned =   51178 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     130 /  102400             (  0.13%) | total_pruned =  102270 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =      25 /  204800             (  0.01%) | total_pruned =  204775 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =      43 /  409600             (  0.01%) | total_pruned =  409557 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =      35 /  409600             (  0.01%) | total_pruned =  409565 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    1726 /  409600             (  0.42%) | total_pruned =  407874 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    6730 /  409600             (  1.64%) | total_pruned =  402870 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   23306 /  409600             (  5.69%) | total_pruned =  386294 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   26258 /  147456             ( 17.81%) | total_pruned =  121198 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   20792 /  147456             ( 14.10%) | total_pruned =  126664 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   16634 /  147456             ( 11.28%) | total_pruned =  130822 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    7998 /   73728             ( 10.85%) | total_pruned =   65730 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2411 /   18432             ( 13.08%) | total_pruned =   16021 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1294 /    4608             ( 28.08%) | total_pruned =    3314 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      28 /      48             ( 58.33%) | total_pruned =      20 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       3 /       3             (100.00%) | total_pruned =       0 | shape = torch.Size([3])
alive: 109770, pruned : 2899097, total: 3008867, Compression rate :      27.41x  ( 96.35% pruned)
PSNR of output image is:  18.419363910229325
Experiment done
