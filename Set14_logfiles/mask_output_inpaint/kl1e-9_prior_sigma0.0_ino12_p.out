(3, 512, 512)
(3, 512, 512)
Noisy PSNR is '9.350719561028328'
(3, 512, 512) torch.Size([1, 3, 512, 512]) torch.Size([1, 32, 512, 512])
Output directory: data/inpainting/Set14/mask/12/0.5/det/0.0/1e-09
epoch:  0 quantization_loss:  0.02780250273644924
p mean is: tensor(-3.6740e-07, device='cuda:1')
epoch:  1000 quantization_loss:  0.023795127868652344
p mean is: tensor(0.0004, device='cuda:1')
epoch:  2000 quantization_loss:  0.022959211841225624
p mean is: tensor(0.0004, device='cuda:1')
epoch:  3000 quantization_loss:  0.023080866783857346
p mean is: tensor(0.0005, device='cuda:1')
epoch:  4000 quantization_loss:  0.023063166067004204
p mean is: tensor(0.0006, device='cuda:1')
epoch:  5000 quantization_loss:  0.022765662521123886
p mean is: tensor(0.0006, device='cuda:1')
epoch:  6000 quantization_loss:  0.022731207311153412
p mean is: tensor(0.0008, device='cuda:1')
epoch:  7000 quantization_loss:  0.021365251392126083
p mean is: tensor(0.0006, device='cuda:1')
epoch:  8000 quantization_loss:  0.01979811117053032
p mean is: tensor(0.0007, device='cuda:1')
epoch:  9000 quantization_loss:  0.01798197813332081
p mean is: tensor(0.0002, device='cuda:1')
epoch:  10000 quantization_loss:  0.01614435575902462
p mean is: tensor(-0.0003, device='cuda:1')
epoch:  11000 quantization_loss:  0.013698596507310867
p mean is: tensor(-0.0011, device='cuda:1')
epoch:  12000 quantization_loss:  0.012655711732804775
p mean is: tensor(-0.0015, device='cuda:1')
epoch:  13000 quantization_loss:  0.011261769570410252
p mean is: tensor(-0.0019, device='cuda:1')
epoch:  14000 quantization_loss:  0.010754690505564213
p mean is: tensor(-0.0020, device='cuda:1')
epoch:  15000 quantization_loss:  0.010558145120739937
p mean is: tensor(-0.0019, device='cuda:1')
epoch:  16000 quantization_loss:  0.009830927476286888
p mean is: tensor(-0.0016, device='cuda:1')
epoch:  17000 quantization_loss:  0.009725932963192463
p mean is: tensor(-0.0013, device='cuda:1')
epoch:  18000 quantization_loss:  0.009512803517282009
p mean is: tensor(-0.0008, device='cuda:1')
epoch:  19000 quantization_loss:  0.009381395764648914
p mean is: tensor(-0.0002, device='cuda:1')
epoch:  20000 quantization_loss:  0.00925294030457735
p mean is: tensor(0.0004, device='cuda:1')
epoch:  21000 quantization_loss:  0.009217411279678345
p mean is: tensor(0.0010, device='cuda:1')
epoch:  22000 quantization_loss:  0.009048620238900185
p mean is: tensor(0.0016, device='cuda:1')
epoch:  23000 quantization_loss:  0.008997604250907898
p mean is: tensor(0.0022, device='cuda:1')
epoch:  24000 quantization_loss:  0.008963300846517086
p mean is: tensor(0.0029, device='cuda:1')
epoch:  25000 quantization_loss:  0.008909370750188828
p mean is: tensor(0.0034, device='cuda:1')
epoch:  26000 quantization_loss:  0.00885989610105753
p mean is: tensor(0.0039, device='cuda:1')
epoch:  27000 quantization_loss:  0.008823246695101261
p mean is: tensor(0.0044, device='cuda:1')
epoch:  28000 quantization_loss:  0.008788562379777431
p mean is: tensor(0.0048, device='cuda:1')
epoch:  29000 quantization_loss:  0.008786046877503395
p mean is: tensor(0.0052, device='cuda:1')
epoch:  30000 quantization_loss:  0.00871709082275629
p mean is: tensor(0.0055, device='cuda:1')
epoch:  31000 quantization_loss:  0.008697041310369968
p mean is: tensor(0.0058, device='cuda:1')
epoch:  32000 quantization_loss:  0.008676067925989628
p mean is: tensor(0.0059, device='cuda:1')
epoch:  33000 quantization_loss:  0.008636459708213806
p mean is: tensor(0.0061, device='cuda:1')
epoch:  34000 quantization_loss:  0.008633273653686047
p mean is: tensor(0.0062, device='cuda:1')
epoch:  35000 quantization_loss:  0.008601206354796886
p mean is: tensor(0.0062, device='cuda:1')
epoch:  36000 quantization_loss:  0.008593844249844551
p mean is: tensor(0.0063, device='cuda:1')
epoch:  37000 quantization_loss:  0.008566454984247684
p mean is: tensor(0.0064, device='cuda:1')
epoch:  38000 quantization_loss:  0.008561751805245876
p mean is: tensor(0.0064, device='cuda:1')
epoch:  39000 quantization_loss:  0.008543870411813259
p mean is: tensor(0.0064, device='cuda:1')
epoch:  40000 quantization_loss:  0.008540019392967224
p mean is: tensor(0.0064, device='cuda:1')
epoch:  41000 quantization_loss:  0.00852280855178833
p mean is: tensor(0.0064, device='cuda:1')
epoch:  42000 quantization_loss:  0.0085075031965971
p mean is: tensor(0.0063, device='cuda:1')
epoch:  43000 quantization_loss:  0.008506018668413162
p mean is: tensor(0.0062, device='cuda:1')
epoch:  44000 quantization_loss:  0.008502167649567127
p mean is: tensor(0.0062, device='cuda:1')
epoch:  45000 quantization_loss:  0.008489650674164295
p mean is: tensor(0.0061, device='cuda:1')
epoch:  46000 quantization_loss:  0.008479192852973938
p mean is: tensor(0.0061, device='cuda:1')
epoch:  47000 quantization_loss:  0.008469833061099052
p mean is: tensor(0.0060, device='cuda:1')
epoch:  48000 quantization_loss:  0.008466750383377075
p mean is: tensor(0.0060, device='cuda:1')
epoch:  49000 quantization_loss:  0.008457009680569172
p mean is: tensor(0.0060, device='cuda:1')
epoch:  50000 quantization_loss:  0.008459438569843769
p mean is: tensor(0.0059, device='cuda:1')
epoch:  51000 quantization_loss:  0.008455456234514713
p mean is: tensor(0.0058, device='cuda:1')
epoch:  52000 quantization_loss:  0.00843831431120634
p mean is: tensor(0.0058, device='cuda:1')
epoch:  53000 quantization_loss:  0.008439313620328903
p mean is: tensor(0.0057, device='cuda:1')
epoch:  54000 quantization_loss:  0.008436386473476887
p mean is: tensor(0.0057, device='cuda:1')
epoch:  55000 quantization_loss:  0.008430017158389091
p mean is: tensor(0.0057, device='cuda:1')
epoch:  56000 quantization_loss:  0.008426711894571781
p mean is: tensor(0.0057, device='cuda:1')
epoch:  57000 quantization_loss:  0.008421230129897594
p mean is: tensor(0.0056, device='cuda:1')
epoch:  58000 quantization_loss:  0.008423772640526295
p mean is: tensor(0.0057, device='cuda:1')
epoch:  59000 quantization_loss:  0.008428027853369713
p mean is: tensor(0.0056, device='cuda:1')
epoch:  60000 quantization_loss:  0.008407746441662312
p mean is: tensor(0.0056, device='cuda:1')
epoch:  61000 quantization_loss:  0.008413786068558693
p mean is: tensor(0.0056, device='cuda:1')
epoch:  62000 quantization_loss:  0.008410632610321045
p mean is: tensor(0.0055, device='cuda:1')
epoch:  63000 quantization_loss:  0.008412899449467659
p mean is: tensor(0.0055, device='cuda:1')
epoch:  64000 quantization_loss:  0.00840331893414259
p mean is: tensor(0.0055, device='cuda:1')
epoch:  65000 quantization_loss:  0.008402809500694275
p mean is: tensor(0.0055, device='cuda:1')
epoch:  66000 quantization_loss:  0.008404402993619442
p mean is: tensor(0.0055, device='cuda:1')
epoch:  67000 quantization_loss:  0.008398002944886684
p mean is: tensor(0.0054, device='cuda:1')
epoch:  68000 quantization_loss:  0.008393357507884502
p mean is: tensor(0.0054, device='cuda:1')
epoch:  69000 quantization_loss:  0.008396061137318611
p mean is: tensor(0.0054, device='cuda:1')
epoch:  70000 quantization_loss:  0.008390374481678009
p mean is: tensor(0.0054, device='cuda:1')
epoch:  71000 quantization_loss:  0.008395561017096043
p mean is: tensor(0.0054, device='cuda:1')
epoch:  72000 quantization_loss:  0.008387915790081024
p mean is: tensor(0.0054, device='cuda:1')
epoch:  73000 quantization_loss:  0.008390113711357117
p mean is: tensor(0.0053, device='cuda:1')
epoch:  74000 quantization_loss:  0.008388383314013481
p mean is: tensor(0.0053, device='cuda:1')
epoch:  75000 quantization_loss:  0.008385997265577316
p mean is: tensor(0.0053, device='cuda:1')
epoch:  76000 quantization_loss:  0.008380274288356304
p mean is: tensor(0.0052, device='cuda:1')
epoch:  77000 quantization_loss:  0.008383535780012608
p mean is: tensor(0.0052, device='cuda:1')
epoch:  78000 quantization_loss:  0.008379877544939518
p mean is: tensor(0.0051, device='cuda:1')
epoch:  79000 quantization_loss:  0.008377661928534508
p mean is: tensor(0.0051, device='cuda:1')
here
1.1.1.weight         | nonzeros =    6492 /   12800             ( 50.72%) | total_pruned =    6308 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       3 /      16             ( 18.75%) | total_pruned =      13 | shape = torch.Size([16])
1.2.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =    3175 /    6400             ( 49.61%) | total_pruned =    3225 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       4 /      16             ( 25.00%) | total_pruned =      12 | shape = torch.Size([16])
1.5.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =    6453 /   12800             ( 50.41%) | total_pruned =    6347 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       5 /      32             ( 15.62%) | total_pruned =      27 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =   12947 /   25600             ( 50.57%) | total_pruned =   12653 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       3 /      32             (  9.38%) | total_pruned =      29 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =   25930 /   51200             ( 50.64%) | total_pruned =   25270 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =   51575 /  102400             ( 50.37%) | total_pruned =   50825 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =  102899 /  204800             ( 50.24%) | total_pruned =  101901 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =  203582 /  409600             ( 49.70%) | total_pruned =  206018 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  201050 /  409600             ( 49.08%) | total_pruned =  208550 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  189628 /  409600             ( 46.30%) | total_pruned =  219972 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  193283 /  409600             ( 47.19%) | total_pruned =  216317 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  188510 /  409600             ( 46.02%) | total_pruned =  221090 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   63136 /  147456             ( 42.82%) | total_pruned =   84320 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   63829 /  147456             ( 43.29%) | total_pruned =   83627 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   63479 /  147456             ( 43.05%) | total_pruned =   83977 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   31988 /   73728             ( 43.39%) | total_pruned =   41740 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    7487 /   18432             ( 40.62%) | total_pruned =   10945 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       8 /      32             ( 25.00%) | total_pruned =      24 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    2080 /    4608             ( 45.14%) | total_pruned =    2528 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      24 /      48             ( 50.00%) | total_pruned =      24 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 1418980, pruned : 1589887, total: 3008867, Compression rate :       2.12x  ( 52.84% pruned)
PSNR of output image is:  17.66846426286906
Experiment done
