(3, 480, 480)
Noisy PSNR is '20.086821468496268'
(3, 480, 480) (3, 480, 480) torch.Size([1, 32, 480, 480])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/face/mask/1/sparsity/skip/det/0.069/1e-09
epoch:  0 quantization_loss:  0.040394723415374756
p mean is: tensor(-0.0004, device='cuda:0')
epoch:  1000 quantization_loss:  0.03248206898570061
p mean is: tensor(-0.0184, device='cuda:0')
epoch:  2000 quantization_loss:  0.03173556178808212
p mean is: tensor(-0.0332, device='cuda:0')
epoch:  3000 quantization_loss:  0.030569687485694885
p mean is: tensor(-0.0487, device='cuda:0')
epoch:  4000 quantization_loss:  0.03143532574176788
p mean is: tensor(-0.0646, device='cuda:0')
epoch:  5000 quantization_loss:  0.03144834563136101
p mean is: tensor(-0.0805, device='cuda:0')
epoch:  6000 quantization_loss:  0.03118687868118286
p mean is: tensor(-0.0971, device='cuda:0')
epoch:  7000 quantization_loss:  0.03087971732020378
p mean is: tensor(-0.1143, device='cuda:0')
epoch:  8000 quantization_loss:  0.030323857441544533
p mean is: tensor(-0.1321, device='cuda:0')
epoch:  9000 quantization_loss:  0.030427483841776848
p mean is: tensor(-0.1509, device='cuda:0')
epoch:  10000 quantization_loss:  0.03048465959727764
p mean is: tensor(-0.1705, device='cuda:0')
epoch:  11000 quantization_loss:  0.026204340159893036
p mean is: tensor(-0.1909, device='cuda:0')
epoch:  12000 quantization_loss:  0.02380913309752941
p mean is: tensor(-0.2129, device='cuda:0')
epoch:  13000 quantization_loss:  0.02005910687148571
p mean is: tensor(-0.2395, device='cuda:0')
epoch:  14000 quantization_loss:  0.01784086786210537
p mean is: tensor(-0.2695, device='cuda:0')
epoch:  15000 quantization_loss:  0.016286149621009827
p mean is: tensor(-0.3049, device='cuda:0')
epoch:  16000 quantization_loss:  0.015713008120656013
p mean is: tensor(-0.3478, device='cuda:0')
epoch:  17000 quantization_loss:  0.01510804332792759
p mean is: tensor(-0.4005, device='cuda:0')
epoch:  18000 quantization_loss:  0.014395566657185555
p mean is: tensor(-0.4642, device='cuda:0')
epoch:  19000 quantization_loss:  0.013403712771832943
p mean is: tensor(-0.5388, device='cuda:0')
epoch:  20000 quantization_loss:  0.013087502680718899
p mean is: tensor(-0.6234, device='cuda:0')
epoch:  21000 quantization_loss:  0.012873531319200993
p mean is: tensor(-0.7160, device='cuda:0')
epoch:  22000 quantization_loss:  0.012394934892654419
p mean is: tensor(-0.8136, device='cuda:0')
epoch:  23000 quantization_loss:  0.012146233581006527
p mean is: tensor(-0.9129, device='cuda:0')
epoch:  24000 quantization_loss:  0.011920813471078873
p mean is: tensor(-1.0113, device='cuda:0')
epoch:  25000 quantization_loss:  0.011802693828940392
p mean is: tensor(-1.1069, device='cuda:0')
epoch:  26000 quantization_loss:  0.011616755276918411
p mean is: tensor(-1.1976, device='cuda:0')
epoch:  27000 quantization_loss:  0.011515269987285137
p mean is: tensor(-1.2826, device='cuda:0')
epoch:  28000 quantization_loss:  0.01138303428888321
p mean is: tensor(-1.3619, device='cuda:0')
epoch:  29000 quantization_loss:  0.011229417286813259
p mean is: tensor(-1.4356, device='cuda:0')
epoch:  30000 quantization_loss:  0.01115461252629757
p mean is: tensor(-1.5040, device='cuda:0')
epoch:  31000 quantization_loss:  0.011120880022644997
p mean is: tensor(-1.5671, device='cuda:0')
epoch:  32000 quantization_loss:  0.011043896898627281
p mean is: tensor(-1.6256, device='cuda:0')
epoch:  33000 quantization_loss:  0.010923998430371284
p mean is: tensor(-1.6799, device='cuda:0')
epoch:  34000 quantization_loss:  0.010877466760575771
p mean is: tensor(-1.7306, device='cuda:0')
epoch:  35000 quantization_loss:  0.010851267725229263
p mean is: tensor(-1.7776, device='cuda:0')
epoch:  36000 quantization_loss:  0.010781452991068363
p mean is: tensor(-1.8215, device='cuda:0')
epoch:  37000 quantization_loss:  0.010822211392223835
p mean is: tensor(-1.8621, device='cuda:0')
epoch:  38000 quantization_loss:  0.010727087035775185
p mean is: tensor(-1.8999, device='cuda:0')
epoch:  39000 quantization_loss:  0.010715757496654987
p mean is: tensor(-1.9354, device='cuda:0')
epoch:  40000 quantization_loss:  0.010672205127775669
p mean is: tensor(-1.9686, device='cuda:0')
epoch:  41000 quantization_loss:  0.010668386705219746
p mean is: tensor(-1.9997, device='cuda:0')
epoch:  42000 quantization_loss:  0.010621259920299053
p mean is: tensor(-2.0289, device='cuda:0')
epoch:  43000 quantization_loss:  0.010599831119179726
p mean is: tensor(-2.0563, device='cuda:0')
epoch:  44000 quantization_loss:  0.010652955621480942
p mean is: tensor(-2.0819, device='cuda:0')
epoch:  45000 quantization_loss:  0.010539285838603973
p mean is: tensor(-2.1063, device='cuda:0')
epoch:  46000 quantization_loss:  0.01056679617613554
p mean is: tensor(-2.1292, device='cuda:0')
epoch:  47000 quantization_loss:  0.010541227646172047
p mean is: tensor(-2.1508, device='cuda:0')
epoch:  48000 quantization_loss:  0.010516607202589512
p mean is: tensor(-2.1711, device='cuda:0')
epoch:  49000 quantization_loss:  0.010500271804630756
p mean is: tensor(-2.1904, device='cuda:0')
epoch:  50000 quantization_loss:  0.01049295999109745
p mean is: tensor(-2.2088, device='cuda:0')
epoch:  51000 quantization_loss:  0.010458363220095634
p mean is: tensor(-2.2263, device='cuda:0')
epoch:  52000 quantization_loss:  0.010476579889655113
p mean is: tensor(-2.2429, device='cuda:0')
epoch:  53000 quantization_loss:  0.010436671786010265
p mean is: tensor(-2.2588, device='cuda:0')
epoch:  54000 quantization_loss:  0.010437527671456337
p mean is: tensor(-2.2739, device='cuda:0')
epoch:  55000 quantization_loss:  0.010421350598335266
p mean is: tensor(-2.2884, device='cuda:0')
epoch:  56000 quantization_loss:  0.010426795110106468
p mean is: tensor(-2.3022, device='cuda:0')
epoch:  57000 quantization_loss:  0.0104001360014081
p mean is: tensor(-2.3155, device='cuda:0')
epoch:  58000 quantization_loss:  0.010406984947621822
p mean is: tensor(-2.3282, device='cuda:0')
epoch:  59000 quantization_loss:  0.01038249023258686
p mean is: tensor(-2.3403, device='cuda:0')
Number of elements to keep: 153030
Threshold value: -1.032304286956787
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.06899984714795672
Number of elements to keep: 153030
Threshold value: -1.032304286956787
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.06899984714795672
1.0.1.1.weight       | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =   14350 /   36864             ( 38.93%) | total_pruned =   22514 | shape = torch.Size([128, 32, 3, 3])
1.1.1.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.2.weight         | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
1.1.2.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.4.1.weight       | nonzeros =   32328 /  147456             ( 21.92%) | total_pruned =  115128 | shape = torch.Size([128, 128, 3, 3])
1.1.4.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.5.weight         | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
1.1.5.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.0.1.1.weight | nonzeros =      86 /     512             ( 16.80%) | total_pruned =     426 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =   17592 /  147456             ( 11.93%) | total_pruned =  129864 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.2.weight   | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.1.7.1.1.2.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.4.1.weight | nonzeros =   10245 /  147456             (  6.95%) | total_pruned =  137211 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.5.weight   | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.1.7.1.1.5.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     111 /     512             ( 21.68%) | total_pruned =     401 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    4306 /  147456             (  2.92%) | total_pruned =  143150 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    3799 /  147456             (  2.58%) | total_pruned =  143657 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =     114 /     512             ( 22.27%) | total_pruned =     398 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       3 /       4             ( 75.00%) | total_pruned =       1 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    1744 /  147456             (  1.18%) | total_pruned =  145712 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    2988 /  147456             (  2.03%) | total_pruned =  144468 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      93 /     512             ( 18.16%) | total_pruned =     419 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       4 /       4             (100.00%) | total_pruned =       0 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    4199 /  147456             (  2.85%) | total_pruned =  143257 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    6127 /  147456             (  4.16%) | total_pruned =  141329 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      75 /     132             ( 56.82%) | total_pruned =      57 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =    6426 /  152064             (  4.23%) | total_pruned =  145638 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =    1547 /   16384             (  9.44%) | total_pruned =   14837 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      57 /     132             ( 43.18%) | total_pruned =      75 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =    7096 /  152064             (  4.67%) | total_pruned =  144968 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =    1691 /   16384             ( 10.32%) | total_pruned =   14693 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      50 /     132             ( 37.88%) | total_pruned =      82 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =    7232 /  152064             (  4.76%) | total_pruned =  144832 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.4.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.6.1.weight | nonzeros =    1969 /   16384             ( 12.02%) | total_pruned =   14415 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.7.weight | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
1.1.7.1.1.7.7.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.2.weight       | nonzeros =      52 /     132             ( 39.39%) | total_pruned =      80 | shape = torch.Size([132])
1.1.7.2.bias         | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.3.1.weight     | nonzeros =    8990 /  152064             (  5.91%) | total_pruned =  143074 | shape = torch.Size([128, 132, 3, 3])
1.1.7.3.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.4.weight       | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.1.7.4.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.6.1.weight     | nonzeros =    2353 /   16384             ( 14.36%) | total_pruned =   14031 | shape = torch.Size([128, 128, 1, 1])
1.1.7.6.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.7.weight       | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.1.7.7.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
2.weight             | nonzeros =      71 /     132             ( 53.79%) | total_pruned =      61 | shape = torch.Size([132])
2.bias               | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
3.1.weight           | nonzeros =   12439 /  152064             (  8.18%) | total_pruned =  139625 | shape = torch.Size([128, 132, 3, 3])
3.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
4.weight             | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
6.1.weight           | nonzeros =    3053 /   16384             ( 18.63%) | total_pruned =   13331 | shape = torch.Size([128, 128, 1, 1])
6.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
7.weight             | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
7.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =     116 /     384             ( 30.21%) | total_pruned =     268 | shape = torch.Size([3, 128, 1, 1])
9.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 153030, pruned : 2064801, total: 2217831, Compression rate :      14.49x  ( 93.10% pruned)
(3, 480, 480) (3, 480, 480) (3, 480, 480)
PSNR of output image is:  31.223008130274327
Experiment done
