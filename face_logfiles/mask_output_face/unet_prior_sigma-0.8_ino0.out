(3, 512, 512)
0
Noisy PSNR is '21.12798223967474'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/face/mask/0/unet/det/-0.8/1e-09
epoch:  0 quantization_loss:  0.15157556533813477
p mean is: tensor(-0.0001, device='cuda:2')
epoch:  1000 quantization_loss:  0.11039964854717255
p mean is: tensor(-0.0049, device='cuda:2')
epoch:  2000 quantization_loss:  0.10856062918901443
p mean is: tensor(-0.0076, device='cuda:2')
epoch:  3000 quantization_loss:  0.10647080838680267
p mean is: tensor(-0.0103, device='cuda:2')
epoch:  4000 quantization_loss:  0.09750169515609741
p mean is: tensor(-0.0134, device='cuda:2')
epoch:  5000 quantization_loss:  0.08104835450649261
p mean is: tensor(-0.0164, device='cuda:2')
epoch:  6000 quantization_loss:  0.07925686985254288
p mean is: tensor(-0.0198, device='cuda:2')
epoch:  7000 quantization_loss:  0.07882183790206909
p mean is: tensor(-0.0246, device='cuda:2')
epoch:  8000 quantization_loss:  0.07762090116739273
p mean is: tensor(-0.0315, device='cuda:2')
epoch:  9000 quantization_loss:  0.07591842859983444
p mean is: tensor(-0.0410, device='cuda:2')
epoch:  10000 quantization_loss:  0.07434149086475372
p mean is: tensor(-0.0543, device='cuda:2')
epoch:  11000 quantization_loss:  0.07272380590438843
p mean is: tensor(-0.0717, device='cuda:2')
epoch:  12000 quantization_loss:  0.0723412036895752
p mean is: tensor(-0.0940, device='cuda:2')
epoch:  13000 quantization_loss:  0.07210716605186462
p mean is: tensor(-0.1221, device='cuda:2')
epoch:  14000 quantization_loss:  0.07196211814880371
p mean is: tensor(-0.1566, device='cuda:2')
epoch:  15000 quantization_loss:  0.07156023383140564
p mean is: tensor(-0.1967, device='cuda:2')
epoch:  16000 quantization_loss:  0.07145687192678452
p mean is: tensor(-0.2419, device='cuda:2')
epoch:  17000 quantization_loss:  0.07128791511058807
p mean is: tensor(-0.2900, device='cuda:2')
epoch:  18000 quantization_loss:  0.07296642661094666
p mean is: tensor(-0.3389, device='cuda:2')
epoch:  19000 quantization_loss:  0.07088150084018707
p mean is: tensor(-0.3869, device='cuda:2')
epoch:  20000 quantization_loss:  0.07078474760055542
p mean is: tensor(-0.4328, device='cuda:2')
epoch:  21000 quantization_loss:  0.07070963084697723
p mean is: tensor(-0.4754, device='cuda:2')
epoch:  22000 quantization_loss:  0.07060837745666504
p mean is: tensor(-0.5141, device='cuda:2')
epoch:  23000 quantization_loss:  0.07061384618282318
p mean is: tensor(-0.5485, device='cuda:2')
epoch:  24000 quantization_loss:  0.07054508477449417
p mean is: tensor(-0.5790, device='cuda:2')
epoch:  25000 quantization_loss:  0.07046552002429962
p mean is: tensor(-0.6057, device='cuda:2')
epoch:  26000 quantization_loss:  0.07040927559137344
p mean is: tensor(-0.6292, device='cuda:2')
epoch:  27000 quantization_loss:  0.07050220668315887
p mean is: tensor(-0.6497, device='cuda:2')
epoch:  28000 quantization_loss:  0.07035303860902786
p mean is: tensor(-0.6675, device='cuda:2')
epoch:  29000 quantization_loss:  0.07012366503477097
p mean is: tensor(-0.6829, device='cuda:2')
epoch:  30000 quantization_loss:  0.07016962766647339
p mean is: tensor(-0.6961, device='cuda:2')
epoch:  31000 quantization_loss:  0.07008768618106842
p mean is: tensor(-0.7076, device='cuda:2')
epoch:  32000 quantization_loss:  0.07008777558803558
p mean is: tensor(-0.7176, device='cuda:2')
epoch:  33000 quantization_loss:  0.07000520080327988
p mean is: tensor(-0.7266, device='cuda:2')
epoch:  34000 quantization_loss:  0.06998459994792938
p mean is: tensor(-0.7343, device='cuda:2')
epoch:  35000 quantization_loss:  0.06998199969530106
p mean is: tensor(-0.7413, device='cuda:2')
epoch:  36000 quantization_loss:  0.0696859285235405
p mean is: tensor(-0.7475, device='cuda:2')
epoch:  37000 quantization_loss:  0.0692775696516037
p mean is: tensor(-0.7529, device='cuda:2')
epoch:  38000 quantization_loss:  0.06917288899421692
p mean is: tensor(-0.7576, device='cuda:2')
epoch:  39000 quantization_loss:  0.06909870356321335
p mean is: tensor(-0.7617, device='cuda:2')
epoch:  40000 quantization_loss:  0.06919065862894058
p mean is: tensor(-0.7655, device='cuda:2')
epoch:  41000 quantization_loss:  0.06908096373081207
p mean is: tensor(-0.7689, device='cuda:2')
epoch:  42000 quantization_loss:  0.0691172182559967
p mean is: tensor(-0.7719, device='cuda:2')
epoch:  43000 quantization_loss:  0.06902699917554855
p mean is: tensor(-0.7747, device='cuda:2')
epoch:  44000 quantization_loss:  0.06903640925884247
p mean is: tensor(-0.7773, device='cuda:2')
epoch:  45000 quantization_loss:  0.06895241141319275
p mean is: tensor(-0.7797, device='cuda:2')
epoch:  46000 quantization_loss:  0.06891772896051407
p mean is: tensor(-0.7817, device='cuda:2')
epoch:  47000 quantization_loss:  0.0688411220908165
p mean is: tensor(-0.7838, device='cuda:2')
epoch:  48000 quantization_loss:  0.06878844648599625
p mean is: tensor(-0.7855, device='cuda:2')
epoch:  49000 quantization_loss:  0.0688096433877945
p mean is: tensor(-0.7872, device='cuda:2')
epoch:  50000 quantization_loss:  0.06869682669639587
p mean is: tensor(-0.7887, device='cuda:2')
epoch:  51000 quantization_loss:  0.06869035959243774
p mean is: tensor(-0.7901, device='cuda:2')
epoch:  52000 quantization_loss:  0.06869426369667053
p mean is: tensor(-0.7914, device='cuda:2')
epoch:  53000 quantization_loss:  0.06865163892507553
p mean is: tensor(-0.7927, device='cuda:2')
epoch:  54000 quantization_loss:  0.06865041702985764
p mean is: tensor(-0.7939, device='cuda:2')
epoch:  55000 quantization_loss:  0.06865342706441879
p mean is: tensor(-0.7951, device='cuda:2')
epoch:  56000 quantization_loss:  0.06861121207475662
p mean is: tensor(-0.7962, device='cuda:2')
epoch:  57000 quantization_loss:  0.06863203644752502
p mean is: tensor(-0.7973, device='cuda:2')
epoch:  58000 quantization_loss:  0.06858883053064346
p mean is: tensor(-0.7983, device='cuda:2')
epoch:  59000 quantization_loss:  0.0685911700129509
p mean is: tensor(-0.7992, device='cuda:2')
epoch:  60000 quantization_loss:  0.06859175860881805
p mean is: tensor(-0.8001, device='cuda:2')
epoch:  61000 quantization_loss:  0.06858858466148376
p mean is: tensor(-0.8009, device='cuda:2')
epoch:  62000 quantization_loss:  0.06857384741306305
p mean is: tensor(-0.8017, device='cuda:2')
epoch:  63000 quantization_loss:  0.06855928897857666
p mean is: tensor(-0.8025, device='cuda:2')
epoch:  64000 quantization_loss:  0.06856312602758408
p mean is: tensor(-0.8032, device='cuda:2')
epoch:  65000 quantization_loss:  0.06854768842458725
p mean is: tensor(-0.8039, device='cuda:2')
epoch:  66000 quantization_loss:  0.06855636090040207
p mean is: tensor(-0.8045, device='cuda:2')
epoch:  67000 quantization_loss:  0.06855141371488571
p mean is: tensor(-0.8052, device='cuda:2')
epoch:  68000 quantization_loss:  0.06854380667209625
p mean is: tensor(-0.8058, device='cuda:2')
epoch:  69000 quantization_loss:  0.0685405284166336
p mean is: tensor(-0.8064, device='cuda:2')
epoch:  70000 quantization_loss:  0.0685378760099411
p mean is: tensor(-0.8069, device='cuda:2')
epoch:  71000 quantization_loss:  0.0685250535607338
p mean is: tensor(-0.8074, device='cuda:2')
epoch:  72000 quantization_loss:  0.06852992624044418
p mean is: tensor(-0.8080, device='cuda:2')
epoch:  73000 quantization_loss:  0.06853033602237701
p mean is: tensor(-0.8084, device='cuda:2')
epoch:  74000 quantization_loss:  0.06851530075073242
p mean is: tensor(-0.8089, device='cuda:2')
epoch:  75000 quantization_loss:  0.06851129978895187
p mean is: tensor(-0.8094, device='cuda:2')
epoch:  76000 quantization_loss:  0.06851525604724884
p mean is: tensor(-0.8098, device='cuda:2')
epoch:  77000 quantization_loss:  0.06850254535675049
p mean is: tensor(-0.8103, device='cuda:2')
epoch:  78000 quantization_loss:  0.06849724054336548
p mean is: tensor(-0.8108, device='cuda:2')
epoch:  79000 quantization_loss:  0.06849204748868942
p mean is: tensor(-0.8112, device='cuda:2')
1.1.1.weight         | nonzeros =     743 /   12800             (  5.80%) | total_pruned =   12057 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     148 /    6400             (  2.31%) | total_pruned =    6252 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      81 /   12800             (  0.63%) | total_pruned =   12719 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     161 /   25600             (  0.63%) | total_pruned =   25439 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      13 /      32             ( 40.62%) | total_pruned =      19 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     152 /   51200             (  0.30%) | total_pruned =   51048 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     280 /  102400             (  0.27%) | total_pruned =  102120 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =      95 /  204800             (  0.05%) | total_pruned =  204705 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     385 /  409600             (  0.09%) | total_pruned =  409215 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     741 /  409600             (  0.18%) | total_pruned =  408859 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    3521 /  409600             (  0.86%) | total_pruned =  406079 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    9853 /  409600             (  2.41%) | total_pruned =  399747 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   27491 /  409600             (  6.71%) | total_pruned =  382109 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   24008 /  147456             ( 16.28%) | total_pruned =  123448 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   13228 /  147456             (  8.97%) | total_pruned =  134228 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =    9270 /  147456             (  6.29%) | total_pruned =  138186 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    9822 /   73728             ( 13.32%) | total_pruned =   63906 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    3857 /   18432             ( 20.93%) | total_pruned =   14575 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      21 /      32             ( 65.62%) | total_pruned =      11 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      21 /      32             ( 65.62%) | total_pruned =      11 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1471 /    4608             ( 31.92%) | total_pruned =    3137 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      31 /      48             ( 64.58%) | total_pruned =      17 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 106536, pruned : 2902331, total: 3008867, Compression rate :      28.24x  ( 96.46% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  11.82154835707248
Experiment done
