(3, 512, 512)
2
Noisy PSNR is '20.579823705248124'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/face/mask/2/unet/det/-1.5/1e-09
epoch:  0 quantization_loss:  0.09536954760551453
p mean is: tensor(-0.0003, device='cuda:2')
epoch:  1000 quantization_loss:  0.07615770399570465
p mean is: tensor(-0.0076, device='cuda:2')
epoch:  2000 quantization_loss:  0.07326103001832962
p mean is: tensor(-0.0117, device='cuda:2')
epoch:  3000 quantization_loss:  0.07247530668973923
p mean is: tensor(-0.0166, device='cuda:2')
epoch:  4000 quantization_loss:  0.044346701353788376
p mean is: tensor(-0.0208, device='cuda:2')
epoch:  5000 quantization_loss:  0.034486424177885056
p mean is: tensor(-0.0258, device='cuda:2')
epoch:  6000 quantization_loss:  0.03287282586097717
p mean is: tensor(-0.0325, device='cuda:2')
epoch:  7000 quantization_loss:  0.031018417328596115
p mean is: tensor(-0.0420, device='cuda:2')
epoch:  8000 quantization_loss:  0.030568351969122887
p mean is: tensor(-0.0555, device='cuda:2')
epoch:  9000 quantization_loss:  0.02989209070801735
p mean is: tensor(-0.0742, device='cuda:2')
epoch:  10000 quantization_loss:  0.029344072565436363
p mean is: tensor(-0.0996, device='cuda:2')
epoch:  11000 quantization_loss:  0.029051709920167923
p mean is: tensor(-0.1330, device='cuda:2')
epoch:  12000 quantization_loss:  0.028554117307066917
p mean is: tensor(-0.1763, device='cuda:2')
epoch:  13000 quantization_loss:  0.028344543650746346
p mean is: tensor(-0.2310, device='cuda:2')
epoch:  14000 quantization_loss:  0.027866773307323456
p mean is: tensor(-0.2972, device='cuda:2')
epoch:  15000 quantization_loss:  0.027488475665450096
p mean is: tensor(-0.3735, device='cuda:2')
epoch:  16000 quantization_loss:  0.027297906577587128
p mean is: tensor(-0.4573, device='cuda:2')
epoch:  17000 quantization_loss:  0.027092978358268738
p mean is: tensor(-0.5450, device='cuda:2')
epoch:  18000 quantization_loss:  0.026870811358094215
p mean is: tensor(-0.6329, device='cuda:2')
epoch:  19000 quantization_loss:  0.026705486699938774
p mean is: tensor(-0.7176, device='cuda:2')
epoch:  20000 quantization_loss:  0.026574403047561646
p mean is: tensor(-0.7968, device='cuda:2')
epoch:  21000 quantization_loss:  0.02644052356481552
p mean is: tensor(-0.8689, device='cuda:2')
epoch:  22000 quantization_loss:  0.02641771361231804
p mean is: tensor(-0.9339, device='cuda:2')
epoch:  23000 quantization_loss:  0.026264172047376633
p mean is: tensor(-0.9922, device='cuda:2')
epoch:  24000 quantization_loss:  0.026170754805207253
p mean is: tensor(-1.0440, device='cuda:2')
epoch:  25000 quantization_loss:  0.02614327147603035
p mean is: tensor(-1.0897, device='cuda:2')
epoch:  26000 quantization_loss:  0.026089314371347427
p mean is: tensor(-1.1303, device='cuda:2')
epoch:  27000 quantization_loss:  0.026078157126903534
p mean is: tensor(-1.1664, device='cuda:2')
epoch:  28000 quantization_loss:  0.025988493114709854
p mean is: tensor(-1.1984, device='cuda:2')
epoch:  29000 quantization_loss:  0.025961892679333687
p mean is: tensor(-1.2269, device='cuda:2')
epoch:  30000 quantization_loss:  0.025931106880307198
p mean is: tensor(-1.2523, device='cuda:2')
epoch:  31000 quantization_loss:  0.025896668434143066
p mean is: tensor(-1.2750, device='cuda:2')
epoch:  32000 quantization_loss:  0.02588539756834507
p mean is: tensor(-1.2954, device='cuda:2')
epoch:  33000 quantization_loss:  0.025837494060397148
p mean is: tensor(-1.3137, device='cuda:2')
epoch:  34000 quantization_loss:  0.025832070037722588
p mean is: tensor(-1.3302, device='cuda:2')
epoch:  35000 quantization_loss:  0.02577774040400982
p mean is: tensor(-1.3451, device='cuda:2')
epoch:  36000 quantization_loss:  0.02582203410565853
p mean is: tensor(-1.3586, device='cuda:2')
epoch:  37000 quantization_loss:  0.025771593675017357
p mean is: tensor(-1.3707, device='cuda:2')
epoch:  38000 quantization_loss:  0.02572539635002613
p mean is: tensor(-1.3818, device='cuda:2')
epoch:  39000 quantization_loss:  0.02570958621799946
p mean is: tensor(-1.3919, device='cuda:2')
epoch:  40000 quantization_loss:  0.025703178718686104
p mean is: tensor(-1.4011, device='cuda:2')
epoch:  41000 quantization_loss:  0.025672532618045807
p mean is: tensor(-1.4095, device='cuda:2')
epoch:  42000 quantization_loss:  0.025677688419818878
p mean is: tensor(-1.4172, device='cuda:2')
epoch:  43000 quantization_loss:  0.02567201294004917
p mean is: tensor(-1.4243, device='cuda:2')
epoch:  44000 quantization_loss:  0.02566537633538246
p mean is: tensor(-1.4309, device='cuda:2')
epoch:  45000 quantization_loss:  0.025651028379797935
p mean is: tensor(-1.4370, device='cuda:2')
epoch:  46000 quantization_loss:  0.02561124600470066
p mean is: tensor(-1.4425, device='cuda:2')
epoch:  47000 quantization_loss:  0.02560938149690628
p mean is: tensor(-1.4477, device='cuda:2')
epoch:  48000 quantization_loss:  0.025603773072361946
p mean is: tensor(-1.4525, device='cuda:2')
epoch:  49000 quantization_loss:  0.025588328018784523
p mean is: tensor(-1.4569, device='cuda:2')
epoch:  50000 quantization_loss:  0.025576120242476463
p mean is: tensor(-1.4611, device='cuda:2')
epoch:  51000 quantization_loss:  0.02559170126914978
p mean is: tensor(-1.4650, device='cuda:2')
epoch:  52000 quantization_loss:  0.025561045855283737
p mean is: tensor(-1.4687, device='cuda:2')
epoch:  53000 quantization_loss:  0.025549305602908134
p mean is: tensor(-1.4721, device='cuda:2')
epoch:  54000 quantization_loss:  0.025546029210090637
p mean is: tensor(-1.4754, device='cuda:2')
epoch:  55000 quantization_loss:  0.025534534826874733
p mean is: tensor(-1.4785, device='cuda:2')
epoch:  56000 quantization_loss:  0.025557680055499077
p mean is: tensor(-1.4814, device='cuda:2')
epoch:  57000 quantization_loss:  0.025525012984871864
p mean is: tensor(-1.4842, device='cuda:2')
epoch:  58000 quantization_loss:  0.0255264975130558
p mean is: tensor(-1.4868, device='cuda:2')
epoch:  59000 quantization_loss:  0.025520334020256996
p mean is: tensor(-1.4892, device='cuda:2')
epoch:  60000 quantization_loss:  0.025523893535137177
p mean is: tensor(-1.4916, device='cuda:2')
epoch:  61000 quantization_loss:  0.02550925686955452
p mean is: tensor(-1.4939, device='cuda:2')
epoch:  62000 quantization_loss:  0.02550389990210533
p mean is: tensor(-1.4961, device='cuda:2')
epoch:  63000 quantization_loss:  0.025496836751699448
p mean is: tensor(-1.4981, device='cuda:2')
epoch:  64000 quantization_loss:  0.025489965453743935
p mean is: tensor(-1.5002, device='cuda:2')
epoch:  65000 quantization_loss:  0.025488469749689102
p mean is: tensor(-1.5021, device='cuda:2')
epoch:  66000 quantization_loss:  0.025482024997472763
p mean is: tensor(-1.5039, device='cuda:2')
epoch:  67000 quantization_loss:  0.025488784536719322
p mean is: tensor(-1.5057, device='cuda:2')
epoch:  68000 quantization_loss:  0.025469448417425156
p mean is: tensor(-1.5075, device='cuda:2')
epoch:  69000 quantization_loss:  0.02547944150865078
p mean is: tensor(-1.5092, device='cuda:2')
epoch:  70000 quantization_loss:  0.025479314848780632
p mean is: tensor(-1.5108, device='cuda:2')
epoch:  71000 quantization_loss:  0.02546965889632702
p mean is: tensor(-1.5124, device='cuda:2')
epoch:  72000 quantization_loss:  0.025469649583101273
p mean is: tensor(-1.5139, device='cuda:2')
epoch:  73000 quantization_loss:  0.02546730823814869
p mean is: tensor(-1.5154, device='cuda:2')
epoch:  74000 quantization_loss:  0.02546042948961258
p mean is: tensor(-1.5168, device='cuda:2')
epoch:  75000 quantization_loss:  0.02547266334295273
p mean is: tensor(-1.5182, device='cuda:2')
epoch:  76000 quantization_loss:  0.025459948927164078
p mean is: tensor(-1.5196, device='cuda:2')
epoch:  77000 quantization_loss:  0.025459354743361473
p mean is: tensor(-1.5209, device='cuda:2')
epoch:  78000 quantization_loss:  0.02544739656150341
p mean is: tensor(-1.5221, device='cuda:2')
epoch:  79000 quantization_loss:  0.025454193353652954
p mean is: tensor(-1.5233, device='cuda:2')
1.1.1.weight         | nonzeros =     709 /   12800             (  5.54%) | total_pruned =   12091 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =      78 /    6400             (  1.22%) | total_pruned =    6322 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       5 /      16             ( 31.25%) | total_pruned =      11 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      38 /   12800             (  0.30%) | total_pruned =   12762 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =      50 /   25600             (  0.20%) | total_pruned =   25550 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      12 /      32             ( 37.50%) | total_pruned =      20 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =      11 /   51200             (  0.02%) | total_pruned =   51189 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =      32 /  102400             (  0.03%) | total_pruned =  102368 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =       2 /  204800             (  0.00%) | total_pruned =  204798 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =      16 /  409600             (  0.00%) | total_pruned =  409584 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =       2 /  409600             (  0.00%) | total_pruned =  409598 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =     731 /  409600             (  0.18%) | total_pruned =  408869 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    3053 /  409600             (  0.75%) | total_pruned =  406547 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   14604 /  409600             (  3.57%) | total_pruned =  394996 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   22058 /  147456             ( 14.96%) | total_pruned =  125398 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   20368 /  147456             ( 13.81%) | total_pruned =  127088 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   16601 /  147456             ( 11.26%) | total_pruned =  130855 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    9093 /   73728             ( 12.33%) | total_pruned =   64635 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2487 /   18432             ( 13.49%) | total_pruned =   15945 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1029 /    4608             ( 22.33%) | total_pruned =    3579 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      30 /      48             ( 62.50%) | total_pruned =      18 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 92263, pruned : 2916604, total: 3008867, Compression rate :      32.61x  ( 96.93% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  10.403961832281041
Experiment done
