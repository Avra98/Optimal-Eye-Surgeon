(3, 512, 512)
0
Noisy PSNR is '21.13348038420739'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/face/mask/0/unet/det/0.0/1e-09
epoch:  0 quantization_loss:  0.1537778228521347
p mean is: tensor(3.7298e-07, device='cuda:2')
epoch:  1000 quantization_loss:  0.11791624128818512
p mean is: tensor(7.9540e-05, device='cuda:2')
epoch:  2000 quantization_loss:  0.10989053547382355
p mean is: tensor(0.0003, device='cuda:2')
epoch:  3000 quantization_loss:  0.11019328981637955
p mean is: tensor(0.0003, device='cuda:2')
epoch:  4000 quantization_loss:  0.0985330268740654
p mean is: tensor(0.0001, device='cuda:2')
epoch:  5000 quantization_loss:  0.08454196155071259
p mean is: tensor(-0.0003, device='cuda:2')
epoch:  6000 quantization_loss:  0.08117086440324783
p mean is: tensor(-0.0006, device='cuda:2')
epoch:  7000 quantization_loss:  0.08461274206638336
p mean is: tensor(-0.0010, device='cuda:2')
epoch:  8000 quantization_loss:  0.08075461536645889
p mean is: tensor(-0.0013, device='cuda:2')
epoch:  9000 quantization_loss:  0.07894791662693024
p mean is: tensor(-0.0016, device='cuda:2')
epoch:  10000 quantization_loss:  0.0771634429693222
p mean is: tensor(-0.0021, device='cuda:2')
epoch:  11000 quantization_loss:  0.07724951952695847
p mean is: tensor(-0.0023, device='cuda:2')
epoch:  12000 quantization_loss:  0.07565497606992722
p mean is: tensor(-0.0026, device='cuda:2')
epoch:  13000 quantization_loss:  0.07537736743688583
p mean is: tensor(-0.0029, device='cuda:2')
epoch:  14000 quantization_loss:  0.0749666839838028
p mean is: tensor(-0.0032, device='cuda:2')
epoch:  15000 quantization_loss:  0.07495567947626114
p mean is: tensor(-0.0033, device='cuda:2')
epoch:  16000 quantization_loss:  0.07466332614421844
p mean is: tensor(-0.0035, device='cuda:2')
epoch:  17000 quantization_loss:  0.07461263239383698
p mean is: tensor(-0.0035, device='cuda:2')
epoch:  18000 quantization_loss:  0.07444915175437927
p mean is: tensor(-0.0035, device='cuda:2')
epoch:  19000 quantization_loss:  0.07431059330701828
p mean is: tensor(-0.0032, device='cuda:2')
epoch:  20000 quantization_loss:  0.07435967773199081
p mean is: tensor(-0.0031, device='cuda:2')
epoch:  21000 quantization_loss:  0.07424451410770416
p mean is: tensor(-0.0029, device='cuda:2')
epoch:  22000 quantization_loss:  0.07416149228811264
p mean is: tensor(-0.0026, device='cuda:2')
epoch:  23000 quantization_loss:  0.07419576495885849
p mean is: tensor(-0.0022, device='cuda:2')
epoch:  24000 quantization_loss:  0.07413539290428162
p mean is: tensor(-0.0019, device='cuda:2')
epoch:  25000 quantization_loss:  0.07409348338842392
p mean is: tensor(-0.0015, device='cuda:2')
epoch:  26000 quantization_loss:  0.07403961569070816
p mean is: tensor(-0.0011, device='cuda:2')
epoch:  27000 quantization_loss:  0.07397612929344177
p mean is: tensor(-0.0007, device='cuda:2')
epoch:  28000 quantization_loss:  0.07394156605005264
p mean is: tensor(-0.0003, device='cuda:2')
epoch:  29000 quantization_loss:  0.07393550127744675
p mean is: tensor(-5.6288e-05, device='cuda:2')
epoch:  30000 quantization_loss:  0.07272502034902573
p mean is: tensor(0.0002, device='cuda:2')
epoch:  31000 quantization_loss:  0.07274069637060165
p mean is: tensor(0.0004, device='cuda:2')
epoch:  32000 quantization_loss:  0.07272996753454208
p mean is: tensor(0.0006, device='cuda:2')
epoch:  33000 quantization_loss:  0.07266900688409805
p mean is: tensor(0.0009, device='cuda:2')
epoch:  34000 quantization_loss:  0.0726546198129654
p mean is: tensor(0.0011, device='cuda:2')
epoch:  35000 quantization_loss:  0.07264811545610428
p mean is: tensor(0.0012, device='cuda:2')
epoch:  36000 quantization_loss:  0.07261437922716141
p mean is: tensor(0.0014, device='cuda:2')
epoch:  37000 quantization_loss:  0.07259257137775421
p mean is: tensor(0.0016, device='cuda:2')
epoch:  38000 quantization_loss:  0.0725693330168724
p mean is: tensor(0.0016, device='cuda:2')
epoch:  39000 quantization_loss:  0.07256186753511429
p mean is: tensor(0.0017, device='cuda:2')
epoch:  40000 quantization_loss:  0.07255204766988754
p mean is: tensor(0.0018, device='cuda:2')
epoch:  41000 quantization_loss:  0.07254137098789215
p mean is: tensor(0.0018, device='cuda:2')
epoch:  42000 quantization_loss:  0.07251972705125809
p mean is: tensor(0.0019, device='cuda:2')
epoch:  43000 quantization_loss:  0.07249850034713745
p mean is: tensor(0.0019, device='cuda:2')
epoch:  44000 quantization_loss:  0.07251142710447311
p mean is: tensor(0.0019, device='cuda:2')
epoch:  45000 quantization_loss:  0.07248488068580627
p mean is: tensor(0.0020, device='cuda:2')
epoch:  46000 quantization_loss:  0.0724790096282959
p mean is: tensor(0.0020, device='cuda:2')
epoch:  47000 quantization_loss:  0.07247316092252731
p mean is: tensor(0.0020, device='cuda:2')
epoch:  48000 quantization_loss:  0.07245815545320511
p mean is: tensor(0.0020, device='cuda:2')
epoch:  49000 quantization_loss:  0.0724467858672142
p mean is: tensor(0.0019, device='cuda:2')
epoch:  50000 quantization_loss:  0.0724480152130127
p mean is: tensor(0.0020, device='cuda:2')
epoch:  51000 quantization_loss:  0.07243324816226959
p mean is: tensor(0.0020, device='cuda:2')
epoch:  52000 quantization_loss:  0.07243675738573074
p mean is: tensor(0.0019, device='cuda:2')
epoch:  53000 quantization_loss:  0.07241775840520859
p mean is: tensor(0.0019, device='cuda:2')
epoch:  54000 quantization_loss:  0.07241985946893692
p mean is: tensor(0.0019, device='cuda:2')
epoch:  55000 quantization_loss:  0.07242576777935028
p mean is: tensor(0.0018, device='cuda:2')
epoch:  56000 quantization_loss:  0.07240859419107437
p mean is: tensor(0.0018, device='cuda:2')
epoch:  57000 quantization_loss:  0.07240695506334305
p mean is: tensor(0.0017, device='cuda:2')
epoch:  58000 quantization_loss:  0.07238152623176575
p mean is: tensor(0.0016, device='cuda:2')
epoch:  59000 quantization_loss:  0.07238417118787766
p mean is: tensor(0.0016, device='cuda:2')
epoch:  60000 quantization_loss:  0.07240935415029526
p mean is: tensor(0.0014, device='cuda:2')
epoch:  61000 quantization_loss:  0.07233394682407379
p mean is: tensor(0.0013, device='cuda:2')
epoch:  62000 quantization_loss:  0.07223636656999588
p mean is: tensor(0.0012, device='cuda:2')
epoch:  63000 quantization_loss:  0.07217990607023239
p mean is: tensor(0.0012, device='cuda:2')
epoch:  64000 quantization_loss:  0.07212942093610764
p mean is: tensor(0.0011, device='cuda:2')
epoch:  65000 quantization_loss:  0.0721193328499794
p mean is: tensor(0.0012, device='cuda:2')
epoch:  66000 quantization_loss:  0.0720934197306633
p mean is: tensor(0.0011, device='cuda:2')
epoch:  67000 quantization_loss:  0.07209470868110657
p mean is: tensor(0.0010, device='cuda:2')
epoch:  68000 quantization_loss:  0.07208231091499329
p mean is: tensor(0.0010, device='cuda:2')
epoch:  69000 quantization_loss:  0.07206312566995621
p mean is: tensor(0.0009, device='cuda:2')
epoch:  70000 quantization_loss:  0.07206856459379196
p mean is: tensor(0.0008, device='cuda:2')
epoch:  71000 quantization_loss:  0.07206173986196518
p mean is: tensor(0.0007, device='cuda:2')
epoch:  72000 quantization_loss:  0.07205203175544739
p mean is: tensor(0.0007, device='cuda:2')
epoch:  73000 quantization_loss:  0.07205953449010849
p mean is: tensor(0.0006, device='cuda:2')
epoch:  74000 quantization_loss:  0.07205010950565338
p mean is: tensor(0.0005, device='cuda:2')
epoch:  75000 quantization_loss:  0.07205221801996231
p mean is: tensor(0.0004, device='cuda:2')
epoch:  76000 quantization_loss:  0.07204210758209229
p mean is: tensor(0.0004, device='cuda:2')
epoch:  77000 quantization_loss:  0.0720461905002594
p mean is: tensor(0.0003, device='cuda:2')
epoch:  78000 quantization_loss:  0.07204224914312363
p mean is: tensor(0.0002, device='cuda:2')
epoch:  79000 quantization_loss:  0.0720350369811058
p mean is: tensor(0.0002, device='cuda:2')
1.1.1.weight         | nonzeros =    6399 /   12800             ( 49.99%) | total_pruned =    6401 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.2.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =    3211 /    6400             ( 50.17%) | total_pruned =    3189 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       1 /      16             (  6.25%) | total_pruned =      15 | shape = torch.Size([16])
1.5.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =    6394 /   12800             ( 49.95%) | total_pruned =    6406 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       6 /      32             ( 18.75%) | total_pruned =      26 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =   12972 /   25600             ( 50.67%) | total_pruned =   12628 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       1 /      32             (  3.12%) | total_pruned =      31 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =   25715 /   51200             ( 50.22%) | total_pruned =   25485 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =   51328 /  102400             ( 50.12%) | total_pruned =   51072 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =  102709 /  204800             ( 50.15%) | total_pruned =  102091 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =  204760 /  409600             ( 49.99%) | total_pruned =  204840 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  204170 /  409600             ( 49.85%) | total_pruned =  205430 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  202745 /  409600             ( 49.50%) | total_pruned =  206855 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  199957 /  409600             ( 48.82%) | total_pruned =  209643 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  194149 /  409600             ( 47.40%) | total_pruned =  215451 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   66442 /  147456             ( 45.06%) | total_pruned =   81014 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   61662 /  147456             ( 41.82%) | total_pruned =   85794 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   53738 /  147456             ( 36.44%) | total_pruned =   93718 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   21488 /   73728             ( 29.14%) | total_pruned =   52240 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    6660 /   18432             ( 36.13%) | total_pruned =   11772 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       7 /      32             ( 21.88%) | total_pruned =      25 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    2050 /    4608             ( 44.49%) | total_pruned =    2558 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
4.weight             | nonzeros =      15 /      16             ( 93.75%) | total_pruned =       1 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      28 /      48             ( 58.33%) | total_pruned =      20 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 1427895, pruned : 1580972, total: 3008867, Compression rate :       2.11x  ( 52.54% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  11.577326919814013
Experiment done
