(3, 512, 512)
4
Noisy PSNR is '20.210911525301096'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/face/mask/4/unet/det/1.0/1e-09
epoch:  0 quantization_loss:  0.07569950073957443
p mean is: tensor(0.0002, device='cuda:2')
epoch:  1000 quantization_loss:  0.07347500324249268
p mean is: tensor(0.0063, device='cuda:2')
epoch:  2000 quantization_loss:  0.07018778473138809
p mean is: tensor(0.0106, device='cuda:2')
epoch:  3000 quantization_loss:  0.07184072583913803
p mean is: tensor(0.0150, device='cuda:2')
epoch:  4000 quantization_loss:  0.07167915999889374
p mean is: tensor(0.0192, device='cuda:2')
epoch:  5000 quantization_loss:  0.07188410311937332
p mean is: tensor(0.0234, device='cuda:2')
epoch:  6000 quantization_loss:  0.07118010520935059
p mean is: tensor(0.0274, device='cuda:2')
epoch:  7000 quantization_loss:  0.060326673090457916
p mean is: tensor(0.0313, device='cuda:2')
epoch:  8000 quantization_loss:  0.04490126296877861
p mean is: tensor(0.0362, device='cuda:2')
epoch:  9000 quantization_loss:  0.03828912973403931
p mean is: tensor(0.0424, device='cuda:2')
epoch:  10000 quantization_loss:  0.03400608152151108
p mean is: tensor(0.0509, device='cuda:2')
epoch:  11000 quantization_loss:  0.03223240002989769
p mean is: tensor(0.0630, device='cuda:2')
epoch:  12000 quantization_loss:  0.03171578049659729
p mean is: tensor(0.0795, device='cuda:2')
epoch:  13000 quantization_loss:  0.031217128038406372
p mean is: tensor(0.1018, device='cuda:2')
epoch:  14000 quantization_loss:  0.030817639082670212
p mean is: tensor(0.1311, device='cuda:2')
epoch:  15000 quantization_loss:  0.030311353504657745
p mean is: tensor(0.1683, device='cuda:2')
epoch:  16000 quantization_loss:  0.03001151978969574
p mean is: tensor(0.2136, device='cuda:2')
epoch:  17000 quantization_loss:  0.029906513169407845
p mean is: tensor(0.2667, device='cuda:2')
epoch:  18000 quantization_loss:  0.02978898398578167
p mean is: tensor(0.3256, device='cuda:2')
epoch:  19000 quantization_loss:  0.029629645869135857
p mean is: tensor(0.3878, device='cuda:2')
epoch:  20000 quantization_loss:  0.029445694759488106
p mean is: tensor(0.4504, device='cuda:2')
epoch:  21000 quantization_loss:  0.02940083108842373
p mean is: tensor(0.5108, device='cuda:2')
epoch:  22000 quantization_loss:  0.029279744252562523
p mean is: tensor(0.5671, device='cuda:2')
epoch:  23000 quantization_loss:  0.029185224324464798
p mean is: tensor(0.6182, device='cuda:2')
epoch:  24000 quantization_loss:  0.029113158583641052
p mean is: tensor(0.6638, device='cuda:2')
epoch:  25000 quantization_loss:  0.029093964025378227
p mean is: tensor(0.7040, device='cuda:2')
epoch:  26000 quantization_loss:  0.02902650274336338
p mean is: tensor(0.7393, device='cuda:2')
epoch:  27000 quantization_loss:  0.029089946299791336
p mean is: tensor(0.7703, device='cuda:2')
epoch:  28000 quantization_loss:  0.028999345377087593
p mean is: tensor(0.7974, device='cuda:2')
epoch:  29000 quantization_loss:  0.02892056666314602
p mean is: tensor(0.8209, device='cuda:2')
epoch:  30000 quantization_loss:  0.028906721621751785
p mean is: tensor(0.8414, device='cuda:2')
epoch:  31000 quantization_loss:  0.028861982747912407
p mean is: tensor(0.8593, device='cuda:2')
epoch:  32000 quantization_loss:  0.02886764332652092
p mean is: tensor(0.8751, device='cuda:2')
epoch:  33000 quantization_loss:  0.028828255832195282
p mean is: tensor(0.8889, device='cuda:2')
epoch:  34000 quantization_loss:  0.02881438098847866
p mean is: tensor(0.9011, device='cuda:2')
epoch:  35000 quantization_loss:  0.0287955179810524
p mean is: tensor(0.9119, device='cuda:2')
epoch:  36000 quantization_loss:  0.02879292145371437
p mean is: tensor(0.9213, device='cuda:2')
epoch:  37000 quantization_loss:  0.02879965864121914
p mean is: tensor(0.9297, device='cuda:2')
epoch:  38000 quantization_loss:  0.02879822440445423
p mean is: tensor(0.9371, device='cuda:2')
epoch:  39000 quantization_loss:  0.028753452003002167
p mean is: tensor(0.9438, device='cuda:2')
epoch:  40000 quantization_loss:  0.028761442750692368
p mean is: tensor(0.9497, device='cuda:2')
epoch:  41000 quantization_loss:  0.028763342648744583
p mean is: tensor(0.9551, device='cuda:2')
epoch:  42000 quantization_loss:  0.028736285865306854
p mean is: tensor(0.9599, device='cuda:2')
epoch:  43000 quantization_loss:  0.028742780908942223
p mean is: tensor(0.9642, device='cuda:2')
epoch:  44000 quantization_loss:  0.02873840555548668
p mean is: tensor(0.9683, device='cuda:2')
epoch:  45000 quantization_loss:  0.028715090826153755
p mean is: tensor(0.9719, device='cuda:2')
epoch:  46000 quantization_loss:  0.02870873734354973
p mean is: tensor(0.9751, device='cuda:2')
epoch:  47000 quantization_loss:  0.028694212436676025
p mean is: tensor(0.9781, device='cuda:2')
epoch:  48000 quantization_loss:  0.028697781264781952
p mean is: tensor(0.9810, device='cuda:2')
epoch:  49000 quantization_loss:  0.028689231723546982
p mean is: tensor(0.9835, device='cuda:2')
epoch:  50000 quantization_loss:  0.02868456020951271
p mean is: tensor(0.9859, device='cuda:2')
epoch:  51000 quantization_loss:  0.028673188760876656
p mean is: tensor(0.9881, device='cuda:2')
epoch:  52000 quantization_loss:  0.028670283034443855
p mean is: tensor(0.9901, device='cuda:2')
epoch:  53000 quantization_loss:  0.028667446225881577
p mean is: tensor(0.9920, device='cuda:2')
epoch:  54000 quantization_loss:  0.02867615595459938
p mean is: tensor(0.9938, device='cuda:2')
epoch:  55000 quantization_loss:  0.0286544356495142
p mean is: tensor(0.9955, device='cuda:2')
epoch:  56000 quantization_loss:  0.028652027249336243
p mean is: tensor(0.9971, device='cuda:2')
epoch:  57000 quantization_loss:  0.028650909662246704
p mean is: tensor(0.9986, device='cuda:2')
epoch:  58000 quantization_loss:  0.028646159917116165
p mean is: tensor(1.0000, device='cuda:2')
epoch:  59000 quantization_loss:  0.02866726741194725
p mean is: tensor(1.0014, device='cuda:2')
epoch:  60000 quantization_loss:  0.028650738298892975
p mean is: tensor(1.0027, device='cuda:2')
epoch:  61000 quantization_loss:  0.02865210548043251
p mean is: tensor(1.0038, device='cuda:2')
epoch:  62000 quantization_loss:  0.02864324115216732
p mean is: tensor(1.0050, device='cuda:2')
epoch:  63000 quantization_loss:  0.028632350265979767
p mean is: tensor(1.0060, device='cuda:2')
epoch:  64000 quantization_loss:  0.028634585440158844
p mean is: tensor(1.0070, device='cuda:2')
epoch:  65000 quantization_loss:  0.028631465509533882
p mean is: tensor(1.0080, device='cuda:2')
epoch:  66000 quantization_loss:  0.02862091362476349
p mean is: tensor(1.0089, device='cuda:2')
epoch:  67000 quantization_loss:  0.0286328736692667
p mean is: tensor(1.0098, device='cuda:2')
epoch:  68000 quantization_loss:  0.02862408198416233
p mean is: tensor(1.0107, device='cuda:2')
epoch:  69000 quantization_loss:  0.028630871325731277
p mean is: tensor(1.0115, device='cuda:2')
epoch:  70000 quantization_loss:  0.028624745085835457
p mean is: tensor(1.0124, device='cuda:2')
epoch:  71000 quantization_loss:  0.02861858159303665
p mean is: tensor(1.0131, device='cuda:2')
epoch:  72000 quantization_loss:  0.028614241629838943
p mean is: tensor(1.0139, device='cuda:2')
epoch:  73000 quantization_loss:  0.028611676767468452
p mean is: tensor(1.0146, device='cuda:2')
epoch:  74000 quantization_loss:  0.028613341972231865
p mean is: tensor(1.0153, device='cuda:2')
epoch:  75000 quantization_loss:  0.028606537729501724
p mean is: tensor(1.0160, device='cuda:2')
epoch:  76000 quantization_loss:  0.02860555611550808
p mean is: tensor(1.0167, device='cuda:2')
epoch:  77000 quantization_loss:  0.02860882692039013
p mean is: tensor(1.0173, device='cuda:2')
epoch:  78000 quantization_loss:  0.02860560454428196
p mean is: tensor(1.0180, device='cuda:2')
epoch:  79000 quantization_loss:  0.028607740998268127
p mean is: tensor(1.0185, device='cuda:2')
1.1.1.weight         | nonzeros =   12093 /   12800             ( 94.48%) | total_pruned =     707 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.2.weight           | nonzeros =      12 /      16             ( 75.00%) | total_pruned =       4 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =    6329 /    6400             ( 98.89%) | total_pruned =      71 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.5.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =   12757 /   12800             ( 99.66%) | total_pruned =      43 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      26 /      32             ( 81.25%) | total_pruned =       6 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =   25551 /   25600             ( 99.81%) | total_pruned =      49 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =   51172 /   51200             ( 99.95%) | total_pruned =      28 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =  102386 /  102400             ( 99.99%) | total_pruned =      14 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =  204766 /  204800             ( 99.98%) | total_pruned =      34 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =  409590 /  409600             (100.00%) | total_pruned =      10 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  409506 /  409600             ( 99.98%) | total_pruned =      94 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  408121 /  409600             ( 99.64%) | total_pruned =    1479 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  404494 /  409600             ( 98.75%) | total_pruned =    5106 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  390312 /  409600             ( 95.29%) | total_pruned =   19288 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  125099 /  147456             ( 84.84%) | total_pruned =   22357 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  124281 /  147456             ( 84.28%) | total_pruned =   23175 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =  126850 /  147456             ( 86.03%) | total_pruned =   20606 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   62785 /   73728             ( 85.16%) | total_pruned =   10943 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =   15400 /   18432             ( 83.55%) | total_pruned =    3032 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    3433 /    4608             ( 74.50%) | total_pruned =    1175 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      23 /      48             ( 47.92%) | total_pruned =      25 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       3 /       3             (100.00%) | total_pruned =       0 | shape = torch.Size([3])
alive: 2897950, pruned : 110917, total: 3008867, Compression rate :       1.04x  (  3.69% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  16.939409914738796
Experiment done
