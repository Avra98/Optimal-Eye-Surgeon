(3, 512, 512)
4
Noisy PSNR is '20.22453392042258'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/face/mask/4/unet/det/0.5/1e-09
epoch:  0 quantization_loss:  0.08078573644161224
p mean is: tensor(8.5747e-05, device='cuda:0')
epoch:  1000 quantization_loss:  0.0713174119591713
p mean is: tensor(0.0032, device='cuda:0')
epoch:  2000 quantization_loss:  0.07043088227510452
p mean is: tensor(0.0053, device='cuda:0')
epoch:  3000 quantization_loss:  0.07006444782018661
p mean is: tensor(0.0074, device='cuda:0')
epoch:  4000 quantization_loss:  0.06986517459154129
p mean is: tensor(0.0097, device='cuda:0')
epoch:  5000 quantization_loss:  0.07029565423727036
p mean is: tensor(0.0122, device='cuda:0')
epoch:  6000 quantization_loss:  0.07061467319726944
p mean is: tensor(0.0145, device='cuda:0')
epoch:  7000 quantization_loss:  0.07094637304544449
p mean is: tensor(0.0174, device='cuda:0')
epoch:  8000 quantization_loss:  0.06953544914722443
p mean is: tensor(0.0201, device='cuda:0')
epoch:  9000 quantization_loss:  0.06193507835268974
p mean is: tensor(0.0224, device='cuda:0')
epoch:  10000 quantization_loss:  0.05098074674606323
p mean is: tensor(0.0253, device='cuda:0')
epoch:  11000 quantization_loss:  0.04182970151305199
p mean is: tensor(0.0290, device='cuda:0')
epoch:  12000 quantization_loss:  0.039378080517053604
p mean is: tensor(0.0345, device='cuda:0')
epoch:  13000 quantization_loss:  0.038542136549949646
p mean is: tensor(0.0423, device='cuda:0')
epoch:  14000 quantization_loss:  0.03844702988862991
p mean is: tensor(0.0531, device='cuda:0')
epoch:  15000 quantization_loss:  0.03477509692311287
p mean is: tensor(0.0674, device='cuda:0')
epoch:  16000 quantization_loss:  0.03441784903407097
p mean is: tensor(0.0856, device='cuda:0')
epoch:  17000 quantization_loss:  0.03384288400411606
p mean is: tensor(0.1080, device='cuda:0')
epoch:  18000 quantization_loss:  0.03379217907786369
p mean is: tensor(0.1345, device='cuda:0')
epoch:  19000 quantization_loss:  0.03358272463083267
p mean is: tensor(0.1643, device='cuda:0')
epoch:  20000 quantization_loss:  0.03125281259417534
p mean is: tensor(0.1961, device='cuda:0')
epoch:  21000 quantization_loss:  0.0282948836684227
p mean is: tensor(0.2280, device='cuda:0')
epoch:  22000 quantization_loss:  0.025246400386095047
p mean is: tensor(0.2585, device='cuda:0')
epoch:  23000 quantization_loss:  0.024592140689492226
p mean is: tensor(0.2866, device='cuda:0')
epoch:  24000 quantization_loss:  0.021169200539588928
p mean is: tensor(0.3118, device='cuda:0')
epoch:  25000 quantization_loss:  0.021077020093798637
p mean is: tensor(0.3341, device='cuda:0')
epoch:  26000 quantization_loss:  0.020861133933067322
p mean is: tensor(0.3539, device='cuda:0')
epoch:  27000 quantization_loss:  0.020830489695072174
p mean is: tensor(0.3714, device='cuda:0')
epoch:  28000 quantization_loss:  0.020746426656842232
p mean is: tensor(0.3869, device='cuda:0')
epoch:  29000 quantization_loss:  0.02080710418522358
p mean is: tensor(0.4005, device='cuda:0')
epoch:  30000 quantization_loss:  0.020657582208514214
p mean is: tensor(0.4124, device='cuda:0')
epoch:  31000 quantization_loss:  0.02058630995452404
p mean is: tensor(0.4228, device='cuda:0')
epoch:  32000 quantization_loss:  0.020741552114486694
p mean is: tensor(0.4319, device='cuda:0')
epoch:  33000 quantization_loss:  0.0205170139670372
p mean is: tensor(0.4399, device='cuda:0')
epoch:  34000 quantization_loss:  0.020511569455266
p mean is: tensor(0.4468, device='cuda:0')
epoch:  35000 quantization_loss:  0.020465124398469925
p mean is: tensor(0.4529, device='cuda:0')
epoch:  36000 quantization_loss:  0.020459290593862534
p mean is: tensor(0.4582, device='cuda:0')
epoch:  37000 quantization_loss:  0.020444387570023537
p mean is: tensor(0.4630, device='cuda:0')
epoch:  38000 quantization_loss:  0.020420629531145096
p mean is: tensor(0.4673, device='cuda:0')
epoch:  39000 quantization_loss:  0.020406637340784073
p mean is: tensor(0.4709, device='cuda:0')
epoch:  40000 quantization_loss:  0.020375998690724373
p mean is: tensor(0.4742, device='cuda:0')
epoch:  41000 quantization_loss:  0.020379865542054176
p mean is: tensor(0.4772, device='cuda:0')
epoch:  42000 quantization_loss:  0.020367294549942017
p mean is: tensor(0.4798, device='cuda:0')
epoch:  43000 quantization_loss:  0.020360596477985382
p mean is: tensor(0.4821, device='cuda:0')
epoch:  44000 quantization_loss:  0.02033357508480549
p mean is: tensor(0.4842, device='cuda:0')
epoch:  45000 quantization_loss:  0.020328285172581673
p mean is: tensor(0.4862, device='cuda:0')
epoch:  46000 quantization_loss:  0.020332183688879013
p mean is: tensor(0.4879, device='cuda:0')
epoch:  47000 quantization_loss:  0.020301375538110733
p mean is: tensor(0.4894, device='cuda:0')
epoch:  48000 quantization_loss:  0.02029189094901085
p mean is: tensor(0.4909, device='cuda:0')
epoch:  49000 quantization_loss:  0.020279062911868095
p mean is: tensor(0.4924, device='cuda:0')
epoch:  50000 quantization_loss:  0.02026999555528164
p mean is: tensor(0.4936, device='cuda:0')
epoch:  51000 quantization_loss:  0.020275237038731575
p mean is: tensor(0.4948, device='cuda:0')
epoch:  52000 quantization_loss:  0.0202599186450243
p mean is: tensor(0.4958, device='cuda:0')
epoch:  53000 quantization_loss:  0.020269541069865227
p mean is: tensor(0.4968, device='cuda:0')
epoch:  54000 quantization_loss:  0.020246239379048347
p mean is: tensor(0.4977, device='cuda:0')
epoch:  55000 quantization_loss:  0.020261432975530624
p mean is: tensor(0.4985, device='cuda:0')
epoch:  56000 quantization_loss:  0.020232949405908585
p mean is: tensor(0.4993, device='cuda:0')
epoch:  57000 quantization_loss:  0.020228156819939613
p mean is: tensor(0.5000, device='cuda:0')
epoch:  58000 quantization_loss:  0.020224234089255333
p mean is: tensor(0.5007, device='cuda:0')
epoch:  59000 quantization_loss:  0.020218029618263245
p mean is: tensor(0.5014, device='cuda:0')
epoch:  60000 quantization_loss:  0.020223740488290787
p mean is: tensor(0.5021, device='cuda:0')
epoch:  61000 quantization_loss:  0.02021842449903488
p mean is: tensor(0.5026, device='cuda:0')
epoch:  62000 quantization_loss:  0.020214321091771126
p mean is: tensor(0.5031, device='cuda:0')
epoch:  63000 quantization_loss:  0.020232655107975006
p mean is: tensor(0.5036, device='cuda:0')
epoch:  64000 quantization_loss:  0.02021198533475399
p mean is: tensor(0.5040, device='cuda:0')
epoch:  65000 quantization_loss:  0.02021157182753086
p mean is: tensor(0.5045, device='cuda:0')
epoch:  66000 quantization_loss:  0.02019353210926056
p mean is: tensor(0.5050, device='cuda:0')
epoch:  67000 quantization_loss:  0.020198773592710495
p mean is: tensor(0.5054, device='cuda:0')
epoch:  68000 quantization_loss:  0.020201891660690308
p mean is: tensor(0.5058, device='cuda:0')
epoch:  69000 quantization_loss:  0.020201684907078743
p mean is: tensor(0.5061, device='cuda:0')
epoch:  70000 quantization_loss:  0.020191246643662453
p mean is: tensor(0.5065, device='cuda:0')
epoch:  71000 quantization_loss:  0.020195191726088524
p mean is: tensor(0.5069, device='cuda:0')
epoch:  72000 quantization_loss:  0.020178411155939102
p mean is: tensor(0.5073, device='cuda:0')
epoch:  73000 quantization_loss:  0.020183686167001724
p mean is: tensor(0.5076, device='cuda:0')
epoch:  74000 quantization_loss:  0.020185939967632294
p mean is: tensor(0.5079, device='cuda:0')
epoch:  75000 quantization_loss:  0.020174482837319374
p mean is: tensor(0.5083, device='cuda:0')
epoch:  76000 quantization_loss:  0.02018434926867485
p mean is: tensor(0.5085, device='cuda:0')
epoch:  77000 quantization_loss:  0.020173316821455956
p mean is: tensor(0.5088, device='cuda:0')
epoch:  78000 quantization_loss:  0.020170453935861588
p mean is: tensor(0.5091, device='cuda:0')
epoch:  79000 quantization_loss:  0.020174292847514153
p mean is: tensor(0.5094, device='cuda:0')
1.1.1.weight         | nonzeros =   11188 /   12800             ( 87.41%) | total_pruned =    1612 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.2.weight           | nonzeros =      11 /      16             ( 68.75%) | total_pruned =       5 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =    6079 /    6400             ( 94.98%) | total_pruned =     321 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.5.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =   12657 /   12800             ( 98.88%) | total_pruned =     143 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =   25364 /   25600             ( 99.08%) | total_pruned =     236 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =   50898 /   51200             ( 99.41%) | total_pruned =     302 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =  101853 /  102400             ( 99.47%) | total_pruned =     547 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =  204345 /  204800             ( 99.78%) | total_pruned =     455 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =  408578 /  409600             ( 99.75%) | total_pruned =    1022 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  406966 /  409600             ( 99.36%) | total_pruned =    2634 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  400308 /  409600             ( 97.73%) | total_pruned =    9292 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  388346 /  409600             ( 94.81%) | total_pruned =   21254 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  365168 /  409600             ( 89.15%) | total_pruned =   44432 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  122108 /  147456             ( 82.81%) | total_pruned =   25348 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  119414 /  147456             ( 80.98%) | total_pruned =   28042 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =  121064 /  147456             ( 82.10%) | total_pruned =   26392 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   61938 /   73728             ( 84.01%) | total_pruned =   11790 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =   15322 /   18432             ( 83.13%) | total_pruned =    3110 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      21 /      32             ( 65.62%) | total_pruned =      11 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    3284 /    4608             ( 71.27%) | total_pruned =    1324 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      31 /      48             ( 64.58%) | total_pruned =      17 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 2827822, pruned : 181045, total: 3008867, Compression rate :       1.06x  (  6.02% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  19.46223123770557
Experiment done
