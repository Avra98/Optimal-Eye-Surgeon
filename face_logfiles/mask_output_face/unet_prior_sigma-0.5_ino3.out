(3, 512, 512)
3
Noisy PSNR is '20.315487038456315'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/face/mask/3/unet/det/-0.5/1e-09
epoch:  0 quantization_loss:  0.06779469549655914
p mean is: tensor(-8.7434e-05, device='cuda:4')
epoch:  1000 quantization_loss:  0.059378065168857574
p mean is: tensor(-0.0035, device='cuda:4')
epoch:  2000 quantization_loss:  0.057771842926740646
p mean is: tensor(-0.0056, device='cuda:4')
epoch:  3000 quantization_loss:  0.056838057935237885
p mean is: tensor(-0.0074, device='cuda:4')
epoch:  4000 quantization_loss:  0.056257713586091995
p mean is: tensor(-0.0096, device='cuda:4')
epoch:  5000 quantization_loss:  0.05042643845081329
p mean is: tensor(-0.0119, device='cuda:4')
epoch:  6000 quantization_loss:  0.033982884138822556
p mean is: tensor(-0.0140, device='cuda:4')
epoch:  7000 quantization_loss:  0.029691478237509727
p mean is: tensor(-0.0168, device='cuda:4')
epoch:  8000 quantization_loss:  0.02846653014421463
p mean is: tensor(-0.0205, device='cuda:4')
epoch:  9000 quantization_loss:  0.025627650320529938
p mean is: tensor(-0.0256, device='cuda:4')
epoch:  10000 quantization_loss:  0.024199513718485832
p mean is: tensor(-0.0327, device='cuda:4')
epoch:  11000 quantization_loss:  0.02297508902847767
p mean is: tensor(-0.0421, device='cuda:4')
epoch:  12000 quantization_loss:  0.021815577521920204
p mean is: tensor(-0.0543, device='cuda:4')
epoch:  13000 quantization_loss:  0.02133047953248024
p mean is: tensor(-0.0699, device='cuda:4')
epoch:  14000 quantization_loss:  0.02068842574954033
p mean is: tensor(-0.0889, device='cuda:4')
epoch:  15000 quantization_loss:  0.020399020984768867
p mean is: tensor(-0.1115, device='cuda:4')
epoch:  16000 quantization_loss:  0.020092161372303963
p mean is: tensor(-0.1375, device='cuda:4')
epoch:  17000 quantization_loss:  0.019785461947321892
p mean is: tensor(-0.1658, device='cuda:4')
epoch:  18000 quantization_loss:  0.01968594640493393
p mean is: tensor(-0.1955, device='cuda:4')
epoch:  19000 quantization_loss:  0.019464857876300812
p mean is: tensor(-0.2250, device='cuda:4')
epoch:  20000 quantization_loss:  0.019319701939821243
p mean is: tensor(-0.2537, device='cuda:4')
epoch:  21000 quantization_loss:  0.01931045576930046
p mean is: tensor(-0.2804, device='cuda:4')
epoch:  22000 quantization_loss:  0.019199348986148834
p mean is: tensor(-0.3049, device='cuda:4')
epoch:  23000 quantization_loss:  0.019125109538435936
p mean is: tensor(-0.3269, device='cuda:4')
epoch:  24000 quantization_loss:  0.019010275602340698
p mean is: tensor(-0.3463, device='cuda:4')
epoch:  25000 quantization_loss:  0.018989039584994316
p mean is: tensor(-0.3634, device='cuda:4')
epoch:  26000 quantization_loss:  0.01892656646668911
p mean is: tensor(-0.3782, device='cuda:4')
epoch:  27000 quantization_loss:  0.018822502344846725
p mean is: tensor(-0.3912, device='cuda:4')
epoch:  28000 quantization_loss:  0.018840398639440536
p mean is: tensor(-0.4024, device='cuda:4')
epoch:  29000 quantization_loss:  0.018777964636683464
p mean is: tensor(-0.4121, device='cuda:4')
epoch:  30000 quantization_loss:  0.018713362514972687
p mean is: tensor(-0.4206, device='cuda:4')
epoch:  31000 quantization_loss:  0.01871245913207531
p mean is: tensor(-0.4280, device='cuda:4')
epoch:  32000 quantization_loss:  0.01867951638996601
p mean is: tensor(-0.4344, device='cuda:4')
epoch:  33000 quantization_loss:  0.018653733655810356
p mean is: tensor(-0.4400, device='cuda:4')
epoch:  34000 quantization_loss:  0.018640505149960518
p mean is: tensor(-0.4450, device='cuda:4')
epoch:  35000 quantization_loss:  0.018605273216962814
p mean is: tensor(-0.4493, device='cuda:4')
epoch:  36000 quantization_loss:  0.01858832873404026
p mean is: tensor(-0.4532, device='cuda:4')
epoch:  37000 quantization_loss:  0.018580211326479912
p mean is: tensor(-0.4566, device='cuda:4')
epoch:  38000 quantization_loss:  0.018577367067337036
p mean is: tensor(-0.4597, device='cuda:4')
epoch:  39000 quantization_loss:  0.018543671816587448
p mean is: tensor(-0.4624, device='cuda:4')
epoch:  40000 quantization_loss:  0.018534621223807335
p mean is: tensor(-0.4649, device='cuda:4')
epoch:  41000 quantization_loss:  0.018514784052968025
p mean is: tensor(-0.4672, device='cuda:4')
epoch:  42000 quantization_loss:  0.018510926514863968
p mean is: tensor(-0.4693, device='cuda:4')
epoch:  43000 quantization_loss:  0.01850535348057747
p mean is: tensor(-0.4712, device='cuda:4')
epoch:  44000 quantization_loss:  0.018492432311177254
p mean is: tensor(-0.4729, device='cuda:4')
epoch:  45000 quantization_loss:  0.018475588411092758
p mean is: tensor(-0.4744, device='cuda:4')
epoch:  46000 quantization_loss:  0.01846366561949253
p mean is: tensor(-0.4759, device='cuda:4')
epoch:  47000 quantization_loss:  0.0184524804353714
p mean is: tensor(-0.4773, device='cuda:4')
epoch:  48000 quantization_loss:  0.018442759290337563
p mean is: tensor(-0.4786, device='cuda:4')
epoch:  49000 quantization_loss:  0.01843738555908203
p mean is: tensor(-0.4798, device='cuda:4')
epoch:  50000 quantization_loss:  0.018429098650813103
p mean is: tensor(-0.4809, device='cuda:4')
epoch:  51000 quantization_loss:  0.018433703109622
p mean is: tensor(-0.4819, device='cuda:4')
epoch:  52000 quantization_loss:  0.018415795639157295
p mean is: tensor(-0.4828, device='cuda:4')
epoch:  53000 quantization_loss:  0.018411220982670784
p mean is: tensor(-0.4838, device='cuda:4')
epoch:  54000 quantization_loss:  0.01841278187930584
p mean is: tensor(-0.4847, device='cuda:4')
epoch:  55000 quantization_loss:  0.018403809517621994
p mean is: tensor(-0.4856, device='cuda:4')
epoch:  56000 quantization_loss:  0.018400633707642555
p mean is: tensor(-0.4864, device='cuda:4')
epoch:  57000 quantization_loss:  0.018391842022538185
p mean is: tensor(-0.4871, device='cuda:4')
epoch:  58000 quantization_loss:  0.018385307863354683
p mean is: tensor(-0.4879, device='cuda:4')
epoch:  59000 quantization_loss:  0.018398011103272438
p mean is: tensor(-0.4886, device='cuda:4')
epoch:  60000 quantization_loss:  0.018382856622338295
p mean is: tensor(-0.4892, device='cuda:4')
epoch:  61000 quantization_loss:  0.018376320600509644
p mean is: tensor(-0.4898, device='cuda:4')
epoch:  62000 quantization_loss:  0.018380744382739067
p mean is: tensor(-0.4904, device='cuda:4')
epoch:  63000 quantization_loss:  0.018376771360635757
p mean is: tensor(-0.4910, device='cuda:4')
epoch:  64000 quantization_loss:  0.018366387113928795
p mean is: tensor(-0.4915, device='cuda:4')
epoch:  65000 quantization_loss:  0.018371349200606346
p mean is: tensor(-0.4921, device='cuda:4')
epoch:  66000 quantization_loss:  0.018359143286943436
p mean is: tensor(-0.4927, device='cuda:4')
epoch:  67000 quantization_loss:  0.018358873203396797
p mean is: tensor(-0.4932, device='cuda:4')
epoch:  68000 quantization_loss:  0.01836632564663887
p mean is: tensor(-0.4937, device='cuda:4')
epoch:  69000 quantization_loss:  0.018361901864409447
p mean is: tensor(-0.4941, device='cuda:4')
epoch:  70000 quantization_loss:  0.01835276186466217
p mean is: tensor(-0.4945, device='cuda:4')
epoch:  71000 quantization_loss:  0.01836264505982399
p mean is: tensor(-0.4950, device='cuda:4')
epoch:  72000 quantization_loss:  0.01834796741604805
p mean is: tensor(-0.4954, device='cuda:4')
epoch:  73000 quantization_loss:  0.018347280099987984
p mean is: tensor(-0.4958, device='cuda:4')
epoch:  74000 quantization_loss:  0.01835000142455101
p mean is: tensor(-0.4963, device='cuda:4')
epoch:  75000 quantization_loss:  0.018341660499572754
p mean is: tensor(-0.4967, device='cuda:4')
epoch:  76000 quantization_loss:  0.01834212802350521
p mean is: tensor(-0.4970, device='cuda:4')
epoch:  77000 quantization_loss:  0.01836795173585415
p mean is: tensor(-0.4974, device='cuda:4')
epoch:  78000 quantization_loss:  0.018340498208999634
p mean is: tensor(-0.4977, device='cuda:4')
epoch:  79000 quantization_loss:  0.018340623006224632
p mean is: tensor(-0.4981, device='cuda:4')
1.1.1.weight         | nonzeros =    1446 /   12800             ( 11.30%) | total_pruned =   11354 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     256 /    6400             (  4.00%) | total_pruned =    6144 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     278 /   12800             (  2.17%) | total_pruned =   12522 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      13 /      32             ( 40.62%) | total_pruned =      19 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     346 /   25600             (  1.35%) | total_pruned =   25254 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      10 /      32             ( 31.25%) | total_pruned =      22 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     498 /   51200             (  0.97%) | total_pruned =   50702 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     857 /  102400             (  0.84%) | total_pruned =  101543 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     962 /  204800             (  0.47%) | total_pruned =  203838 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =    2210 /  409600             (  0.54%) | total_pruned =  407390 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    3792 /  409600             (  0.93%) | total_pruned =  405808 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    9947 /  409600             (  2.43%) | total_pruned =  399653 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   24695 /  409600             (  6.03%) | total_pruned =  384905 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   46241 /  409600             ( 11.29%) | total_pruned =  363359 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   30320 /  147456             ( 20.56%) | total_pruned =  117136 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   28242 /  147456             ( 19.15%) | total_pruned =  119214 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   27178 /  147456             ( 18.43%) | total_pruned =  120278 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   15550 /   73728             ( 21.09%) | total_pruned =   58178 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    4522 /   18432             ( 24.53%) | total_pruned =   13910 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1484 /    4608             ( 32.20%) | total_pruned =    3124 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      25 /      48             ( 52.08%) | total_pruned =      23 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 200228, pruned : 2808639, total: 3008867, Compression rate :      15.03x  ( 93.35% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  20.150624489241657
Experiment done
