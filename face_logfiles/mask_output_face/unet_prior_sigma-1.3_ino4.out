(3, 512, 512)
4
Noisy PSNR is '20.219804547068335'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/face/mask/4/unet/det/-1.3/1e-09
epoch:  0 quantization_loss:  0.07483940571546555
p mean is: tensor(-0.0002, device='cuda:2')
epoch:  1000 quantization_loss:  0.0708722472190857
p mean is: tensor(-0.0077, device='cuda:2')
epoch:  2000 quantization_loss:  0.07160567492246628
p mean is: tensor(-0.0133, device='cuda:2')
epoch:  3000 quantization_loss:  0.07116691768169403
p mean is: tensor(-0.0190, device='cuda:2')
epoch:  4000 quantization_loss:  0.07198750227689743
p mean is: tensor(-0.0248, device='cuda:2')
epoch:  5000 quantization_loss:  0.0705680325627327
p mean is: tensor(-0.0313, device='cuda:2')
epoch:  6000 quantization_loss:  0.07085374742746353
p mean is: tensor(-0.0379, device='cuda:2')
epoch:  7000 quantization_loss:  0.06576072424650192
p mean is: tensor(-0.0452, device='cuda:2')
epoch:  8000 quantization_loss:  0.05556032061576843
p mean is: tensor(-0.0519, device='cuda:2')
epoch:  9000 quantization_loss:  0.032095231115818024
p mean is: tensor(-0.0597, device='cuda:2')
epoch:  10000 quantization_loss:  0.028822174295783043
p mean is: tensor(-0.0695, device='cuda:2')
epoch:  11000 quantization_loss:  0.02230437658727169
p mean is: tensor(-0.0830, device='cuda:2')
epoch:  12000 quantization_loss:  0.01995338685810566
p mean is: tensor(-0.1013, device='cuda:2')
epoch:  13000 quantization_loss:  0.01864573173224926
p mean is: tensor(-0.1259, device='cuda:2')
epoch:  14000 quantization_loss:  0.018123509362339973
p mean is: tensor(-0.1578, device='cuda:2')
epoch:  15000 quantization_loss:  0.017079468816518784
p mean is: tensor(-0.1984, device='cuda:2')
epoch:  16000 quantization_loss:  0.016674218699336052
p mean is: tensor(-0.2481, device='cuda:2')
epoch:  17000 quantization_loss:  0.01633169688284397
p mean is: tensor(-0.3065, device='cuda:2')
epoch:  18000 quantization_loss:  0.017443878576159477
p mean is: tensor(-0.3720, device='cuda:2')
epoch:  19000 quantization_loss:  0.015809647738933563
p mean is: tensor(-0.4419, device='cuda:2')
epoch:  20000 quantization_loss:  0.015429682098329067
p mean is: tensor(-0.5133, device='cuda:2')
epoch:  21000 quantization_loss:  0.015158070251345634
p mean is: tensor(-0.5835, device='cuda:2')
epoch:  22000 quantization_loss:  0.015100639313459396
p mean is: tensor(-0.6503, device='cuda:2')
epoch:  23000 quantization_loss:  0.014978713355958462
p mean is: tensor(-0.7124, device='cuda:2')
epoch:  24000 quantization_loss:  0.014804462902247906
p mean is: tensor(-0.7692, device='cuda:2')
epoch:  25000 quantization_loss:  0.014777791686356068
p mean is: tensor(-0.8208, device='cuda:2')
epoch:  26000 quantization_loss:  0.014615729451179504
p mean is: tensor(-0.8670, device='cuda:2')
epoch:  27000 quantization_loss:  0.014567752368748188
p mean is: tensor(-0.9083, device='cuda:2')
epoch:  28000 quantization_loss:  0.014506197534501553
p mean is: tensor(-0.9451, device='cuda:2')
epoch:  29000 quantization_loss:  0.014522173441946507
p mean is: tensor(-0.9780, device='cuda:2')
epoch:  30000 quantization_loss:  0.014422893524169922
p mean is: tensor(-1.0074, device='cuda:2')
epoch:  31000 quantization_loss:  0.014394848607480526
p mean is: tensor(-1.0336, device='cuda:2')
epoch:  32000 quantization_loss:  0.01436682604253292
p mean is: tensor(-1.0570, device='cuda:2')
epoch:  33000 quantization_loss:  0.014334194362163544
p mean is: tensor(-1.0778, device='cuda:2')
epoch:  34000 quantization_loss:  0.01426389068365097
p mean is: tensor(-1.0964, device='cuda:2')
epoch:  35000 quantization_loss:  0.014243973419070244
p mean is: tensor(-1.1131, device='cuda:2')
epoch:  36000 quantization_loss:  0.014212720096111298
p mean is: tensor(-1.1281, device='cuda:2')
epoch:  37000 quantization_loss:  0.014234268106520176
p mean is: tensor(-1.1416, device='cuda:2')
epoch:  38000 quantization_loss:  0.014196479693055153
p mean is: tensor(-1.1539, device='cuda:2')
epoch:  39000 quantization_loss:  0.014473152346909046
p mean is: tensor(-1.1648, device='cuda:2')
epoch:  40000 quantization_loss:  0.014123326167464256
p mean is: tensor(-1.1748, device='cuda:2')
epoch:  41000 quantization_loss:  0.01413397490978241
p mean is: tensor(-1.1838, device='cuda:2')
epoch:  42000 quantization_loss:  0.014124155044555664
p mean is: tensor(-1.1920, device='cuda:2')
epoch:  43000 quantization_loss:  0.014088159427046776
p mean is: tensor(-1.1995, device='cuda:2')
epoch:  44000 quantization_loss:  0.014090538024902344
p mean is: tensor(-1.2063, device='cuda:2')
epoch:  45000 quantization_loss:  0.014088899828493595
p mean is: tensor(-1.2126, device='cuda:2')
epoch:  46000 quantization_loss:  0.014065166935324669
p mean is: tensor(-1.2183, device='cuda:2')
epoch:  47000 quantization_loss:  0.014060410670936108
p mean is: tensor(-1.2236, device='cuda:2')
epoch:  48000 quantization_loss:  0.014035805128514767
p mean is: tensor(-1.2284, device='cuda:2')
epoch:  49000 quantization_loss:  0.01403447613120079
p mean is: tensor(-1.2329, device='cuda:2')
epoch:  50000 quantization_loss:  0.014032181352376938
p mean is: tensor(-1.2372, device='cuda:2')
epoch:  51000 quantization_loss:  0.014006497338414192
p mean is: tensor(-1.2410, device='cuda:2')
epoch:  52000 quantization_loss:  0.014013724401593208
p mean is: tensor(-1.2447, device='cuda:2')
epoch:  53000 quantization_loss:  0.013998735696077347
p mean is: tensor(-1.2480, device='cuda:2')
epoch:  54000 quantization_loss:  0.014001776464283466
p mean is: tensor(-1.2511, device='cuda:2')
epoch:  55000 quantization_loss:  0.013979047536849976
p mean is: tensor(-1.2541, device='cuda:2')
epoch:  56000 quantization_loss:  0.013984126038849354
p mean is: tensor(-1.2569, device='cuda:2')
epoch:  57000 quantization_loss:  0.013979941606521606
p mean is: tensor(-1.2595, device='cuda:2')
epoch:  58000 quantization_loss:  0.013994408771395683
p mean is: tensor(-1.2620, device='cuda:2')
epoch:  59000 quantization_loss:  0.013963685370981693
p mean is: tensor(-1.2643, device='cuda:2')
epoch:  60000 quantization_loss:  0.013952493667602539
p mean is: tensor(-1.2666, device='cuda:2')
epoch:  61000 quantization_loss:  0.013953907415270805
p mean is: tensor(-1.2687, device='cuda:2')
epoch:  62000 quantization_loss:  0.013982545584440231
p mean is: tensor(-1.2707, device='cuda:2')
epoch:  63000 quantization_loss:  0.013945311307907104
p mean is: tensor(-1.2726, device='cuda:2')
epoch:  64000 quantization_loss:  0.013942941091954708
p mean is: tensor(-1.2744, device='cuda:2')
epoch:  65000 quantization_loss:  0.013933329842984676
p mean is: tensor(-1.2761, device='cuda:2')
epoch:  66000 quantization_loss:  0.013948659412562847
p mean is: tensor(-1.2776, device='cuda:2')
epoch:  67000 quantization_loss:  0.013937713578343391
p mean is: tensor(-1.2793, device='cuda:2')
epoch:  68000 quantization_loss:  0.013924721628427505
p mean is: tensor(-1.2808, device='cuda:2')
epoch:  69000 quantization_loss:  0.013926105573773384
p mean is: tensor(-1.2822, device='cuda:2')
epoch:  70000 quantization_loss:  0.013922473415732384
p mean is: tensor(-1.2836, device='cuda:2')
epoch:  71000 quantization_loss:  0.01392029132694006
p mean is: tensor(-1.2849, device='cuda:2')
epoch:  72000 quantization_loss:  0.013919263146817684
p mean is: tensor(-1.2862, device='cuda:2')
epoch:  73000 quantization_loss:  0.013921028934419155
p mean is: tensor(-1.2875, device='cuda:2')
epoch:  74000 quantization_loss:  0.013912689872086048
p mean is: tensor(-1.2886, device='cuda:2')
epoch:  75000 quantization_loss:  0.013916727155447006
p mean is: tensor(-1.2898, device='cuda:2')
epoch:  76000 quantization_loss:  0.013910843059420586
p mean is: tensor(-1.2908, device='cuda:2')
epoch:  77000 quantization_loss:  0.013917261734604836
p mean is: tensor(-1.2919, device='cuda:2')
epoch:  78000 quantization_loss:  0.013907000422477722
p mean is: tensor(-1.2930, device='cuda:2')
epoch:  79000 quantization_loss:  0.013904553838074207
p mean is: tensor(-1.2940, device='cuda:2')
1.1.1.weight         | nonzeros =     718 /   12800             (  5.61%) | total_pruned =   12082 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =      95 /    6400             (  1.48%) | total_pruned =    6305 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      31 /   12800             (  0.24%) | total_pruned =   12769 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      13 /      32             ( 40.62%) | total_pruned =      19 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =      44 /   25600             (  0.17%) | total_pruned =   25556 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      10 /      32             ( 31.25%) | total_pruned =      22 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =      17 /   51200             (  0.03%) | total_pruned =   51183 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =      31 /  102400             (  0.03%) | total_pruned =  102369 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =       1 /  204800             (  0.00%) | total_pruned =  204799 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =      20 /  409600             (  0.00%) | total_pruned =  409580 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =      40 /  409600             (  0.01%) | total_pruned =  409560 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    1198 /  409600             (  0.29%) | total_pruned =  408402 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    3854 /  409600             (  0.94%) | total_pruned =  405746 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   17866 /  409600             (  4.36%) | total_pruned =  391734 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   23095 /  147456             ( 15.66%) | total_pruned =  124361 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   28563 /  147456             ( 19.37%) | total_pruned =  118893 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   23095 /  147456             ( 15.66%) | total_pruned =  124361 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    8658 /   73728             ( 11.74%) | total_pruned =   65070 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    1987 /   18432             ( 10.78%) | total_pruned =   16445 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =     981 /    4608             ( 21.29%) | total_pruned =    3627 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      31 /      48             ( 64.58%) | total_pruned =      17 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 111612, pruned : 2897255, total: 3008867, Compression rate :      26.96x  ( 96.29% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  19.542799129713465
Experiment done
