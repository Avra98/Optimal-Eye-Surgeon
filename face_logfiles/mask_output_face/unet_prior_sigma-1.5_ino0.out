(3, 512, 512)
0
Noisy PSNR is '21.126893863088185'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/face/mask/0/unet/det/-1.5/1e-09
epoch:  0 quantization_loss:  0.15222613513469696
p mean is: tensor(-0.0003, device='cuda:0')
epoch:  1000 quantization_loss:  0.10671139508485794
p mean is: tensor(-0.0081, device='cuda:0')
epoch:  2000 quantization_loss:  0.10628458112478256
p mean is: tensor(-0.0137, device='cuda:0')
epoch:  3000 quantization_loss:  0.10061299055814743
p mean is: tensor(-0.0191, device='cuda:0')
epoch:  4000 quantization_loss:  0.10637106001377106
p mean is: tensor(-0.0247, device='cuda:0')
epoch:  5000 quantization_loss:  0.08347702771425247
p mean is: tensor(-0.0307, device='cuda:0')
epoch:  6000 quantization_loss:  0.08044973015785217
p mean is: tensor(-0.0373, device='cuda:0')
epoch:  7000 quantization_loss:  0.08018186688423157
p mean is: tensor(-0.0462, device='cuda:0')
epoch:  8000 quantization_loss:  0.07828741520643234
p mean is: tensor(-0.0589, device='cuda:0')
epoch:  9000 quantization_loss:  0.07791873812675476
p mean is: tensor(-0.0764, device='cuda:0')
epoch:  10000 quantization_loss:  0.07766526192426682
p mean is: tensor(-0.1005, device='cuda:0')
epoch:  11000 quantization_loss:  0.07441713660955429
p mean is: tensor(-0.1326, device='cuda:0')
epoch:  12000 quantization_loss:  0.07374511659145355
p mean is: tensor(-0.1737, device='cuda:0')
epoch:  13000 quantization_loss:  0.07381922751665115
p mean is: tensor(-0.2248, device='cuda:0')
epoch:  14000 quantization_loss:  0.07014131546020508
p mean is: tensor(-0.2856, device='cuda:0')
epoch:  15000 quantization_loss:  0.06984718143939972
p mean is: tensor(-0.3538, device='cuda:0')
epoch:  16000 quantization_loss:  0.07230272889137268
p mean is: tensor(-0.4286, device='cuda:0')
epoch:  17000 quantization_loss:  0.0689297541975975
p mean is: tensor(-0.5079, device='cuda:0')
epoch:  18000 quantization_loss:  0.06870786100625992
p mean is: tensor(-0.5890, device='cuda:0')
epoch:  19000 quantization_loss:  0.06861282140016556
p mean is: tensor(-0.6694, device='cuda:0')
epoch:  20000 quantization_loss:  0.06848631054162979
p mean is: tensor(-0.7467, device='cuda:0')
epoch:  21000 quantization_loss:  0.0682656317949295
p mean is: tensor(-0.8188, device='cuda:0')
epoch:  22000 quantization_loss:  0.06799336522817612
p mean is: tensor(-0.8853, device='cuda:0')
epoch:  23000 quantization_loss:  0.06798925995826721
p mean is: tensor(-0.9458, device='cuda:0')
epoch:  24000 quantization_loss:  0.06790967285633087
p mean is: tensor(-1.0003, device='cuda:0')
epoch:  25000 quantization_loss:  0.06706179678440094
p mean is: tensor(-1.0490, device='cuda:0')
epoch:  26000 quantization_loss:  0.06678150594234467
p mean is: tensor(-1.0912, device='cuda:0')
epoch:  27000 quantization_loss:  0.0667155459523201
p mean is: tensor(-1.1292, device='cuda:0')
epoch:  28000 quantization_loss:  0.06664585322141647
p mean is: tensor(-1.1636, device='cuda:0')
epoch:  29000 quantization_loss:  0.06657037883996964
p mean is: tensor(-1.1949, device='cuda:0')
epoch:  30000 quantization_loss:  0.06662032008171082
p mean is: tensor(-1.2234, device='cuda:0')
epoch:  31000 quantization_loss:  0.07553596794605255
p mean is: tensor(-1.2491, device='cuda:0')
epoch:  32000 quantization_loss:  0.06639096140861511
p mean is: tensor(-1.2723, device='cuda:0')
epoch:  33000 quantization_loss:  0.06638824194669724
p mean is: tensor(-1.2933, device='cuda:0')
epoch:  34000 quantization_loss:  0.06631489098072052
p mean is: tensor(-1.3123, device='cuda:0')
epoch:  35000 quantization_loss:  0.06628172844648361
p mean is: tensor(-1.3295, device='cuda:0')
epoch:  36000 quantization_loss:  0.06626034528017044
p mean is: tensor(-1.3450, device='cuda:0')
epoch:  37000 quantization_loss:  0.06623600423336029
p mean is: tensor(-1.3590, device='cuda:0')
epoch:  38000 quantization_loss:  0.0661984458565712
p mean is: tensor(-1.3716, device='cuda:0')
epoch:  39000 quantization_loss:  0.06622917205095291
p mean is: tensor(-1.3831, device='cuda:0')
epoch:  40000 quantization_loss:  0.06670284271240234
p mean is: tensor(-1.3936, device='cuda:0')
epoch:  41000 quantization_loss:  0.06617584079504013
p mean is: tensor(-1.4031, device='cuda:0')
epoch:  42000 quantization_loss:  0.06613755971193314
p mean is: tensor(-1.4118, device='cuda:0')
epoch:  43000 quantization_loss:  0.06612547487020493
p mean is: tensor(-1.4197, device='cuda:0')
epoch:  44000 quantization_loss:  0.06610387563705444
p mean is: tensor(-1.4270, device='cuda:0')
epoch:  45000 quantization_loss:  0.06609383225440979
p mean is: tensor(-1.4336, device='cuda:0')
epoch:  46000 quantization_loss:  0.06608258187770844
p mean is: tensor(-1.4396, device='cuda:0')
epoch:  47000 quantization_loss:  0.06610729545354843
p mean is: tensor(-1.4452, device='cuda:0')
epoch:  48000 quantization_loss:  0.06608143448829651
p mean is: tensor(-1.4503, device='cuda:0')
epoch:  49000 quantization_loss:  0.06608045101165771
p mean is: tensor(-1.4550, device='cuda:0')
epoch:  50000 quantization_loss:  0.06604219973087311
p mean is: tensor(-1.4594, device='cuda:0')
epoch:  51000 quantization_loss:  0.06605099141597748
p mean is: tensor(-1.4634, device='cuda:0')
epoch:  52000 quantization_loss:  0.06606953591108322
p mean is: tensor(-1.4672, device='cuda:0')
epoch:  53000 quantization_loss:  0.06601574271917343
p mean is: tensor(-1.4707, device='cuda:0')
epoch:  54000 quantization_loss:  0.06601614505052567
p mean is: tensor(-1.4740, device='cuda:0')
epoch:  55000 quantization_loss:  0.06599269807338715
p mean is: tensor(-1.4770, device='cuda:0')
epoch:  56000 quantization_loss:  0.06603623926639557
p mean is: tensor(-1.4798, device='cuda:0')
epoch:  57000 quantization_loss:  0.06598269939422607
p mean is: tensor(-1.4824, device='cuda:0')
epoch:  58000 quantization_loss:  0.06597649306058884
p mean is: tensor(-1.4849, device='cuda:0')
epoch:  59000 quantization_loss:  0.06598170101642609
p mean is: tensor(-1.4872, device='cuda:0')
epoch:  60000 quantization_loss:  0.06596941500902176
p mean is: tensor(-1.4893, device='cuda:0')
epoch:  61000 quantization_loss:  0.06597248464822769
p mean is: tensor(-1.4913, device='cuda:0')
epoch:  62000 quantization_loss:  0.06597018986940384
p mean is: tensor(-1.4932, device='cuda:0')
epoch:  63000 quantization_loss:  0.06598930060863495
p mean is: tensor(-1.4950, device='cuda:0')
epoch:  64000 quantization_loss:  0.06595107167959213
p mean is: tensor(-1.4968, device='cuda:0')
epoch:  65000 quantization_loss:  0.0659460499882698
p mean is: tensor(-1.4985, device='cuda:0')
epoch:  66000 quantization_loss:  0.065948985517025
p mean is: tensor(-1.5000, device='cuda:0')
epoch:  67000 quantization_loss:  0.06594808399677277
p mean is: tensor(-1.5014, device='cuda:0')
epoch:  68000 quantization_loss:  0.06594942510128021
p mean is: tensor(-1.5029, device='cuda:0')
epoch:  69000 quantization_loss:  0.06593833118677139
p mean is: tensor(-1.5042, device='cuda:0')
epoch:  70000 quantization_loss:  0.06593117862939835
p mean is: tensor(-1.5055, device='cuda:0')
epoch:  71000 quantization_loss:  0.06593160331249237
p mean is: tensor(-1.5069, device='cuda:0')
epoch:  72000 quantization_loss:  0.06596573442220688
p mean is: tensor(-1.5080, device='cuda:0')
epoch:  73000 quantization_loss:  0.06592255085706711
p mean is: tensor(-1.5091, device='cuda:0')
epoch:  74000 quantization_loss:  0.06592877209186554
p mean is: tensor(-1.5102, device='cuda:0')
epoch:  75000 quantization_loss:  0.06592396646738052
p mean is: tensor(-1.5112, device='cuda:0')
epoch:  76000 quantization_loss:  0.06592263281345367
p mean is: tensor(-1.5122, device='cuda:0')
epoch:  77000 quantization_loss:  0.06591933220624924
p mean is: tensor(-1.5132, device='cuda:0')
epoch:  78000 quantization_loss:  0.06591499596834183
p mean is: tensor(-1.5142, device='cuda:0')
epoch:  79000 quantization_loss:  0.06594554334878922
p mean is: tensor(-1.5150, device='cuda:0')
1.1.1.weight         | nonzeros =     821 /   12800             (  6.41%) | total_pruned =   11979 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     104 /    6400             (  1.62%) | total_pruned =    6296 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      55 /   12800             (  0.43%) | total_pruned =   12745 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =      58 /   25600             (  0.23%) | total_pruned =   25542 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =      29 /   51200             (  0.06%) | total_pruned =   51171 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =      42 /  102400             (  0.04%) | total_pruned =  102358 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =       3 /  204800             (  0.00%) | total_pruned =  204797 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =       0 /  409600             (  0.00%) | total_pruned =  409600 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =       0 /  409600             (  0.00%) | total_pruned =  409600 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =     647 /  409600             (  0.16%) | total_pruned =  408953 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    2553 /  409600             (  0.62%) | total_pruned =  407047 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   12552 /  409600             (  3.06%) | total_pruned =  397048 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   17512 /  147456             ( 11.88%) | total_pruned =  129944 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   14748 /  147456             ( 10.00%) | total_pruned =  132708 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =    8230 /  147456             (  5.58%) | total_pruned =  139226 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    4460 /   73728             (  6.05%) | total_pruned =   69268 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2279 /   18432             ( 12.36%) | total_pruned =   16153 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1113 /    4608             ( 24.15%) | total_pruned =    3495 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      15 /      16             ( 93.75%) | total_pruned =       1 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      26 /      48             ( 54.17%) | total_pruned =      22 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       3 /       3             (100.00%) | total_pruned =       0 | shape = torch.Size([3])
alive: 66362, pruned : 2942505, total: 3008867, Compression rate :      45.34x  ( 97.79% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  9.14100656800031
Experiment done
