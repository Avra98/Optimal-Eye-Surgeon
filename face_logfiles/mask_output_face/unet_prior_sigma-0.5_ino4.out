(3, 512, 512)
4
Noisy PSNR is '20.20995321009025'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/face/mask/4/unet/det/-0.5/1e-09
epoch:  0 quantization_loss:  0.0806201919913292
p mean is: tensor(-8.9296e-05, device='cuda:0')
epoch:  1000 quantization_loss:  0.07737410813570023
p mean is: tensor(-0.0034, device='cuda:0')
epoch:  2000 quantization_loss:  0.07752636820077896
p mean is: tensor(-0.0059, device='cuda:0')
epoch:  3000 quantization_loss:  0.0730522945523262
p mean is: tensor(-0.0088, device='cuda:0')
epoch:  4000 quantization_loss:  0.07261469215154648
p mean is: tensor(-0.0119, device='cuda:0')
epoch:  5000 quantization_loss:  0.07301256060600281
p mean is: tensor(-0.0151, device='cuda:0')
epoch:  6000 quantization_loss:  0.07273068279027939
p mean is: tensor(-0.0183, device='cuda:0')
epoch:  7000 quantization_loss:  0.07219953089952469
p mean is: tensor(-0.0222, device='cuda:0')
epoch:  8000 quantization_loss:  0.0693129301071167
p mean is: tensor(-0.0260, device='cuda:0')
epoch:  9000 quantization_loss:  0.0585540235042572
p mean is: tensor(-0.0302, device='cuda:0')
epoch:  10000 quantization_loss:  0.044829387217760086
p mean is: tensor(-0.0349, device='cuda:0')
epoch:  11000 quantization_loss:  0.040824152529239655
p mean is: tensor(-0.0409, device='cuda:0')
epoch:  12000 quantization_loss:  0.03262677416205406
p mean is: tensor(-0.0486, device='cuda:0')
epoch:  13000 quantization_loss:  0.030016683042049408
p mean is: tensor(-0.0584, device='cuda:0')
epoch:  14000 quantization_loss:  0.029467985033988953
p mean is: tensor(-0.0711, device='cuda:0')
epoch:  15000 quantization_loss:  0.026890553534030914
p mean is: tensor(-0.0869, device='cuda:0')
epoch:  16000 quantization_loss:  0.02636817842721939
p mean is: tensor(-0.1062, device='cuda:0')
epoch:  17000 quantization_loss:  0.02582545578479767
p mean is: tensor(-0.1289, device='cuda:0')
epoch:  18000 quantization_loss:  0.02701154537498951
p mean is: tensor(-0.1544, device='cuda:0')
epoch:  19000 quantization_loss:  0.025280902162194252
p mean is: tensor(-0.1820, device='cuda:0')
epoch:  20000 quantization_loss:  0.0251625906676054
p mean is: tensor(-0.2107, device='cuda:0')
epoch:  21000 quantization_loss:  0.025082575157284737
p mean is: tensor(-0.2392, device='cuda:0')
epoch:  22000 quantization_loss:  0.024927271530032158
p mean is: tensor(-0.2664, device='cuda:0')
epoch:  23000 quantization_loss:  0.02475796639919281
p mean is: tensor(-0.2918, device='cuda:0')
epoch:  24000 quantization_loss:  0.024872470647096634
p mean is: tensor(-0.3150, device='cuda:0')
epoch:  25000 quantization_loss:  0.024655597284436226
p mean is: tensor(-0.3358, device='cuda:0')
epoch:  26000 quantization_loss:  0.02457902394235134
p mean is: tensor(-0.3543, device='cuda:0')
epoch:  27000 quantization_loss:  0.024447845295071602
p mean is: tensor(-0.3707, device='cuda:0')
epoch:  28000 quantization_loss:  0.02453033998608589
p mean is: tensor(-0.3850, device='cuda:0')
epoch:  29000 quantization_loss:  0.024350449442863464
p mean is: tensor(-0.3974, device='cuda:0')
epoch:  30000 quantization_loss:  0.02439626306295395
p mean is: tensor(-0.4083, device='cuda:0')
epoch:  31000 quantization_loss:  0.0243962574750185
p mean is: tensor(-0.4178, device='cuda:0')
epoch:  32000 quantization_loss:  0.02332071214914322
p mean is: tensor(-0.4261, device='cuda:0')
epoch:  33000 quantization_loss:  0.023339470848441124
p mean is: tensor(-0.4331, device='cuda:0')
epoch:  34000 quantization_loss:  0.023267392069101334
p mean is: tensor(-0.4393, device='cuda:0')
epoch:  35000 quantization_loss:  0.023236282169818878
p mean is: tensor(-0.4448, device='cuda:0')
epoch:  36000 quantization_loss:  0.023093923926353455
p mean is: tensor(-0.4495, device='cuda:0')
epoch:  37000 quantization_loss:  0.023213697597384453
p mean is: tensor(-0.4538, device='cuda:0')
epoch:  38000 quantization_loss:  0.023191070184111595
p mean is: tensor(-0.4575, device='cuda:0')
epoch:  39000 quantization_loss:  0.023146845400333405
p mean is: tensor(-0.4609, device='cuda:0')
epoch:  40000 quantization_loss:  0.023158486932516098
p mean is: tensor(-0.4640, device='cuda:0')
epoch:  41000 quantization_loss:  0.023113951086997986
p mean is: tensor(-0.4667, device='cuda:0')
epoch:  42000 quantization_loss:  0.02311793342232704
p mean is: tensor(-0.4690, device='cuda:0')
epoch:  43000 quantization_loss:  0.023086415603756905
p mean is: tensor(-0.4712, device='cuda:0')
epoch:  44000 quantization_loss:  0.02307778224349022
p mean is: tensor(-0.4731, device='cuda:0')
epoch:  45000 quantization_loss:  0.023084115236997604
p mean is: tensor(-0.4749, device='cuda:0')
epoch:  46000 quantization_loss:  0.02308247797191143
p mean is: tensor(-0.4765, device='cuda:0')
epoch:  47000 quantization_loss:  0.023059317842125893
p mean is: tensor(-0.4780, device='cuda:0')
epoch:  48000 quantization_loss:  0.023046962916851044
p mean is: tensor(-0.4793, device='cuda:0')
epoch:  49000 quantization_loss:  0.023070501163601875
p mean is: tensor(-0.4806, device='cuda:0')
epoch:  50000 quantization_loss:  0.023020239546895027
p mean is: tensor(-0.4818, device='cuda:0')
epoch:  51000 quantization_loss:  0.023026807233691216
p mean is: tensor(-0.4829, device='cuda:0')
epoch:  52000 quantization_loss:  0.023046007379889488
p mean is: tensor(-0.4839, device='cuda:0')
epoch:  53000 quantization_loss:  0.023021114990115166
p mean is: tensor(-0.4849, device='cuda:0')
epoch:  54000 quantization_loss:  0.023015441372990608
p mean is: tensor(-0.4857, device='cuda:0')
epoch:  55000 quantization_loss:  0.02300138771533966
p mean is: tensor(-0.4865, device='cuda:0')
epoch:  56000 quantization_loss:  0.02299634739756584
p mean is: tensor(-0.4873, device='cuda:0')
epoch:  57000 quantization_loss:  0.023009877651929855
p mean is: tensor(-0.4880, device='cuda:0')
epoch:  58000 quantization_loss:  0.02298031933605671
p mean is: tensor(-0.4887, device='cuda:0')
epoch:  59000 quantization_loss:  0.022980615496635437
p mean is: tensor(-0.4894, device='cuda:0')
epoch:  60000 quantization_loss:  0.02297273650765419
p mean is: tensor(-0.4900, device='cuda:0')
epoch:  61000 quantization_loss:  0.022979075089097023
p mean is: tensor(-0.4906, device='cuda:0')
epoch:  62000 quantization_loss:  0.022970419377088547
p mean is: tensor(-0.4911, device='cuda:0')
epoch:  63000 quantization_loss:  0.022958658635616302
p mean is: tensor(-0.4917, device='cuda:0')
epoch:  64000 quantization_loss:  0.02296222746372223
p mean is: tensor(-0.4922, device='cuda:0')
epoch:  65000 quantization_loss:  0.022957611829042435
p mean is: tensor(-0.4927, device='cuda:0')
epoch:  66000 quantization_loss:  0.022957419976592064
p mean is: tensor(-0.4932, device='cuda:0')
epoch:  67000 quantization_loss:  0.022954879328608513
p mean is: tensor(-0.4937, device='cuda:0')
epoch:  68000 quantization_loss:  0.022943904623389244
p mean is: tensor(-0.4942, device='cuda:0')
epoch:  69000 quantization_loss:  0.022945450618863106
p mean is: tensor(-0.4946, device='cuda:0')
epoch:  70000 quantization_loss:  0.02294841594994068
p mean is: tensor(-0.4950, device='cuda:0')
epoch:  71000 quantization_loss:  0.02293919399380684
p mean is: tensor(-0.4954, device='cuda:0')
epoch:  72000 quantization_loss:  0.022941922768950462
p mean is: tensor(-0.4958, device='cuda:0')
epoch:  73000 quantization_loss:  0.022939138114452362
p mean is: tensor(-0.4962, device='cuda:0')
epoch:  74000 quantization_loss:  0.02293238788843155
p mean is: tensor(-0.4965, device='cuda:0')
epoch:  75000 quantization_loss:  0.02292858622968197
p mean is: tensor(-0.4968, device='cuda:0')
epoch:  76000 quantization_loss:  0.02291562408208847
p mean is: tensor(-0.4972, device='cuda:0')
epoch:  77000 quantization_loss:  0.022933589294552803
p mean is: tensor(-0.4976, device='cuda:0')
epoch:  78000 quantization_loss:  0.02294456586241722
p mean is: tensor(-0.4979, device='cuda:0')
epoch:  79000 quantization_loss:  0.022934656590223312
p mean is: tensor(-0.4982, device='cuda:0')
1.1.1.weight         | nonzeros =    1465 /   12800             ( 11.45%) | total_pruned =   11335 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     288 /    6400             (  4.50%) | total_pruned =    6112 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     308 /   12800             (  2.41%) | total_pruned =   12492 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     366 /   25600             (  1.43%) | total_pruned =   25234 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      13 /      32             ( 40.62%) | total_pruned =      19 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     454 /   51200             (  0.89%) | total_pruned =   50746 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     856 /  102400             (  0.84%) | total_pruned =  101544 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     966 /  204800             (  0.47%) | total_pruned =  203834 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =    2108 /  409600             (  0.51%) | total_pruned =  407492 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    3164 /  409600             (  0.77%) | total_pruned =  406436 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    9627 /  409600             (  2.35%) | total_pruned =  399973 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   22316 /  409600             (  5.45%) | total_pruned =  387284 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   45068 /  409600             ( 11.00%) | total_pruned =  364532 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   28388 /  147456             ( 19.25%) | total_pruned =  119068 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   26513 /  147456             ( 17.98%) | total_pruned =  120943 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   22456 /  147456             ( 15.23%) | total_pruned =  125000 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   10030 /   73728             ( 13.60%) | total_pruned =   63698 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2861 /   18432             ( 15.52%) | total_pruned =   15571 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1352 /    4608             ( 29.34%) | total_pruned =    3256 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      34 /      48             ( 70.83%) | total_pruned =      14 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 179939, pruned : 2828928, total: 3008867, Compression rate :      16.72x  ( 94.02% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  18.52110073664591
Experiment done
