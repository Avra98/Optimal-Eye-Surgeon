(3, 512, 512)
Noisy PSNR is '20.22915861231354'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/face/mask/4/unet/det/0.03/1e-09
epoch:  0 quantization_loss:  0.07845161110162735
p mean is: tensor(-0.0006, device='cuda:1')
epoch:  1000 quantization_loss:  0.07753892987966537
p mean is: tensor(-0.0171, device='cuda:1')
epoch:  2000 quantization_loss:  0.07797396183013916
p mean is: tensor(-0.0284, device='cuda:1')
epoch:  3000 quantization_loss:  0.07448427379131317
p mean is: tensor(-0.0395, device='cuda:1')
epoch:  4000 quantization_loss:  0.07236652076244354
p mean is: tensor(-0.0506, device='cuda:1')
epoch:  5000 quantization_loss:  0.07469277828931808
p mean is: tensor(-0.0621, device='cuda:1')
epoch:  6000 quantization_loss:  0.06826979666948318
p mean is: tensor(-0.0737, device='cuda:1')
epoch:  7000 quantization_loss:  0.05897868424654007
p mean is: tensor(-0.0858, device='cuda:1')
epoch:  8000 quantization_loss:  0.04388873279094696
p mean is: tensor(-0.1001, device='cuda:1')
epoch:  9000 quantization_loss:  0.030746566131711006
p mean is: tensor(-0.1178, device='cuda:1')
epoch:  10000 quantization_loss:  0.02689429000020027
p mean is: tensor(-0.1418, device='cuda:1')
epoch:  11000 quantization_loss:  0.02546815387904644
p mean is: tensor(-0.1750, device='cuda:1')
epoch:  12000 quantization_loss:  0.024413902312517166
p mean is: tensor(-0.2205, device='cuda:1')
epoch:  13000 quantization_loss:  0.023517709225416183
p mean is: tensor(-0.2818, device='cuda:1')
epoch:  14000 quantization_loss:  0.021879123523831367
p mean is: tensor(-0.3614, device='cuda:1')
epoch:  15000 quantization_loss:  0.020790286362171173
p mean is: tensor(-0.4617, device='cuda:1')
epoch:  16000 quantization_loss:  0.019849512726068497
p mean is: tensor(-0.5833, device='cuda:1')
epoch:  17000 quantization_loss:  0.01894562691450119
p mean is: tensor(-0.7235, device='cuda:1')
epoch:  18000 quantization_loss:  0.018445724621415138
p mean is: tensor(-0.8759, device='cuda:1')
epoch:  19000 quantization_loss:  0.017970070242881775
p mean is: tensor(-1.0329, device='cuda:1')
epoch:  20000 quantization_loss:  0.017839794978499413
p mean is: tensor(-1.1874, device='cuda:1')
epoch:  21000 quantization_loss:  0.017337201163172722
p mean is: tensor(-1.3343, device='cuda:1')
epoch:  22000 quantization_loss:  0.01701585203409195
p mean is: tensor(-1.4705, device='cuda:1')
epoch:  23000 quantization_loss:  0.01679639331996441
p mean is: tensor(-1.5950, device='cuda:1')
epoch:  24000 quantization_loss:  0.01662803441286087
p mean is: tensor(-1.7079, device='cuda:1')
epoch:  25000 quantization_loss:  0.016453681513667107
p mean is: tensor(-1.8105, device='cuda:1')
epoch:  26000 quantization_loss:  0.016371043398976326
p mean is: tensor(-1.9036, device='cuda:1')
epoch:  27000 quantization_loss:  0.016264760866761208
p mean is: tensor(-1.9884, device='cuda:1')
epoch:  28000 quantization_loss:  0.016178883612155914
p mean is: tensor(-2.0660, device='cuda:1')
epoch:  29000 quantization_loss:  0.01607287861406803
p mean is: tensor(-2.1371, device='cuda:1')
epoch:  30000 quantization_loss:  0.015979524701833725
p mean is: tensor(-2.2026, device='cuda:1')
epoch:  31000 quantization_loss:  0.015940817072987556
p mean is: tensor(-2.2629, device='cuda:1')
epoch:  32000 quantization_loss:  0.01582505740225315
p mean is: tensor(-2.3188, device='cuda:1')
epoch:  33000 quantization_loss:  0.015862833708524704
p mean is: tensor(-2.3707, device='cuda:1')
epoch:  34000 quantization_loss:  0.0157522764056921
p mean is: tensor(-2.4190, device='cuda:1')
epoch:  35000 quantization_loss:  0.015705913305282593
p mean is: tensor(-2.4642, device='cuda:1')
epoch:  36000 quantization_loss:  0.01569327339529991
p mean is: tensor(-2.5065, device='cuda:1')
epoch:  37000 quantization_loss:  0.015654657036066055
p mean is: tensor(-2.5462, device='cuda:1')
epoch:  38000 quantization_loss:  0.015625668689608574
p mean is: tensor(-2.5835, device='cuda:1')
epoch:  39000 quantization_loss:  0.015593701042234898
p mean is: tensor(-2.6188, device='cuda:1')
epoch:  40000 quantization_loss:  0.015593359246850014
p mean is: tensor(-2.6520, device='cuda:1')
epoch:  41000 quantization_loss:  0.015560733154416084
p mean is: tensor(-2.6835, device='cuda:1')
epoch:  42000 quantization_loss:  0.015522168017923832
p mean is: tensor(-2.7133, device='cuda:1')
epoch:  43000 quantization_loss:  0.01548993494361639
p mean is: tensor(-2.7416, device='cuda:1')
epoch:  44000 quantization_loss:  0.01547885313630104
p mean is: tensor(-2.7685, device='cuda:1')
epoch:  45000 quantization_loss:  0.015446373261511326
p mean is: tensor(-2.7941, device='cuda:1')
epoch:  46000 quantization_loss:  0.015444881282746792
p mean is: tensor(-2.8184, device='cuda:1')
epoch:  47000 quantization_loss:  0.015439571812748909
p mean is: tensor(-2.8417, device='cuda:1')
epoch:  48000 quantization_loss:  0.015424394980072975
p mean is: tensor(-2.8640, device='cuda:1')
epoch:  49000 quantization_loss:  0.015406874939799309
p mean is: tensor(-2.8852, device='cuda:1')
epoch:  50000 quantization_loss:  0.015379265882074833
p mean is: tensor(-2.9056, device='cuda:1')
epoch:  51000 quantization_loss:  0.01538714300841093
p mean is: tensor(-2.9251, device='cuda:1')
epoch:  52000 quantization_loss:  0.015754472464323044
p mean is: tensor(-2.9437, device='cuda:1')
epoch:  53000 quantization_loss:  0.015344547107815742
p mean is: tensor(-2.9617, device='cuda:1')
epoch:  54000 quantization_loss:  0.015341083519160748
p mean is: tensor(-2.9789, device='cuda:1')
epoch:  55000 quantization_loss:  0.015338977798819542
p mean is: tensor(-2.9954, device='cuda:1')
epoch:  56000 quantization_loss:  0.015323991887271404
p mean is: tensor(-3.0113, device='cuda:1')
epoch:  57000 quantization_loss:  0.015316138043999672
p mean is: tensor(-3.0266, device='cuda:1')
epoch:  58000 quantization_loss:  0.015320870094001293
p mean is: tensor(-3.0413, device='cuda:1')
epoch:  59000 quantization_loss:  0.015300468541681767
p mean is: tensor(-3.0555, device='cuda:1')
Number of elements to keep: 90266
Threshold value: -0.7488483190536499
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.029999996676489855
Number of elements to keep: 90266
Threshold value: -0.7488483190536499
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.029999996676489855
1.1.1.weight         | nonzeros =     873 /   12800             (  6.82%) | total_pruned =   11927 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     102 /    6400             (  1.59%) | total_pruned =    6298 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      45 /   12800             (  0.35%) | total_pruned =   12755 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =      85 /   25600             (  0.33%) | total_pruned =   25515 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      13 /      32             ( 40.62%) | total_pruned =      19 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =      70 /   51200             (  0.14%) | total_pruned =   51130 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     145 /  102400             (  0.14%) | total_pruned =  102255 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =      76 /  204800             (  0.04%) | total_pruned =  204724 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     144 /  409600             (  0.04%) | total_pruned =  409456 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     167 /  409600             (  0.04%) | total_pruned =  409433 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    1245 /  409600             (  0.30%) | total_pruned =  408355 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    3710 /  409600             (  0.91%) | total_pruned =  405890 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   13165 /  409600             (  3.21%) | total_pruned =  396435 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   19915 /  147456             ( 13.51%) | total_pruned =  127541 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   19489 /  147456             ( 13.22%) | total_pruned =  127967 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   16199 /  147456             ( 10.99%) | total_pruned =  131257 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    9549 /   73728             ( 12.95%) | total_pruned =   64179 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2837 /   18432             ( 15.39%) | total_pruned =   15595 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1113 /    4608             ( 24.15%) | total_pruned =    3495 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      38 /      48             ( 79.17%) | total_pruned =      10 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 90266, pruned : 2918601, total: 3008867, Compression rate :      33.33x  ( 97.00% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  22.08396080745876
Experiment done
