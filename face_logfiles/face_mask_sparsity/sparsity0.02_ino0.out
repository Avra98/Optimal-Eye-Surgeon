(3, 512, 512)
Noisy PSNR is '21.120236574940677'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/face/mask/0/unet/det/0.02/1e-09
epoch:  0 quantization_loss:  0.1758866012096405
p mean is: tensor(-0.0006, device='cuda:2')
epoch:  1000 quantization_loss:  0.12276338040828705
p mean is: tensor(-0.0210, device='cuda:2')
epoch:  2000 quantization_loss:  0.11436258256435394
p mean is: tensor(-0.0343, device='cuda:2')
epoch:  3000 quantization_loss:  0.11059936136007309
p mean is: tensor(-0.0466, device='cuda:2')
epoch:  4000 quantization_loss:  0.10350129008293152
p mean is: tensor(-0.0588, device='cuda:2')
epoch:  5000 quantization_loss:  0.08708391338586807
p mean is: tensor(-0.0712, device='cuda:2')
epoch:  6000 quantization_loss:  0.0866129994392395
p mean is: tensor(-0.0875, device='cuda:2')
epoch:  7000 quantization_loss:  0.08437279611825943
p mean is: tensor(-0.1102, device='cuda:2')
epoch:  8000 quantization_loss:  0.08310103416442871
p mean is: tensor(-0.1421, device='cuda:2')
epoch:  9000 quantization_loss:  0.08321569114923477
p mean is: tensor(-0.1865, device='cuda:2')
epoch:  10000 quantization_loss:  0.0824168398976326
p mean is: tensor(-0.2472, device='cuda:2')
epoch:  11000 quantization_loss:  0.07840961962938309
p mean is: tensor(-0.3271, device='cuda:2')
epoch:  12000 quantization_loss:  0.07781446725130081
p mean is: tensor(-0.4261, device='cuda:2')
epoch:  13000 quantization_loss:  0.07692605257034302
p mean is: tensor(-0.5453, device='cuda:2')
epoch:  14000 quantization_loss:  0.07646776735782623
p mean is: tensor(-0.6860, device='cuda:2')
epoch:  15000 quantization_loss:  0.07559355348348618
p mean is: tensor(-0.8453, device='cuda:2')
epoch:  16000 quantization_loss:  0.07410074770450592
p mean is: tensor(-1.0155, device='cuda:2')
epoch:  17000 quantization_loss:  0.07382205873727798
p mean is: tensor(-1.1872, device='cuda:2')
epoch:  18000 quantization_loss:  0.073075070977211
p mean is: tensor(-1.3545, device='cuda:2')
epoch:  19000 quantization_loss:  0.0726030021905899
p mean is: tensor(-1.5112, device='cuda:2')
epoch:  20000 quantization_loss:  0.07225463539361954
p mean is: tensor(-1.6544, device='cuda:2')
epoch:  21000 quantization_loss:  0.07208982855081558
p mean is: tensor(-1.7849, device='cuda:2')
epoch:  22000 quantization_loss:  0.07199953496456146
p mean is: tensor(-1.9032, device='cuda:2')
epoch:  23000 quantization_loss:  0.07175809144973755
p mean is: tensor(-2.0105, device='cuda:2')
epoch:  24000 quantization_loss:  0.0715966746211052
p mean is: tensor(-2.1079, device='cuda:2')
epoch:  25000 quantization_loss:  0.07141286879777908
p mean is: tensor(-2.1967, device='cuda:2')
epoch:  26000 quantization_loss:  0.07132252305746078
p mean is: tensor(-2.2782, device='cuda:2')
epoch:  27000 quantization_loss:  0.07125939428806305
p mean is: tensor(-2.3532, device='cuda:2')
epoch:  28000 quantization_loss:  0.07111403346061707
p mean is: tensor(-2.4224, device='cuda:2')
epoch:  29000 quantization_loss:  0.07176139950752258
p mean is: tensor(-2.4867, device='cuda:2')
epoch:  30000 quantization_loss:  0.07099419832229614
p mean is: tensor(-2.5466, device='cuda:2')
epoch:  31000 quantization_loss:  0.07092071324586868
p mean is: tensor(-2.6023, device='cuda:2')
epoch:  32000 quantization_loss:  0.07089392095804214
p mean is: tensor(-2.6544, device='cuda:2')
epoch:  33000 quantization_loss:  0.07083999365568161
p mean is: tensor(-2.7033, device='cuda:2')
epoch:  34000 quantization_loss:  0.07073965668678284
p mean is: tensor(-2.7493, device='cuda:2')
epoch:  35000 quantization_loss:  0.0707290843129158
p mean is: tensor(-2.7925, device='cuda:2')
epoch:  36000 quantization_loss:  0.07069726288318634
p mean is: tensor(-2.8334, device='cuda:2')
epoch:  37000 quantization_loss:  0.07065174728631973
p mean is: tensor(-2.8719, device='cuda:2')
epoch:  38000 quantization_loss:  0.07061384618282318
p mean is: tensor(-2.9082, device='cuda:2')
epoch:  39000 quantization_loss:  0.07058203965425491
p mean is: tensor(-2.9424, device='cuda:2')
epoch:  40000 quantization_loss:  0.07054320722818375
p mean is: tensor(-2.9749, device='cuda:2')
epoch:  41000 quantization_loss:  0.07053407281637192
p mean is: tensor(-3.0058, device='cuda:2')
epoch:  42000 quantization_loss:  0.07049893587827682
p mean is: tensor(-3.0352, device='cuda:2')
epoch:  43000 quantization_loss:  0.07048870623111725
p mean is: tensor(-3.0634, device='cuda:2')
epoch:  44000 quantization_loss:  0.0704633891582489
p mean is: tensor(-3.0903, device='cuda:2')
epoch:  45000 quantization_loss:  0.07044825702905655
p mean is: tensor(-3.1158, device='cuda:2')
epoch:  46000 quantization_loss:  0.07043567299842834
p mean is: tensor(-3.1404, device='cuda:2')
epoch:  47000 quantization_loss:  0.07040542364120483
p mean is: tensor(-3.1638, device='cuda:2')
epoch:  48000 quantization_loss:  0.07041087746620178
p mean is: tensor(-3.1863, device='cuda:2')
epoch:  49000 quantization_loss:  0.0703803226351738
p mean is: tensor(-3.2078, device='cuda:2')
epoch:  50000 quantization_loss:  0.07037302106618881
p mean is: tensor(-3.2285, device='cuda:2')
epoch:  51000 quantization_loss:  0.07035260647535324
p mean is: tensor(-3.2483, device='cuda:2')
epoch:  52000 quantization_loss:  0.07033112645149231
p mean is: tensor(-3.2675, device='cuda:2')
epoch:  53000 quantization_loss:  0.07033014297485352
p mean is: tensor(-3.2859, device='cuda:2')
epoch:  54000 quantization_loss:  0.07031845301389694
p mean is: tensor(-3.3035, device='cuda:2')
epoch:  55000 quantization_loss:  0.07031814754009247
p mean is: tensor(-3.3206, device='cuda:2')
epoch:  56000 quantization_loss:  0.07031384855508804
p mean is: tensor(-3.3370, device='cuda:2')
epoch:  57000 quantization_loss:  0.07030034810304642
p mean is: tensor(-3.3528, device='cuda:2')
epoch:  58000 quantization_loss:  0.07028645277023315
p mean is: tensor(-3.3682, device='cuda:2')
epoch:  59000 quantization_loss:  0.07028203457593918
p mean is: tensor(-3.3830, device='cuda:2')
Number of elements to keep: 60177
Threshold value: -1.127077579498291
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.019999887000655064
Number of elements to keep: 60177
Threshold value: -1.127077579498291
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.019999887000655064
1.1.1.weight         | nonzeros =     536 /   12800             (  4.19%) | total_pruned =   12264 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =      53 /    6400             (  0.83%) | total_pruned =    6347 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      34 /   12800             (  0.27%) | total_pruned =   12766 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =      63 /   25600             (  0.25%) | total_pruned =   25537 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      10 /      32             ( 31.25%) | total_pruned =      22 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =      70 /   51200             (  0.14%) | total_pruned =   51130 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     142 /  102400             (  0.14%) | total_pruned =  102258 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =      48 /  204800             (  0.02%) | total_pruned =  204752 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     200 /  409600             (  0.05%) | total_pruned =  409400 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     159 /  409600             (  0.04%) | total_pruned =  409441 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    1149 /  409600             (  0.28%) | total_pruned =  408451 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    3543 /  409600             (  0.86%) | total_pruned =  406057 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   10305 /  409600             (  2.52%) | total_pruned =  399295 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   14013 /  147456             (  9.50%) | total_pruned =  133443 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =    9772 /  147456             (  6.63%) | total_pruned =  137684 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =    9165 /  147456             (  6.22%) | total_pruned =  138291 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    6353 /   73728             (  8.62%) | total_pruned =   67375 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2269 /   18432             ( 12.31%) | total_pruned =   16163 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1126 /    4608             ( 24.44%) | total_pruned =    3482 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      27 /      48             ( 56.25%) | total_pruned =      21 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 60177, pruned : 2948690, total: 3008867, Compression rate :      50.00x  ( 98.00% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  11.713393947067619
Experiment done
