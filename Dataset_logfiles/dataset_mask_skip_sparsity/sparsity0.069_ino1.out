(3, 512, 512)
Noisy PSNR is '20.396612950267873'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Dataset/mask/1/sparsity/skip/det/0.069/1e-09
(3, 512, 512)
Noisy PSNR is '20.407116927009046'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Dataset/mask/1/sparsity/skip/det/0.069/1e-09
epoch:  0 quantization_loss:  0.0801100805401802
p mean is: tensor(-0.0004, device='cuda:0')
epoch:  1000 quantization_loss:  0.032292161136865616
p mean is: tensor(-0.0231, device='cuda:0')
epoch:  2000 quantization_loss:  0.026651903986930847
p mean is: tensor(-0.0421, device='cuda:0')
epoch:  3000 quantization_loss:  0.027050919830799103
p mean is: tensor(-0.0614, device='cuda:0')
epoch:  4000 quantization_loss:  0.025278564542531967
p mean is: tensor(-0.0814, device='cuda:0')
epoch:  5000 quantization_loss:  0.022989626973867416
p mean is: tensor(-0.1028, device='cuda:0')
epoch:  6000 quantization_loss:  0.021274790167808533
p mean is: tensor(-0.1257, device='cuda:0')
epoch:  7000 quantization_loss:  0.02109455317258835
p mean is: tensor(-0.1521, device='cuda:0')
epoch:  8000 quantization_loss:  0.02140035852789879
p mean is: tensor(-0.1828, device='cuda:0')
epoch:  9000 quantization_loss:  0.021266549825668335
p mean is: tensor(-0.2185, device='cuda:0')
epoch:  10000 quantization_loss:  0.020734427496790886
p mean is: tensor(-0.2592, device='cuda:0')
epoch:  11000 quantization_loss:  0.02108505554497242
p mean is: tensor(-0.3039, device='cuda:0')
epoch:  12000 quantization_loss:  0.020801912993192673
p mean is: tensor(-0.3513, device='cuda:0')
epoch:  13000 quantization_loss:  0.02076602540910244
p mean is: tensor(-0.3994, device='cuda:0')
epoch:  14000 quantization_loss:  0.020593643188476562
p mean is: tensor(-0.4473, device='cuda:0')
epoch:  15000 quantization_loss:  0.02052317187190056
p mean is: tensor(-0.4934, device='cuda:0')
epoch:  16000 quantization_loss:  0.0207770187407732
p mean is: tensor(-0.5379, device='cuda:0')
epoch:  17000 quantization_loss:  0.020457398146390915
p mean is: tensor(-0.5809, device='cuda:0')
epoch:  18000 quantization_loss:  0.020410306751728058
p mean is: tensor(-0.6221, device='cuda:0')
epoch:  19000 quantization_loss:  0.02048342488706112
p mean is: tensor(-0.6615, device='cuda:0')
epoch:  20000 quantization_loss:  0.02034766785800457
p mean is: tensor(-0.6986, device='cuda:0')
epoch:  21000 quantization_loss:  0.02035217545926571
p mean is: tensor(-0.7342, device='cuda:0')
epoch:  22000 quantization_loss:  0.020466478541493416
p mean is: tensor(-0.7691, device='cuda:0')
epoch:  23000 quantization_loss:  0.020285995677113533
p mean is: tensor(-0.8026, device='cuda:0')
epoch:  24000 quantization_loss:  0.020298028364777565
p mean is: tensor(-0.8344, device='cuda:0')
epoch:  25000 quantization_loss:  0.020388789474964142
p mean is: tensor(-0.8651, device='cuda:0')
epoch:  26000 quantization_loss:  0.02027435228228569
p mean is: tensor(-0.8950, device='cuda:0')
epoch:  27000 quantization_loss:  0.020246386528015137
p mean is: tensor(-0.9237, device='cuda:0')
epoch:  28000 quantization_loss:  0.02027345448732376
p mean is: tensor(-0.9521, device='cuda:0')
epoch:  29000 quantization_loss:  0.020242979750037193
p mean is: tensor(-0.9793, device='cuda:0')
epoch:  30000 quantization_loss:  0.02036507986485958
p mean is: tensor(-1.0059, device='cuda:0')
epoch:  31000 quantization_loss:  0.019371850416064262
p mean is: tensor(-1.0311, device='cuda:0')
epoch:  32000 quantization_loss:  0.01863470859825611
p mean is: tensor(-1.0524, device='cuda:0')
epoch:  33000 quantization_loss:  0.017978200688958168
p mean is: tensor(-1.0736, device='cuda:0')
epoch:  34000 quantization_loss:  0.017351187765598297
p mean is: tensor(-1.0968, device='cuda:0')
epoch:  35000 quantization_loss:  0.017477402463555336
p mean is: tensor(-1.1232, device='cuda:0')
epoch:  36000 quantization_loss:  0.01701364852488041
p mean is: tensor(-1.1539, device='cuda:0')
epoch:  37000 quantization_loss:  0.0166971106082201
p mean is: tensor(-1.1895, device='cuda:0')
epoch:  38000 quantization_loss:  0.016354916617274284
p mean is: tensor(-1.2301, device='cuda:0')
epoch:  39000 quantization_loss:  0.0162042248994112
p mean is: tensor(-1.2758, device='cuda:0')
epoch:  40000 quantization_loss:  0.015969783067703247
p mean is: tensor(-1.3261, device='cuda:0')
epoch:  41000 quantization_loss:  0.01592293754220009
p mean is: tensor(-1.3801, device='cuda:0')
epoch:  42000 quantization_loss:  0.015670171007514
p mean is: tensor(-1.4371, device='cuda:0')
epoch:  43000 quantization_loss:  0.01557440496981144
p mean is: tensor(-1.4953, device='cuda:0')
epoch:  44000 quantization_loss:  0.015257769264280796
p mean is: tensor(-1.5527, device='cuda:0')
epoch:  45000 quantization_loss:  0.015131107531487942
p mean is: tensor(-1.6087, device='cuda:0')
epoch:  46000 quantization_loss:  0.014957696199417114
p mean is: tensor(-1.6632, device='cuda:0')
epoch:  47000 quantization_loss:  0.014742940664291382
p mean is: tensor(-1.7151, device='cuda:0')
epoch:  48000 quantization_loss:  0.014681778848171234
p mean is: tensor(-1.7640, device='cuda:0')
epoch:  49000 quantization_loss:  0.014456292614340782
p mean is: tensor(-1.8101, device='cuda:0')
epoch:  50000 quantization_loss:  0.014419416896998882
p mean is: tensor(-1.8531, device='cuda:0')
epoch:  51000 quantization_loss:  0.014097296632826328
p mean is: tensor(-1.8928, device='cuda:0')
epoch:  52000 quantization_loss:  0.014141030609607697
p mean is: tensor(-1.9297, device='cuda:0')
epoch:  53000 quantization_loss:  0.013986884616315365
p mean is: tensor(-1.9644, device='cuda:0')
epoch:  54000 quantization_loss:  0.013799959793686867
p mean is: tensor(-1.9973, device='cuda:0')
epoch:  55000 quantization_loss:  0.013861200772225857
p mean is: tensor(-2.0282, device='cuda:0')
epoch:  56000 quantization_loss:  0.013826277107000351
p mean is: tensor(-2.0575, device='cuda:0')
epoch:  57000 quantization_loss:  0.013721195980906487
p mean is: tensor(-2.0854, device='cuda:0')
epoch:  58000 quantization_loss:  0.01369309239089489
p mean is: tensor(-2.1117, device='cuda:0')
epoch:  59000 quantization_loss:  0.013577085919678211
p mean is: tensor(-2.1365, device='cuda:0')
Number of elements to keep: 153030
Threshold value: -0.23298555612564087
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.06899984714795672
Number of elements to keep: 153030
Threshold value: -0.23298555612564087
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.06899984714795672
1.0.1.1.weight       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([4, 32, 1, 1])
1.0.1.1.bias         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.weight         | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.0.2.bias           | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.1.1.weight       | nonzeros =    9902 /   36864             ( 26.86%) | total_pruned =   26962 | shape = torch.Size([128, 32, 3, 3])
1.1.1.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.2.weight         | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.1.2.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.4.1.weight       | nonzeros =   18578 /  147456             ( 12.60%) | total_pruned =  128878 | shape = torch.Size([128, 128, 3, 3])
1.1.4.1.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.5.weight         | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.1.5.bias           | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.0.1.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.0.1.1.bias   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.weight   | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.0.2.bias     | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.1.1.weight | nonzeros =   14083 /  147456             (  9.55%) | total_pruned =  133373 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.1.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.2.weight   | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.1.7.1.1.2.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.4.1.weight | nonzeros =   10638 /  147456             (  7.21%) | total_pruned =  136818 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.4.1.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.5.weight   | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.1.7.1.1.5.bias     | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.0.1.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.weight | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    9190 /  147456             (  6.23%) | total_pruned =  138266 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    7110 /  147456             (  4.82%) | total_pruned =  140346 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      43 /     512             (  8.40%) | total_pruned =     469 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       2 /       4             ( 50.00%) | total_pruned =       2 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    4787 /  147456             (  3.25%) | total_pruned =  142669 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =    6911 /  147456             (  4.69%) | total_pruned =  140545 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.weight | nonzeros =      30 /     512             (  5.86%) | total_pruned =     482 | shape = torch.Size([4, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.1.1.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.weight | nonzeros =       1 /       4             ( 25.00%) | total_pruned =       3 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.0.2.bias | nonzeros =       0 /       4             (  0.00%) | total_pruned =       4 | shape = torch.Size([4])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.weight | nonzeros =    9232 /  147456             (  6.26%) | total_pruned =  138224 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.weight | nonzeros =   11102 /  147456             (  7.53%) | total_pruned =  136354 | shape = torch.Size([128, 128, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.weight | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.1.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      69 /     132             ( 52.27%) | total_pruned =      63 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =    9103 /  152064             (  5.99%) | total_pruned =  142961 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =    1535 /   16384             (  9.37%) | total_pruned =   14849 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.2.weight | nonzeros =      46 /     132             ( 34.85%) | total_pruned =      86 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.2.bias | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.1.1.7.3.1.weight | nonzeros =    5584 /  152064             (  3.67%) | total_pruned =  146480 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.weight | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.6.1.weight | nonzeros =    1909 /   16384             ( 11.65%) | total_pruned =   14475 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.1.7.1.1.7.1.1.7.7.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.2.weight | nonzeros =      67 /     132             ( 50.76%) | total_pruned =      65 | shape = torch.Size([132])
1.1.7.1.1.7.2.bias   | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.1.1.7.3.1.weight | nonzeros =    7589 /  152064             (  4.99%) | total_pruned =  144475 | shape = torch.Size([128, 132, 3, 3])
1.1.7.1.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.4.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.1.7.1.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.6.1.weight | nonzeros =    1436 /   16384             (  8.76%) | total_pruned =   14948 | shape = torch.Size([128, 128, 1, 1])
1.1.7.1.1.7.6.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.1.1.7.7.weight | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
1.1.7.1.1.7.7.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.2.weight       | nonzeros =      57 /     132             ( 43.18%) | total_pruned =      75 | shape = torch.Size([132])
1.1.7.2.bias         | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
1.1.7.3.1.weight     | nonzeros =    6022 /  152064             (  3.96%) | total_pruned =  146042 | shape = torch.Size([128, 132, 3, 3])
1.1.7.3.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.4.weight       | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.1.7.4.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.6.1.weight     | nonzeros =    1646 /   16384             ( 10.05%) | total_pruned =   14738 | shape = torch.Size([128, 128, 1, 1])
1.1.7.6.1.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.1.7.7.weight       | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.1.7.7.bias         | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
2.weight             | nonzeros =      75 /     132             ( 56.82%) | total_pruned =      57 | shape = torch.Size([132])
2.bias               | nonzeros =       0 /     132             (  0.00%) | total_pruned =     132 | shape = torch.Size([132])
3.1.weight           | nonzeros =   10551 /  152064             (  6.94%) | total_pruned =  141513 | shape = torch.Size([128, 132, 3, 3])
3.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
4.weight             | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
4.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
6.1.weight           | nonzeros =    4012 /   16384             ( 24.49%) | total_pruned =   12372 | shape = torch.Size([128, 128, 1, 1])
6.1.bias             | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
7.weight             | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
7.bias               | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
9.1.weight           | nonzeros =     181 /     384             ( 47.14%) | total_pruned =     203 | shape = torch.Size([3, 128, 1, 1])
9.1.bias             | nonzeros =       3 /       3             (100.00%) | total_pruned =       0 | shape = torch.Size([3])
alive: 153030, pruned : 2064801, total: 2217831, Compression rate :      14.49x  ( 93.10% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  23.268965361679378
Experiment done
