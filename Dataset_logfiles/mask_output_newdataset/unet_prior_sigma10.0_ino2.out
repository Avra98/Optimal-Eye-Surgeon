(3, 512, 512)
Noisy PSNR is '20.1919102670805'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Dataset/mask/2/unet/det/10.0/1e-09
epoch:  0 quantization_loss:  0.06715676933526993
p mean is: tensor(0.0015, device='cuda:2')
epoch:  1000 quantization_loss:  0.05879241228103638
p mean is: tensor(0.0759, device='cuda:2')
epoch:  2000 quantization_loss:  0.0577939935028553
p mean is: tensor(0.1282, device='cuda:2')
epoch:  3000 quantization_loss:  0.05444988235831261
p mean is: tensor(0.1774, device='cuda:2')
epoch:  4000 quantization_loss:  0.05363525450229645
p mean is: tensor(0.2255, device='cuda:2')
epoch:  5000 quantization_loss:  0.0487421490252018
p mean is: tensor(0.2727, device='cuda:2')
epoch:  6000 quantization_loss:  0.043214116245508194
p mean is: tensor(0.3266, device='cuda:2')
epoch:  7000 quantization_loss:  0.040939923375844955
p mean is: tensor(0.4000, device='cuda:2')
epoch:  8000 quantization_loss:  0.03884885460138321
p mean is: tensor(0.4999, device='cuda:2')
epoch:  9000 quantization_loss:  0.036201879382133484
p mean is: tensor(0.6337, device='cuda:2')
epoch:  10000 quantization_loss:  0.03239911422133446
p mean is: tensor(0.8021, device='cuda:2')
epoch:  11000 quantization_loss:  0.030188094824552536
p mean is: tensor(0.9990, device='cuda:2')
epoch:  12000 quantization_loss:  0.02830607071518898
p mean is: tensor(1.2284, device='cuda:2')
epoch:  13000 quantization_loss:  0.02674233540892601
p mean is: tensor(1.4849, device='cuda:2')
epoch:  14000 quantization_loss:  0.025524064898490906
p mean is: tensor(1.7563, device='cuda:2')
epoch:  15000 quantization_loss:  0.024289915338158607
p mean is: tensor(2.0271, device='cuda:2')
epoch:  16000 quantization_loss:  0.02336108684539795
p mean is: tensor(2.2850, device='cuda:2')
epoch:  17000 quantization_loss:  0.022807354107499123
p mean is: tensor(2.5231, device='cuda:2')
epoch:  18000 quantization_loss:  0.02238135039806366
p mean is: tensor(2.7389, device='cuda:2')
epoch:  19000 quantization_loss:  0.022124145179986954
p mean is: tensor(2.9324, device='cuda:2')
epoch:  20000 quantization_loss:  0.02154027298092842
p mean is: tensor(3.1054, device='cuda:2')
epoch:  21000 quantization_loss:  0.02133145183324814
p mean is: tensor(3.2599, device='cuda:2')
epoch:  22000 quantization_loss:  0.021095624193549156
p mean is: tensor(3.3987, device='cuda:2')
epoch:  23000 quantization_loss:  0.021061761304736137
p mean is: tensor(3.5236, device='cuda:2')
epoch:  24000 quantization_loss:  0.02078666351735592
p mean is: tensor(3.6367, device='cuda:2')
epoch:  25000 quantization_loss:  0.020690590143203735
p mean is: tensor(3.7398, device='cuda:2')
epoch:  26000 quantization_loss:  0.020588863641023636
p mean is: tensor(3.8341, device='cuda:2')
epoch:  27000 quantization_loss:  0.02049410529434681
p mean is: tensor(3.9210, device='cuda:2')
epoch:  28000 quantization_loss:  0.020482219755649567
p mean is: tensor(4.0016, device='cuda:2')
epoch:  29000 quantization_loss:  0.020368525758385658
p mean is: tensor(4.0764, device='cuda:2')
epoch:  30000 quantization_loss:  0.020293651148676872
p mean is: tensor(4.1463, device='cuda:2')
epoch:  31000 quantization_loss:  0.02027577906847
p mean is: tensor(4.2118, device='cuda:2')
epoch:  32000 quantization_loss:  0.020216679200530052
p mean is: tensor(4.2732, device='cuda:2')
epoch:  33000 quantization_loss:  0.02015422098338604
p mean is: tensor(4.3312, device='cuda:2')
epoch:  34000 quantization_loss:  0.02013283595442772
p mean is: tensor(4.3862, device='cuda:2')
epoch:  35000 quantization_loss:  0.020087826997041702
p mean is: tensor(4.4385, device='cuda:2')
epoch:  36000 quantization_loss:  0.02007623389363289
p mean is: tensor(4.4882, device='cuda:2')
epoch:  37000 quantization_loss:  0.020636681467294693
p mean is: tensor(4.5356, device='cuda:2')
epoch:  38000 quantization_loss:  0.020065221935510635
p mean is: tensor(4.5809, device='cuda:2')
epoch:  39000 quantization_loss:  0.019963877275586128
p mean is: tensor(4.6242, device='cuda:2')
epoch:  40000 quantization_loss:  0.019952287897467613
p mean is: tensor(4.6658, device='cuda:2')
epoch:  41000 quantization_loss:  0.019943414255976677
p mean is: tensor(4.7058, device='cuda:2')
epoch:  42000 quantization_loss:  0.019897157326340675
p mean is: tensor(4.7442, device='cuda:2')
epoch:  43000 quantization_loss:  0.019881311804056168
p mean is: tensor(4.7812, device='cuda:2')
epoch:  44000 quantization_loss:  0.01986732892692089
p mean is: tensor(4.8169, device='cuda:2')
epoch:  45000 quantization_loss:  0.019836192950606346
p mean is: tensor(4.8515, device='cuda:2')
epoch:  46000 quantization_loss:  0.019827064126729965
p mean is: tensor(4.8849, device='cuda:2')
epoch:  47000 quantization_loss:  0.019813355058431625
p mean is: tensor(4.9172, device='cuda:2')
epoch:  48000 quantization_loss:  0.019805483520030975
p mean is: tensor(4.9485, device='cuda:2')
epoch:  49000 quantization_loss:  0.01979573629796505
p mean is: tensor(4.9788, device='cuda:2')
epoch:  50000 quantization_loss:  0.019777022302150726
p mean is: tensor(5.0083, device='cuda:2')
epoch:  51000 quantization_loss:  0.01978052407503128
p mean is: tensor(5.0369, device='cuda:2')
epoch:  52000 quantization_loss:  0.019761500880122185
p mean is: tensor(5.0647, device='cuda:2')
epoch:  53000 quantization_loss:  0.019750235602259636
p mean is: tensor(5.0917, device='cuda:2')
epoch:  54000 quantization_loss:  0.01974366419017315
p mean is: tensor(5.1181, device='cuda:2')
epoch:  55000 quantization_loss:  0.01973225176334381
p mean is: tensor(5.1437, device='cuda:2')
epoch:  56000 quantization_loss:  0.01972476951777935
p mean is: tensor(5.1686, device='cuda:2')
epoch:  57000 quantization_loss:  0.019712159410119057
p mean is: tensor(5.1930, device='cuda:2')
epoch:  58000 quantization_loss:  0.01970311440527439
p mean is: tensor(5.2167, device='cuda:2')
epoch:  59000 quantization_loss:  0.01970275677740574
p mean is: tensor(5.2400, device='cuda:2')
epoch:  60000 quantization_loss:  0.019697066396474838
p mean is: tensor(5.2626, device='cuda:2')
epoch:  61000 quantization_loss:  0.019688252359628677
p mean is: tensor(5.2846, device='cuda:2')
epoch:  62000 quantization_loss:  0.019686317071318626
p mean is: tensor(5.3062, device='cuda:2')
epoch:  63000 quantization_loss:  0.019677896052598953
p mean is: tensor(5.3274, device='cuda:2')
epoch:  64000 quantization_loss:  0.019674889743328094
p mean is: tensor(5.3481, device='cuda:2')
epoch:  65000 quantization_loss:  0.01968792825937271
p mean is: tensor(5.3684, device='cuda:2')
epoch:  66000 quantization_loss:  0.019670655950903893
p mean is: tensor(5.3882, device='cuda:2')
epoch:  67000 quantization_loss:  0.01966795139014721
p mean is: tensor(5.4077, device='cuda:2')
epoch:  68000 quantization_loss:  0.01965860091149807
p mean is: tensor(5.4267, device='cuda:2')
epoch:  69000 quantization_loss:  0.019652005285024643
p mean is: tensor(5.4453, device='cuda:2')
epoch:  70000 quantization_loss:  0.019651981070637703
p mean is: tensor(5.4636, device='cuda:2')
epoch:  71000 quantization_loss:  0.019647842273116112
p mean is: tensor(5.4815, device='cuda:2')
epoch:  72000 quantization_loss:  0.019663706421852112
p mean is: tensor(5.4991, device='cuda:2')
epoch:  73000 quantization_loss:  0.01964329555630684
p mean is: tensor(5.5164, device='cuda:2')
epoch:  74000 quantization_loss:  0.019640475511550903
p mean is: tensor(5.5334, device='cuda:2')
epoch:  75000 quantization_loss:  0.019641099497675896
p mean is: tensor(5.5501, device='cuda:2')
epoch:  76000 quantization_loss:  0.01963207684457302
p mean is: tensor(5.5664, device='cuda:2')
epoch:  77000 quantization_loss:  0.01962980441749096
p mean is: tensor(5.5825, device='cuda:2')
epoch:  78000 quantization_loss:  0.01962866820394993
p mean is: tensor(5.5984, device='cuda:2')
epoch:  79000 quantization_loss:  0.019625237211585045
p mean is: tensor(5.6139, device='cuda:2')
1.1.1.weight         | nonzeros =   12402 /   12800             ( 96.89%) | total_pruned =     398 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.2.weight           | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =    6314 /    6400             ( 98.66%) | total_pruned =      86 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.5.weight           | nonzeros =      11 /      16             ( 68.75%) | total_pruned =       5 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =   12764 /   12800             ( 99.72%) | total_pruned =      36 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =   25543 /   25600             ( 99.78%) | total_pruned =      57 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =   51129 /   51200             ( 99.86%) | total_pruned =      71 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =  102323 /  102400             ( 99.92%) | total_pruned =      77 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =  204703 /  204800             ( 99.95%) | total_pruned =      97 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =  409412 /  409600             ( 99.95%) | total_pruned =     188 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  409264 /  409600             ( 99.92%) | total_pruned =     336 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  408807 /  409600             ( 99.81%) | total_pruned =     793 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  408247 /  409600             ( 99.67%) | total_pruned =    1353 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  405827 /  409600             ( 99.08%) | total_pruned =    3773 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  139617 /  147456             ( 94.68%) | total_pruned =    7839 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  138579 /  147456             ( 93.98%) | total_pruned =    8877 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =  139156 /  147456             ( 94.37%) | total_pruned =    8300 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   67946 /   73728             ( 92.16%) | total_pruned =    5782 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =   16500 /   18432             ( 89.52%) | total_pruned =    1932 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    3768 /    4608             ( 81.77%) | total_pruned =     840 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      15 /      16             ( 93.75%) | total_pruned =       1 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      25 /      48             ( 52.08%) | total_pruned =      23 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 2965334, pruned : 43533, total: 3008867, Compression rate :       1.01x  (  1.45% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  19.8302855650011
Experiment done
