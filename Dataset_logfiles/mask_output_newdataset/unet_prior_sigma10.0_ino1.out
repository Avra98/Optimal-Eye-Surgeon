(3, 512, 512)
Noisy PSNR is '20.416712224121312'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Dataset/mask/1/unet/det/10.0/1e-09
epoch:  0 quantization_loss:  0.09854593127965927
p mean is: tensor(0.0015, device='cuda:1')
epoch:  1000 quantization_loss:  0.06467686593532562
p mean is: tensor(0.1033, device='cuda:1')
epoch:  2000 quantization_loss:  0.0574224628508091
p mean is: tensor(0.1697, device='cuda:1')
epoch:  3000 quantization_loss:  0.05370338261127472
p mean is: tensor(0.2222, device='cuda:1')
epoch:  4000 quantization_loss:  0.052314285188913345
p mean is: tensor(0.2688, device='cuda:1')
epoch:  5000 quantization_loss:  0.05048708617687225
p mean is: tensor(0.3176, device='cuda:1')
epoch:  6000 quantization_loss:  0.05087665468454361
p mean is: tensor(0.3729, device='cuda:1')
epoch:  7000 quantization_loss:  0.0500103160738945
p mean is: tensor(0.4350, device='cuda:1')
epoch:  8000 quantization_loss:  0.04942778870463371
p mean is: tensor(0.5039, device='cuda:1')
epoch:  9000 quantization_loss:  0.04950360953807831
p mean is: tensor(0.5780, device='cuda:1')
epoch:  10000 quantization_loss:  0.04864192008972168
p mean is: tensor(0.6556, device='cuda:1')
epoch:  11000 quantization_loss:  0.04809850826859474
p mean is: tensor(0.7346, device='cuda:1')
epoch:  12000 quantization_loss:  0.0483020544052124
p mean is: tensor(0.8139, device='cuda:1')
epoch:  13000 quantization_loss:  0.04764648526906967
p mean is: tensor(0.8927, device='cuda:1')
epoch:  14000 quantization_loss:  0.0470283105969429
p mean is: tensor(0.9701, device='cuda:1')
epoch:  15000 quantization_loss:  0.04700986668467522
p mean is: tensor(1.0471, device='cuda:1')
epoch:  16000 quantization_loss:  0.046768732368946075
p mean is: tensor(1.1264, device='cuda:1')
epoch:  17000 quantization_loss:  0.04607975482940674
p mean is: tensor(1.2154, device='cuda:1')
epoch:  18000 quantization_loss:  0.045509785413742065
p mean is: tensor(1.3235, device='cuda:1')
epoch:  19000 quantization_loss:  0.04494716227054596
p mean is: tensor(1.4560, device='cuda:1')
epoch:  20000 quantization_loss:  0.04343344643712044
p mean is: tensor(1.6149, device='cuda:1')
epoch:  21000 quantization_loss:  0.042171258479356766
p mean is: tensor(1.7915, device='cuda:1')
epoch:  22000 quantization_loss:  0.041302479803562164
p mean is: tensor(1.9953, device='cuda:1')
epoch:  23000 quantization_loss:  0.04025687277317047
p mean is: tensor(2.2242, device='cuda:1')
epoch:  24000 quantization_loss:  0.03940635174512863
p mean is: tensor(2.4678, device='cuda:1')
epoch:  25000 quantization_loss:  0.03851587325334549
p mean is: tensor(2.7116, device='cuda:1')
epoch:  26000 quantization_loss:  0.03786664828658104
p mean is: tensor(2.9416, device='cuda:1')
epoch:  27000 quantization_loss:  0.03740639239549637
p mean is: tensor(3.1501, device='cuda:1')
epoch:  28000 quantization_loss:  0.037124961614608765
p mean is: tensor(3.3343, device='cuda:1')
epoch:  29000 quantization_loss:  0.03674858808517456
p mean is: tensor(3.4959, device='cuda:1')
epoch:  30000 quantization_loss:  0.036665067076683044
p mean is: tensor(3.6379, device='cuda:1')
epoch:  31000 quantization_loss:  0.03645053133368492
p mean is: tensor(3.7633, device='cuda:1')
epoch:  32000 quantization_loss:  0.03630845621228218
p mean is: tensor(3.8747, device='cuda:1')
epoch:  33000 quantization_loss:  0.035642825067043304
p mean is: tensor(3.9745, device='cuda:1')
epoch:  34000 quantization_loss:  0.03544458746910095
p mean is: tensor(4.0640, device='cuda:1')
epoch:  35000 quantization_loss:  0.0353887602686882
p mean is: tensor(4.1455, device='cuda:1')
epoch:  36000 quantization_loss:  0.03537386655807495
p mean is: tensor(4.2204, device='cuda:1')
epoch:  37000 quantization_loss:  0.035369545221328735
p mean is: tensor(4.2898, device='cuda:1')
epoch:  38000 quantization_loss:  0.0351722314953804
p mean is: tensor(4.3544, device='cuda:1')
epoch:  39000 quantization_loss:  0.035131923854351044
p mean is: tensor(4.4147, device='cuda:1')
epoch:  40000 quantization_loss:  0.03509364649653435
p mean is: tensor(4.4714, device='cuda:1')
epoch:  41000 quantization_loss:  0.035391345620155334
p mean is: tensor(4.5249, device='cuda:1')
epoch:  42000 quantization_loss:  0.0350693054497242
p mean is: tensor(4.5754, device='cuda:1')
epoch:  43000 quantization_loss:  0.03495672717690468
p mean is: tensor(4.6234, device='cuda:1')
epoch:  44000 quantization_loss:  0.03490937501192093
p mean is: tensor(4.6689, device='cuda:1')
epoch:  45000 quantization_loss:  0.03491038829088211
p mean is: tensor(4.7124, device='cuda:1')
epoch:  46000 quantization_loss:  0.03488493338227272
p mean is: tensor(4.7539, device='cuda:1')
epoch:  47000 quantization_loss:  0.034869566559791565
p mean is: tensor(4.7936, device='cuda:1')
epoch:  48000 quantization_loss:  0.034785155206918716
p mean is: tensor(4.8316, device='cuda:1')
epoch:  49000 quantization_loss:  0.0347650982439518
p mean is: tensor(4.8681, device='cuda:1')
epoch:  50000 quantization_loss:  0.03474240377545357
p mean is: tensor(4.9032, device='cuda:1')
epoch:  51000 quantization_loss:  0.03473654389381409
p mean is: tensor(4.9371, device='cuda:1')
epoch:  52000 quantization_loss:  0.034710194915533066
p mean is: tensor(4.9696, device='cuda:1')
epoch:  53000 quantization_loss:  0.03469410911202431
p mean is: tensor(5.0011, device='cuda:1')
epoch:  54000 quantization_loss:  0.034713923931121826
p mean is: tensor(5.0316, device='cuda:1')
epoch:  55000 quantization_loss:  0.034783560782670975
p mean is: tensor(5.0612, device='cuda:1')
epoch:  56000 quantization_loss:  0.034661442041397095
p mean is: tensor(5.0898, device='cuda:1')
epoch:  57000 quantization_loss:  0.034649427980184555
p mean is: tensor(5.1175, device='cuda:1')
epoch:  58000 quantization_loss:  0.034638699144124985
p mean is: tensor(5.1444, device='cuda:1')
epoch:  59000 quantization_loss:  0.03468167409300804
p mean is: tensor(5.1705, device='cuda:1')
epoch:  60000 quantization_loss:  0.03460824862122536
p mean is: tensor(5.1960, device='cuda:1')
epoch:  61000 quantization_loss:  0.0346086323261261
p mean is: tensor(5.2207, device='cuda:1')
epoch:  62000 quantization_loss:  0.03462321311235428
p mean is: tensor(5.2449, device='cuda:1')
epoch:  63000 quantization_loss:  0.03459060937166214
p mean is: tensor(5.2684, device='cuda:1')
epoch:  64000 quantization_loss:  0.03457704186439514
p mean is: tensor(5.2913, device='cuda:1')
epoch:  65000 quantization_loss:  0.03457774966955185
p mean is: tensor(5.3136, device='cuda:1')
epoch:  66000 quantization_loss:  0.03456953912973404
p mean is: tensor(5.3355, device='cuda:1')
epoch:  67000 quantization_loss:  0.03456085920333862
p mean is: tensor(5.3569, device='cuda:1')
epoch:  68000 quantization_loss:  0.03456052392721176
p mean is: tensor(5.3778, device='cuda:1')
epoch:  69000 quantization_loss:  0.034549225121736526
p mean is: tensor(5.3982, device='cuda:1')
epoch:  70000 quantization_loss:  0.034546129405498505
p mean is: tensor(5.4181, device='cuda:1')
epoch:  71000 quantization_loss:  0.03453870117664337
p mean is: tensor(5.4377, device='cuda:1')
epoch:  72000 quantization_loss:  0.03453982248902321
p mean is: tensor(5.4568, device='cuda:1')
epoch:  73000 quantization_loss:  0.0345296636223793
p mean is: tensor(5.4756, device='cuda:1')
epoch:  74000 quantization_loss:  0.034524865448474884
p mean is: tensor(5.4940, device='cuda:1')
epoch:  75000 quantization_loss:  0.034527771174907684
p mean is: tensor(5.5120, device='cuda:1')
epoch:  76000 quantization_loss:  0.034522946923971176
p mean is: tensor(5.5297, device='cuda:1')
epoch:  77000 quantization_loss:  0.03451666235923767
p mean is: tensor(5.5470, device='cuda:1')
epoch:  78000 quantization_loss:  0.034511927515268326
p mean is: tensor(5.5641, device='cuda:1')
epoch:  79000 quantization_loss:  0.034508127719163895
p mean is: tensor(5.5808, device='cuda:1')
1.1.1.weight         | nonzeros =   12273 /   12800             ( 95.88%) | total_pruned =     527 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.2.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =    6306 /    6400             ( 98.53%) | total_pruned =      94 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.5.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =   12744 /   12800             ( 99.56%) | total_pruned =      56 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =   25564 /   25600             ( 99.86%) | total_pruned =      36 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =   51099 /   51200             ( 99.80%) | total_pruned =     101 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =  102275 /  102400             ( 99.88%) | total_pruned =     125 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =  204608 /  204800             ( 99.91%) | total_pruned =     192 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =  409406 /  409600             ( 99.95%) | total_pruned =     194 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  409172 /  409600             ( 99.90%) | total_pruned =     428 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  408805 /  409600             ( 99.81%) | total_pruned =     795 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  408460 /  409600             ( 99.72%) | total_pruned =    1140 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  406667 /  409600             ( 99.28%) | total_pruned =    2933 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  144043 /  147456             ( 97.69%) | total_pruned =    3413 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  145159 /  147456             ( 98.44%) | total_pruned =    2297 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =  144631 /  147456             ( 98.08%) | total_pruned =    2825 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   71113 /   73728             ( 96.45%) | total_pruned =    2615 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =   16867 /   18432             ( 91.51%) | total_pruned =    1565 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      27 /      32             ( 84.38%) | total_pruned =       5 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      21 /      32             ( 65.62%) | total_pruned =      11 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    3598 /    4608             ( 78.08%) | total_pruned =    1010 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      15 /      16             ( 93.75%) | total_pruned =       1 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      34 /      48             ( 70.83%) | total_pruned =      14 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 2985516, pruned : 23351, total: 3008867, Compression rate :       1.01x  (  0.78% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  15.744805751357626
Experiment done
