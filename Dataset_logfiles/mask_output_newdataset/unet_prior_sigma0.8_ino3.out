(3, 512, 512)
Noisy PSNR is '20.20181238683294'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Dataset/mask/3/unet/det/0.8/1e-09
epoch:  0 quantization_loss:  0.09678453207015991
p mean is: tensor(0.0001, device='cuda:1')
epoch:  1000 quantization_loss:  0.0689195841550827
p mean is: tensor(0.0073, device='cuda:1')
epoch:  2000 quantization_loss:  0.06396962702274323
p mean is: tensor(0.0122, device='cuda:1')
epoch:  3000 quantization_loss:  0.06123049557209015
p mean is: tensor(0.0168, device='cuda:1')
epoch:  4000 quantization_loss:  0.060421016067266464
p mean is: tensor(0.0213, device='cuda:1')
epoch:  5000 quantization_loss:  0.06011902540922165
p mean is: tensor(0.0252, device='cuda:1')
epoch:  6000 quantization_loss:  0.058477774262428284
p mean is: tensor(0.0288, device='cuda:1')
epoch:  7000 quantization_loss:  0.05579424649477005
p mean is: tensor(0.0336, device='cuda:1')
epoch:  8000 quantization_loss:  0.05245809257030487
p mean is: tensor(0.0398, device='cuda:1')
epoch:  9000 quantization_loss:  0.05096666142344475
p mean is: tensor(0.0483, device='cuda:1')
epoch:  10000 quantization_loss:  0.04885903000831604
p mean is: tensor(0.0598, device='cuda:1')
epoch:  11000 quantization_loss:  0.047073815017938614
p mean is: tensor(0.0742, device='cuda:1')
epoch:  12000 quantization_loss:  0.04581166058778763
p mean is: tensor(0.0931, device='cuda:1')
epoch:  13000 quantization_loss:  0.04523630440235138
p mean is: tensor(0.1174, device='cuda:1')
epoch:  14000 quantization_loss:  0.04459886625409126
p mean is: tensor(0.1480, device='cuda:1')
epoch:  15000 quantization_loss:  0.044533032923936844
p mean is: tensor(0.1847, device='cuda:1')
epoch:  16000 quantization_loss:  0.04390263929963112
p mean is: tensor(0.2270, device='cuda:1')
epoch:  17000 quantization_loss:  0.04366108775138855
p mean is: tensor(0.2739, device='cuda:1')
epoch:  18000 quantization_loss:  0.04368465393781662
p mean is: tensor(0.3232, device='cuda:1')
epoch:  19000 quantization_loss:  0.04329102486371994
p mean is: tensor(0.3728, device='cuda:1')
epoch:  20000 quantization_loss:  0.043170008808374405
p mean is: tensor(0.4209, device='cuda:1')
epoch:  21000 quantization_loss:  0.04300231114029884
p mean is: tensor(0.4654, device='cuda:1')
epoch:  22000 quantization_loss:  0.04280424118041992
p mean is: tensor(0.5058, device='cuda:1')
epoch:  23000 quantization_loss:  0.04277331754565239
p mean is: tensor(0.5419, device='cuda:1')
epoch:  24000 quantization_loss:  0.0425732247531414
p mean is: tensor(0.5737, device='cuda:1')
epoch:  25000 quantization_loss:  0.042504310607910156
p mean is: tensor(0.6016, device='cuda:1')
epoch:  26000 quantization_loss:  0.042483508586883545
p mean is: tensor(0.6259, device='cuda:1')
epoch:  27000 quantization_loss:  0.04247712343931198
p mean is: tensor(0.6470, device='cuda:1')
epoch:  28000 quantization_loss:  0.04232238233089447
p mean is: tensor(0.6653, device='cuda:1')
epoch:  29000 quantization_loss:  0.04224779084324837
p mean is: tensor(0.6811, device='cuda:1')
epoch:  30000 quantization_loss:  0.042126547545194626
p mean is: tensor(0.6950, device='cuda:1')
epoch:  31000 quantization_loss:  0.04206842556595802
p mean is: tensor(0.7070, device='cuda:1')
epoch:  32000 quantization_loss:  0.042050015181303024
p mean is: tensor(0.7174, device='cuda:1')
epoch:  33000 quantization_loss:  0.04203279688954353
p mean is: tensor(0.7264, device='cuda:1')
epoch:  34000 quantization_loss:  0.04194077104330063
p mean is: tensor(0.7343, device='cuda:1')
epoch:  35000 quantization_loss:  0.041900333017110825
p mean is: tensor(0.7413, device='cuda:1')
epoch:  36000 quantization_loss:  0.041868921369314194
p mean is: tensor(0.7475, device='cuda:1')
epoch:  37000 quantization_loss:  0.0418151319026947
p mean is: tensor(0.7529, device='cuda:1')
epoch:  38000 quantization_loss:  0.04177422821521759
p mean is: tensor(0.7577, device='cuda:1')
epoch:  39000 quantization_loss:  0.04176033288240433
p mean is: tensor(0.7619, device='cuda:1')
epoch:  40000 quantization_loss:  0.04172974452376366
p mean is: tensor(0.7657, device='cuda:1')
epoch:  41000 quantization_loss:  0.04169527441263199
p mean is: tensor(0.7691, device='cuda:1')
epoch:  42000 quantization_loss:  0.04170416295528412
p mean is: tensor(0.7722, device='cuda:1')
epoch:  43000 quantization_loss:  0.04168108478188515
p mean is: tensor(0.7749, device='cuda:1')
epoch:  44000 quantization_loss:  0.041644591838121414
p mean is: tensor(0.7774, device='cuda:1')
epoch:  45000 quantization_loss:  0.04161664471030235
p mean is: tensor(0.7797, device='cuda:1')
epoch:  46000 quantization_loss:  0.041650060564279556
p mean is: tensor(0.7817, device='cuda:1')
epoch:  47000 quantization_loss:  0.04160859435796738
p mean is: tensor(0.7836, device='cuda:1')
epoch:  48000 quantization_loss:  0.04158133268356323
p mean is: tensor(0.7853, device='cuda:1')
epoch:  49000 quantization_loss:  0.04158634692430496
p mean is: tensor(0.7869, device='cuda:1')
epoch:  50000 quantization_loss:  0.04155723750591278
p mean is: tensor(0.7884, device='cuda:1')
epoch:  51000 quantization_loss:  0.0415479838848114
p mean is: tensor(0.7898, device='cuda:1')
epoch:  52000 quantization_loss:  0.04153032228350639
p mean is: tensor(0.7910, device='cuda:1')
epoch:  53000 quantization_loss:  0.04154296964406967
p mean is: tensor(0.7921, device='cuda:1')
epoch:  54000 quantization_loss:  0.041512444615364075
p mean is: tensor(0.7932, device='cuda:1')
epoch:  55000 quantization_loss:  0.04150961712002754
p mean is: tensor(0.7943, device='cuda:1')
epoch:  56000 quantization_loss:  0.04149934649467468
p mean is: tensor(0.7952, device='cuda:1')
epoch:  57000 quantization_loss:  0.041537463665008545
p mean is: tensor(0.7961, device='cuda:1')
epoch:  58000 quantization_loss:  0.041488584131002426
p mean is: tensor(0.7970, device='cuda:1')
epoch:  59000 quantization_loss:  0.04148590937256813
p mean is: tensor(0.7979, device='cuda:1')
epoch:  60000 quantization_loss:  0.041477497667074203
p mean is: tensor(0.7987, device='cuda:1')
epoch:  61000 quantization_loss:  0.04147784411907196
p mean is: tensor(0.7994, device='cuda:1')
epoch:  62000 quantization_loss:  0.041475992649793625
p mean is: tensor(0.8002, device='cuda:1')
epoch:  63000 quantization_loss:  0.041455477476119995
p mean is: tensor(0.8009, device='cuda:1')
epoch:  64000 quantization_loss:  0.04146068915724754
p mean is: tensor(0.8015, device='cuda:1')
epoch:  65000 quantization_loss:  0.04145098105072975
p mean is: tensor(0.8021, device='cuda:1')
epoch:  66000 quantization_loss:  0.041444431990385056
p mean is: tensor(0.8027, device='cuda:1')
epoch:  67000 quantization_loss:  0.041443269699811935
p mean is: tensor(0.8033, device='cuda:1')
epoch:  68000 quantization_loss:  0.04144040495157242
p mean is: tensor(0.8038, device='cuda:1')
epoch:  69000 quantization_loss:  0.04144147038459778
p mean is: tensor(0.8042, device='cuda:1')
epoch:  70000 quantization_loss:  0.04143837094306946
p mean is: tensor(0.8048, device='cuda:1')
epoch:  71000 quantization_loss:  0.041440434753894806
p mean is: tensor(0.8053, device='cuda:1')
epoch:  72000 quantization_loss:  0.041429661214351654
p mean is: tensor(0.8058, device='cuda:1')
epoch:  73000 quantization_loss:  0.04142151027917862
p mean is: tensor(0.8062, device='cuda:1')
epoch:  74000 quantization_loss:  0.041426073759794235
p mean is: tensor(0.8066, device='cuda:1')
epoch:  75000 quantization_loss:  0.041424233466386795
p mean is: tensor(0.8070, device='cuda:1')
epoch:  76000 quantization_loss:  0.04141295328736305
p mean is: tensor(0.8074, device='cuda:1')
epoch:  77000 quantization_loss:  0.04141294211149216
p mean is: tensor(0.8077, device='cuda:1')
epoch:  78000 quantization_loss:  0.041410453617572784
p mean is: tensor(0.8082, device='cuda:1')
epoch:  79000 quantization_loss:  0.041497424244880676
p mean is: tensor(0.8085, device='cuda:1')
1.1.1.weight         | nonzeros =   11870 /   12800             ( 92.73%) | total_pruned =     930 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.2.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =    6268 /    6400             ( 97.94%) | total_pruned =     132 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.5.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =   12696 /   12800             ( 99.19%) | total_pruned =     104 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =   25445 /   25600             ( 99.39%) | total_pruned =     155 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =   51075 /   51200             ( 99.76%) | total_pruned =     125 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =  102174 /  102400             ( 99.78%) | total_pruned =     226 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =  204530 /  204800             ( 99.87%) | total_pruned =     270 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =  409231 /  409600             ( 99.91%) | total_pruned =     369 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  408657 /  409600             ( 99.77%) | total_pruned =     943 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  404391 /  409600             ( 98.73%) | total_pruned =    5209 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  394771 /  409600             ( 96.38%) | total_pruned =   14829 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  368997 /  409600             ( 90.09%) | total_pruned =   40603 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  120788 /  147456             ( 81.91%) | total_pruned =   26668 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  133951 /  147456             ( 90.84%) | total_pruned =   13505 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =  135050 /  147456             ( 91.59%) | total_pruned =   12406 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   65891 /   73728             ( 89.37%) | total_pruned =    7837 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =   16185 /   18432             ( 87.81%) | total_pruned =    2247 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      24 /      32             ( 75.00%) | total_pruned =       8 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    3432 /    4608             ( 74.48%) | total_pruned =    1176 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      14 /      16             ( 87.50%) | total_pruned =       2 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      20 /      48             ( 41.67%) | total_pruned =      28 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 2878213, pruned : 130654, total: 3008867, Compression rate :       1.05x  (  4.34% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  14.915743169594624
Experiment done
