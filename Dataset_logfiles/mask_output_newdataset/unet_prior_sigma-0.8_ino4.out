(3, 512, 512)
Noisy PSNR is '20.097504774727184'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Dataset/mask/4/unet/det/-0.8/1e-09
epoch:  0 quantization_loss:  0.04286996275186539
p mean is: tensor(-0.0002, device='cuda:2')
epoch:  1000 quantization_loss:  0.035354066640138626
p mean is: tensor(-0.0093, device='cuda:2')
epoch:  2000 quantization_loss:  0.03468313068151474
p mean is: tensor(-0.0170, device='cuda:2')
epoch:  3000 quantization_loss:  0.034603167325258255
p mean is: tensor(-0.0247, device='cuda:2')
epoch:  4000 quantization_loss:  0.034033503383398056
p mean is: tensor(-0.0325, device='cuda:2')
epoch:  5000 quantization_loss:  0.034114982932806015
p mean is: tensor(-0.0407, device='cuda:2')
epoch:  6000 quantization_loss:  0.03384703770279884
p mean is: tensor(-0.0500, device='cuda:2')
epoch:  7000 quantization_loss:  0.033906761556863785
p mean is: tensor(-0.0603, device='cuda:2')
epoch:  8000 quantization_loss:  0.0315280556678772
p mean is: tensor(-0.0712, device='cuda:2')
epoch:  9000 quantization_loss:  0.028622502461075783
p mean is: tensor(-0.0844, device='cuda:2')
epoch:  10000 quantization_loss:  0.02532115951180458
p mean is: tensor(-0.1008, device='cuda:2')
epoch:  11000 quantization_loss:  0.023064449429512024
p mean is: tensor(-0.1207, device='cuda:2')
epoch:  12000 quantization_loss:  0.021844804286956787
p mean is: tensor(-0.1453, device='cuda:2')
epoch:  13000 quantization_loss:  0.020925432443618774
p mean is: tensor(-0.1752, device='cuda:2')
epoch:  14000 quantization_loss:  0.020266560837626457
p mean is: tensor(-0.2108, device='cuda:2')
epoch:  15000 quantization_loss:  0.019756102934479713
p mean is: tensor(-0.2518, device='cuda:2')
epoch:  16000 quantization_loss:  0.0194211695343256
p mean is: tensor(-0.2968, device='cuda:2')
epoch:  17000 quantization_loss:  0.018593862652778625
p mean is: tensor(-0.3437, device='cuda:2')
epoch:  18000 quantization_loss:  0.018294205889105797
p mean is: tensor(-0.3901, device='cuda:2')
epoch:  19000 quantization_loss:  0.017864733934402466
p mean is: tensor(-0.4343, device='cuda:2')
epoch:  20000 quantization_loss:  0.017154207453131676
p mean is: tensor(-0.4751, device='cuda:2')
epoch:  21000 quantization_loss:  0.01695258542895317
p mean is: tensor(-0.5119, device='cuda:2')
epoch:  22000 quantization_loss:  0.01672365702688694
p mean is: tensor(-0.5447, device='cuda:2')
epoch:  23000 quantization_loss:  0.016497310250997543
p mean is: tensor(-0.5734, device='cuda:2')
epoch:  24000 quantization_loss:  0.01637374982237816
p mean is: tensor(-0.5987, device='cuda:2')
epoch:  25000 quantization_loss:  0.016162188723683357
p mean is: tensor(-0.6207, device='cuda:2')
epoch:  26000 quantization_loss:  0.0160144604742527
p mean is: tensor(-0.6397, device='cuda:2')
epoch:  27000 quantization_loss:  0.015914466232061386
p mean is: tensor(-0.6562, device='cuda:2')
epoch:  28000 quantization_loss:  0.01578211598098278
p mean is: tensor(-0.6705, device='cuda:2')
epoch:  29000 quantization_loss:  0.015680355951189995
p mean is: tensor(-0.6829, device='cuda:2')
epoch:  30000 quantization_loss:  0.01559778954833746
p mean is: tensor(-0.6938, device='cuda:2')
epoch:  31000 quantization_loss:  0.015466418117284775
p mean is: tensor(-0.7031, device='cuda:2')
epoch:  32000 quantization_loss:  0.015417804941534996
p mean is: tensor(-0.7114, device='cuda:2')
epoch:  33000 quantization_loss:  0.015313616953790188
p mean is: tensor(-0.7186, device='cuda:2')
epoch:  34000 quantization_loss:  0.015270180068910122
p mean is: tensor(-0.7249, device='cuda:2')
epoch:  35000 quantization_loss:  0.015226803719997406
p mean is: tensor(-0.7305, device='cuda:2')
epoch:  36000 quantization_loss:  0.015158659778535366
p mean is: tensor(-0.7354, device='cuda:2')
epoch:  37000 quantization_loss:  0.015098108910024166
p mean is: tensor(-0.7399, device='cuda:2')
epoch:  38000 quantization_loss:  0.015059496276080608
p mean is: tensor(-0.7438, device='cuda:2')
epoch:  39000 quantization_loss:  0.015036865137517452
p mean is: tensor(-0.7474, device='cuda:2')
epoch:  40000 quantization_loss:  0.01502027828246355
p mean is: tensor(-0.7507, device='cuda:2')
epoch:  41000 quantization_loss:  0.014958546496927738
p mean is: tensor(-0.7537, device='cuda:2')
epoch:  42000 quantization_loss:  0.014958279207348824
p mean is: tensor(-0.7564, device='cuda:2')
epoch:  43000 quantization_loss:  0.01492149569094181
p mean is: tensor(-0.7588, device='cuda:2')
epoch:  44000 quantization_loss:  0.01490824669599533
p mean is: tensor(-0.7611, device='cuda:2')
epoch:  45000 quantization_loss:  0.0148800453171134
p mean is: tensor(-0.7632, device='cuda:2')
epoch:  46000 quantization_loss:  0.014843816868960857
p mean is: tensor(-0.7652, device='cuda:2')
epoch:  47000 quantization_loss:  0.014826645143330097
p mean is: tensor(-0.7670, device='cuda:2')
epoch:  48000 quantization_loss:  0.014814317226409912
p mean is: tensor(-0.7686, device='cuda:2')
epoch:  49000 quantization_loss:  0.014810582622885704
p mean is: tensor(-0.7702, device='cuda:2')
epoch:  50000 quantization_loss:  0.014792470261454582
p mean is: tensor(-0.7717, device='cuda:2')
epoch:  51000 quantization_loss:  0.014780323952436447
p mean is: tensor(-0.7731, device='cuda:2')
epoch:  52000 quantization_loss:  0.014768657274544239
p mean is: tensor(-0.7744, device='cuda:2')
epoch:  53000 quantization_loss:  0.014768325723707676
p mean is: tensor(-0.7758, device='cuda:2')
epoch:  54000 quantization_loss:  0.014546963386237621
p mean is: tensor(-0.7770, device='cuda:2')
epoch:  55000 quantization_loss:  0.014500418677926064
p mean is: tensor(-0.7781, device='cuda:2')
epoch:  56000 quantization_loss:  0.014473841525614262
p mean is: tensor(-0.7792, device='cuda:2')
epoch:  57000 quantization_loss:  0.014467946253716946
p mean is: tensor(-0.7803, device='cuda:2')
epoch:  58000 quantization_loss:  0.014455337077379227
p mean is: tensor(-0.7813, device='cuda:2')
epoch:  59000 quantization_loss:  0.014434345066547394
p mean is: tensor(-0.7823, device='cuda:2')
epoch:  60000 quantization_loss:  0.014431553892791271
p mean is: tensor(-0.7833, device='cuda:2')
epoch:  61000 quantization_loss:  0.014422412030398846
p mean is: tensor(-0.7842, device='cuda:2')
epoch:  62000 quantization_loss:  0.014413473196327686
p mean is: tensor(-0.7852, device='cuda:2')
epoch:  63000 quantization_loss:  0.014393790625035763
p mean is: tensor(-0.7861, device='cuda:2')
epoch:  64000 quantization_loss:  0.014396050944924355
p mean is: tensor(-0.7870, device='cuda:2')
epoch:  65000 quantization_loss:  0.014392906799912453
p mean is: tensor(-0.7878, device='cuda:2')
epoch:  66000 quantization_loss:  0.014388149604201317
p mean is: tensor(-0.7886, device='cuda:2')
epoch:  67000 quantization_loss:  0.014373288489878178
p mean is: tensor(-0.7895, device='cuda:2')
epoch:  68000 quantization_loss:  0.01437144260853529
p mean is: tensor(-0.7903, device='cuda:2')
epoch:  69000 quantization_loss:  0.014371691271662712
p mean is: tensor(-0.7910, device='cuda:2')
epoch:  70000 quantization_loss:  0.014363731257617474
p mean is: tensor(-0.7918, device='cuda:2')
epoch:  71000 quantization_loss:  0.014360920526087284
p mean is: tensor(-0.7925, device='cuda:2')
epoch:  72000 quantization_loss:  0.014360428787767887
p mean is: tensor(-0.7932, device='cuda:2')
epoch:  73000 quantization_loss:  0.014356192201375961
p mean is: tensor(-0.7939, device='cuda:2')
epoch:  74000 quantization_loss:  0.014345920644700527
p mean is: tensor(-0.7945, device='cuda:2')
epoch:  75000 quantization_loss:  0.014352022670209408
p mean is: tensor(-0.7952, device='cuda:2')
epoch:  76000 quantization_loss:  0.014347939752042294
p mean is: tensor(-0.7959, device='cuda:2')
epoch:  77000 quantization_loss:  0.014338470064103603
p mean is: tensor(-0.7965, device='cuda:2')
epoch:  78000 quantization_loss:  0.014341514557600021
p mean is: tensor(-0.7972, device='cuda:2')
epoch:  79000 quantization_loss:  0.014336694963276386
p mean is: tensor(-0.7978, device='cuda:2')
1.1.1.weight         | nonzeros =    1192 /   12800             (  9.31%) | total_pruned =   11608 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     140 /    6400             (  2.19%) | total_pruned =    6260 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     120 /   12800             (  0.94%) | total_pruned =   12680 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      10 /      32             ( 31.25%) | total_pruned =      22 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     291 /   25600             (  1.14%) | total_pruned =   25309 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      12 /      32             ( 37.50%) | total_pruned =      20 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     340 /   51200             (  0.66%) | total_pruned =   50860 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     482 /  102400             (  0.47%) | total_pruned =  101918 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     348 /  204800             (  0.17%) | total_pruned =  204452 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =    1022 /  409600             (  0.25%) | total_pruned =  408578 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    1322 /  409600             (  0.32%) | total_pruned =  408278 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    5676 /  409600             (  1.39%) | total_pruned =  403924 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   16840 /  409600             (  4.11%) | total_pruned =  392760 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   40569 /  409600             (  9.90%) | total_pruned =  369031 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   30410 /  147456             ( 20.62%) | total_pruned =  117046 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   30803 /  147456             ( 20.89%) | total_pruned =  116653 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   26943 /  147456             ( 18.27%) | total_pruned =  120513 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   13494 /   73728             ( 18.30%) | total_pruned =   60234 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    3422 /   18432             ( 18.57%) | total_pruned =   15010 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1251 /    4608             ( 27.15%) | total_pruned =    3357 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      27 /      48             ( 56.25%) | total_pruned =      21 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 176008, pruned : 2832859, total: 3008867, Compression rate :      17.10x  ( 94.15% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  23.220069644151998
Experiment done
