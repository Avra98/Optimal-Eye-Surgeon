(3, 512, 512)
Noisy PSNR is '20.413884008014037'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Dataset/mask/1/unet/det/-1.3/1e-09
epoch:  0 quantization_loss:  0.10898083448410034
p mean is: tensor(-0.0002, device='cuda:0')
epoch:  1000 quantization_loss:  0.06469134241342545
p mean is: tensor(-0.0154, device='cuda:0')
epoch:  2000 quantization_loss:  0.06521223485469818
p mean is: tensor(-0.0266, device='cuda:0')
epoch:  3000 quantization_loss:  0.05820741876959801
p mean is: tensor(-0.0372, device='cuda:0')
epoch:  4000 quantization_loss:  0.05841495096683502
p mean is: tensor(-0.0475, device='cuda:0')
epoch:  5000 quantization_loss:  0.056641869246959686
p mean is: tensor(-0.0573, device='cuda:0')
epoch:  6000 quantization_loss:  0.055775005370378494
p mean is: tensor(-0.0683, device='cuda:0')
epoch:  7000 quantization_loss:  0.05540059506893158
p mean is: tensor(-0.0809, device='cuda:0')
epoch:  8000 quantization_loss:  0.05506815388798714
p mean is: tensor(-0.0968, device='cuda:0')
epoch:  9000 quantization_loss:  0.05490086227655411
p mean is: tensor(-0.1179, device='cuda:0')
epoch:  10000 quantization_loss:  0.0548485666513443
p mean is: tensor(-0.1459, device='cuda:0')
epoch:  11000 quantization_loss:  0.05470963194966316
p mean is: tensor(-0.1822, device='cuda:0')
epoch:  12000 quantization_loss:  0.05429467558860779
p mean is: tensor(-0.2260, device='cuda:0')
epoch:  13000 quantization_loss:  0.053894802927970886
p mean is: tensor(-0.2771, device='cuda:0')
epoch:  14000 quantization_loss:  0.053657498210668564
p mean is: tensor(-0.3374, device='cuda:0')
epoch:  15000 quantization_loss:  0.05341394990682602
p mean is: tensor(-0.4074, device='cuda:0')
epoch:  16000 quantization_loss:  0.05298719182610512
p mean is: tensor(-0.4834, device='cuda:0')
epoch:  17000 quantization_loss:  0.053042564541101456
p mean is: tensor(-0.5618, device='cuda:0')
epoch:  18000 quantization_loss:  0.05258535221219063
p mean is: tensor(-0.6407, device='cuda:0')
epoch:  19000 quantization_loss:  0.05250997096300125
p mean is: tensor(-0.7176, device='cuda:0')
epoch:  20000 quantization_loss:  0.0523122139275074
p mean is: tensor(-0.7900, device='cuda:0')
epoch:  21000 quantization_loss:  0.052204232662916183
p mean is: tensor(-0.8559, device='cuda:0')
epoch:  22000 quantization_loss:  0.05212738364934921
p mean is: tensor(-0.9144, device='cuda:0')
epoch:  23000 quantization_loss:  0.05208183079957962
p mean is: tensor(-0.9654, device='cuda:0')
epoch:  24000 quantization_loss:  0.05200650915503502
p mean is: tensor(-1.0094, device='cuda:0')
epoch:  25000 quantization_loss:  0.05198939889669418
p mean is: tensor(-1.0472, device='cuda:0')
epoch:  26000 quantization_loss:  0.051918406039476395
p mean is: tensor(-1.0798, device='cuda:0')
epoch:  27000 quantization_loss:  0.05185481160879135
p mean is: tensor(-1.1079, device='cuda:0')
epoch:  28000 quantization_loss:  0.05182843655347824
p mean is: tensor(-1.1322, device='cuda:0')
epoch:  29000 quantization_loss:  0.05130957439541817
p mean is: tensor(-1.1531, device='cuda:0')
epoch:  30000 quantization_loss:  0.05126409977674484
p mean is: tensor(-1.1711, device='cuda:0')
epoch:  31000 quantization_loss:  0.051242370158433914
p mean is: tensor(-1.1868, device='cuda:0')
epoch:  32000 quantization_loss:  0.05119313299655914
p mean is: tensor(-1.2006, device='cuda:0')
epoch:  33000 quantization_loss:  0.05117317661643028
p mean is: tensor(-1.2125, device='cuda:0')
epoch:  34000 quantization_loss:  0.05115242302417755
p mean is: tensor(-1.2230, device='cuda:0')
epoch:  35000 quantization_loss:  0.05112883076071739
p mean is: tensor(-1.2322, device='cuda:0')
epoch:  36000 quantization_loss:  0.05109454318881035
p mean is: tensor(-1.2403, device='cuda:0')
epoch:  37000 quantization_loss:  0.05108515918254852
p mean is: tensor(-1.2476, device='cuda:0')
epoch:  38000 quantization_loss:  0.05065663903951645
p mean is: tensor(-1.2537, device='cuda:0')
epoch:  39000 quantization_loss:  0.05059792101383209
p mean is: tensor(-1.2592, device='cuda:0')
epoch:  40000 quantization_loss:  0.05055531486868858
p mean is: tensor(-1.2640, device='cuda:0')
epoch:  41000 quantization_loss:  0.05052819848060608
p mean is: tensor(-1.2685, device='cuda:0')
epoch:  42000 quantization_loss:  0.05052805319428444
p mean is: tensor(-1.2725, device='cuda:0')
epoch:  43000 quantization_loss:  0.050520267337560654
p mean is: tensor(-1.2762, device='cuda:0')
epoch:  44000 quantization_loss:  0.05050724372267723
p mean is: tensor(-1.2794, device='cuda:0')
epoch:  45000 quantization_loss:  0.0504147931933403
p mean is: tensor(-1.2824, device='cuda:0')
epoch:  46000 quantization_loss:  0.05035598948597908
p mean is: tensor(-1.2851, device='cuda:0')
epoch:  47000 quantization_loss:  0.050344716757535934
p mean is: tensor(-1.2875, device='cuda:0')
epoch:  48000 quantization_loss:  0.05028148368000984
p mean is: tensor(-1.2897, device='cuda:0')
epoch:  49000 quantization_loss:  0.05028203874826431
p mean is: tensor(-1.2919, device='cuda:0')
epoch:  50000 quantization_loss:  0.05029914528131485
p mean is: tensor(-1.2939, device='cuda:0')
epoch:  51000 quantization_loss:  0.05027451738715172
p mean is: tensor(-1.2957, device='cuda:0')
epoch:  52000 quantization_loss:  0.05025041103363037
p mean is: tensor(-1.2975, device='cuda:0')
epoch:  53000 quantization_loss:  0.05023908615112305
p mean is: tensor(-1.2991, device='cuda:0')
epoch:  54000 quantization_loss:  0.05027272552251816
p mean is: tensor(-1.3006, device='cuda:0')
epoch:  55000 quantization_loss:  0.05007649213075638
p mean is: tensor(-1.3020, device='cuda:0')
epoch:  56000 quantization_loss:  0.05007506534457207
p mean is: tensor(-1.3033, device='cuda:0')
epoch:  57000 quantization_loss:  0.050069794058799744
p mean is: tensor(-1.3045, device='cuda:0')
epoch:  58000 quantization_loss:  0.05005882307887077
p mean is: tensor(-1.3057, device='cuda:0')
epoch:  59000 quantization_loss:  0.05005017668008804
p mean is: tensor(-1.3068, device='cuda:0')
epoch:  60000 quantization_loss:  0.05005162954330444
p mean is: tensor(-1.3079, device='cuda:0')
epoch:  61000 quantization_loss:  0.05004141479730606
p mean is: tensor(-1.3090, device='cuda:0')
epoch:  62000 quantization_loss:  0.050031598657369614
p mean is: tensor(-1.3101, device='cuda:0')
epoch:  63000 quantization_loss:  0.050030726939439774
p mean is: tensor(-1.3111, device='cuda:0')
epoch:  64000 quantization_loss:  0.05002161115407944
p mean is: tensor(-1.3120, device='cuda:0')
epoch:  65000 quantization_loss:  0.050019100308418274
p mean is: tensor(-1.3129, device='cuda:0')
epoch:  66000 quantization_loss:  0.05001726746559143
p mean is: tensor(-1.3138, device='cuda:0')
epoch:  67000 quantization_loss:  0.05003126710653305
p mean is: tensor(-1.3147, device='cuda:0')
epoch:  68000 quantization_loss:  0.050013162195682526
p mean is: tensor(-1.3155, device='cuda:0')
epoch:  69000 quantization_loss:  0.05000997334718704
p mean is: tensor(-1.3163, device='cuda:0')
epoch:  70000 quantization_loss:  0.05000561848282814
p mean is: tensor(-1.3170, device='cuda:0')
epoch:  71000 quantization_loss:  0.05000237002968788
p mean is: tensor(-1.3178, device='cuda:0')
epoch:  72000 quantization_loss:  0.04999743402004242
p mean is: tensor(-1.3185, device='cuda:0')
epoch:  73000 quantization_loss:  0.049997396767139435
p mean is: tensor(-1.3193, device='cuda:0')
epoch:  74000 quantization_loss:  0.04999455064535141
p mean is: tensor(-1.3200, device='cuda:0')
epoch:  75000 quantization_loss:  0.04999685287475586
p mean is: tensor(-1.3207, device='cuda:0')
epoch:  76000 quantization_loss:  0.04999672621488571
p mean is: tensor(-1.3214, device='cuda:0')
epoch:  77000 quantization_loss:  0.04999159649014473
p mean is: tensor(-1.3221, device='cuda:0')
epoch:  78000 quantization_loss:  0.04997417703270912
p mean is: tensor(-1.3227, device='cuda:0')
epoch:  79000 quantization_loss:  0.04999278485774994
p mean is: tensor(-1.3233, device='cuda:0')
1.1.1.weight         | nonzeros =     492 /   12800             (  3.84%) | total_pruned =   12308 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       5 /      16             ( 31.25%) | total_pruned =      11 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =      75 /    6400             (  1.17%) | total_pruned =    6325 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      34 /   12800             (  0.27%) | total_pruned =   12766 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      12 /      32             ( 37.50%) | total_pruned =      20 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =      84 /   25600             (  0.33%) | total_pruned =   25516 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      10 /      32             ( 31.25%) | total_pruned =      22 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =      34 /   51200             (  0.07%) | total_pruned =   51166 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =      63 /  102400             (  0.06%) | total_pruned =  102337 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =       0 /  204800             (  0.00%) | total_pruned =  204800 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      49 /     128             ( 38.28%) | total_pruned =      79 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =       2 /  409600             (  0.00%) | total_pruned =  409598 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =       7 /  409600             (  0.00%) | total_pruned =  409593 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    1065 /  409600             (  0.26%) | total_pruned =  408535 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    3694 /  409600             (  0.90%) | total_pruned =  405906 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   15091 /  409600             (  3.68%) | total_pruned =  394509 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   14720 /  147456             (  9.98%) | total_pruned =  132736 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =    9339 /  147456             (  6.33%) | total_pruned =  138117 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =    7385 /  147456             (  5.01%) | total_pruned =  140071 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    4663 /   73728             (  6.32%) | total_pruned =   69065 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2173 /   18432             ( 11.79%) | total_pruned =   16259 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1342 /    4608             ( 29.12%) | total_pruned =    3266 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      15 /      16             ( 93.75%) | total_pruned =       1 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      24 /      48             ( 50.00%) | total_pruned =      24 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 61289, pruned : 2947578, total: 3008867, Compression rate :      49.09x  ( 97.96% pruned)
(3, 512, 512) (3, 512, 512) (3, 512, 512)
PSNR of output image is:  10.74832903327768
Experiment done
