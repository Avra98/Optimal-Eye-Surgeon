(3, 256, 256)
Noisy PSNR is '20.12100082627045'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Starting optimization with optimizer 'SAM'
Output directory: data/denoising/Dataset/mask/0/sparsity/unet/det/0.03/1e-09
epoch:  0 quantization_loss:  0.058529745787382126
p mean is: tensor(-0.0006, device='cuda:1')
epoch:  1000 quantization_loss:  0.05495188385248184
p mean is: tensor(-0.0168, device='cuda:1')
epoch:  2000 quantization_loss:  0.053933631628751755
p mean is: tensor(-0.0315, device='cuda:1')
epoch:  3000 quantization_loss:  0.054269950836896896
p mean is: tensor(-0.0482, device='cuda:1')
epoch:  4000 quantization_loss:  0.054111048579216
p mean is: tensor(-0.0671, device='cuda:1')
epoch:  5000 quantization_loss:  0.05434379726648331
p mean is: tensor(-0.0873, device='cuda:1')
epoch:  6000 quantization_loss:  0.05470781400799751
p mean is: tensor(-0.1081, device='cuda:1')
epoch:  7000 quantization_loss:  0.054100826382637024
p mean is: tensor(-0.1295, device='cuda:1')
epoch:  8000 quantization_loss:  0.054154444485902786
p mean is: tensor(-0.1515, device='cuda:1')
epoch:  9000 quantization_loss:  0.054107118397951126
p mean is: tensor(-0.1735, device='cuda:1')
epoch:  10000 quantization_loss:  0.053845927119255066
p mean is: tensor(-0.1952, device='cuda:1')
epoch:  11000 quantization_loss:  0.05343111976981163
p mean is: tensor(-0.2171, device='cuda:1')
epoch:  12000 quantization_loss:  0.05369357764720917
p mean is: tensor(-0.2384, device='cuda:1')
epoch:  13000 quantization_loss:  0.0541025809943676
p mean is: tensor(-0.2595, device='cuda:1')
epoch:  14000 quantization_loss:  0.05424157902598381
p mean is: tensor(-0.2796, device='cuda:1')
epoch:  15000 quantization_loss:  0.047235213220119476
p mean is: tensor(-0.2973, device='cuda:1')
epoch:  16000 quantization_loss:  0.035424694418907166
p mean is: tensor(-0.3159, device='cuda:1')
epoch:  17000 quantization_loss:  0.03221100941300392
p mean is: tensor(-0.3408, device='cuda:1')
epoch:  18000 quantization_loss:  0.03102485090494156
p mean is: tensor(-0.3752, device='cuda:1')
epoch:  19000 quantization_loss:  0.030600719153881073
p mean is: tensor(-0.4228, device='cuda:1')
epoch:  20000 quantization_loss:  0.029714951291680336
p mean is: tensor(-0.4871, device='cuda:1')
epoch:  21000 quantization_loss:  0.02300170250236988
p mean is: tensor(-0.5701, device='cuda:1')
epoch:  22000 quantization_loss:  0.021783169358968735
p mean is: tensor(-0.6734, device='cuda:1')
epoch:  23000 quantization_loss:  0.0206375140696764
p mean is: tensor(-0.7982, device='cuda:1')
epoch:  24000 quantization_loss:  0.019863057881593704
p mean is: tensor(-0.9435, device='cuda:1')
epoch:  25000 quantization_loss:  0.019412610679864883
p mean is: tensor(-1.1041, device='cuda:1')
epoch:  26000 quantization_loss:  0.018394509330391884
p mean is: tensor(-1.2720, device='cuda:1')
epoch:  27000 quantization_loss:  0.017932159826159477
p mean is: tensor(-1.4375, device='cuda:1')
epoch:  28000 quantization_loss:  0.01705039292573929
p mean is: tensor(-1.5925, device='cuda:1')
epoch:  29000 quantization_loss:  0.015246860682964325
p mean is: tensor(-1.7326, device='cuda:1')
epoch:  30000 quantization_loss:  0.014622118324041367
p mean is: tensor(-1.8559, device='cuda:1')
epoch:  31000 quantization_loss:  0.014055736362934113
p mean is: tensor(-1.9645, device='cuda:1')
epoch:  32000 quantization_loss:  0.013548861257731915
p mean is: tensor(-2.0603, device='cuda:1')
epoch:  33000 quantization_loss:  0.013366962783038616
p mean is: tensor(-2.1460, device='cuda:1')
epoch:  34000 quantization_loss:  0.013183504343032837
p mean is: tensor(-2.2229, device='cuda:1')
epoch:  35000 quantization_loss:  0.013250894844532013
p mean is: tensor(-2.2928, device='cuda:1')
epoch:  36000 quantization_loss:  0.01300015952438116
p mean is: tensor(-2.3562, device='cuda:1')
epoch:  37000 quantization_loss:  0.012895140796899796
p mean is: tensor(-2.4142, device='cuda:1')
epoch:  38000 quantization_loss:  0.01279539242386818
p mean is: tensor(-2.4674, device='cuda:1')
epoch:  39000 quantization_loss:  0.0126759959384799
p mean is: tensor(-2.5163, device='cuda:1')
epoch:  40000 quantization_loss:  0.012630324810743332
p mean is: tensor(-2.5616, device='cuda:1')
epoch:  41000 quantization_loss:  0.012583750300109386
p mean is: tensor(-2.6035, device='cuda:1')
epoch:  42000 quantization_loss:  0.012507875449955463
p mean is: tensor(-2.6424, device='cuda:1')
epoch:  43000 quantization_loss:  0.01248112041503191
p mean is: tensor(-2.6786, device='cuda:1')
epoch:  44000 quantization_loss:  0.01243199035525322
p mean is: tensor(-2.7124, device='cuda:1')
epoch:  45000 quantization_loss:  0.012411316856741905
p mean is: tensor(-2.7441, device='cuda:1')
epoch:  46000 quantization_loss:  0.012362058274447918
p mean is: tensor(-2.7738, device='cuda:1')
epoch:  47000 quantization_loss:  0.012308070436120033
p mean is: tensor(-2.8018, device='cuda:1')
epoch:  48000 quantization_loss:  0.012277556583285332
p mean is: tensor(-2.8281, device='cuda:1')
epoch:  49000 quantization_loss:  0.012254985980689526
p mean is: tensor(-2.8528, device='cuda:1')
epoch:  50000 quantization_loss:  0.012230494990944862
p mean is: tensor(-2.8762, device='cuda:1')
epoch:  51000 quantization_loss:  0.012213892303407192
p mean is: tensor(-2.8984, device='cuda:1')
epoch:  52000 quantization_loss:  0.012180667370557785
p mean is: tensor(-2.9194, device='cuda:1')
epoch:  53000 quantization_loss:  0.01216082088649273
p mean is: tensor(-2.9388, device='cuda:1')
epoch:  54000 quantization_loss:  0.012157417833805084
p mean is: tensor(-2.9569, device='cuda:1')
epoch:  55000 quantization_loss:  0.012140522710978985
p mean is: tensor(-2.9741, device='cuda:1')
epoch:  56000 quantization_loss:  0.012138500809669495
p mean is: tensor(-2.9906, device='cuda:1')
epoch:  57000 quantization_loss:  0.01211183238774538
p mean is: tensor(-3.0064, device='cuda:1')
epoch:  58000 quantization_loss:  0.01209400873631239
p mean is: tensor(-3.0216, device='cuda:1')
epoch:  59000 quantization_loss:  0.012090297415852547
p mean is: tensor(-3.0361, device='cuda:1')
Number of elements to keep: 90266
Threshold value: -2.0540027618408203
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.029999996676489855
Number of elements to keep: 90266
Threshold value: -2.0540027618408203
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.029999996676489855
1.1.1.weight         | nonzeros =     421 /   12800             (  3.29%) | total_pruned =   12379 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =      70 /    6400             (  1.09%) | total_pruned =    6330 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      56 /   12800             (  0.44%) | total_pruned =   12744 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =      85 /   25600             (  0.33%) | total_pruned =   25515 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     131 /   51200             (  0.26%) | total_pruned =   51069 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     227 /  102400             (  0.22%) | total_pruned =  102173 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     325 /  204800             (  0.16%) | total_pruned =  204475 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     699 /  409600             (  0.17%) | total_pruned =  408901 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    1261 /  409600             (  0.31%) | total_pruned =  408339 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    2466 /  409600             (  0.60%) | total_pruned =  407134 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    6212 /  409600             (  1.52%) | total_pruned =  403388 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   13184 /  409600             (  3.22%) | total_pruned =  396416 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   14213 /  147456             (  9.64%) | total_pruned =  133243 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   18265 /  147456             ( 12.39%) | total_pruned =  129191 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   19487 /  147456             ( 13.22%) | total_pruned =  127969 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    8621 /   73728             ( 11.69%) | total_pruned =   65107 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2323 /   18432             ( 12.60%) | total_pruned =   16109 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1063 /    4608             ( 23.07%) | total_pruned =    3545 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      33 /      48             ( 68.75%) | total_pruned =      15 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 90266, pruned : 2918601, total: 3008867, Compression rate :      33.33x  ( 97.00% pruned)
(3, 256, 256) (3, 256, 256) (3, 256, 256)
PSNR of output image is:  26.005515895150182
Experiment done
