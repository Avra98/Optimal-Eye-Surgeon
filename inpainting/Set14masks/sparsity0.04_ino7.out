(3, 256, 256)
(3, 256, 256)
Noisy PSNR is '7.360955016302153'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Output directory: data/inpainting/Set14/mask/7/sparsity/0.5/det/0.04/1e-09
epoch:  0 quantization_loss:  0.036936402320861816
p mean is: tensor(-0.0002, device='cuda:5')
epoch:  1000 quantization_loss:  0.0323953814804554
p mean is: tensor(-0.0109, device='cuda:5')
epoch:  2000 quantization_loss:  0.031921807676553726
p mean is: tensor(-0.0190, device='cuda:5')
epoch:  3000 quantization_loss:  0.03170352801680565
p mean is: tensor(-0.0267, device='cuda:5')
epoch:  4000 quantization_loss:  0.03202451020479202
p mean is: tensor(-0.0346, device='cuda:5')
epoch:  5000 quantization_loss:  0.03179531916975975
p mean is: tensor(-0.0428, device='cuda:5')
epoch:  6000 quantization_loss:  0.03175234794616699
p mean is: tensor(-0.0510, device='cuda:5')
epoch:  7000 quantization_loss:  0.03159220889210701
p mean is: tensor(-0.0593, device='cuda:5')
epoch:  8000 quantization_loss:  0.03187203034758568
p mean is: tensor(-0.0680, device='cuda:5')
epoch:  9000 quantization_loss:  0.03157101944088936
p mean is: tensor(-0.0768, device='cuda:5')
epoch:  10000 quantization_loss:  0.03176744654774666
p mean is: tensor(-0.0860, device='cuda:5')
epoch:  11000 quantization_loss:  0.031198911368846893
p mean is: tensor(-0.0957, device='cuda:5')
epoch:  12000 quantization_loss:  0.03160393238067627
p mean is: tensor(-0.1053, device='cuda:5')
epoch:  13000 quantization_loss:  0.031646162271499634
p mean is: tensor(-0.1152, device='cuda:5')
epoch:  14000 quantization_loss:  0.031315743923187256
p mean is: tensor(-0.1251, device='cuda:5')
epoch:  15000 quantization_loss:  0.031864363700151443
p mean is: tensor(-0.1352, device='cuda:5')
epoch:  16000 quantization_loss:  0.03131799399852753
p mean is: tensor(-0.1453, device='cuda:5')
epoch:  17000 quantization_loss:  0.029441475868225098
p mean is: tensor(-0.1552, device='cuda:5')
epoch:  18000 quantization_loss:  0.026029756292700768
p mean is: tensor(-0.1662, device='cuda:5')
epoch:  19000 quantization_loss:  0.022260291501879692
p mean is: tensor(-0.1806, device='cuda:5')
epoch:  20000 quantization_loss:  0.01902739517390728
p mean is: tensor(-0.1998, device='cuda:5')
epoch:  21000 quantization_loss:  0.017774362117052078
p mean is: tensor(-0.2251, device='cuda:5')
epoch:  22000 quantization_loss:  0.01671813800930977
p mean is: tensor(-0.2584, device='cuda:5')
epoch:  23000 quantization_loss:  0.015871252864599228
p mean is: tensor(-0.3008, device='cuda:5')
epoch:  24000 quantization_loss:  0.014368338510394096
p mean is: tensor(-0.3533, device='cuda:5')
epoch:  25000 quantization_loss:  0.013645708560943604
p mean is: tensor(-0.4156, device='cuda:5')
epoch:  26000 quantization_loss:  0.012365194037556648
p mean is: tensor(-0.4859, device='cuda:5')
epoch:  27000 quantization_loss:  0.01186263095587492
p mean is: tensor(-0.5612, device='cuda:5')
epoch:  28000 quantization_loss:  0.011553955264389515
p mean is: tensor(-0.6376, device='cuda:5')
epoch:  29000 quantization_loss:  0.011294460855424404
p mean is: tensor(-0.7117, device='cuda:5')
epoch:  30000 quantization_loss:  0.01085093803703785
p mean is: tensor(-0.7809, device='cuda:5')
epoch:  31000 quantization_loss:  0.010612095706164837
p mean is: tensor(-0.8432, device='cuda:5')
epoch:  32000 quantization_loss:  0.010488376021385193
p mean is: tensor(-0.8985, device='cuda:5')
epoch:  33000 quantization_loss:  0.010143239982426167
p mean is: tensor(-0.9469, device='cuda:5')
epoch:  34000 quantization_loss:  0.00995970331132412
p mean is: tensor(-0.9888, device='cuda:5')
epoch:  35000 quantization_loss:  0.009745337069034576
p mean is: tensor(-1.0250, device='cuda:5')
epoch:  36000 quantization_loss:  0.009163828566670418
p mean is: tensor(-1.0560, device='cuda:5')
epoch:  37000 quantization_loss:  0.008553491905331612
p mean is: tensor(-1.0825, device='cuda:5')
epoch:  38000 quantization_loss:  0.008307977579534054
p mean is: tensor(-1.1052, device='cuda:5')
epoch:  39000 quantization_loss:  0.008212548680603504
p mean is: tensor(-1.1247, device='cuda:5')
epoch:  40000 quantization_loss:  0.008101167157292366
p mean is: tensor(-1.1415, device='cuda:5')
epoch:  41000 quantization_loss:  0.008097309619188309
p mean is: tensor(-1.1560, device='cuda:5')
epoch:  42000 quantization_loss:  0.007916496135294437
p mean is: tensor(-1.1687, device='cuda:5')
epoch:  43000 quantization_loss:  0.00808759219944477
p mean is: tensor(-1.1796, device='cuda:5')
epoch:  44000 quantization_loss:  0.007761337328702211
p mean is: tensor(-1.1891, device='cuda:5')
epoch:  45000 quantization_loss:  0.007717794273048639
p mean is: tensor(-1.1973, device='cuda:5')
epoch:  46000 quantization_loss:  0.007705672178417444
p mean is: tensor(-1.2046, device='cuda:5')
epoch:  47000 quantization_loss:  0.007633357308804989
p mean is: tensor(-1.2108, device='cuda:5')
epoch:  48000 quantization_loss:  0.007574922870844603
p mean is: tensor(-1.2163, device='cuda:5')
epoch:  49000 quantization_loss:  0.007558134850114584
p mean is: tensor(-1.2212, device='cuda:5')
epoch:  50000 quantization_loss:  0.007521481718868017
p mean is: tensor(-1.2255, device='cuda:5')
epoch:  51000 quantization_loss:  0.0074884118512272835
p mean is: tensor(-1.2292, device='cuda:5')
epoch:  52000 quantization_loss:  0.007455641869455576
p mean is: tensor(-1.2326, device='cuda:5')
epoch:  53000 quantization_loss:  0.007429840043187141
p mean is: tensor(-1.2355, device='cuda:5')
epoch:  54000 quantization_loss:  0.007418310735374689
p mean is: tensor(-1.2382, device='cuda:5')
epoch:  55000 quantization_loss:  0.0074015334248542786
p mean is: tensor(-1.2406, device='cuda:5')
epoch:  56000 quantization_loss:  0.007372742053121328
p mean is: tensor(-1.2427, device='cuda:5')
epoch:  57000 quantization_loss:  0.00735732214525342
p mean is: tensor(-1.2447, device='cuda:5')
epoch:  58000 quantization_loss:  0.007340127602219582
p mean is: tensor(-1.2464, device='cuda:5')
epoch:  59000 quantization_loss:  0.007333514280617237
p mean is: tensor(-1.2480, device='cuda:5')
Number of elements to keep: 120354
Threshold value: -0.5079565644264221
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.03999977400131013
here
Number of elements to keep: 150443
Threshold value: -0.8246816396713257
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
1.1.1.weight         | nonzeros =     587 /   12800             (  4.59%) | total_pruned =   12213 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     113 /    6400             (  1.77%) | total_pruned =    6287 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      58 /   12800             (  0.45%) | total_pruned =   12742 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      13 /      32             ( 40.62%) | total_pruned =      19 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =      73 /   25600             (  0.29%) | total_pruned =   25527 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =      73 /   51200             (  0.14%) | total_pruned =   51127 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     129 /  102400             (  0.13%) | total_pruned =  102271 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     117 /  204800             (  0.06%) | total_pruned =  204683 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     196 /  409600             (  0.05%) | total_pruned =  409404 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     485 /  409600             (  0.12%) | total_pruned =  409115 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    1977 /  409600             (  0.48%) | total_pruned =  407623 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    7180 /  409600             (  1.75%) | total_pruned =  402420 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   21289 /  409600             (  5.20%) | total_pruned =  388311 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   19185 /  147456             ( 13.01%) | total_pruned =  128271 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   24388 /  147456             ( 16.54%) | total_pruned =  123068 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   23953 /  147456             ( 16.24%) | total_pruned =  123503 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   13625 /   73728             ( 18.48%) | total_pruned =   60103 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    4224 /   18432             ( 22.92%) | total_pruned =   14208 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      24 /      32             ( 75.00%) | total_pruned =       8 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      24 /      32             ( 75.00%) | total_pruned =       8 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1500 /    4608             ( 32.55%) | total_pruned =    3108 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      33 /      48             ( 68.75%) | total_pruned =      15 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 120354, pruned : 2888513, total: 3008867, Compression rate :      25.00x  ( 96.00% pruned)
PSNR of output image is:  18.080040747787116
Experiment done
