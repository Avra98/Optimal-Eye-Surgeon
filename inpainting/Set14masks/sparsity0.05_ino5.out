(3, 512, 512)
(3, 512, 512)
Noisy PSNR is '8.289330126733157'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Output directory: data/inpainting/Set14/mask/5/sparsity/0.5/det/0.05/1e-09
epoch:  0 quantization_loss:  0.03588957339525223
p mean is: tensor(-0.0002, device='cuda:5')
epoch:  1000 quantization_loss:  0.029610849916934967
p mean is: tensor(-0.0154, device='cuda:5')
epoch:  2000 quantization_loss:  0.029562409967184067
p mean is: tensor(-0.0282, device='cuda:5')
epoch:  3000 quantization_loss:  0.029475199058651924
p mean is: tensor(-0.0410, device='cuda:5')
epoch:  4000 quantization_loss:  0.02919270470738411
p mean is: tensor(-0.0541, device='cuda:5')
epoch:  5000 quantization_loss:  0.029030608013272285
p mean is: tensor(-0.0679, device='cuda:5')
epoch:  6000 quantization_loss:  0.028902608901262283
p mean is: tensor(-0.0818, device='cuda:5')
epoch:  7000 quantization_loss:  0.0289202481508255
p mean is: tensor(-0.0970, device='cuda:5')
epoch:  8000 quantization_loss:  0.02853577397763729
p mean is: tensor(-0.1134, device='cuda:5')
epoch:  9000 quantization_loss:  0.02738879807293415
p mean is: tensor(-0.1314, device='cuda:5')
epoch:  10000 quantization_loss:  0.02425401099026203
p mean is: tensor(-0.1534, device='cuda:5')
epoch:  11000 quantization_loss:  0.022768666967749596
p mean is: tensor(-0.1800, device='cuda:5')
epoch:  12000 quantization_loss:  0.02139466442167759
p mean is: tensor(-0.2134, device='cuda:5')
epoch:  13000 quantization_loss:  0.018887784332036972
p mean is: tensor(-0.2549, device='cuda:5')
epoch:  14000 quantization_loss:  0.01603742502629757
p mean is: tensor(-0.3043, device='cuda:5')
epoch:  15000 quantization_loss:  0.014590887352824211
p mean is: tensor(-0.3618, device='cuda:5')
epoch:  16000 quantization_loss:  0.013889802619814873
p mean is: tensor(-0.4270, device='cuda:5')
epoch:  17000 quantization_loss:  0.01404652651399374
p mean is: tensor(-0.4983, device='cuda:5')
epoch:  18000 quantization_loss:  0.013581501320004463
p mean is: tensor(-0.5730, device='cuda:5')
epoch:  19000 quantization_loss:  0.013211329467594624
p mean is: tensor(-0.6473, device='cuda:5')
epoch:  20000 quantization_loss:  0.011335223913192749
p mean is: tensor(-0.7177, device='cuda:5')
epoch:  21000 quantization_loss:  0.011167418211698532
p mean is: tensor(-0.7819, device='cuda:5')
epoch:  22000 quantization_loss:  0.011054964736104012
p mean is: tensor(-0.8398, device='cuda:5')
epoch:  23000 quantization_loss:  0.010925925336778164
p mean is: tensor(-0.8912, device='cuda:5')
epoch:  24000 quantization_loss:  0.01085381954908371
p mean is: tensor(-0.9365, device='cuda:5')
epoch:  25000 quantization_loss:  0.010800497606396675
p mean is: tensor(-0.9762, device='cuda:5')
epoch:  26000 quantization_loss:  0.010771634057164192
p mean is: tensor(-1.0110, device='cuda:5')
epoch:  27000 quantization_loss:  0.010687406174838543
p mean is: tensor(-1.0415, device='cuda:5')
epoch:  28000 quantization_loss:  0.010595684871077538
p mean is: tensor(-1.0682, device='cuda:5')
epoch:  29000 quantization_loss:  0.010552422143518925
p mean is: tensor(-1.0916, device='cuda:5')
epoch:  30000 quantization_loss:  0.010508892126381397
p mean is: tensor(-1.1121, device='cuda:5')
epoch:  31000 quantization_loss:  0.010462624952197075
p mean is: tensor(-1.1302, device='cuda:5')
epoch:  32000 quantization_loss:  0.010446442291140556
p mean is: tensor(-1.1462, device='cuda:5')
epoch:  33000 quantization_loss:  0.010410558432340622
p mean is: tensor(-1.1605, device='cuda:5')
epoch:  34000 quantization_loss:  0.010380147024989128
p mean is: tensor(-1.1732, device='cuda:5')
epoch:  35000 quantization_loss:  0.010371295735239983
p mean is: tensor(-1.1845, device='cuda:5')
epoch:  36000 quantization_loss:  0.010342802852392197
p mean is: tensor(-1.1945, device='cuda:5')
epoch:  37000 quantization_loss:  0.010324702598154545
p mean is: tensor(-1.2036, device='cuda:5')
epoch:  38000 quantization_loss:  0.010312107391655445
p mean is: tensor(-1.2118, device='cuda:5')
epoch:  39000 quantization_loss:  0.010370523668825626
p mean is: tensor(-1.2192, device='cuda:5')
epoch:  40000 quantization_loss:  0.010274115018546581
p mean is: tensor(-1.2260, device='cuda:5')
epoch:  41000 quantization_loss:  0.010247297585010529
p mean is: tensor(-1.2321, device='cuda:5')
epoch:  42000 quantization_loss:  0.010248856619000435
p mean is: tensor(-1.2376, device='cuda:5')
epoch:  43000 quantization_loss:  0.010225427336990833
p mean is: tensor(-1.2427, device='cuda:5')
epoch:  44000 quantization_loss:  0.010240363888442516
p mean is: tensor(-1.2474, device='cuda:5')
epoch:  45000 quantization_loss:  0.010210281237959862
p mean is: tensor(-1.2517, device='cuda:5')
epoch:  46000 quantization_loss:  0.010187674313783646
p mean is: tensor(-1.2557, device='cuda:5')
epoch:  47000 quantization_loss:  0.010179884731769562
p mean is: tensor(-1.2593, device='cuda:5')
epoch:  48000 quantization_loss:  0.01016860269010067
p mean is: tensor(-1.2628, device='cuda:5')
epoch:  49000 quantization_loss:  0.010161525569856167
p mean is: tensor(-1.2660, device='cuda:5')
epoch:  50000 quantization_loss:  0.010150028392672539
p mean is: tensor(-1.2689, device='cuda:5')
epoch:  51000 quantization_loss:  0.010146049782633781
p mean is: tensor(-1.2717, device='cuda:5')
epoch:  52000 quantization_loss:  0.010136744938790798
p mean is: tensor(-1.2743, device='cuda:5')
epoch:  53000 quantization_loss:  0.010125437751412392
p mean is: tensor(-1.2767, device='cuda:5')
epoch:  54000 quantization_loss:  0.010122161358594894
p mean is: tensor(-1.2790, device='cuda:5')
epoch:  55000 quantization_loss:  0.010132442228496075
p mean is: tensor(-1.2812, device='cuda:5')
epoch:  56000 quantization_loss:  0.010111168958246708
p mean is: tensor(-1.2832, device='cuda:5')
epoch:  57000 quantization_loss:  0.010124697349965572
p mean is: tensor(-1.2851, device='cuda:5')
epoch:  58000 quantization_loss:  0.010108956135809422
p mean is: tensor(-1.2870, device='cuda:5')
epoch:  59000 quantization_loss:  0.010099374689161777
p mean is: tensor(-1.2887, device='cuda:5')
Number of elements to keep: 150443
Threshold value: -0.6018134951591492
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
here
Number of elements to keep: 150443
Threshold value: -0.6018134951591492
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
1.1.1.weight         | nonzeros =    1532 /   12800             ( 11.97%) | total_pruned =   11268 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =      11 /      16             ( 68.75%) | total_pruned =       5 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     263 /    6400             (  4.11%) | total_pruned =    6137 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     192 /   12800             (  1.50%) | total_pruned =   12608 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     245 /   25600             (  0.96%) | total_pruned =   25355 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      12 /      32             ( 37.50%) | total_pruned =      20 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     331 /   51200             (  0.65%) | total_pruned =   50869 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     674 /  102400             (  0.66%) | total_pruned =  101726 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     478 /  204800             (  0.23%) | total_pruned =  204322 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =    1208 /  409600             (  0.29%) | total_pruned =  408392 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    1784 /  409600             (  0.44%) | total_pruned =  407816 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    5487 /  409600             (  1.34%) | total_pruned =  404113 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   13992 /  409600             (  3.42%) | total_pruned =  395608 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   35936 /  409600             (  8.77%) | total_pruned =  373664 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   28087 /  147456             ( 19.05%) | total_pruned =  119369 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   23357 /  147456             ( 15.84%) | total_pruned =  124099 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   20504 /  147456             ( 13.91%) | total_pruned =  126952 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   10166 /   73728             ( 13.79%) | total_pruned =   63562 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    3371 /   18432             ( 18.29%) | total_pruned =   15061 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      24 /      32             ( 75.00%) | total_pruned =       8 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      24 /      32             ( 75.00%) | total_pruned =       8 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1506 /    4608             ( 32.68%) | total_pruned =    3102 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      27 /      48             ( 56.25%) | total_pruned =      21 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       3 /       3             (100.00%) | total_pruned =       0 | shape = torch.Size([3])
alive: 150443, pruned : 2858424, total: 3008867, Compression rate :      20.00x  ( 95.00% pruned)
PSNR of output image is:  16.57806251598697
Experiment done
