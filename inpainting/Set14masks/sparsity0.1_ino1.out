(3, 512, 512)
(3, 512, 512)
Noisy PSNR is '9.654258285739468'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Output directory: data/inpainting/Set14/mask/1/sparsity/0.5/det/0.1/1e-09
epoch:  0 quantization_loss:  0.037004001438617706
p mean is: tensor(-0.0002, device='cuda:5')
epoch:  1000 quantization_loss:  0.030646823346614838
p mean is: tensor(-0.0124, device='cuda:5')
epoch:  2000 quantization_loss:  0.029345668852329254
p mean is: tensor(-0.0217, device='cuda:5')
epoch:  3000 quantization_loss:  0.03027137741446495
p mean is: tensor(-0.0308, device='cuda:5')
epoch:  4000 quantization_loss:  0.02997151017189026
p mean is: tensor(-0.0400, device='cuda:5')
epoch:  5000 quantization_loss:  0.028725020587444305
p mean is: tensor(-0.0492, device='cuda:5')
epoch:  6000 quantization_loss:  0.02921467088162899
p mean is: tensor(-0.0592, device='cuda:5')
epoch:  7000 quantization_loss:  0.02951398491859436
p mean is: tensor(-0.0696, device='cuda:5')
epoch:  8000 quantization_loss:  0.029405752196907997
p mean is: tensor(-0.0808, device='cuda:5')
epoch:  9000 quantization_loss:  0.028880266472697258
p mean is: tensor(-0.0923, device='cuda:5')
epoch:  10000 quantization_loss:  0.024107376113533974
p mean is: tensor(-0.1045, device='cuda:5')
epoch:  11000 quantization_loss:  0.018475396558642387
p mean is: tensor(-0.1186, device='cuda:5')
epoch:  12000 quantization_loss:  0.016543634235858917
p mean is: tensor(-0.1372, device='cuda:5')
epoch:  13000 quantization_loss:  0.015588582493364811
p mean is: tensor(-0.1618, device='cuda:5')
epoch:  14000 quantization_loss:  0.014222524128854275
p mean is: tensor(-0.1945, device='cuda:5')
epoch:  15000 quantization_loss:  0.013321343809366226
p mean is: tensor(-0.2362, device='cuda:5')
epoch:  16000 quantization_loss:  0.011891063302755356
p mean is: tensor(-0.2873, device='cuda:5')
epoch:  17000 quantization_loss:  0.01113293319940567
p mean is: tensor(-0.3477, device='cuda:5')
epoch:  18000 quantization_loss:  0.010698826052248478
p mean is: tensor(-0.4164, device='cuda:5')
epoch:  19000 quantization_loss:  0.010068275965750217
p mean is: tensor(-0.4899, device='cuda:5')
epoch:  20000 quantization_loss:  0.009518512524664402
p mean is: tensor(-0.5654, device='cuda:5')
epoch:  21000 quantization_loss:  0.00973299890756607
p mean is: tensor(-0.6394, device='cuda:5')
epoch:  22000 quantization_loss:  0.009141880087554455
p mean is: tensor(-0.7097, device='cuda:5')
epoch:  23000 quantization_loss:  0.008984037674963474
p mean is: tensor(-0.7740, device='cuda:5')
epoch:  24000 quantization_loss:  0.008813195861876011
p mean is: tensor(-0.8317, device='cuda:5')
epoch:  25000 quantization_loss:  0.008673693984746933
p mean is: tensor(-0.8827, device='cuda:5')
epoch:  26000 quantization_loss:  0.008569084107875824
p mean is: tensor(-0.9276, device='cuda:5')
epoch:  27000 quantization_loss:  0.008542247116565704
p mean is: tensor(-0.9668, device='cuda:5')
epoch:  28000 quantization_loss:  0.00844806618988514
p mean is: tensor(-1.0012, device='cuda:5')
epoch:  29000 quantization_loss:  0.0083124078810215
p mean is: tensor(-1.0315, device='cuda:5')
epoch:  30000 quantization_loss:  0.008309979923069477
p mean is: tensor(-1.0581, device='cuda:5')
epoch:  31000 quantization_loss:  0.008180161006748676
p mean is: tensor(-1.0814, device='cuda:5')
epoch:  32000 quantization_loss:  0.008130199275910854
p mean is: tensor(-1.1022, device='cuda:5')
epoch:  33000 quantization_loss:  0.00809374637901783
p mean is: tensor(-1.1205, device='cuda:5')
epoch:  34000 quantization_loss:  0.008061202242970467
p mean is: tensor(-1.1367, device='cuda:5')
epoch:  35000 quantization_loss:  0.007979856804013252
p mean is: tensor(-1.1509, device='cuda:5')
epoch:  36000 quantization_loss:  0.007932620123028755
p mean is: tensor(-1.1637, device='cuda:5')
epoch:  37000 quantization_loss:  0.00790438987314701
p mean is: tensor(-1.1751, device='cuda:5')
epoch:  38000 quantization_loss:  0.007896124385297298
p mean is: tensor(-1.1854, device='cuda:5')
epoch:  39000 quantization_loss:  0.007812979631125927
p mean is: tensor(-1.1947, device='cuda:5')
epoch:  40000 quantization_loss:  0.007784818299114704
p mean is: tensor(-1.2030, device='cuda:5')
epoch:  41000 quantization_loss:  0.007745468523353338
p mean is: tensor(-1.2105, device='cuda:5')
epoch:  42000 quantization_loss:  0.007722447160631418
p mean is: tensor(-1.2173, device='cuda:5')
epoch:  43000 quantization_loss:  0.007678927853703499
p mean is: tensor(-1.2235, device='cuda:5')
epoch:  44000 quantization_loss:  0.007663593161851168
p mean is: tensor(-1.2291, device='cuda:5')
epoch:  45000 quantization_loss:  0.007635173387825489
p mean is: tensor(-1.2343, device='cuda:5')
epoch:  46000 quantization_loss:  0.007601716555655003
p mean is: tensor(-1.2391, device='cuda:5')
epoch:  47000 quantization_loss:  0.0075901648961007595
p mean is: tensor(-1.2436, device='cuda:5')
epoch:  48000 quantization_loss:  0.007581112906336784
p mean is: tensor(-1.2477, device='cuda:5')
epoch:  49000 quantization_loss:  0.00755690224468708
p mean is: tensor(-1.2516, device='cuda:5')
epoch:  50000 quantization_loss:  0.007538577076047659
p mean is: tensor(-1.2551, device='cuda:5')
epoch:  51000 quantization_loss:  0.007521620485931635
p mean is: tensor(-1.2584, device='cuda:5')
epoch:  52000 quantization_loss:  0.0075032999739050865
p mean is: tensor(-1.2615, device='cuda:5')
epoch:  53000 quantization_loss:  0.0074949804693460464
p mean is: tensor(-1.2644, device='cuda:5')
epoch:  54000 quantization_loss:  0.007479757070541382
p mean is: tensor(-1.2671, device='cuda:5')
epoch:  55000 quantization_loss:  0.007469802163541317
p mean is: tensor(-1.2696, device='cuda:5')
epoch:  56000 quantization_loss:  0.007455685641616583
p mean is: tensor(-1.2721, device='cuda:5')
epoch:  57000 quantization_loss:  0.0074551720172166824
p mean is: tensor(-1.2743, device='cuda:5')
epoch:  58000 quantization_loss:  0.007438866887241602
p mean is: tensor(-1.2765, device='cuda:5')
epoch:  59000 quantization_loss:  0.007419649977236986
p mean is: tensor(-1.2786, device='cuda:5')
Number of elements to keep: 300886
Threshold value: -1.1028789281845093
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.09999976735428984
here
Number of elements to keep: 150443
Threshold value: -0.4622693657875061
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
1.1.1.weight         | nonzeros =    2517 /   12800             ( 19.66%) | total_pruned =   10283 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     783 /    6400             ( 12.23%) | total_pruned =    5617 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =    1039 /   12800             (  8.12%) | total_pruned =   11761 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =    1256 /   25600             (  4.91%) | total_pruned =   24344 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      21 /      32             ( 65.62%) | total_pruned =      11 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =    1744 /   51200             (  3.41%) | total_pruned =   49456 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =    3148 /  102400             (  3.07%) | total_pruned =   99252 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =    5972 /  204800             (  2.92%) | total_pruned =  198828 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =   12806 /  409600             (  3.13%) | total_pruned =  396794 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   18457 /  409600             (  4.51%) | total_pruned =  391143 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   29275 /  409600             (  7.15%) | total_pruned =  380325 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   56522 /  409600             ( 13.80%) | total_pruned =  353078 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   70994 /  409600             ( 17.33%) | total_pruned =  338606 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   29219 /  147456             ( 19.82%) | total_pruned =  118237 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   26043 /  147456             ( 17.66%) | total_pruned =  121413 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   24857 /  147456             ( 16.86%) | total_pruned =  122599 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   11030 /   73728             ( 14.96%) | total_pruned =   62698 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2672 /   18432             ( 14.50%) | total_pruned =   15760 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1233 /    4608             ( 26.76%) | total_pruned =    3375 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      29 /      48             ( 60.42%) | total_pruned =      19 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 300886, pruned : 2707981, total: 3008867, Compression rate :      10.00x  ( 90.00% pruned)
PSNR of output image is:  18.23730287881836
Experiment done
