(3, 256, 256)
(3, 256, 256)
Noisy PSNR is '11.28157754270044'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Output directory: data/inpainting/Set14/mask/6/sparsity/0.5/det/0.8/1e-09
epoch:  0 quantization_loss:  0.06489081680774689
p mean is: tensor(-0.0002, device='cuda:6')
epoch:  1000 quantization_loss:  0.04503677412867546
p mean is: tensor(-0.0062, device='cuda:6')
epoch:  2000 quantization_loss:  0.04691331833600998
p mean is: tensor(-0.0097, device='cuda:6')
epoch:  3000 quantization_loss:  0.043114010244607925
p mean is: tensor(-0.0129, device='cuda:6')
epoch:  4000 quantization_loss:  0.04249725490808487
p mean is: tensor(-0.0160, device='cuda:6')
epoch:  5000 quantization_loss:  0.04556833952665329
p mean is: tensor(-0.0191, device='cuda:6')
epoch:  6000 quantization_loss:  0.04302424192428589
p mean is: tensor(-0.0221, device='cuda:6')
epoch:  7000 quantization_loss:  0.04310940206050873
p mean is: tensor(-0.0252, device='cuda:6')
epoch:  8000 quantization_loss:  0.043659746646881104
p mean is: tensor(-0.0284, device='cuda:6')
epoch:  9000 quantization_loss:  0.042375050485134125
p mean is: tensor(-0.0316, device='cuda:6')
epoch:  10000 quantization_loss:  0.04393034055829048
p mean is: tensor(-0.0346, device='cuda:6')
epoch:  11000 quantization_loss:  0.042201194912195206
p mean is: tensor(-0.0380, device='cuda:6')
epoch:  12000 quantization_loss:  0.03817705065011978
p mean is: tensor(-0.0417, device='cuda:6')
epoch:  13000 quantization_loss:  0.02314613200724125
p mean is: tensor(-0.0458, device='cuda:6')
epoch:  14000 quantization_loss:  0.022716833278536797
p mean is: tensor(-0.0511, device='cuda:6')
epoch:  15000 quantization_loss:  0.021841663867235184
p mean is: tensor(-0.0589, device='cuda:6')
epoch:  16000 quantization_loss:  0.021228015422821045
p mean is: tensor(-0.0700, device='cuda:6')
epoch:  17000 quantization_loss:  0.020359791815280914
p mean is: tensor(-0.0856, device='cuda:6')
epoch:  18000 quantization_loss:  0.02001047134399414
p mean is: tensor(-0.1074, device='cuda:6')
epoch:  19000 quantization_loss:  0.019475135952234268
p mean is: tensor(-0.1373, device='cuda:6')
epoch:  20000 quantization_loss:  0.019123641774058342
p mean is: tensor(-0.1769, device='cuda:6')
epoch:  21000 quantization_loss:  0.018774375319480896
p mean is: tensor(-0.2278, device='cuda:6')
epoch:  22000 quantization_loss:  0.01862230896949768
p mean is: tensor(-0.2906, device='cuda:6')
epoch:  23000 quantization_loss:  0.018390262499451637
p mean is: tensor(-0.3648, device='cuda:6')
epoch:  24000 quantization_loss:  0.018175067380070686
p mean is: tensor(-0.4481, device='cuda:6')
epoch:  25000 quantization_loss:  0.01808672770857811
p mean is: tensor(-0.5370, device='cuda:6')
epoch:  26000 quantization_loss:  0.017918739467859268
p mean is: tensor(-0.6266, device='cuda:6')
epoch:  27000 quantization_loss:  0.017763689160346985
p mean is: tensor(-0.7123, device='cuda:6')
epoch:  28000 quantization_loss:  0.01767493039369583
p mean is: tensor(-0.7906, device='cuda:6')
epoch:  29000 quantization_loss:  0.017579738050699234
p mean is: tensor(-0.8599, device='cuda:6')
epoch:  30000 quantization_loss:  0.017499128356575966
p mean is: tensor(-0.9197, device='cuda:6')
epoch:  31000 quantization_loss:  0.01742619276046753
p mean is: tensor(-0.9707, device='cuda:6')
epoch:  32000 quantization_loss:  0.017376279458403587
p mean is: tensor(-1.0141, device='cuda:6')
epoch:  33000 quantization_loss:  0.01737266592681408
p mean is: tensor(-1.0507, device='cuda:6')
epoch:  34000 quantization_loss:  0.01727847009897232
p mean is: tensor(-1.0819, device='cuda:6')
epoch:  35000 quantization_loss:  0.017210068181157112
p mean is: tensor(-1.1081, device='cuda:6')
epoch:  36000 quantization_loss:  0.017213737592101097
p mean is: tensor(-1.1306, device='cuda:6')
epoch:  37000 quantization_loss:  0.017149055376648903
p mean is: tensor(-1.1499, device='cuda:6')
epoch:  38000 quantization_loss:  0.017115464434027672
p mean is: tensor(-1.1666, device='cuda:6')
epoch:  39000 quantization_loss:  0.017079586163163185
p mean is: tensor(-1.1808, device='cuda:6')
epoch:  40000 quantization_loss:  0.017066292464733124
p mean is: tensor(-1.1931, device='cuda:6')
epoch:  41000 quantization_loss:  0.017034444957971573
p mean is: tensor(-1.2038, device='cuda:6')
epoch:  42000 quantization_loss:  0.016998251900076866
p mean is: tensor(-1.2131, device='cuda:6')
epoch:  43000 quantization_loss:  0.016963405534625053
p mean is: tensor(-1.2213, device='cuda:6')
epoch:  44000 quantization_loss:  0.016958601772785187
p mean is: tensor(-1.2285, device='cuda:6')
epoch:  45000 quantization_loss:  0.016926096752285957
p mean is: tensor(-1.2348, device='cuda:6')
epoch:  46000 quantization_loss:  0.01690841093659401
p mean is: tensor(-1.2403, device='cuda:6')
epoch:  47000 quantization_loss:  0.016930241137742996
p mean is: tensor(-1.2452, device='cuda:6')
epoch:  48000 quantization_loss:  0.016855383291840553
p mean is: tensor(-1.2497, device='cuda:6')
epoch:  49000 quantization_loss:  0.016844019293785095
p mean is: tensor(-1.2536, device='cuda:6')
epoch:  50000 quantization_loss:  0.01682446338236332
p mean is: tensor(-1.2572, device='cuda:6')
epoch:  51000 quantization_loss:  0.016803307458758354
p mean is: tensor(-1.2604, device='cuda:6')
epoch:  52000 quantization_loss:  0.016800401732325554
p mean is: tensor(-1.2633, device='cuda:6')
epoch:  53000 quantization_loss:  0.01677359826862812
p mean is: tensor(-1.2659, device='cuda:6')
epoch:  54000 quantization_loss:  0.01675991714000702
p mean is: tensor(-1.2683, device='cuda:6')
epoch:  55000 quantization_loss:  0.016766006126999855
p mean is: tensor(-1.2705, device='cuda:6')
epoch:  56000 quantization_loss:  0.016743266955018044
p mean is: tensor(-1.2725, device='cuda:6')
epoch:  57000 quantization_loss:  0.016730479896068573
p mean is: tensor(-1.2743, device='cuda:6')
epoch:  58000 quantization_loss:  0.016714056953787804
p mean is: tensor(-1.2760, device='cuda:6')
epoch:  59000 quantization_loss:  0.016716133803129196
p mean is: tensor(-1.2777, device='cuda:6')
Number of elements to keep: 2407093
Threshold value: -1.3126392364501953
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.7999998005893912
here
Number of elements to keep: 150443
Threshold value: -1.1086606979370117
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
1.1.1.weight         | nonzeros =    7528 /   12800             ( 58.81%) | total_pruned =    5272 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.2.weight           | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =    3997 /    6400             ( 62.45%) | total_pruned =    2403 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.5.weight           | nonzeros =      12 /      16             ( 75.00%) | total_pruned =       4 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =    8300 /   12800             ( 64.84%) | total_pruned =    4500 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =   17675 /   25600             ( 69.04%) | total_pruned =    7925 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =   37248 /   51200             ( 72.75%) | total_pruned =   13952 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =   78579 /  102400             ( 76.74%) | total_pruned =   23821 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =  165290 /  204800             ( 80.71%) | total_pruned =   39510 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =  350868 /  409600             ( 85.66%) | total_pruned =   58732 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  344454 /  409600             ( 84.10%) | total_pruned =   65146 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  345396 /  409600             ( 84.33%) | total_pruned =   64204 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  326026 /  409600             ( 79.60%) | total_pruned =   83574 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  325354 /  409600             ( 79.43%) | total_pruned =   84246 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  109349 /  147456             ( 74.16%) | total_pruned =   38107 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  109144 /  147456             ( 74.02%) | total_pruned =   38312 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =  107965 /  147456             ( 73.22%) | total_pruned =   39491 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   50135 /   73728             ( 68.00%) | total_pruned =   23593 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =   12417 /   18432             ( 67.37%) | total_pruned =    6015 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    2599 /    4608             ( 56.40%) | total_pruned =    2009 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      27 /      48             ( 56.25%) | total_pruned =      21 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 2404997, pruned : 603870, total: 3008867, Compression rate :       1.25x  ( 20.07% pruned)
PSNR of output image is:  14.578309524153209
Experiment done
