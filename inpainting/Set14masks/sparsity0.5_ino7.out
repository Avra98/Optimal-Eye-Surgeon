(3, 256, 256)
(3, 256, 256)
Noisy PSNR is '7.34486744141577'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Output directory: data/inpainting/Set14/mask/7/sparsity/0.5/det/0.5/1e-09
epoch:  0 quantization_loss:  0.035161539912223816
p mean is: tensor(-0.0002, device='cuda:5')
epoch:  1000 quantization_loss:  0.0320855975151062
p mean is: tensor(-0.0118, device='cuda:5')
epoch:  2000 quantization_loss:  0.03212021291255951
p mean is: tensor(-0.0212, device='cuda:5')
epoch:  3000 quantization_loss:  0.03172117844223976
p mean is: tensor(-0.0306, device='cuda:5')
epoch:  4000 quantization_loss:  0.03245260939002037
p mean is: tensor(-0.0400, device='cuda:5')
epoch:  5000 quantization_loss:  0.032002225518226624
p mean is: tensor(-0.0495, device='cuda:5')
epoch:  6000 quantization_loss:  0.03155020996928215
p mean is: tensor(-0.0590, device='cuda:5')
epoch:  7000 quantization_loss:  0.031778402626514435
p mean is: tensor(-0.0686, device='cuda:5')
epoch:  8000 quantization_loss:  0.03174189478158951
p mean is: tensor(-0.0791, device='cuda:5')
epoch:  9000 quantization_loss:  0.031351570039987564
p mean is: tensor(-0.0900, device='cuda:5')
epoch:  10000 quantization_loss:  0.031530436128377914
p mean is: tensor(-0.1016, device='cuda:5')
epoch:  11000 quantization_loss:  0.03171416372060776
p mean is: tensor(-0.1134, device='cuda:5')
epoch:  12000 quantization_loss:  0.031258903443813324
p mean is: tensor(-0.1256, device='cuda:5')
epoch:  13000 quantization_loss:  0.031330887228250504
p mean is: tensor(-0.1374, device='cuda:5')
epoch:  14000 quantization_loss:  0.02868540585041046
p mean is: tensor(-0.1495, device='cuda:5')
epoch:  15000 quantization_loss:  0.02652149274945259
p mean is: tensor(-0.1633, device='cuda:5')
epoch:  16000 quantization_loss:  0.02160409651696682
p mean is: tensor(-0.1812, device='cuda:5')
epoch:  17000 quantization_loss:  0.01886020042002201
p mean is: tensor(-0.2046, device='cuda:5')
epoch:  18000 quantization_loss:  0.01762680523097515
p mean is: tensor(-0.2351, device='cuda:5')
epoch:  19000 quantization_loss:  0.015122962184250355
p mean is: tensor(-0.2747, device='cuda:5')
epoch:  20000 quantization_loss:  0.01430587563663721
p mean is: tensor(-0.3245, device='cuda:5')
epoch:  21000 quantization_loss:  0.013485342264175415
p mean is: tensor(-0.3846, device='cuda:5')
epoch:  22000 quantization_loss:  0.013039725832641125
p mean is: tensor(-0.4543, device='cuda:5')
epoch:  23000 quantization_loss:  0.012661335989832878
p mean is: tensor(-0.5311, device='cuda:5')
epoch:  24000 quantization_loss:  0.01143704168498516
p mean is: tensor(-0.6110, device='cuda:5')
epoch:  25000 quantization_loss:  0.011012289673089981
p mean is: tensor(-0.6895, device='cuda:5')
epoch:  26000 quantization_loss:  0.010766622610390186
p mean is: tensor(-0.7631, device='cuda:5')
epoch:  27000 quantization_loss:  0.011335964314639568
p mean is: tensor(-0.8296, device='cuda:5')
epoch:  28000 quantization_loss:  0.010304959490895271
p mean is: tensor(-0.8882, device='cuda:5')
epoch:  29000 quantization_loss:  0.010109693743288517
p mean is: tensor(-0.9390, device='cuda:5')
epoch:  30000 quantization_loss:  0.00983794778585434
p mean is: tensor(-0.9827, device='cuda:5')
epoch:  31000 quantization_loss:  0.009764782153069973
p mean is: tensor(-1.0200, device='cuda:5')
epoch:  32000 quantization_loss:  0.009033547714352608
p mean is: tensor(-1.0520, device='cuda:5')
epoch:  33000 quantization_loss:  0.008847483433783054
p mean is: tensor(-1.0792, device='cuda:5')
epoch:  34000 quantization_loss:  0.008822042495012283
p mean is: tensor(-1.1023, device='cuda:5')
epoch:  35000 quantization_loss:  0.008636991493403912
p mean is: tensor(-1.1221, device='cuda:5')
epoch:  36000 quantization_loss:  0.008535336703062057
p mean is: tensor(-1.1390, device='cuda:5')
epoch:  37000 quantization_loss:  0.008440899662673473
p mean is: tensor(-1.1536, device='cuda:5')
epoch:  38000 quantization_loss:  0.00841770600527525
p mean is: tensor(-1.1662, device='cuda:5')
epoch:  39000 quantization_loss:  0.008289597928524017
p mean is: tensor(-1.1770, device='cuda:5')
epoch:  40000 quantization_loss:  0.008244538679718971
p mean is: tensor(-1.1864, device='cuda:5')
epoch:  41000 quantization_loss:  0.008213936351239681
p mean is: tensor(-1.1946, device='cuda:5')
epoch:  42000 quantization_loss:  0.00814727135002613
p mean is: tensor(-1.2016, device='cuda:5')
epoch:  43000 quantization_loss:  0.008234779350459576
p mean is: tensor(-1.2078, device='cuda:5')
epoch:  44000 quantization_loss:  0.008106732740998268
p mean is: tensor(-1.2132, device='cuda:5')
epoch:  45000 quantization_loss:  0.008035652339458466
p mean is: tensor(-1.2179, device='cuda:5')
epoch:  46000 quantization_loss:  0.007985551841557026
p mean is: tensor(-1.2221, device='cuda:5')
epoch:  47000 quantization_loss:  0.007971315644681454
p mean is: tensor(-1.2258, device='cuda:5')
epoch:  48000 quantization_loss:  0.007944203913211823
p mean is: tensor(-1.2291, device='cuda:5')
epoch:  49000 quantization_loss:  0.007927238009870052
p mean is: tensor(-1.2319, device='cuda:5')
epoch:  50000 quantization_loss:  0.007908501662313938
p mean is: tensor(-1.2345, device='cuda:5')
epoch:  51000 quantization_loss:  0.007888801395893097
p mean is: tensor(-1.2367, device='cuda:5')
epoch:  52000 quantization_loss:  0.007897011935710907
p mean is: tensor(-1.2387, device='cuda:5')
epoch:  53000 quantization_loss:  0.007856646552681923
p mean is: tensor(-1.2404, device='cuda:5')
epoch:  54000 quantization_loss:  0.007842563092708588
p mean is: tensor(-1.2421, device='cuda:5')
epoch:  55000 quantization_loss:  0.007870451547205448
p mean is: tensor(-1.2435, device='cuda:5')
epoch:  56000 quantization_loss:  0.007812908850610256
p mean is: tensor(-1.2450, device='cuda:5')
epoch:  57000 quantization_loss:  0.007806906010955572
p mean is: tensor(-1.2462, device='cuda:5')
epoch:  58000 quantization_loss:  0.0078025758266448975
p mean is: tensor(-1.2474, device='cuda:5')
epoch:  59000 quantization_loss:  0.007793123368173838
p mean is: tensor(-1.2484, device='cuda:5')
Number of elements to keep: 1504433
Threshold value: -1.2992830276489258
Number of elements equal to threshold: 53
Number of elements to randomly select: 29
Warning: Random selection among elements equal to the threshold is being performed to maintain sparsity.
Actual sparsity achieved: 0.49999983382449276
here
Number of elements to keep: 150443
Threshold value: -0.9859015345573425
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
1.1.1.weight         | nonzeros =    6501 /   12800             ( 50.79%) | total_pruned =    6299 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =    3390 /    6400             ( 52.97%) | total_pruned =    3010 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =    6672 /   12800             ( 52.12%) | total_pruned =    6128 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =   13205 /   25600             ( 51.58%) | total_pruned =   12395 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      23 /      32             ( 71.88%) | total_pruned =       9 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =   26277 /   51200             ( 51.32%) | total_pruned =   24923 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =   51931 /  102400             ( 50.71%) | total_pruned =   50469 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =  102819 /  204800             ( 50.20%) | total_pruned =  101981 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =  202890 /  409600             ( 49.53%) | total_pruned =  206710 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  204101 /  409600             ( 49.83%) | total_pruned =  205499 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  205832 /  409600             ( 50.25%) | total_pruned =  203768 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  201656 /  409600             ( 49.23%) | total_pruned =  207944 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  207061 /  409600             ( 50.55%) | total_pruned =  202539 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   77540 /  147456             ( 52.59%) | total_pruned =   69916 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   74500 /  147456             ( 50.52%) | total_pruned =   72956 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   71867 /  147456             ( 48.74%) | total_pruned =   75589 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   36166 /   73728             ( 49.05%) | total_pruned =   37562 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    8768 /   18432             ( 47.57%) | total_pruned =    9664 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    2043 /    4608             ( 44.34%) | total_pruned =    2565 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      15 /      16             ( 93.75%) | total_pruned =       1 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      30 /      48             ( 62.50%) | total_pruned =      18 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 1504433, pruned : 1504434, total: 3008867, Compression rate :       2.00x  ( 50.00% pruned)
PSNR of output image is:  17.763685655534015
Experiment done
