(3, 512, 512)
(3, 512, 512)
Noisy PSNR is '9.337805271439137'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Output directory: data/inpainting/Set14/mask/12/sparsity/0.5/det/0.08/1e-09
epoch:  0 quantization_loss:  0.027097437530755997
p mean is: tensor(-0.0002, device='cuda:6')
epoch:  1000 quantization_loss:  0.02416628785431385
p mean is: tensor(-0.0158, device='cuda:6')
epoch:  2000 quantization_loss:  0.02311260625720024
p mean is: tensor(-0.0285, device='cuda:6')
epoch:  3000 quantization_loss:  0.022951757535338402
p mean is: tensor(-0.0414, device='cuda:6')
epoch:  4000 quantization_loss:  0.022722506895661354
p mean is: tensor(-0.0548, device='cuda:6')
epoch:  5000 quantization_loss:  0.022360937669873238
p mean is: tensor(-0.0693, device='cuda:6')
epoch:  6000 quantization_loss:  0.022687023505568504
p mean is: tensor(-0.0856, device='cuda:6')
epoch:  7000 quantization_loss:  0.02140006050467491
p mean is: tensor(-0.1036, device='cuda:6')
epoch:  8000 quantization_loss:  0.019142910838127136
p mean is: tensor(-0.1236, device='cuda:6')
epoch:  9000 quantization_loss:  0.015406157821416855
p mean is: tensor(-0.1482, device='cuda:6')
epoch:  10000 quantization_loss:  0.012009376659989357
p mean is: tensor(-0.1772, device='cuda:6')
epoch:  11000 quantization_loss:  0.01019536517560482
p mean is: tensor(-0.2119, device='cuda:6')
epoch:  12000 quantization_loss:  0.009142883121967316
p mean is: tensor(-0.2546, device='cuda:6')
epoch:  13000 quantization_loss:  0.00830436497926712
p mean is: tensor(-0.3060, device='cuda:6')
epoch:  14000 quantization_loss:  0.007656363770365715
p mean is: tensor(-0.3661, device='cuda:6')
epoch:  15000 quantization_loss:  0.007293632719665766
p mean is: tensor(-0.4338, device='cuda:6')
epoch:  16000 quantization_loss:  0.006854972802102566
p mean is: tensor(-0.5062, device='cuda:6')
epoch:  17000 quantization_loss:  0.006664409302175045
p mean is: tensor(-0.5796, device='cuda:6')
epoch:  18000 quantization_loss:  0.006370586343109608
p mean is: tensor(-0.6510, device='cuda:6')
epoch:  19000 quantization_loss:  0.00609622010961175
p mean is: tensor(-0.7180, device='cuda:6')
epoch:  20000 quantization_loss:  0.005990155041217804
p mean is: tensor(-0.7794, device='cuda:6')
epoch:  21000 quantization_loss:  0.005875472445040941
p mean is: tensor(-0.8344, device='cuda:6')
epoch:  22000 quantization_loss:  0.005712212063372135
p mean is: tensor(-0.8829, device='cuda:6')
epoch:  23000 quantization_loss:  0.005243087653070688
p mean is: tensor(-0.9259, device='cuda:6')
epoch:  24000 quantization_loss:  0.005075586959719658
p mean is: tensor(-0.9634, device='cuda:6')
epoch:  25000 quantization_loss:  0.00495230732485652
p mean is: tensor(-0.9963, device='cuda:6')
epoch:  26000 quantization_loss:  0.0048950291238725185
p mean is: tensor(-1.0253, device='cuda:6')
epoch:  27000 quantization_loss:  0.00484626367688179
p mean is: tensor(-1.0510, device='cuda:6')
epoch:  28000 quantization_loss:  0.0047652083449065685
p mean is: tensor(-1.0737, device='cuda:6')
epoch:  29000 quantization_loss:  0.004752185195684433
p mean is: tensor(-1.0939, device='cuda:6')
epoch:  30000 quantization_loss:  0.004695853218436241
p mean is: tensor(-1.1117, device='cuda:6')
epoch:  31000 quantization_loss:  0.004633218981325626
p mean is: tensor(-1.1276, device='cuda:6')
epoch:  32000 quantization_loss:  0.004582514055073261
p mean is: tensor(-1.1418, device='cuda:6')
epoch:  33000 quantization_loss:  0.004551635589450598
p mean is: tensor(-1.1545, device='cuda:6')
epoch:  34000 quantization_loss:  0.0045355986803770065
p mean is: tensor(-1.1658, device='cuda:6')
epoch:  35000 quantization_loss:  0.0044708470813930035
p mean is: tensor(-1.1761, device='cuda:6')
epoch:  36000 quantization_loss:  0.004454460926353931
p mean is: tensor(-1.1853, device='cuda:6')
epoch:  37000 quantization_loss:  0.0043921940959990025
p mean is: tensor(-1.1935, device='cuda:6')
epoch:  38000 quantization_loss:  0.004379549063742161
p mean is: tensor(-1.2012, device='cuda:6')
epoch:  39000 quantization_loss:  0.0043562729842960835
p mean is: tensor(-1.2079, device='cuda:6')
epoch:  40000 quantization_loss:  0.004346991423517466
p mean is: tensor(-1.2143, device='cuda:6')
epoch:  41000 quantization_loss:  0.004298765677958727
p mean is: tensor(-1.2200, device='cuda:6')
epoch:  42000 quantization_loss:  0.0042868186719715595
p mean is: tensor(-1.2252, device='cuda:6')
epoch:  43000 quantization_loss:  0.004274370148777962
p mean is: tensor(-1.2300, device='cuda:6')
epoch:  44000 quantization_loss:  0.004257530439645052
p mean is: tensor(-1.2344, device='cuda:6')
epoch:  45000 quantization_loss:  0.0043280962854623795
p mean is: tensor(-1.2386, device='cuda:6')
epoch:  46000 quantization_loss:  0.004226475954055786
p mean is: tensor(-1.2423, device='cuda:6')
epoch:  47000 quantization_loss:  0.004221069160848856
p mean is: tensor(-1.2458, device='cuda:6')
epoch:  48000 quantization_loss:  0.004210534505546093
p mean is: tensor(-1.2490, device='cuda:6')
epoch:  49000 quantization_loss:  0.00419914023950696
p mean is: tensor(-1.2520, device='cuda:6')
epoch:  50000 quantization_loss:  0.004194089211523533
p mean is: tensor(-1.2548, device='cuda:6')
epoch:  51000 quantization_loss:  0.004185590427368879
p mean is: tensor(-1.2575, device='cuda:6')
epoch:  52000 quantization_loss:  0.004180183634161949
p mean is: tensor(-1.2600, device='cuda:6')
epoch:  53000 quantization_loss:  0.0041754404082894325
p mean is: tensor(-1.2623, device='cuda:6')
epoch:  54000 quantization_loss:  0.004156476352363825
p mean is: tensor(-1.2644, device='cuda:6')
epoch:  55000 quantization_loss:  0.004157808143645525
p mean is: tensor(-1.2665, device='cuda:6')
epoch:  56000 quantization_loss:  0.004159154370427132
p mean is: tensor(-1.2685, device='cuda:6')
epoch:  57000 quantization_loss:  0.004148370120674372
p mean is: tensor(-1.2704, device='cuda:6')
epoch:  58000 quantization_loss:  0.0041391924023628235
p mean is: tensor(-1.2721, device='cuda:6')
epoch:  59000 quantization_loss:  0.004132770001888275
p mean is: tensor(-1.2738, device='cuda:6')
Number of elements to keep: 240709
Threshold value: -0.9285343289375305
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.07999988035363477
here
Number of elements to keep: 150443
Threshold value: -0.36406198143959045
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
1.1.1.weight         | nonzeros =    1532 /   12800             ( 11.97%) | total_pruned =   11268 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     339 /    6400             (  5.30%) | total_pruned =    6061 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     483 /   12800             (  3.77%) | total_pruned =   12317 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     838 /   25600             (  3.27%) | total_pruned =   24762 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     946 /   51200             (  1.85%) | total_pruned =   50254 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =    1861 /  102400             (  1.82%) | total_pruned =  100539 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =    3323 /  204800             (  1.62%) | total_pruned =  201477 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =    6452 /  409600             (  1.58%) | total_pruned =  403148 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   10135 /  409600             (  2.47%) | total_pruned =  399465 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   20299 /  409600             (  4.96%) | total_pruned =  389301 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   37418 /  409600             (  9.14%) | total_pruned =  372182 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   51800 /  409600             ( 12.65%) | total_pruned =  357800 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   28731 /  147456             ( 19.48%) | total_pruned =  118725 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   28826 /  147456             ( 19.55%) | total_pruned =  118630 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   26905 /  147456             ( 18.25%) | total_pruned =  120551 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   15172 /   73728             ( 20.58%) | total_pruned =   58556 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    3224 /   18432             ( 17.49%) | total_pruned =   15208 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1059 /    4608             ( 22.98%) | total_pruned =    3549 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      29 /      48             ( 60.42%) | total_pruned =      19 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 240709, pruned : 2768158, total: 3008867, Compression rate :      12.50x  ( 92.00% pruned)
PSNR of output image is:  20.86617568672958
Experiment done
