(3, 512, 512)
(3, 512, 512)
Noisy PSNR is '4.739292106822054'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Output directory: data/inpainting/Set14/mask/0/sparsity/0.5/det/0.8/1e-09
epoch:  0 quantization_loss:  0.09249696135520935
p mean is: tensor(-0.0002, device='cuda:0')
epoch:  1000 quantization_loss:  0.07339871674776077
p mean is: tensor(-0.0117, device='cuda:0')
epoch:  2000 quantization_loss:  0.07150814682245255
p mean is: tensor(-0.0189, device='cuda:0')
epoch:  3000 quantization_loss:  0.0715247094631195
p mean is: tensor(-0.0259, device='cuda:0')
epoch:  4000 quantization_loss:  0.07140248268842697
p mean is: tensor(-0.0324, device='cuda:0')
epoch:  5000 quantization_loss:  0.07161839306354523
p mean is: tensor(-0.0390, device='cuda:0')
epoch:  6000 quantization_loss:  0.07210125774145126
p mean is: tensor(-0.0459, device='cuda:0')
epoch:  7000 quantization_loss:  0.06895588338375092
p mean is: tensor(-0.0532, device='cuda:0')
epoch:  8000 quantization_loss:  0.05928688123822212
p mean is: tensor(-0.0615, device='cuda:0')
epoch:  9000 quantization_loss:  0.053230173885822296
p mean is: tensor(-0.0715, device='cuda:0')
epoch:  10000 quantization_loss:  0.05127453804016113
p mean is: tensor(-0.0842, device='cuda:0')
epoch:  11000 quantization_loss:  0.04992741718888283
p mean is: tensor(-0.1016, device='cuda:0')
epoch:  12000 quantization_loss:  0.04941585659980774
p mean is: tensor(-0.1250, device='cuda:0')
epoch:  13000 quantization_loss:  0.048810865730047226
p mean is: tensor(-0.1561, device='cuda:0')
epoch:  14000 quantization_loss:  0.048160653561353683
p mean is: tensor(-0.1964, device='cuda:0')
epoch:  15000 quantization_loss:  0.0474468395113945
p mean is: tensor(-0.2466, device='cuda:0')
epoch:  16000 quantization_loss:  0.04493746906518936
p mean is: tensor(-0.3065, device='cuda:0')
epoch:  17000 quantization_loss:  0.04318059980869293
p mean is: tensor(-0.3741, device='cuda:0')
epoch:  18000 quantization_loss:  0.04263542592525482
p mean is: tensor(-0.4474, device='cuda:0')
epoch:  19000 quantization_loss:  0.04228711500763893
p mean is: tensor(-0.5237, device='cuda:0')
epoch:  20000 quantization_loss:  0.04199482500553131
p mean is: tensor(-0.5996, device='cuda:0')
epoch:  21000 quantization_loss:  0.0416390523314476
p mean is: tensor(-0.6722, device='cuda:0')
epoch:  22000 quantization_loss:  0.04132472723722458
p mean is: tensor(-0.7394, device='cuda:0')
epoch:  23000 quantization_loss:  0.04114935174584389
p mean is: tensor(-0.8005, device='cuda:0')
epoch:  24000 quantization_loss:  0.04101550579071045
p mean is: tensor(-0.8553, device='cuda:0')
epoch:  25000 quantization_loss:  0.0402427539229393
p mean is: tensor(-0.9039, device='cuda:0')
epoch:  26000 quantization_loss:  0.03989244997501373
p mean is: tensor(-0.9465, device='cuda:0')
epoch:  27000 quantization_loss:  0.03977470099925995
p mean is: tensor(-0.9836, device='cuda:0')
epoch:  28000 quantization_loss:  0.03970164433121681
p mean is: tensor(-1.0161, device='cuda:0')
epoch:  29000 quantization_loss:  0.03964429721236229
p mean is: tensor(-1.0446, device='cuda:0')
epoch:  30000 quantization_loss:  0.039510805159807205
p mean is: tensor(-1.0696, device='cuda:0')
epoch:  31000 quantization_loss:  0.03944985941052437
p mean is: tensor(-1.0916, device='cuda:0')
epoch:  32000 quantization_loss:  0.039319343864917755
p mean is: tensor(-1.1109, device='cuda:0')
epoch:  33000 quantization_loss:  0.03930738940834999
p mean is: tensor(-1.1280, device='cuda:0')
epoch:  34000 quantization_loss:  0.03921986371278763
p mean is: tensor(-1.1432, device='cuda:0')
epoch:  35000 quantization_loss:  0.039170753210783005
p mean is: tensor(-1.1565, device='cuda:0')
epoch:  36000 quantization_loss:  0.041151002049446106
p mean is: tensor(-1.1684, device='cuda:0')
epoch:  37000 quantization_loss:  0.03905806690454483
p mean is: tensor(-1.1792, device='cuda:0')
epoch:  38000 quantization_loss:  0.039024561643600464
p mean is: tensor(-1.1887, device='cuda:0')
epoch:  39000 quantization_loss:  0.03905220329761505
p mean is: tensor(-1.1973, device='cuda:0')
epoch:  40000 quantization_loss:  0.038932669907808304
p mean is: tensor(-1.2051, device='cuda:0')
epoch:  41000 quantization_loss:  0.03893107920885086
p mean is: tensor(-1.2120, device='cuda:0')
epoch:  42000 quantization_loss:  0.03888234123587608
p mean is: tensor(-1.2184, device='cuda:0')
epoch:  43000 quantization_loss:  0.03884609043598175
p mean is: tensor(-1.2241, device='cuda:0')
epoch:  44000 quantization_loss:  0.03882947936654091
p mean is: tensor(-1.2293, device='cuda:0')
epoch:  45000 quantization_loss:  0.03883036598563194
p mean is: tensor(-1.2341, device='cuda:0')
epoch:  46000 quantization_loss:  0.038802795112133026
p mean is: tensor(-1.2385, device='cuda:0')
epoch:  47000 quantization_loss:  0.03877722844481468
p mean is: tensor(-1.2426, device='cuda:0')
epoch:  48000 quantization_loss:  0.03875930607318878
p mean is: tensor(-1.2463, device='cuda:0')
epoch:  49000 quantization_loss:  0.038737114518880844
p mean is: tensor(-1.2498, device='cuda:0')
epoch:  50000 quantization_loss:  0.038735128939151764
p mean is: tensor(-1.2529, device='cuda:0')
epoch:  51000 quantization_loss:  0.0387139655649662
p mean is: tensor(-1.2560, device='cuda:0')
epoch:  52000 quantization_loss:  0.03869489207863808
p mean is: tensor(-1.2587, device='cuda:0')
epoch:  53000 quantization_loss:  0.038745567202568054
p mean is: tensor(-1.2613, device='cuda:0')
epoch:  54000 quantization_loss:  0.0386681966483593
p mean is: tensor(-1.2637, device='cuda:0')
epoch:  55000 quantization_loss:  0.0386647991836071
p mean is: tensor(-1.2661, device='cuda:0')
epoch:  56000 quantization_loss:  0.03878749907016754
p mean is: tensor(-1.2683, device='cuda:0')
epoch:  57000 quantization_loss:  0.038637060672044754
p mean is: tensor(-1.2704, device='cuda:0')
epoch:  58000 quantization_loss:  0.038629669696092606
p mean is: tensor(-1.2724, device='cuda:0')
epoch:  59000 quantization_loss:  0.03861941397190094
p mean is: tensor(-1.2744, device='cuda:0')
Number of elements to keep: 2407093
Threshold value: -1.342094898223877
Number of elements equal to threshold: 2
Number of elements to randomly select: 2
Actual sparsity achieved: 0.7999998005893912
here
Number of elements to keep: 150443
Threshold value: -0.48993492126464844
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
1.1.1.weight         | nonzeros =    7927 /   12800             ( 61.93%) | total_pruned =    4873 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.2.weight           | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =    4376 /    6400             ( 68.38%) | total_pruned =    2024 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.5.weight           | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =    9566 /   12800             ( 74.73%) | total_pruned =    3234 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =   20638 /   25600             ( 80.62%) | total_pruned =    4962 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =   40875 /   51200             ( 79.83%) | total_pruned =   10325 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =   83106 /  102400             ( 81.16%) | total_pruned =   19294 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =  174360 /  204800             ( 85.14%) | total_pruned =   30440 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =  358104 /  409600             ( 87.43%) | total_pruned =   51496 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  352830 /  409600             ( 86.14%) | total_pruned =   56770 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  330280 /  409600             ( 80.63%) | total_pruned =   79320 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  306965 /  409600             ( 74.94%) | total_pruned =  102635 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  295009 /  409600             ( 72.02%) | total_pruned =  114591 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  109633 /  147456             ( 74.35%) | total_pruned =   37823 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  111806 /  147456             ( 75.82%) | total_pruned =   35650 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =  120062 /  147456             ( 81.42%) | total_pruned =   27394 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   59948 /   73728             ( 81.31%) | total_pruned =   13780 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =   13975 /   18432             ( 75.82%) | total_pruned =    4457 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    2762 /    4608             ( 59.94%) | total_pruned =    1846 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      25 /      48             ( 52.08%) | total_pruned =      23 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 2404997, pruned : 603870, total: 3008867, Compression rate :       1.25x  ( 20.07% pruned)
PSNR of output image is:  11.06309492286595
Experiment done
