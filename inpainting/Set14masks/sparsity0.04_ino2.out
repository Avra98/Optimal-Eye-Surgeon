(3, 256, 256)
(3, 256, 256)
Noisy PSNR is '8.852241976350125'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Output directory: data/inpainting/Set14/mask/2/sparsity/0.5/det/0.04/1e-09
epoch:  0 quantization_loss:  0.024518724530935287
p mean is: tensor(-0.0002, device='cuda:0')
epoch:  1000 quantization_loss:  0.02475082315504551
p mean is: tensor(-0.0087, device='cuda:0')
epoch:  2000 quantization_loss:  0.024205535650253296
p mean is: tensor(-0.0158, device='cuda:0')
epoch:  3000 quantization_loss:  0.024362878873944283
p mean is: tensor(-0.0233, device='cuda:0')
epoch:  4000 quantization_loss:  0.023686382919549942
p mean is: tensor(-0.0309, device='cuda:0')
epoch:  5000 quantization_loss:  0.024056561291217804
p mean is: tensor(-0.0387, device='cuda:0')
epoch:  6000 quantization_loss:  0.023852428421378136
p mean is: tensor(-0.0464, device='cuda:0')
epoch:  7000 quantization_loss:  0.024337338283658028
p mean is: tensor(-0.0544, device='cuda:0')
epoch:  8000 quantization_loss:  0.02406998723745346
p mean is: tensor(-0.0627, device='cuda:0')
epoch:  9000 quantization_loss:  0.024100294336676598
p mean is: tensor(-0.0715, device='cuda:0')
epoch:  10000 quantization_loss:  0.023317955434322357
p mean is: tensor(-0.0804, device='cuda:0')
epoch:  11000 quantization_loss:  0.02507130056619644
p mean is: tensor(-0.0896, device='cuda:0')
epoch:  12000 quantization_loss:  0.024492846801877022
p mean is: tensor(-0.0992, device='cuda:0')
epoch:  13000 quantization_loss:  0.023678218945860863
p mean is: tensor(-0.1092, device='cuda:0')
epoch:  14000 quantization_loss:  0.024225987493991852
p mean is: tensor(-0.1194, device='cuda:0')
epoch:  15000 quantization_loss:  0.0242216344922781
p mean is: tensor(-0.1299, device='cuda:0')
epoch:  16000 quantization_loss:  0.024217290803790092
p mean is: tensor(-0.1404, device='cuda:0')
epoch:  17000 quantization_loss:  0.017202623188495636
p mean is: tensor(-0.1515, device='cuda:0')
epoch:  18000 quantization_loss:  0.01212725043296814
p mean is: tensor(-0.1661, device='cuda:0')
epoch:  19000 quantization_loss:  0.00953279621899128
p mean is: tensor(-0.1860, device='cuda:0')
epoch:  20000 quantization_loss:  0.006660460494458675
p mean is: tensor(-0.2124, device='cuda:0')
epoch:  21000 quantization_loss:  0.0052522821351885796
p mean is: tensor(-0.2456, device='cuda:0')
epoch:  22000 quantization_loss:  0.005092916544526815
p mean is: tensor(-0.2876, device='cuda:0')
epoch:  23000 quantization_loss:  0.004729453474283218
p mean is: tensor(-0.3402, device='cuda:0')
epoch:  24000 quantization_loss:  0.00434546684846282
p mean is: tensor(-0.4035, device='cuda:0')
epoch:  25000 quantization_loss:  0.004014469217509031
p mean is: tensor(-0.4758, device='cuda:0')
epoch:  26000 quantization_loss:  0.0037461831234395504
p mean is: tensor(-0.5544, device='cuda:0')
epoch:  27000 quantization_loss:  0.0036950367502868176
p mean is: tensor(-0.6355, device='cuda:0')
epoch:  28000 quantization_loss:  0.00346980057656765
p mean is: tensor(-0.7149, device='cuda:0')
epoch:  29000 quantization_loss:  0.0034684075508266687
p mean is: tensor(-0.7894, device='cuda:0')
epoch:  30000 quantization_loss:  0.003219140227884054
p mean is: tensor(-0.8570, device='cuda:0')
epoch:  31000 quantization_loss:  0.0031217096839100122
p mean is: tensor(-0.9165, device='cuda:0')
epoch:  32000 quantization_loss:  0.0029912132304161787
p mean is: tensor(-0.9679, device='cuda:0')
epoch:  33000 quantization_loss:  0.0028799911960959435
p mean is: tensor(-1.0118, device='cuda:0')
epoch:  34000 quantization_loss:  0.002842180896550417
p mean is: tensor(-1.0491, device='cuda:0')
epoch:  35000 quantization_loss:  0.002826579147949815
p mean is: tensor(-1.0808, device='cuda:0')
epoch:  36000 quantization_loss:  0.0026975658256560564
p mean is: tensor(-1.1077, device='cuda:0')
epoch:  37000 quantization_loss:  0.002647863235324621
p mean is: tensor(-1.1307, device='cuda:0')
epoch:  38000 quantization_loss:  0.0025982665829360485
p mean is: tensor(-1.1505, device='cuda:0')
epoch:  39000 quantization_loss:  0.002567704301327467
p mean is: tensor(-1.1675, device='cuda:0')
epoch:  40000 quantization_loss:  0.002534541767090559
p mean is: tensor(-1.1821, device='cuda:0')
epoch:  41000 quantization_loss:  0.0024871588684618473
p mean is: tensor(-1.1947, device='cuda:0')
epoch:  42000 quantization_loss:  0.0024498957209289074
p mean is: tensor(-1.2055, device='cuda:0')
epoch:  43000 quantization_loss:  0.0024076986592262983
p mean is: tensor(-1.2149, device='cuda:0')
epoch:  44000 quantization_loss:  0.0023781810887157917
p mean is: tensor(-1.2230, device='cuda:0')
epoch:  45000 quantization_loss:  0.0023507126607000828
p mean is: tensor(-1.2301, device='cuda:0')
epoch:  46000 quantization_loss:  0.002342973370105028
p mean is: tensor(-1.2363, device='cuda:0')
epoch:  47000 quantization_loss:  0.0023117861710488796
p mean is: tensor(-1.2418, device='cuda:0')
epoch:  48000 quantization_loss:  0.0022832928225398064
p mean is: tensor(-1.2466, device='cuda:0')
epoch:  49000 quantization_loss:  0.002273960504680872
p mean is: tensor(-1.2509, device='cuda:0')
epoch:  50000 quantization_loss:  0.002243806142359972
p mean is: tensor(-1.2547, device='cuda:0')
epoch:  51000 quantization_loss:  0.00223225518129766
p mean is: tensor(-1.2580, device='cuda:0')
epoch:  52000 quantization_loss:  0.0022223182022571564
p mean is: tensor(-1.2611, device='cuda:0')
epoch:  53000 quantization_loss:  0.002195921493694186
p mean is: tensor(-1.2638, device='cuda:0')
epoch:  54000 quantization_loss:  0.002183768665418029
p mean is: tensor(-1.2663, device='cuda:0')
epoch:  55000 quantization_loss:  0.0021673538722097874
p mean is: tensor(-1.2685, device='cuda:0')
epoch:  56000 quantization_loss:  0.0021617345046252012
p mean is: tensor(-1.2705, device='cuda:0')
epoch:  57000 quantization_loss:  0.002145991660654545
p mean is: tensor(-1.2723, device='cuda:0')
epoch:  58000 quantization_loss:  0.0021383839193731546
p mean is: tensor(-1.2740, device='cuda:0')
epoch:  59000 quantization_loss:  0.0021296031773090363
p mean is: tensor(-1.2755, device='cuda:0')
Number of elements to keep: 120354
Threshold value: -0.9456481337547302
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.03999977400131013
here
Number of elements to keep: 150443
Threshold value: -1.06450617313385
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
1.1.1.weight         | nonzeros =     892 /   12800             (  6.97%) | total_pruned =   11908 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     280 /    6400             (  4.38%) | total_pruned =    6120 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =      12 /      16             ( 75.00%) | total_pruned =       4 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     335 /   12800             (  2.62%) | total_pruned =   12465 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     325 /   25600             (  1.27%) | total_pruned =   25275 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     324 /   51200             (  0.63%) | total_pruned =   50876 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     522 /  102400             (  0.51%) | total_pruned =  101878 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     779 /  204800             (  0.38%) | total_pruned =  204021 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =    1505 /  409600             (  0.37%) | total_pruned =  408095 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      37 /     128             ( 28.91%) | total_pruned =      91 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    2488 /  409600             (  0.61%) | total_pruned =  407112 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    4562 /  409600             (  1.11%) | total_pruned =  405038 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   12507 /  409600             (  3.05%) | total_pruned =  397093 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   26182 /  409600             (  6.39%) | total_pruned =  383418 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   16321 /  147456             ( 11.07%) | total_pruned =  131135 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   20892 /  147456             ( 14.17%) | total_pruned =  126564 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   21041 /  147456             ( 14.27%) | total_pruned =  126415 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    7543 /   73728             ( 10.23%) | total_pruned =   66185 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    1811 /   18432             (  9.83%) | total_pruned =   16621 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =     962 /    4608             ( 20.88%) | total_pruned =    3646 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      33 /      48             ( 68.75%) | total_pruned =      15 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 120354, pruned : 2888513, total: 3008867, Compression rate :      25.00x  ( 96.00% pruned)
PSNR of output image is:  23.61750973835997
Experiment done
