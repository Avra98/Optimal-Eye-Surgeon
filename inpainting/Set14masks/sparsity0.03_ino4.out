(3, 512, 512)
(3, 512, 512)
Noisy PSNR is '8.729726728453446'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Output directory: data/inpainting/Set14/mask/4/sparsity/0.5/det/0.03/1e-09
epoch:  0 quantization_loss:  0.03150477632880211
p mean is: tensor(-0.0002, device='cuda:0')
epoch:  1000 quantization_loss:  0.026475120335817337
p mean is: tensor(-0.0170, device='cuda:0')
epoch:  2000 quantization_loss:  0.025527339428663254
p mean is: tensor(-0.0323, device='cuda:0')
epoch:  3000 quantization_loss:  0.025109564885497093
p mean is: tensor(-0.0489, device='cuda:0')
epoch:  4000 quantization_loss:  0.025024639442563057
p mean is: tensor(-0.0663, device='cuda:0')
epoch:  5000 quantization_loss:  0.02489449642598629
p mean is: tensor(-0.0849, device='cuda:0')
epoch:  6000 quantization_loss:  0.025216422975063324
p mean is: tensor(-0.1052, device='cuda:0')
epoch:  7000 quantization_loss:  0.02416163496673107
p mean is: tensor(-0.1275, device='cuda:0')
epoch:  8000 quantization_loss:  0.020761871710419655
p mean is: tensor(-0.1510, device='cuda:0')
epoch:  9000 quantization_loss:  0.01873554103076458
p mean is: tensor(-0.1778, device='cuda:0')
epoch:  10000 quantization_loss:  0.016596248373389244
p mean is: tensor(-0.2090, device='cuda:0')
epoch:  11000 quantization_loss:  0.014623478055000305
p mean is: tensor(-0.2454, device='cuda:0')
epoch:  12000 quantization_loss:  0.013563251122832298
p mean is: tensor(-0.2885, device='cuda:0')
epoch:  13000 quantization_loss:  0.012149329297244549
p mean is: tensor(-0.3400, device='cuda:0')
epoch:  14000 quantization_loss:  0.010926583781838417
p mean is: tensor(-0.3996, device='cuda:0')
epoch:  15000 quantization_loss:  0.010067665949463844
p mean is: tensor(-0.4653, device='cuda:0')
epoch:  16000 quantization_loss:  0.009137029759585857
p mean is: tensor(-0.5350, device='cuda:0')
epoch:  17000 quantization_loss:  0.008691337890923023
p mean is: tensor(-0.6060, device='cuda:0')
epoch:  18000 quantization_loss:  0.008120700716972351
p mean is: tensor(-0.6753, device='cuda:0')
epoch:  19000 quantization_loss:  0.007755145896226168
p mean is: tensor(-0.7410, device='cuda:0')
epoch:  20000 quantization_loss:  0.007585201412439346
p mean is: tensor(-0.8013, device='cuda:0')
epoch:  21000 quantization_loss:  0.007422778755426407
p mean is: tensor(-0.8555, device='cuda:0')
epoch:  22000 quantization_loss:  0.0071256100200116634
p mean is: tensor(-0.9037, device='cuda:0')
epoch:  23000 quantization_loss:  0.006962918676435947
p mean is: tensor(-0.9460, device='cuda:0')
epoch:  24000 quantization_loss:  0.006789118982851505
p mean is: tensor(-0.9831, device='cuda:0')
epoch:  25000 quantization_loss:  0.006541273556649685
p mean is: tensor(-1.0156, device='cuda:0')
epoch:  26000 quantization_loss:  0.0064955418929457664
p mean is: tensor(-1.0440, device='cuda:0')
epoch:  27000 quantization_loss:  0.006354596931487322
p mean is: tensor(-1.0691, device='cuda:0')
epoch:  28000 quantization_loss:  0.006228187587112188
p mean is: tensor(-1.0910, device='cuda:0')
epoch:  29000 quantization_loss:  0.005775873549282551
p mean is: tensor(-1.1105, device='cuda:0')
epoch:  30000 quantization_loss:  0.005564022343605757
p mean is: tensor(-1.1275, device='cuda:0')
epoch:  31000 quantization_loss:  0.0052468013018369675
p mean is: tensor(-1.1426, device='cuda:0')
epoch:  32000 quantization_loss:  0.005136250052601099
p mean is: tensor(-1.1559, device='cuda:0')
epoch:  33000 quantization_loss:  0.005080330651253462
p mean is: tensor(-1.1678, device='cuda:0')
epoch:  34000 quantization_loss:  0.005009242333471775
p mean is: tensor(-1.1785, device='cuda:0')
epoch:  35000 quantization_loss:  0.004976180382072926
p mean is: tensor(-1.1882, device='cuda:0')
epoch:  36000 quantization_loss:  0.004915416240692139
p mean is: tensor(-1.1970, device='cuda:0')
epoch:  37000 quantization_loss:  0.004859252367168665
p mean is: tensor(-1.2050, device='cuda:0')
epoch:  38000 quantization_loss:  0.0048187109641730785
p mean is: tensor(-1.2123, device='cuda:0')
epoch:  39000 quantization_loss:  0.004793091211467981
p mean is: tensor(-1.2189, device='cuda:0')
epoch:  40000 quantization_loss:  0.00474892184138298
p mean is: tensor(-1.2249, device='cuda:0')
epoch:  41000 quantization_loss:  0.004729956388473511
p mean is: tensor(-1.2305, device='cuda:0')
epoch:  42000 quantization_loss:  0.004697978962212801
p mean is: tensor(-1.2356, device='cuda:0')
epoch:  43000 quantization_loss:  0.004669115878641605
p mean is: tensor(-1.2402, device='cuda:0')
epoch:  44000 quantization_loss:  0.004669285379350185
p mean is: tensor(-1.2446, device='cuda:0')
epoch:  45000 quantization_loss:  0.004625799600034952
p mean is: tensor(-1.2487, device='cuda:0')
epoch:  46000 quantization_loss:  0.004710707347840071
p mean is: tensor(-1.2524, device='cuda:0')
epoch:  47000 quantization_loss:  0.0045764753594994545
p mean is: tensor(-1.2559, device='cuda:0')
epoch:  48000 quantization_loss:  0.004568514879792929
p mean is: tensor(-1.2592, device='cuda:0')
epoch:  49000 quantization_loss:  0.004614247474819422
p mean is: tensor(-1.2622, device='cuda:0')
epoch:  50000 quantization_loss:  0.004532311111688614
p mean is: tensor(-1.2651, device='cuda:0')
epoch:  51000 quantization_loss:  0.004519084934145212
p mean is: tensor(-1.2678, device='cuda:0')
epoch:  52000 quantization_loss:  0.004518359899520874
p mean is: tensor(-1.2704, device='cuda:0')
epoch:  53000 quantization_loss:  0.00450080307200551
p mean is: tensor(-1.2728, device='cuda:0')
epoch:  54000 quantization_loss:  0.004489259794354439
p mean is: tensor(-1.2752, device='cuda:0')
epoch:  55000 quantization_loss:  0.004490762483328581
p mean is: tensor(-1.2774, device='cuda:0')
epoch:  56000 quantization_loss:  0.004479680210351944
p mean is: tensor(-1.2795, device='cuda:0')
epoch:  57000 quantization_loss:  0.004471434745937586
p mean is: tensor(-1.2815, device='cuda:0')
epoch:  58000 quantization_loss:  0.0044649397023022175
p mean is: tensor(-1.2835, device='cuda:0')
epoch:  59000 quantization_loss:  0.004458993207663298
p mean is: tensor(-1.2853, device='cuda:0')
Number of elements to keep: 90266
Threshold value: 4.027775764465332
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.029999996676489855
here
Number of elements to keep: 150443
Threshold value: -0.2638690173625946
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
1.1.1.weight         | nonzeros =     265 /   12800             (  2.07%) | total_pruned =   12535 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =      14 /    6400             (  0.22%) | total_pruned =    6386 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =       0 /   12800             (  0.00%) | total_pruned =   12800 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =       0 /   25600             (  0.00%) | total_pruned =   25600 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =       0 /   51200             (  0.00%) | total_pruned =   51200 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =       0 /  102400             (  0.00%) | total_pruned =  102400 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =       0 /  204800             (  0.00%) | total_pruned =  204800 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =       0 /  409600             (  0.00%) | total_pruned =  409600 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =       0 /  409600             (  0.00%) | total_pruned =  409600 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =       0 /  409600             (  0.00%) | total_pruned =  409600 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =      73 /  409600             (  0.02%) | total_pruned =  409527 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    6982 /  409600             (  1.70%) | total_pruned =  402618 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   25844 /  147456             ( 17.53%) | total_pruned =  121612 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   23557 /  147456             ( 15.98%) | total_pruned =  123899 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   19378 /  147456             ( 13.14%) | total_pruned =  128078 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    8640 /   73728             ( 11.72%) | total_pruned =   65088 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2879 /   18432             ( 15.62%) | total_pruned =   15553 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      22 /      32             ( 68.75%) | total_pruned =      10 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1362 /    4608             ( 29.56%) | total_pruned =    3246 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      34 /      48             ( 70.83%) | total_pruned =      14 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 90266, pruned : 2918601, total: 3008867, Compression rate :      33.33x  ( 97.00% pruned)
PSNR of output image is:  12.398003195997344
Experiment done
