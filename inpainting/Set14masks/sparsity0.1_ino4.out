(3, 512, 512)
(3, 512, 512)
Noisy PSNR is '8.730568502030033'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Output directory: data/inpainting/Set14/mask/4/sparsity/0.5/det/0.1/1e-09
epoch:  0 quantization_loss:  0.032059647142887115
p mean is: tensor(-0.0002, device='cuda:0')
epoch:  1000 quantization_loss:  0.027244092896580696
p mean is: tensor(-0.0214, device='cuda:0')
epoch:  2000 quantization_loss:  0.026756735518574715
p mean is: tensor(-0.0411, device='cuda:0')
epoch:  3000 quantization_loss:  0.02629525400698185
p mean is: tensor(-0.0624, device='cuda:0')
epoch:  4000 quantization_loss:  0.026654304936528206
p mean is: tensor(-0.0846, device='cuda:0')
epoch:  5000 quantization_loss:  0.02628355473279953
p mean is: tensor(-0.1077, device='cuda:0')
epoch:  6000 quantization_loss:  0.024053188040852547
p mean is: tensor(-0.1310, device='cuda:0')
epoch:  7000 quantization_loss:  0.02236318215727806
p mean is: tensor(-0.1574, device='cuda:0')
epoch:  8000 quantization_loss:  0.020394686609506607
p mean is: tensor(-0.1896, device='cuda:0')
epoch:  9000 quantization_loss:  0.018931757658720016
p mean is: tensor(-0.2280, device='cuda:0')
epoch:  10000 quantization_loss:  0.017257755622267723
p mean is: tensor(-0.2740, device='cuda:0')
epoch:  11000 quantization_loss:  0.016568481922149658
p mean is: tensor(-0.3283, device='cuda:0')
epoch:  12000 quantization_loss:  0.014845583587884903
p mean is: tensor(-0.3912, device='cuda:0')
epoch:  13000 quantization_loss:  0.013691028580069542
p mean is: tensor(-0.4605, device='cuda:0')
epoch:  14000 quantization_loss:  0.013265826739370823
p mean is: tensor(-0.5333, device='cuda:0')
epoch:  15000 quantization_loss:  0.010758629068732262
p mean is: tensor(-0.6067, device='cuda:0')
epoch:  16000 quantization_loss:  0.010187148116528988
p mean is: tensor(-0.6769, device='cuda:0')
epoch:  17000 quantization_loss:  0.00989252794533968
p mean is: tensor(-0.7427, device='cuda:0')
epoch:  18000 quantization_loss:  0.00966225378215313
p mean is: tensor(-0.8033, device='cuda:0')
epoch:  19000 quantization_loss:  0.009425103664398193
p mean is: tensor(-0.8581, device='cuda:0')
epoch:  20000 quantization_loss:  0.00928540714085102
p mean is: tensor(-0.9069, device='cuda:0')
epoch:  21000 quantization_loss:  0.009173701517283916
p mean is: tensor(-0.9500, device='cuda:0')
epoch:  22000 quantization_loss:  0.008667942136526108
p mean is: tensor(-0.9876, device='cuda:0')
epoch:  23000 quantization_loss:  0.008600935339927673
p mean is: tensor(-1.0205, device='cuda:0')
epoch:  24000 quantization_loss:  0.008476976305246353
p mean is: tensor(-1.0494, device='cuda:0')
epoch:  25000 quantization_loss:  0.00833891797810793
p mean is: tensor(-1.0748, device='cuda:0')
epoch:  26000 quantization_loss:  0.008236710913479328
p mean is: tensor(-1.0972, device='cuda:0')
epoch:  27000 quantization_loss:  0.008139495737850666
p mean is: tensor(-1.1171, device='cuda:0')
epoch:  28000 quantization_loss:  0.008065929636359215
p mean is: tensor(-1.1346, device='cuda:0')
epoch:  29000 quantization_loss:  0.007992656901478767
p mean is: tensor(-1.1502, device='cuda:0')
epoch:  30000 quantization_loss:  0.007941583171486855
p mean is: tensor(-1.1640, device='cuda:0')
epoch:  31000 quantization_loss:  0.007911209017038345
p mean is: tensor(-1.1763, device='cuda:0')
epoch:  32000 quantization_loss:  0.007841786369681358
p mean is: tensor(-1.1873, device='cuda:0')
epoch:  33000 quantization_loss:  0.007799334824085236
p mean is: tensor(-1.1972, device='cuda:0')
epoch:  34000 quantization_loss:  0.007742565590888262
p mean is: tensor(-1.2062, device='cuda:0')
epoch:  35000 quantization_loss:  0.007710753474384546
p mean is: tensor(-1.2142, device='cuda:0')
epoch:  36000 quantization_loss:  0.007745374459773302
p mean is: tensor(-1.2214, device='cuda:0')
epoch:  37000 quantization_loss:  0.007653601001948118
p mean is: tensor(-1.2281, device='cuda:0')
epoch:  38000 quantization_loss:  0.007630141917616129
p mean is: tensor(-1.2341, device='cuda:0')
epoch:  39000 quantization_loss:  0.0076149748638272285
p mean is: tensor(-1.2396, device='cuda:0')
epoch:  40000 quantization_loss:  0.007582404650747776
p mean is: tensor(-1.2446, device='cuda:0')
epoch:  41000 quantization_loss:  0.007571436930447817
p mean is: tensor(-1.2491, device='cuda:0')
epoch:  42000 quantization_loss:  0.007543704938143492
p mean is: tensor(-1.2534, device='cuda:0')
epoch:  43000 quantization_loss:  0.007537454832345247
p mean is: tensor(-1.2574, device='cuda:0')
epoch:  44000 quantization_loss:  0.007523129228502512
p mean is: tensor(-1.2610, device='cuda:0')
epoch:  45000 quantization_loss:  0.007511598989367485
p mean is: tensor(-1.2644, device='cuda:0')
epoch:  46000 quantization_loss:  0.007537482306361198
p mean is: tensor(-1.2675, device='cuda:0')
epoch:  47000 quantization_loss:  0.007486231159418821
p mean is: tensor(-1.2705, device='cuda:0')
epoch:  48000 quantization_loss:  0.007480976637452841
p mean is: tensor(-1.2732, device='cuda:0')
epoch:  49000 quantization_loss:  0.007460978347808123
p mean is: tensor(-1.2759, device='cuda:0')
epoch:  50000 quantization_loss:  0.007450389210134745
p mean is: tensor(-1.2783, device='cuda:0')
epoch:  51000 quantization_loss:  0.0074501438066363335
p mean is: tensor(-1.2806, device='cuda:0')
epoch:  52000 quantization_loss:  0.007459424901753664
p mean is: tensor(-1.2828, device='cuda:0')
epoch:  53000 quantization_loss:  0.007440236862748861
p mean is: tensor(-1.2849, device='cuda:0')
epoch:  54000 quantization_loss:  0.0074274735525250435
p mean is: tensor(-1.2869, device='cuda:0')
epoch:  55000 quantization_loss:  0.007419331464916468
p mean is: tensor(-1.2887, device='cuda:0')
epoch:  56000 quantization_loss:  0.007421488873660564
p mean is: tensor(-1.2905, device='cuda:0')
epoch:  57000 quantization_loss:  0.007409907877445221
p mean is: tensor(-1.2922, device='cuda:0')
epoch:  58000 quantization_loss:  0.007419675588607788
p mean is: tensor(-1.2939, device='cuda:0')
epoch:  59000 quantization_loss:  0.007400776259601116
p mean is: tensor(-1.2955, device='cuda:0')
Number of elements to keep: 300886
Threshold value: -1.107718586921692
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.09999976735428984
here
Number of elements to keep: 150443
Threshold value: -0.5076724886894226
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
1.1.1.weight         | nonzeros =    2066 /   12800             ( 16.14%) | total_pruned =   10734 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     518 /    6400             (  8.09%) | total_pruned =    5882 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     825 /   12800             (  6.45%) | total_pruned =   11975 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      13 /      32             ( 40.62%) | total_pruned =      19 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =    1071 /   25600             (  4.18%) | total_pruned =   24529 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      12 /      32             ( 37.50%) | total_pruned =      20 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =    1887 /   51200             (  3.69%) | total_pruned =   49313 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =    3985 /  102400             (  3.89%) | total_pruned =   98415 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =    8600 /  204800             (  4.20%) | total_pruned =  196200 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =   14861 /  409600             (  3.63%) | total_pruned =  394739 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   20228 /  409600             (  4.94%) | total_pruned =  389372 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   36091 /  409600             (  8.81%) | total_pruned =  373509 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   51272 /  409600             ( 12.52%) | total_pruned =  358328 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   66108 /  409600             ( 16.14%) | total_pruned =  343492 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   31842 /  147456             ( 21.59%) | total_pruned =  115614 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   25217 /  147456             ( 17.10%) | total_pruned =  122239 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   21238 /  147456             ( 14.40%) | total_pruned =  126218 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    9560 /   73728             ( 12.97%) | total_pruned =   64168 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2874 /   18432             ( 15.59%) | total_pruned =   15558 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1350 /    4608             ( 29.30%) | total_pruned =    3258 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      27 /      48             ( 56.25%) | total_pruned =      21 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 300886, pruned : 2707981, total: 3008867, Compression rate :      10.00x  ( 90.00% pruned)
PSNR of output image is:  18.282135499106648
Experiment done
