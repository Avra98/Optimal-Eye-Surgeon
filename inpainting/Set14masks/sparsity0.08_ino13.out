(3, 512, 512)
(3, 512, 512)
Noisy PSNR is '7.89245948886329'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Output directory: data/inpainting/Set14/mask/13/sparsity/0.5/det/0.08/1e-09
epoch:  0 quantization_loss:  0.029705669730901718
p mean is: tensor(-0.0002, device='cuda:7')
epoch:  1000 quantization_loss:  0.02324455790221691
p mean is: tensor(-0.0153, device='cuda:7')
epoch:  2000 quantization_loss:  0.021338658407330513
p mean is: tensor(-0.0264, device='cuda:7')
epoch:  3000 quantization_loss:  0.02067762054502964
p mean is: tensor(-0.0379, device='cuda:7')
epoch:  4000 quantization_loss:  0.020549865439534187
p mean is: tensor(-0.0497, device='cuda:7')
epoch:  5000 quantization_loss:  0.020772835239768028
p mean is: tensor(-0.0619, device='cuda:7')
epoch:  6000 quantization_loss:  0.02034112811088562
p mean is: tensor(-0.0754, device='cuda:7')
epoch:  7000 quantization_loss:  0.0198159571737051
p mean is: tensor(-0.0903, device='cuda:7')
epoch:  8000 quantization_loss:  0.0179637148976326
p mean is: tensor(-0.1083, device='cuda:7')
epoch:  9000 quantization_loss:  0.01711026206612587
p mean is: tensor(-0.1324, device='cuda:7')
epoch:  10000 quantization_loss:  0.012322241440415382
p mean is: tensor(-0.1598, device='cuda:7')
epoch:  11000 quantization_loss:  0.0108114555478096
p mean is: tensor(-0.1934, device='cuda:7')
epoch:  12000 quantization_loss:  0.009890083223581314
p mean is: tensor(-0.2356, device='cuda:7')
epoch:  13000 quantization_loss:  0.009177811443805695
p mean is: tensor(-0.2873, device='cuda:7')
epoch:  14000 quantization_loss:  0.008459540084004402
p mean is: tensor(-0.3480, device='cuda:7')
epoch:  15000 quantization_loss:  0.008222599513828754
p mean is: tensor(-0.4165, device='cuda:7')
epoch:  16000 quantization_loss:  0.007936477661132812
p mean is: tensor(-0.4903, device='cuda:7')
epoch:  17000 quantization_loss:  0.0077784983441233635
p mean is: tensor(-0.5665, device='cuda:7')
epoch:  18000 quantization_loss:  0.007515286095440388
p mean is: tensor(-0.6417, device='cuda:7')
epoch:  19000 quantization_loss:  0.0073157972656190395
p mean is: tensor(-0.7127, device='cuda:7')
epoch:  20000 quantization_loss:  0.007192688528448343
p mean is: tensor(-0.7782, device='cuda:7')
epoch:  21000 quantization_loss:  0.007088304962962866
p mean is: tensor(-0.8373, device='cuda:7')
epoch:  22000 quantization_loss:  0.007040370721369982
p mean is: tensor(-0.8897, device='cuda:7')
epoch:  23000 quantization_loss:  0.006954167503863573
p mean is: tensor(-0.9360, device='cuda:7')
epoch:  24000 quantization_loss:  0.006899779662489891
p mean is: tensor(-0.9766, device='cuda:7')
epoch:  25000 quantization_loss:  0.006826902274042368
p mean is: tensor(-1.0122, device='cuda:7')
epoch:  26000 quantization_loss:  0.006825560703873634
p mean is: tensor(-1.0434, device='cuda:7')
epoch:  27000 quantization_loss:  0.006739326752722263
p mean is: tensor(-1.0706, device='cuda:7')
epoch:  28000 quantization_loss:  0.006716955453157425
p mean is: tensor(-1.0945, device='cuda:7')
epoch:  29000 quantization_loss:  0.006674342788755894
p mean is: tensor(-1.1155, device='cuda:7')
epoch:  30000 quantization_loss:  0.006644165609031916
p mean is: tensor(-1.1338, device='cuda:7')
epoch:  31000 quantization_loss:  0.006618134677410126
p mean is: tensor(-1.1501, device='cuda:7')
epoch:  32000 quantization_loss:  0.0065928236581385136
p mean is: tensor(-1.1646, device='cuda:7')
epoch:  33000 quantization_loss:  0.0065790265798568726
p mean is: tensor(-1.1773, device='cuda:7')
epoch:  34000 quantization_loss:  0.006565398536622524
p mean is: tensor(-1.1887, device='cuda:7')
epoch:  35000 quantization_loss:  0.006549024023115635
p mean is: tensor(-1.1988, device='cuda:7')
epoch:  36000 quantization_loss:  0.006519169546663761
p mean is: tensor(-1.2080, device='cuda:7')
epoch:  37000 quantization_loss:  0.006494489964097738
p mean is: tensor(-1.2161, device='cuda:7')
epoch:  38000 quantization_loss:  0.006479450035840273
p mean is: tensor(-1.2235, device='cuda:7')
epoch:  39000 quantization_loss:  0.0064844051375985146
p mean is: tensor(-1.2301, device='cuda:7')
epoch:  40000 quantization_loss:  0.006451728288084269
p mean is: tensor(-1.2361, device='cuda:7')
epoch:  41000 quantization_loss:  0.006441102828830481
p mean is: tensor(-1.2416, device='cuda:7')
epoch:  42000 quantization_loss:  0.006441830191761255
p mean is: tensor(-1.2465, device='cuda:7')
epoch:  43000 quantization_loss:  0.006433346774429083
p mean is: tensor(-1.2510, device='cuda:7')
epoch:  44000 quantization_loss:  0.006423079874366522
p mean is: tensor(-1.2552, device='cuda:7')
epoch:  45000 quantization_loss:  0.006411837413907051
p mean is: tensor(-1.2591, device='cuda:7')
epoch:  46000 quantization_loss:  0.006405419670045376
p mean is: tensor(-1.2626, device='cuda:7')
epoch:  47000 quantization_loss:  0.006414015311747789
p mean is: tensor(-1.2658, device='cuda:7')
epoch:  48000 quantization_loss:  0.0063875592313706875
p mean is: tensor(-1.2688, device='cuda:7')
epoch:  49000 quantization_loss:  0.006394113879650831
p mean is: tensor(-1.2715, device='cuda:7')
epoch:  50000 quantization_loss:  0.006374293472617865
p mean is: tensor(-1.2741, device='cuda:7')
epoch:  51000 quantization_loss:  0.006370247807353735
p mean is: tensor(-1.2765, device='cuda:7')
epoch:  52000 quantization_loss:  0.006361670792102814
p mean is: tensor(-1.2788, device='cuda:7')
epoch:  53000 quantization_loss:  0.0063548339530825615
p mean is: tensor(-1.2809, device='cuda:7')
epoch:  54000 quantization_loss:  0.006351697724312544
p mean is: tensor(-1.2829, device='cuda:7')
epoch:  55000 quantization_loss:  0.006357337813824415
p mean is: tensor(-1.2847, device='cuda:7')
epoch:  56000 quantization_loss:  0.006346831563860178
p mean is: tensor(-1.2864, device='cuda:7')
epoch:  57000 quantization_loss:  0.006335619371384382
p mean is: tensor(-1.2881, device='cuda:7')
epoch:  58000 quantization_loss:  0.006351754069328308
p mean is: tensor(-1.2898, device='cuda:7')
epoch:  59000 quantization_loss:  0.006331752520054579
p mean is: tensor(-1.2913, device='cuda:7')
Number of elements to keep: 240709
Threshold value: -1.03038489818573
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.07999988035363477
here
Number of elements to keep: 150443
Threshold value: -0.6990662813186646
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
1.1.1.weight         | nonzeros =    2155 /   12800             ( 16.84%) | total_pruned =   10645 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     546 /    6400             (  8.53%) | total_pruned =    5854 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     791 /   12800             (  6.18%) | total_pruned =   12009 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =    1129 /   25600             (  4.41%) | total_pruned =   24471 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      14 /      32             ( 43.75%) | total_pruned =      18 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =    1374 /   51200             (  2.68%) | total_pruned =   49826 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =    2342 /  102400             (  2.29%) | total_pruned =  100058 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =    3554 /  204800             (  1.74%) | total_pruned =  201246 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =    8368 /  409600             (  2.04%) | total_pruned =  401232 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   13750 /  409600             (  3.36%) | total_pruned =  395850 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   25465 /  409600             (  6.22%) | total_pruned =  384135 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   44413 /  409600             ( 10.84%) | total_pruned =  365187 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   50459 /  409600             ( 12.32%) | total_pruned =  359141 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   25427 /  147456             ( 17.24%) | total_pruned =  122029 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   23884 /  147456             ( 16.20%) | total_pruned =  123572 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   21270 /  147456             ( 14.42%) | total_pruned =  126186 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   11149 /   73728             ( 15.12%) | total_pruned =   62579 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2310 /   18432             ( 12.53%) | total_pruned =   16122 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      15 /      32             ( 46.88%) | total_pruned =      17 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1016 /    4608             ( 22.05%) | total_pruned =    3592 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      35 /      48             ( 72.92%) | total_pruned =      13 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 240709, pruned : 2768158, total: 3008867, Compression rate :      12.50x  ( 92.00% pruned)
PSNR of output image is:  18.61339768623376
Experiment done
