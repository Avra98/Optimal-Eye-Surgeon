(3, 512, 512)
(3, 512, 512)
Noisy PSNR is '7.8887687709135035'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Output directory: data/inpainting/Set14/mask/13/sparsity/0.5/det/0.1/1e-09
epoch:  0 quantization_loss:  0.024078307673335075
p mean is: tensor(-0.0002, device='cuda:1')
epoch:  1000 quantization_loss:  0.020464304834604263
p mean is: tensor(-0.0159, device='cuda:1')
epoch:  2000 quantization_loss:  0.01918584480881691
p mean is: tensor(-0.0284, device='cuda:1')
epoch:  3000 quantization_loss:  0.018629882484674454
p mean is: tensor(-0.0414, device='cuda:1')
epoch:  4000 quantization_loss:  0.01831989735364914
p mean is: tensor(-0.0549, device='cuda:1')
epoch:  5000 quantization_loss:  0.018137803301215172
p mean is: tensor(-0.0693, device='cuda:1')
epoch:  6000 quantization_loss:  0.018047235906124115
p mean is: tensor(-0.0848, device='cuda:1')
epoch:  7000 quantization_loss:  0.017636029049754143
p mean is: tensor(-0.1021, device='cuda:1')
epoch:  8000 quantization_loss:  0.015071653760969639
p mean is: tensor(-0.1212, device='cuda:1')
epoch:  9000 quantization_loss:  0.012256978079676628
p mean is: tensor(-0.1443, device='cuda:1')
epoch:  10000 quantization_loss:  0.009376303292810917
p mean is: tensor(-0.1715, device='cuda:1')
epoch:  11000 quantization_loss:  0.007684980984777212
p mean is: tensor(-0.2044, device='cuda:1')
epoch:  12000 quantization_loss:  0.006931487005203962
p mean is: tensor(-0.2454, device='cuda:1')
epoch:  13000 quantization_loss:  0.006151030771434307
p mean is: tensor(-0.2953, device='cuda:1')
epoch:  14000 quantization_loss:  0.005745519418269396
p mean is: tensor(-0.3543, device='cuda:1')
epoch:  15000 quantization_loss:  0.0054078674875199795
p mean is: tensor(-0.4208, device='cuda:1')
epoch:  16000 quantization_loss:  0.005116182379424572
p mean is: tensor(-0.4925, device='cuda:1')
epoch:  17000 quantization_loss:  0.005125120282173157
p mean is: tensor(-0.5665, device='cuda:1')
epoch:  18000 quantization_loss:  0.0047387066297233105
p mean is: tensor(-0.6395, device='cuda:1')
epoch:  19000 quantization_loss:  0.004473076201975346
p mean is: tensor(-0.7090, device='cuda:1')
epoch:  20000 quantization_loss:  0.0043790703639388084
p mean is: tensor(-0.7733, device='cuda:1')
epoch:  21000 quantization_loss:  0.004259171430021524
p mean is: tensor(-0.8314, device='cuda:1')
epoch:  22000 quantization_loss:  0.00419540423899889
p mean is: tensor(-0.8832, device='cuda:1')
epoch:  23000 quantization_loss:  0.0041246782056987286
p mean is: tensor(-0.9289, device='cuda:1')
epoch:  24000 quantization_loss:  0.004010249860584736
p mean is: tensor(-0.9692, device='cuda:1')
epoch:  25000 quantization_loss:  0.003950508311390877
p mean is: tensor(-1.0045, device='cuda:1')
epoch:  26000 quantization_loss:  0.00392884248867631
p mean is: tensor(-1.0355, device='cuda:1')
epoch:  27000 quantization_loss:  0.0038344687782227993
p mean is: tensor(-1.0627, device='cuda:1')
epoch:  28000 quantization_loss:  0.003790150862187147
p mean is: tensor(-1.0867, device='cuda:1')
epoch:  29000 quantization_loss:  0.0037881515454500914
p mean is: tensor(-1.1078, device='cuda:1')
epoch:  30000 quantization_loss:  0.0037146133836358786
p mean is: tensor(-1.1264, device='cuda:1')
epoch:  31000 quantization_loss:  0.003681604750454426
p mean is: tensor(-1.1430, device='cuda:1')
epoch:  32000 quantization_loss:  0.003658928908407688
p mean is: tensor(-1.1577, device='cuda:1')
epoch:  33000 quantization_loss:  0.0036489437334239483
p mean is: tensor(-1.1707, device='cuda:1')
epoch:  34000 quantization_loss:  0.0036103036254644394
p mean is: tensor(-1.1823, device='cuda:1')
epoch:  35000 quantization_loss:  0.003592913271859288
p mean is: tensor(-1.1927, device='cuda:1')
epoch:  36000 quantization_loss:  0.0035648064222186804
p mean is: tensor(-1.2020, device='cuda:1')
epoch:  37000 quantization_loss:  0.0035661114379763603
p mean is: tensor(-1.2104, device='cuda:1')
epoch:  38000 quantization_loss:  0.0035484370309859514
p mean is: tensor(-1.2180, device='cuda:1')
epoch:  39000 quantization_loss:  0.003534845542162657
p mean is: tensor(-1.2249, device='cuda:1')
epoch:  40000 quantization_loss:  0.0035101864486932755
p mean is: tensor(-1.2311, device='cuda:1')
epoch:  41000 quantization_loss:  0.0034916915465146303
p mean is: tensor(-1.2368, device='cuda:1')
epoch:  42000 quantization_loss:  0.0034879897721111774
p mean is: tensor(-1.2419, device='cuda:1')
epoch:  43000 quantization_loss:  0.00347129232250154
p mean is: tensor(-1.2466, device='cuda:1')
epoch:  44000 quantization_loss:  0.003464412409812212
p mean is: tensor(-1.2509, device='cuda:1')
epoch:  45000 quantization_loss:  0.00344673078507185
p mean is: tensor(-1.2548, device='cuda:1')
epoch:  46000 quantization_loss:  0.0034487652592360973
p mean is: tensor(-1.2584, device='cuda:1')
epoch:  47000 quantization_loss:  0.003431077115237713
p mean is: tensor(-1.2618, device='cuda:1')
epoch:  48000 quantization_loss:  0.0034276912920176983
p mean is: tensor(-1.2648, device='cuda:1')
epoch:  49000 quantization_loss:  0.0034240048844367266
p mean is: tensor(-1.2677, device='cuda:1')
epoch:  50000 quantization_loss:  0.003410345409065485
p mean is: tensor(-1.2703, device='cuda:1')
epoch:  51000 quantization_loss:  0.0034042680636048317
p mean is: tensor(-1.2728, device='cuda:1')
epoch:  52000 quantization_loss:  0.0033952773083001375
p mean is: tensor(-1.2751, device='cuda:1')
epoch:  53000 quantization_loss:  0.0034005139023065567
p mean is: tensor(-1.2774, device='cuda:1')
epoch:  54000 quantization_loss:  0.0033881620038300753
p mean is: tensor(-1.2794, device='cuda:1')
epoch:  55000 quantization_loss:  0.0033794732298702
p mean is: tensor(-1.2814, device='cuda:1')
epoch:  56000 quantization_loss:  0.0033693104051053524
p mean is: tensor(-1.2832, device='cuda:1')
epoch:  57000 quantization_loss:  0.0033670300617814064
p mean is: tensor(-1.2849, device='cuda:1')
epoch:  58000 quantization_loss:  0.003363129450008273
p mean is: tensor(-1.2866, device='cuda:1')
epoch:  59000 quantization_loss:  0.003369151847437024
p mean is: tensor(-1.2881, device='cuda:1')
Number of elements to keep: 300886
Threshold value: -1.1208120584487915
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.09999976735428984
here
Number of elements to keep: 150443
Threshold value: -0.6797773838043213
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
1.1.1.weight         | nonzeros =    1686 /   12800             ( 13.17%) | total_pruned =   11114 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     385 /    6400             (  6.02%) | total_pruned =    6015 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       5 /      16             ( 31.25%) | total_pruned =      11 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     828 /   12800             (  6.47%) | total_pruned =   11972 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =    1628 /   25600             (  6.36%) | total_pruned =   23972 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =    2121 /   51200             (  4.14%) | total_pruned =   49079 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =    3864 /  102400             (  3.77%) | total_pruned =   98536 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =    7791 /  204800             (  3.80%) | total_pruned =  197009 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =   14513 /  409600             (  3.54%) | total_pruned =  395087 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   19385 /  409600             (  4.73%) | total_pruned =  390215 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   32713 /  409600             (  7.99%) | total_pruned =  376887 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   63742 /  409600             ( 15.56%) | total_pruned =  345858 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =     112 /     128             ( 87.50%) | total_pruned =      16 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   66363 /  409600             ( 16.20%) | total_pruned =  343237 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   24934 /  147456             ( 16.91%) | total_pruned =  122522 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   21919 /  147456             ( 14.86%) | total_pruned =  125537 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   20629 /  147456             ( 13.99%) | total_pruned =  126827 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   11572 /   73728             ( 15.70%) | total_pruned =   62156 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    3868 /   18432             ( 20.99%) | total_pruned =   14564 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      24 /      32             ( 75.00%) | total_pruned =       8 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      24 /      32             ( 75.00%) | total_pruned =       8 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1638 /    4608             ( 35.55%) | total_pruned =    2970 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      30 /      48             ( 62.50%) | total_pruned =      18 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       3 /       3             (100.00%) | total_pruned =       0 | shape = torch.Size([3])
alive: 300886, pruned : 2707981, total: 3008867, Compression rate :      10.00x  ( 90.00% pruned)
PSNR of output image is:  21.45154375247815
Experiment done
