(3, 256, 256)
(3, 256, 256)
Noisy PSNR is '8.853165647841246'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Output directory: data/inpainting/Set14/mask/2/sparsity/0.5/det/0.03/1e-09
epoch:  0 quantization_loss:  0.024946967139840126
p mean is: tensor(-0.0002, device='cuda:6')
epoch:  1000 quantization_loss:  0.025089429691433907
p mean is: tensor(-0.0082, device='cuda:6')
epoch:  2000 quantization_loss:  0.023292383179068565
p mean is: tensor(-0.0151, device='cuda:6')
epoch:  3000 quantization_loss:  0.024485738947987556
p mean is: tensor(-0.0226, device='cuda:6')
epoch:  4000 quantization_loss:  0.024239812046289444
p mean is: tensor(-0.0298, device='cuda:6')
epoch:  5000 quantization_loss:  0.02457214891910553
p mean is: tensor(-0.0367, device='cuda:6')
epoch:  6000 quantization_loss:  0.023625705391168594
p mean is: tensor(-0.0437, device='cuda:6')
epoch:  7000 quantization_loss:  0.023908987641334534
p mean is: tensor(-0.0508, device='cuda:6')
epoch:  8000 quantization_loss:  0.024319956079125404
p mean is: tensor(-0.0582, device='cuda:6')
epoch:  9000 quantization_loss:  0.02377011626958847
p mean is: tensor(-0.0660, device='cuda:6')
epoch:  10000 quantization_loss:  0.02403600886464119
p mean is: tensor(-0.0736, device='cuda:6')
epoch:  11000 quantization_loss:  0.02426254376769066
p mean is: tensor(-0.0816, device='cuda:6')
epoch:  12000 quantization_loss:  0.023561427369713783
p mean is: tensor(-0.0903, device='cuda:6')
epoch:  13000 quantization_loss:  0.021055879071354866
p mean is: tensor(-0.0994, device='cuda:6')
epoch:  14000 quantization_loss:  0.015871865674853325
p mean is: tensor(-0.1114, device='cuda:6')
epoch:  15000 quantization_loss:  0.010045175440609455
p mean is: tensor(-0.1282, device='cuda:6')
epoch:  16000 quantization_loss:  0.008997764438390732
p mean is: tensor(-0.1509, device='cuda:6')
epoch:  17000 quantization_loss:  0.008641604334115982
p mean is: tensor(-0.1807, device='cuda:6')
epoch:  18000 quantization_loss:  0.006108418107032776
p mean is: tensor(-0.2188, device='cuda:6')
epoch:  19000 quantization_loss:  0.005293501075357199
p mean is: tensor(-0.2651, device='cuda:6')
epoch:  20000 quantization_loss:  0.0048614852130413055
p mean is: tensor(-0.3215, device='cuda:6')
epoch:  21000 quantization_loss:  0.00454538781195879
p mean is: tensor(-0.3866, device='cuda:6')
epoch:  22000 quantization_loss:  0.004024865105748177
p mean is: tensor(-0.4605, device='cuda:6')
epoch:  23000 quantization_loss:  0.003820451209321618
p mean is: tensor(-0.5402, device='cuda:6')
epoch:  24000 quantization_loss:  0.0036703278310596943
p mean is: tensor(-0.6220, device='cuda:6')
epoch:  25000 quantization_loss:  0.0035417901817709208
p mean is: tensor(-0.7018, device='cuda:6')
epoch:  26000 quantization_loss:  0.0034770129714161158
p mean is: tensor(-0.7764, device='cuda:6')
epoch:  27000 quantization_loss:  0.0032618907280266285
p mean is: tensor(-0.8435, device='cuda:6')
epoch:  28000 quantization_loss:  0.003313552588224411
p mean is: tensor(-0.9028, device='cuda:6')
epoch:  29000 quantization_loss:  0.003043744247406721
p mean is: tensor(-0.9544, device='cuda:6')
epoch:  30000 quantization_loss:  0.0030141621828079224
p mean is: tensor(-0.9990, device='cuda:6')
epoch:  31000 quantization_loss:  0.002923826687037945
p mean is: tensor(-1.0374, device='cuda:6')
epoch:  32000 quantization_loss:  0.002859304193407297
p mean is: tensor(-1.0704, device='cuda:6')
epoch:  33000 quantization_loss:  0.002822251059114933
p mean is: tensor(-1.0988, device='cuda:6')
epoch:  34000 quantization_loss:  0.0027825452852994204
p mean is: tensor(-1.1232, device='cuda:6')
epoch:  35000 quantization_loss:  0.002692942041903734
p mean is: tensor(-1.1441, device='cuda:6')
epoch:  36000 quantization_loss:  0.0027353642508387566
p mean is: tensor(-1.1621, device='cuda:6')
epoch:  37000 quantization_loss:  0.002646043198183179
p mean is: tensor(-1.1777, device='cuda:6')
epoch:  38000 quantization_loss:  0.002596003469079733
p mean is: tensor(-1.1911, device='cuda:6')
epoch:  39000 quantization_loss:  0.002554400358349085
p mean is: tensor(-1.2028, device='cuda:6')
epoch:  40000 quantization_loss:  0.0025177274364978075
p mean is: tensor(-1.2128, device='cuda:6')
epoch:  41000 quantization_loss:  0.002525953808799386
p mean is: tensor(-1.2217, device='cuda:6')
epoch:  42000 quantization_loss:  0.002478028414770961
p mean is: tensor(-1.2293, device='cuda:6')
epoch:  43000 quantization_loss:  0.0024281563237309456
p mean is: tensor(-1.2359, device='cuda:6')
epoch:  44000 quantization_loss:  0.0024121259339153767
p mean is: tensor(-1.2418, device='cuda:6')
epoch:  45000 quantization_loss:  0.0023848344571888447
p mean is: tensor(-1.2470, device='cuda:6')
epoch:  46000 quantization_loss:  0.002380806254222989
p mean is: tensor(-1.2516, device='cuda:6')
epoch:  47000 quantization_loss:  0.002348539885133505
p mean is: tensor(-1.2556, device='cuda:6')
epoch:  48000 quantization_loss:  0.0023272517137229443
p mean is: tensor(-1.2592, device='cuda:6')
epoch:  49000 quantization_loss:  0.0023193187080323696
p mean is: tensor(-1.2624, device='cuda:6')
epoch:  50000 quantization_loss:  0.0023037318605929613
p mean is: tensor(-1.2652, device='cuda:6')
epoch:  51000 quantization_loss:  0.0022757945116609335
p mean is: tensor(-1.2678, device='cuda:6')
epoch:  52000 quantization_loss:  0.0022386787459254265
p mean is: tensor(-1.2701, device='cuda:6')
epoch:  53000 quantization_loss:  0.0022602661047130823
p mean is: tensor(-1.2722, device='cuda:6')
epoch:  54000 quantization_loss:  0.002253923797979951
p mean is: tensor(-1.2741, device='cuda:6')
epoch:  55000 quantization_loss:  0.0022342493757605553
p mean is: tensor(-1.2757, device='cuda:6')
epoch:  56000 quantization_loss:  0.0022207836154848337
p mean is: tensor(-1.2772, device='cuda:6')
epoch:  57000 quantization_loss:  0.0022125975228846073
p mean is: tensor(-1.2787, device='cuda:6')
epoch:  58000 quantization_loss:  0.0022011662367731333
p mean is: tensor(-1.2800, device='cuda:6')
epoch:  59000 quantization_loss:  0.0021990183740854263
p mean is: tensor(-1.2812, device='cuda:6')
Number of elements to keep: 90266
Threshold value: -0.7129138112068176
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.029999996676489855
here
Number of elements to keep: 150443
Threshold value: -1.0508403778076172
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
1.1.1.weight         | nonzeros =     467 /   12800             (  3.65%) | total_pruned =   12333 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =      81 /    6400             (  1.27%) | total_pruned =    6319 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =      81 /   12800             (  0.63%) | total_pruned =   12719 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     134 /   25600             (  0.52%) | total_pruned =   25466 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      10 /      32             ( 31.25%) | total_pruned =      22 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     121 /   51200             (  0.24%) | total_pruned =   51079 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     193 /  102400             (  0.19%) | total_pruned =  102207 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =     190 /  204800             (  0.09%) | total_pruned =  204610 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =     328 /  409600             (  0.08%) | total_pruned =  409272 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =     552 /  409600             (  0.13%) | total_pruned =  409048 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    2031 /  409600             (  0.50%) | total_pruned =  407569 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    6991 /  409600             (  1.71%) | total_pruned =  402609 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   18140 /  409600             (  4.43%) | total_pruned =  391460 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   15257 /  147456             ( 10.35%) | total_pruned =  132199 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   18106 /  147456             ( 12.28%) | total_pruned =  129350 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   15815 /  147456             ( 10.73%) | total_pruned =  131641 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    7604 /   73728             ( 10.31%) | total_pruned =   66124 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2064 /   18432             ( 11.20%) | total_pruned =   16368 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1025 /    4608             ( 22.24%) | total_pruned =    3583 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      30 /      48             ( 62.50%) | total_pruned =      18 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 90266, pruned : 2918601, total: 3008867, Compression rate :      33.33x  ( 97.00% pruned)
PSNR of output image is:  23.457198984580966
Experiment done
