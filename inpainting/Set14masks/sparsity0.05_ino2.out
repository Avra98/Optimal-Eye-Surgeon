(3, 256, 256)
(3, 256, 256)
Noisy PSNR is '8.896226942740066'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Output directory: data/inpainting/Set14/mask/2/sparsity/0.5/det/0.05/1e-09
epoch:  0 quantization_loss:  0.027277175337076187
p mean is: tensor(-0.0002, device='cuda:2')
epoch:  1000 quantization_loss:  0.024113930761814117
p mean is: tensor(-0.0077, device='cuda:2')
epoch:  2000 quantization_loss:  0.024789879098534584
p mean is: tensor(-0.0147, device='cuda:2')
epoch:  3000 quantization_loss:  0.0246572345495224
p mean is: tensor(-0.0221, device='cuda:2')
epoch:  4000 quantization_loss:  0.023986395448446274
p mean is: tensor(-0.0303, device='cuda:2')
epoch:  5000 quantization_loss:  0.02454189769923687
p mean is: tensor(-0.0392, device='cuda:2')
epoch:  6000 quantization_loss:  0.02443196438252926
p mean is: tensor(-0.0482, device='cuda:2')
epoch:  7000 quantization_loss:  0.0242159366607666
p mean is: tensor(-0.0574, device='cuda:2')
epoch:  8000 quantization_loss:  0.023961776867508888
p mean is: tensor(-0.0668, device='cuda:2')
epoch:  9000 quantization_loss:  0.024367451667785645
p mean is: tensor(-0.0765, device='cuda:2')
epoch:  10000 quantization_loss:  0.023877039551734924
p mean is: tensor(-0.0867, device='cuda:2')
epoch:  11000 quantization_loss:  0.02406463772058487
p mean is: tensor(-0.0972, device='cuda:2')
epoch:  12000 quantization_loss:  0.024657797068357468
p mean is: tensor(-0.1083, device='cuda:2')
epoch:  13000 quantization_loss:  0.02469928190112114
p mean is: tensor(-0.1193, device='cuda:2')
epoch:  14000 quantization_loss:  0.022279776632785797
p mean is: tensor(-0.1306, device='cuda:2')
epoch:  15000 quantization_loss:  0.013321662321686745
p mean is: tensor(-0.1440, device='cuda:2')
epoch:  16000 quantization_loss:  0.009831544943153858
p mean is: tensor(-0.1620, device='cuda:2')
epoch:  17000 quantization_loss:  0.007286947686225176
p mean is: tensor(-0.1859, device='cuda:2')
epoch:  18000 quantization_loss:  0.005373390391469002
p mean is: tensor(-0.2160, device='cuda:2')
epoch:  19000 quantization_loss:  0.004411287605762482
p mean is: tensor(-0.2538, device='cuda:2')
epoch:  20000 quantization_loss:  0.004141940735280514
p mean is: tensor(-0.3016, device='cuda:2')
epoch:  21000 quantization_loss:  0.0040139369666576385
p mean is: tensor(-0.3602, device='cuda:2')
epoch:  22000 quantization_loss:  0.0039011824410408735
p mean is: tensor(-0.4291, device='cuda:2')
epoch:  23000 quantization_loss:  0.003495453856885433
p mean is: tensor(-0.5060, device='cuda:2')
epoch:  24000 quantization_loss:  0.003305481281131506
p mean is: tensor(-0.5871, device='cuda:2')
epoch:  25000 quantization_loss:  0.0031828884966671467
p mean is: tensor(-0.6685, device='cuda:2')
epoch:  26000 quantization_loss:  0.0030642207711935043
p mean is: tensor(-0.7459, device='cuda:2')
epoch:  27000 quantization_loss:  0.002987674903124571
p mean is: tensor(-0.8166, device='cuda:2')
epoch:  28000 quantization_loss:  0.0027613062411546707
p mean is: tensor(-0.8795, device='cuda:2')
epoch:  29000 quantization_loss:  0.0026694959960877895
p mean is: tensor(-0.9342, device='cuda:2')
epoch:  30000 quantization_loss:  0.002573325065895915
p mean is: tensor(-0.9814, device='cuda:2')
epoch:  31000 quantization_loss:  0.002556788269430399
p mean is: tensor(-1.0219, device='cuda:2')
epoch:  32000 quantization_loss:  0.0026755183935165405
p mean is: tensor(-1.0567, device='cuda:2')
epoch:  33000 quantization_loss:  0.002367208246141672
p mean is: tensor(-1.0865, device='cuda:2')
epoch:  34000 quantization_loss:  0.0022912113927304745
p mean is: tensor(-1.1120, device='cuda:2')
epoch:  35000 quantization_loss:  0.0022648831363767385
p mean is: tensor(-1.1339, device='cuda:2')
epoch:  36000 quantization_loss:  0.0022721101995557547
p mean is: tensor(-1.1527, device='cuda:2')
epoch:  37000 quantization_loss:  0.002214845735579729
p mean is: tensor(-1.1688, device='cuda:2')
epoch:  38000 quantization_loss:  0.002135438611730933
p mean is: tensor(-1.1828, device='cuda:2')
epoch:  39000 quantization_loss:  0.002093617105856538
p mean is: tensor(-1.1949, device='cuda:2')
epoch:  40000 quantization_loss:  0.002052708761766553
p mean is: tensor(-1.2053, device='cuda:2')
epoch:  41000 quantization_loss:  0.0020090583711862564
p mean is: tensor(-1.2144, device='cuda:2')
epoch:  42000 quantization_loss:  0.001975694205611944
p mean is: tensor(-1.2224, device='cuda:2')
epoch:  43000 quantization_loss:  0.0019277402898296714
p mean is: tensor(-1.2293, device='cuda:2')
epoch:  44000 quantization_loss:  0.0019110619323328137
p mean is: tensor(-1.2352, device='cuda:2')
epoch:  45000 quantization_loss:  0.0018826466985046864
p mean is: tensor(-1.2406, device='cuda:2')
epoch:  46000 quantization_loss:  0.0015792397316545248
p mean is: tensor(-1.2452, device='cuda:2')
epoch:  47000 quantization_loss:  0.0015397353563457727
p mean is: tensor(-1.2494, device='cuda:2')
epoch:  48000 quantization_loss:  0.0015403889119625092
p mean is: tensor(-1.2530, device='cuda:2')
epoch:  49000 quantization_loss:  0.0014884354313835502
p mean is: tensor(-1.2562, device='cuda:2')
epoch:  50000 quantization_loss:  0.0014711907133460045
p mean is: tensor(-1.2591, device='cuda:2')
epoch:  51000 quantization_loss:  0.0014433907344937325
p mean is: tensor(-1.2618, device='cuda:2')
epoch:  52000 quantization_loss:  0.0014394675381481647
p mean is: tensor(-1.2642, device='cuda:2')
epoch:  53000 quantization_loss:  0.0014140646671876311
p mean is: tensor(-1.2664, device='cuda:2')
epoch:  54000 quantization_loss:  0.0014036146458238363
p mean is: tensor(-1.2684, device='cuda:2')
epoch:  55000 quantization_loss:  0.0013887948589399457
p mean is: tensor(-1.2702, device='cuda:2')
epoch:  56000 quantization_loss:  0.0013882527127861977
p mean is: tensor(-1.2719, device='cuda:2')
epoch:  57000 quantization_loss:  0.0013617697404697537
p mean is: tensor(-1.2734, device='cuda:2')
epoch:  58000 quantization_loss:  0.001367795979604125
p mean is: tensor(-1.2748, device='cuda:2')
epoch:  59000 quantization_loss:  0.001348654623143375
p mean is: tensor(-1.2761, device='cuda:2')
Number of elements to keep: 150443
Threshold value: -1.1034836769104004
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
here
Number of elements to keep: 150443
Threshold value: -1.1034836769104004
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
1.1.1.weight         | nonzeros =    1426 /   12800             ( 11.14%) | total_pruned =   11374 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     340 /    6400             (  5.31%) | total_pruned =    6060 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       8 /      16             ( 50.00%) | total_pruned =       8 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =     267 /   12800             (  2.09%) | total_pruned =   12533 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      10 /      32             ( 31.25%) | total_pruned =      22 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =     306 /   25600             (  1.20%) | total_pruned =   25294 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      17 /      32             ( 53.12%) | total_pruned =      15 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =     647 /   51200             (  1.26%) | total_pruned =   50553 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =     825 /  102400             (  0.81%) | total_pruned =  101575 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =    1591 /  204800             (  0.78%) | total_pruned =  203209 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =    3399 /  409600             (  0.83%) | total_pruned =  406201 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    6784 /  409600             (  1.66%) | total_pruned =  402816 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   10819 /  409600             (  2.64%) | total_pruned =  398781 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   21929 /  409600             (  5.35%) | total_pruned =  387671 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   29951 /  409600             (  7.31%) | total_pruned =  379649 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   16079 /  147456             ( 10.90%) | total_pruned =  131377 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   20991 /  147456             ( 14.24%) | total_pruned =  126465 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   21101 /  147456             ( 14.31%) | total_pruned =  126355 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =    8145 /   73728             ( 11.05%) | total_pruned =   65583 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    3185 /   18432             ( 17.28%) | total_pruned =   15247 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      25 /      32             ( 78.12%) | total_pruned =       7 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      25 /      32             ( 78.12%) | total_pruned =       7 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1551 /    4608             ( 33.66%) | total_pruned =    3057 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      32 /      48             ( 66.67%) | total_pruned =      16 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       0 /       3             (  0.00%) | total_pruned =       3 | shape = torch.Size([3])
alive: 150443, pruned : 2858424, total: 3008867, Compression rate :      20.00x  ( 95.00% pruned)
PSNR of output image is:  25.589500267237504
Experiment done
