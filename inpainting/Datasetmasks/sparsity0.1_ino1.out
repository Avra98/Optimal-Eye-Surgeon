(3, 512, 512)
(3, 512, 512)
Noisy PSNR is '10.530828057670591'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Output directory: data/inpainting/Dataset/mask/1/sparsity/0.5/det/0.1/1e-09
epoch:  0 quantization_loss:  0.020940346643328667
p mean is: tensor(-0.0002, device='cuda:5')
epoch:  1000 quantization_loss:  0.01662280783057213
p mean is: tensor(-0.0147, device='cuda:5')
epoch:  2000 quantization_loss:  0.017209729179739952
p mean is: tensor(-0.0263, device='cuda:5')
epoch:  3000 quantization_loss:  0.016784604638814926
p mean is: tensor(-0.0377, device='cuda:5')
epoch:  4000 quantization_loss:  0.016674315556883812
p mean is: tensor(-0.0492, device='cuda:5')
epoch:  5000 quantization_loss:  0.01672385260462761
p mean is: tensor(-0.0606, device='cuda:5')
epoch:  6000 quantization_loss:  0.016565894708037376
p mean is: tensor(-0.0728, device='cuda:5')
epoch:  7000 quantization_loss:  0.016958393156528473
p mean is: tensor(-0.0858, device='cuda:5')
epoch:  8000 quantization_loss:  0.014087331481277943
p mean is: tensor(-0.0993, device='cuda:5')
epoch:  9000 quantization_loss:  0.011894107796251774
p mean is: tensor(-0.1154, device='cuda:5')
epoch:  10000 quantization_loss:  0.010214364156126976
p mean is: tensor(-0.1366, device='cuda:5')
epoch:  11000 quantization_loss:  0.00892459787428379
p mean is: tensor(-0.1641, device='cuda:5')
epoch:  12000 quantization_loss:  0.00767100416123867
p mean is: tensor(-0.1990, device='cuda:5')
epoch:  13000 quantization_loss:  0.007065205369144678
p mean is: tensor(-0.2419, device='cuda:5')
epoch:  14000 quantization_loss:  0.006408021319657564
p mean is: tensor(-0.2935, device='cuda:5')
epoch:  15000 quantization_loss:  0.005060893017798662
p mean is: tensor(-0.3542, device='cuda:5')
epoch:  16000 quantization_loss:  0.004593635909259319
p mean is: tensor(-0.4216, device='cuda:5')
epoch:  17000 quantization_loss:  0.004311990924179554
p mean is: tensor(-0.4939, device='cuda:5')
epoch:  18000 quantization_loss:  0.0041334182024002075
p mean is: tensor(-0.5683, device='cuda:5')
epoch:  19000 quantization_loss:  0.003981426823884249
p mean is: tensor(-0.6419, device='cuda:5')
epoch:  20000 quantization_loss:  0.003767511574551463
p mean is: tensor(-0.7123, device='cuda:5')
epoch:  21000 quantization_loss:  0.003652130253612995
p mean is: tensor(-0.7774, device='cuda:5')
epoch:  22000 quantization_loss:  0.0036148554645478725
p mean is: tensor(-0.8363, device='cuda:5')
epoch:  23000 quantization_loss:  0.0035367566160857677
p mean is: tensor(-0.8888, device='cuda:5')
epoch:  24000 quantization_loss:  0.003446741495281458
p mean is: tensor(-0.9351, device='cuda:5')
epoch:  25000 quantization_loss:  0.0034218281507492065
p mean is: tensor(-0.9759, device='cuda:5')
epoch:  26000 quantization_loss:  0.003356333589181304
p mean is: tensor(-1.0116, device='cuda:5')
epoch:  27000 quantization_loss:  0.0033141106832772493
p mean is: tensor(-1.0429, device='cuda:5')
epoch:  28000 quantization_loss:  0.003252862486988306
p mean is: tensor(-1.0705, device='cuda:5')
epoch:  29000 quantization_loss:  0.0032333845738321543
p mean is: tensor(-1.0948, device='cuda:5')
epoch:  30000 quantization_loss:  0.0031993736047297716
p mean is: tensor(-1.1161, device='cuda:5')
epoch:  31000 quantization_loss:  0.003169105388224125
p mean is: tensor(-1.1349, device='cuda:5')
epoch:  32000 quantization_loss:  0.0031372406519949436
p mean is: tensor(-1.1515, device='cuda:5')
epoch:  33000 quantization_loss:  0.0031356257386505604
p mean is: tensor(-1.1662, device='cuda:5')
epoch:  34000 quantization_loss:  0.0030994305852800608
p mean is: tensor(-1.1793, device='cuda:5')
epoch:  35000 quantization_loss:  0.0030722031369805336
p mean is: tensor(-1.1910, device='cuda:5')
epoch:  36000 quantization_loss:  0.003055677516385913
p mean is: tensor(-1.2013, device='cuda:5')
epoch:  37000 quantization_loss:  0.0029194271191954613
p mean is: tensor(-1.2105, device='cuda:5')
epoch:  38000 quantization_loss:  0.0028977831825613976
p mean is: tensor(-1.2187, device='cuda:5')
epoch:  39000 quantization_loss:  0.0028717785608023405
p mean is: tensor(-1.2262, device='cuda:5')
epoch:  40000 quantization_loss:  0.0028714293148368597
p mean is: tensor(-1.2330, device='cuda:5')
epoch:  41000 quantization_loss:  0.0028648865409195423
p mean is: tensor(-1.2391, device='cuda:5')
epoch:  42000 quantization_loss:  0.0028382958844304085
p mean is: tensor(-1.2446, device='cuda:5')
epoch:  43000 quantization_loss:  0.002950986148789525
p mean is: tensor(-1.2497, device='cuda:5')
epoch:  44000 quantization_loss:  0.0028136165346950293
p mean is: tensor(-1.2544, device='cuda:5')
epoch:  45000 quantization_loss:  0.002788939978927374
p mean is: tensor(-1.2586, device='cuda:5')
epoch:  46000 quantization_loss:  0.0027944608591496944
p mean is: tensor(-1.2626, device='cuda:5')
epoch:  47000 quantization_loss:  0.0027802407275885344
p mean is: tensor(-1.2662, device='cuda:5')
epoch:  48000 quantization_loss:  0.0027906072791665792
p mean is: tensor(-1.2696, device='cuda:5')
epoch:  49000 quantization_loss:  0.0027687482070177794
p mean is: tensor(-1.2728, device='cuda:5')
epoch:  50000 quantization_loss:  0.0027609600219875574
p mean is: tensor(-1.2757, device='cuda:5')
epoch:  51000 quantization_loss:  0.002765210345387459
p mean is: tensor(-1.2784, device='cuda:5')
epoch:  52000 quantization_loss:  0.0027501045260578394
p mean is: tensor(-1.2809, device='cuda:5')
epoch:  53000 quantization_loss:  0.002751751337200403
p mean is: tensor(-1.2834, device='cuda:5')
epoch:  54000 quantization_loss:  0.0027438539545983076
p mean is: tensor(-1.2856, device='cuda:5')
epoch:  55000 quantization_loss:  0.0027426667511463165
p mean is: tensor(-1.2877, device='cuda:5')
epoch:  56000 quantization_loss:  0.002729608677327633
p mean is: tensor(-1.2897, device='cuda:5')
epoch:  57000 quantization_loss:  0.0027336757630109787
p mean is: tensor(-1.2916, device='cuda:5')
epoch:  58000 quantization_loss:  0.002726375125348568
p mean is: tensor(-1.2934, device='cuda:5')
epoch:  59000 quantization_loss:  0.002721949014812708
p mean is: tensor(-1.2951, device='cuda:5')
Number of elements to keep: 300886
Threshold value: -1.1222476959228516
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.09999976735428984
here
Number of elements to keep: 150443
Threshold value: -0.7468140125274658
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
1.1.1.weight         | nonzeros =    1649 /   12800             ( 12.88%) | total_pruned =   11151 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       6 /      16             ( 37.50%) | total_pruned =      10 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     493 /    6400             (  7.70%) | total_pruned =    5907 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =    1276 /   12800             (  9.97%) | total_pruned =   11524 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =    1650 /   25600             (  6.45%) | total_pruned =   23950 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      12 /      32             ( 37.50%) | total_pruned =      20 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =    2848 /   51200             (  5.56%) | total_pruned =   48352 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =    6472 /  102400             (  6.32%) | total_pruned =   95928 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =   10141 /  204800             (  4.95%) | total_pruned =  194659 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =   19090 /  409600             (  4.66%) | total_pruned =  390510 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   24398 /  409600             (  5.96%) | total_pruned =  385202 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   37307 /  409600             (  9.11%) | total_pruned =  372293 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   50377 /  409600             ( 12.30%) | total_pruned =  359223 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   56169 /  409600             ( 13.71%) | total_pruned =  353431 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   24400 /  147456             ( 16.55%) | total_pruned =  123056 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   23559 /  147456             ( 15.98%) | total_pruned =  123897 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   23422 /  147456             ( 15.88%) | total_pruned =  124034 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   11767 /   73728             ( 15.96%) | total_pruned =   61961 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    3195 /   18432             ( 17.33%) | total_pruned =   15237 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1312 /    4608             ( 28.47%) | total_pruned =    3296 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      29 /      48             ( 60.42%) | total_pruned =      19 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       3 /       3             (100.00%) | total_pruned =       0 | shape = torch.Size([3])
alive: 300886, pruned : 2707981, total: 3008867, Compression rate :      10.00x  ( 90.00% pruned)
PSNR of output image is:  22.860106695232403
Experiment done
