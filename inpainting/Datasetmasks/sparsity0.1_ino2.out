(3, 256, 256)
(3, 256, 256)
Noisy PSNR is '7.303676590334013'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Output directory: data/inpainting/Dataset/mask/2/sparsity/0.5/det/0.1/1e-09
epoch:  0 quantization_loss:  0.022721026092767715
p mean is: tensor(-0.0002, device='cuda:6')
epoch:  1000 quantization_loss:  0.021448364481329918
p mean is: tensor(-0.0101, device='cuda:6')
epoch:  2000 quantization_loss:  0.02276972122490406
p mean is: tensor(-0.0197, device='cuda:6')
epoch:  3000 quantization_loss:  0.021719349548220634
p mean is: tensor(-0.0306, device='cuda:6')
epoch:  4000 quantization_loss:  0.021499507129192352
p mean is: tensor(-0.0428, device='cuda:6')
epoch:  5000 quantization_loss:  0.021506935358047485
p mean is: tensor(-0.0568, device='cuda:6')
epoch:  6000 quantization_loss:  0.021499743685126305
p mean is: tensor(-0.0721, device='cuda:6')
epoch:  7000 quantization_loss:  0.021428832784295082
p mean is: tensor(-0.0891, device='cuda:6')
epoch:  8000 quantization_loss:  0.02149593085050583
p mean is: tensor(-0.1073, device='cuda:6')
epoch:  9000 quantization_loss:  0.02144647389650345
p mean is: tensor(-0.1254, device='cuda:6')
epoch:  10000 quantization_loss:  0.021398182958364487
p mean is: tensor(-0.1438, device='cuda:6')
epoch:  11000 quantization_loss:  0.021538499742746353
p mean is: tensor(-0.1618, device='cuda:6')
epoch:  12000 quantization_loss:  0.021415039896965027
p mean is: tensor(-0.1795, device='cuda:6')
epoch:  13000 quantization_loss:  0.021483901888132095
p mean is: tensor(-0.1969, device='cuda:6')
epoch:  14000 quantization_loss:  0.02117050066590309
p mean is: tensor(-0.2137, device='cuda:6')
epoch:  15000 quantization_loss:  0.01649373583495617
p mean is: tensor(-0.2296, device='cuda:6')
epoch:  16000 quantization_loss:  0.015026812441647053
p mean is: tensor(-0.2487, device='cuda:6')
epoch:  17000 quantization_loss:  0.012841411866247654
p mean is: tensor(-0.2739, device='cuda:6')
epoch:  18000 quantization_loss:  0.009855592623353004
p mean is: tensor(-0.3068, device='cuda:6')
epoch:  19000 quantization_loss:  0.009054550901055336
p mean is: tensor(-0.3483, device='cuda:6')
epoch:  20000 quantization_loss:  0.008443471044301987
p mean is: tensor(-0.3994, device='cuda:6')
epoch:  21000 quantization_loss:  0.008065426722168922
p mean is: tensor(-0.4599, device='cuda:6')
epoch:  22000 quantization_loss:  0.0053727286867797375
p mean is: tensor(-0.5287, device='cuda:6')
epoch:  23000 quantization_loss:  0.004526038188487291
p mean is: tensor(-0.6025, device='cuda:6')
epoch:  24000 quantization_loss:  0.004365834873169661
p mean is: tensor(-0.6775, device='cuda:6')
epoch:  25000 quantization_loss:  0.004184531979262829
p mean is: tensor(-0.7506, device='cuda:6')
epoch:  26000 quantization_loss:  0.004063808359205723
p mean is: tensor(-0.8190, device='cuda:6')
epoch:  27000 quantization_loss:  0.0032049710862338543
p mean is: tensor(-0.8803, device='cuda:6')
epoch:  28000 quantization_loss:  0.0034849729854613543
p mean is: tensor(-0.9338, device='cuda:6')
epoch:  29000 quantization_loss:  0.002871615579351783
p mean is: tensor(-0.9803, device='cuda:6')
epoch:  30000 quantization_loss:  0.003089434001594782
p mean is: tensor(-1.0205, device='cuda:6')
epoch:  31000 quantization_loss:  0.002568282186985016
p mean is: tensor(-1.0549, device='cuda:6')
epoch:  32000 quantization_loss:  0.0024817802477627993
p mean is: tensor(-1.0846, device='cuda:6')
epoch:  33000 quantization_loss:  0.0024102991446852684
p mean is: tensor(-1.1102, device='cuda:6')
epoch:  34000 quantization_loss:  0.0023894282057881355
p mean is: tensor(-1.1322, device='cuda:6')
epoch:  35000 quantization_loss:  0.002317512407898903
p mean is: tensor(-1.1512, device='cuda:6')
epoch:  36000 quantization_loss:  0.0018378336681053042
p mean is: tensor(-1.1675, device='cuda:6')
epoch:  37000 quantization_loss:  0.0017823907546699047
p mean is: tensor(-1.1817, device='cuda:6')
epoch:  38000 quantization_loss:  0.0017435875488445163
p mean is: tensor(-1.1939, device='cuda:6')
epoch:  39000 quantization_loss:  0.0017145733581855893
p mean is: tensor(-1.2046, device='cuda:6')
epoch:  40000 quantization_loss:  0.0016871297266334295
p mean is: tensor(-1.2140, device='cuda:6')
epoch:  41000 quantization_loss:  0.001684619695879519
p mean is: tensor(-1.2222, device='cuda:6')
epoch:  42000 quantization_loss:  0.0016685607843101025
p mean is: tensor(-1.2295, device='cuda:6')
epoch:  43000 quantization_loss:  0.0016485460801050067
p mean is: tensor(-1.2359, device='cuda:6')
epoch:  44000 quantization_loss:  0.0016169066075235605
p mean is: tensor(-1.2415, device='cuda:6')
epoch:  45000 quantization_loss:  0.0015962171601131558
p mean is: tensor(-1.2464, device='cuda:6')
epoch:  46000 quantization_loss:  0.0015912192175164819
p mean is: tensor(-1.2508, device='cuda:6')
epoch:  47000 quantization_loss:  0.0015825985465198755
p mean is: tensor(-1.2548, device='cuda:6')
epoch:  48000 quantization_loss:  0.0018874723464250565
p mean is: tensor(-1.2583, device='cuda:6')
epoch:  49000 quantization_loss:  0.0015617588069289923
p mean is: tensor(-1.2615, device='cuda:6')
epoch:  50000 quantization_loss:  0.0015505289193242788
p mean is: tensor(-1.2644, device='cuda:6')
epoch:  51000 quantization_loss:  0.001537612173706293
p mean is: tensor(-1.2670, device='cuda:6')
epoch:  52000 quantization_loss:  0.001539156655780971
p mean is: tensor(-1.2694, device='cuda:6')
epoch:  53000 quantization_loss:  0.001528843306005001
p mean is: tensor(-1.2716, device='cuda:6')
epoch:  54000 quantization_loss:  0.0015167543897405267
p mean is: tensor(-1.2736, device='cuda:6')
epoch:  55000 quantization_loss:  0.001497971243225038
p mean is: tensor(-1.2754, device='cuda:6')
epoch:  56000 quantization_loss:  0.0015033503295853734
p mean is: tensor(-1.2771, device='cuda:6')
epoch:  57000 quantization_loss:  0.0014884606935083866
p mean is: tensor(-1.2787, device='cuda:6')
epoch:  58000 quantization_loss:  0.0014908802695572376
p mean is: tensor(-1.2801, device='cuda:6')
epoch:  59000 quantization_loss:  0.001489629503339529
p mean is: tensor(-1.2814, device='cuda:6')
Number of elements to keep: 300886
Threshold value: -1.2588348388671875
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.09999976735428984
here
Number of elements to keep: 150443
Threshold value: -1.1228476762771606
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
1.1.1.weight         | nonzeros =    3978 /   12800             ( 31.08%) | total_pruned =    8822 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =    1773 /    6400             ( 27.70%) | total_pruned =    4627 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =      10 /      16             ( 62.50%) | total_pruned =       6 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =    2816 /   12800             ( 22.00%) | total_pruned =    9984 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      21 /      32             ( 65.62%) | total_pruned =      11 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =    4353 /   25600             ( 17.00%) | total_pruned =   21247 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =    6124 /   51200             ( 11.96%) | total_pruned =   45076 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =    8695 /  102400             (  8.49%) | total_pruned =   93705 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =   13145 /  204800             (  6.42%) | total_pruned =  191655 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =   17398 /  409600             (  4.25%) | total_pruned =  392202 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   24405 /  409600             (  5.96%) | total_pruned =  385195 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   28703 /  409600             (  7.01%) | total_pruned =  380897 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   48832 /  409600             ( 11.92%) | total_pruned =  360768 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   57540 /  409600             ( 14.05%) | total_pruned =  352060 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   22615 /  147456             ( 15.34%) | total_pruned =  124841 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   23521 /  147456             ( 15.95%) | total_pruned =  123935 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   20621 /  147456             ( 13.98%) | total_pruned =  126835 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   10304 /   73728             ( 13.98%) | total_pruned =   63424 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    3559 /   18432             ( 19.31%) | total_pruned =   14873 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      20 /      32             ( 62.50%) | total_pruned =      12 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1374 /    4608             ( 29.82%) | total_pruned =    3234 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      28 /      48             ( 58.33%) | total_pruned =      20 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 300886, pruned : 2707981, total: 3008867, Compression rate :      10.00x  ( 90.00% pruned)
PSNR of output image is:  25.093043291136322
Experiment done
