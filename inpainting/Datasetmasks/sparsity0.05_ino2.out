(3, 256, 256)
(3, 256, 256)
Noisy PSNR is '7.2929844778999655'
(3, 256, 256) (3, 256, 256) torch.Size([1, 32, 256, 256])
Output directory: data/inpainting/Dataset/mask/2/sparsity/0.5/det/0.05/1e-09
epoch:  0 quantization_loss:  0.021967260167002678
p mean is: tensor(-0.0002, device='cuda:2')
epoch:  1000 quantization_loss:  0.021806975826621056
p mean is: tensor(-0.0106, device='cuda:2')
epoch:  2000 quantization_loss:  0.021613704040646553
p mean is: tensor(-0.0191, device='cuda:2')
epoch:  3000 quantization_loss:  0.022060230374336243
p mean is: tensor(-0.0279, device='cuda:2')
epoch:  4000 quantization_loss:  0.021509813144803047
p mean is: tensor(-0.0367, device='cuda:2')
epoch:  5000 quantization_loss:  0.0217824075371027
p mean is: tensor(-0.0457, device='cuda:2')
epoch:  6000 quantization_loss:  0.021399907767772675
p mean is: tensor(-0.0551, device='cuda:2')
epoch:  7000 quantization_loss:  0.021191226318478584
p mean is: tensor(-0.0645, device='cuda:2')
epoch:  8000 quantization_loss:  0.022048335522413254
p mean is: tensor(-0.0735, device='cuda:2')
epoch:  9000 quantization_loss:  0.021579952910542488
p mean is: tensor(-0.0823, device='cuda:2')
epoch:  10000 quantization_loss:  0.02197732776403427
p mean is: tensor(-0.0913, device='cuda:2')
epoch:  11000 quantization_loss:  0.021339286118745804
p mean is: tensor(-0.1004, device='cuda:2')
epoch:  12000 quantization_loss:  0.019961947575211525
p mean is: tensor(-0.1094, device='cuda:2')
epoch:  13000 quantization_loss:  0.016068410128355026
p mean is: tensor(-0.1189, device='cuda:2')
epoch:  14000 quantization_loss:  0.01287686824798584
p mean is: tensor(-0.1314, device='cuda:2')
epoch:  15000 quantization_loss:  0.011426299810409546
p mean is: tensor(-0.1482, device='cuda:2')
epoch:  16000 quantization_loss:  0.009618488140404224
p mean is: tensor(-0.1706, device='cuda:2')
epoch:  17000 quantization_loss:  0.007475927472114563
p mean is: tensor(-0.2005, device='cuda:2')
epoch:  18000 quantization_loss:  0.006862693466246128
p mean is: tensor(-0.2392, device='cuda:2')
epoch:  19000 quantization_loss:  0.00635540671646595
p mean is: tensor(-0.2879, device='cuda:2')
epoch:  20000 quantization_loss:  0.005219578742980957
p mean is: tensor(-0.3469, device='cuda:2')
epoch:  21000 quantization_loss:  0.0048281485214829445
p mean is: tensor(-0.4157, device='cuda:2')
epoch:  22000 quantization_loss:  0.004871580749750137
p mean is: tensor(-0.4923, device='cuda:2')
epoch:  23000 quantization_loss:  0.004194470588117838
p mean is: tensor(-0.5738, device='cuda:2')
epoch:  24000 quantization_loss:  0.004082126542925835
p mean is: tensor(-0.6560, device='cuda:2')
epoch:  25000 quantization_loss:  0.003890605177730322
p mean is: tensor(-0.7348, device='cuda:2')
epoch:  26000 quantization_loss:  0.0038934946060180664
p mean is: tensor(-0.8072, device='cuda:2')
epoch:  27000 quantization_loss:  0.003642298514023423
p mean is: tensor(-0.8715, device='cuda:2')
epoch:  28000 quantization_loss:  0.003604135476052761
p mean is: tensor(-0.9276, device='cuda:2')
epoch:  29000 quantization_loss:  0.0035069407895207405
p mean is: tensor(-0.9761, device='cuda:2')
epoch:  30000 quantization_loss:  0.0024599514435976744
p mean is: tensor(-1.0174, device='cuda:2')
epoch:  31000 quantization_loss:  0.002384183695539832
p mean is: tensor(-1.0525, device='cuda:2')
epoch:  32000 quantization_loss:  0.0021830187179148197
p mean is: tensor(-1.0822, device='cuda:2')
epoch:  33000 quantization_loss:  0.002106595551595092
p mean is: tensor(-1.1076, device='cuda:2')
epoch:  34000 quantization_loss:  0.00208447128534317
p mean is: tensor(-1.1295, device='cuda:2')
epoch:  35000 quantization_loss:  0.0020630708895623684
p mean is: tensor(-1.1482, device='cuda:2')
epoch:  36000 quantization_loss:  0.002034615958109498
p mean is: tensor(-1.1644, device='cuda:2')
epoch:  37000 quantization_loss:  0.002006921451538801
p mean is: tensor(-1.1783, device='cuda:2')
epoch:  38000 quantization_loss:  0.0020035509951412678
p mean is: tensor(-1.1904, device='cuda:2')
epoch:  39000 quantization_loss:  0.0019885008223354816
p mean is: tensor(-1.2009, device='cuda:2')
epoch:  40000 quantization_loss:  0.001949077588506043
p mean is: tensor(-1.2100, device='cuda:2')
epoch:  41000 quantization_loss:  0.0019430016400292516
p mean is: tensor(-1.2181, device='cuda:2')
epoch:  42000 quantization_loss:  0.0019267192110419273
p mean is: tensor(-1.2252, device='cuda:2')
epoch:  43000 quantization_loss:  0.0019114894093945622
p mean is: tensor(-1.2315, device='cuda:2')
epoch:  44000 quantization_loss:  0.001922924304381013
p mean is: tensor(-1.2370, device='cuda:2')
epoch:  45000 quantization_loss:  0.001890235929749906
p mean is: tensor(-1.2419, device='cuda:2')
epoch:  46000 quantization_loss:  0.001895611872896552
p mean is: tensor(-1.2461, device='cuda:2')
epoch:  47000 quantization_loss:  0.001862730598077178
p mean is: tensor(-1.2501, device='cuda:2')
epoch:  48000 quantization_loss:  0.0018649433040991426
p mean is: tensor(-1.2536, device='cuda:2')
epoch:  49000 quantization_loss:  0.001855541835539043
p mean is: tensor(-1.2567, device='cuda:2')
epoch:  50000 quantization_loss:  0.001842845929786563
p mean is: tensor(-1.2595, device='cuda:2')
epoch:  51000 quantization_loss:  0.0018417264800518751
p mean is: tensor(-1.2621, device='cuda:2')
epoch:  52000 quantization_loss:  0.00183997699059546
p mean is: tensor(-1.2644, device='cuda:2')
epoch:  53000 quantization_loss:  0.001835681963711977
p mean is: tensor(-1.2666, device='cuda:2')
epoch:  54000 quantization_loss:  0.0018254158785566688
p mean is: tensor(-1.2685, device='cuda:2')
epoch:  55000 quantization_loss:  0.001819161232560873
p mean is: tensor(-1.2703, device='cuda:2')
epoch:  56000 quantization_loss:  0.0018117306753993034
p mean is: tensor(-1.2720, device='cuda:2')
epoch:  57000 quantization_loss:  0.0018121872562915087
p mean is: tensor(-1.2736, device='cuda:2')
epoch:  58000 quantization_loss:  0.0018145128851756454
p mean is: tensor(-1.2750, device='cuda:2')
epoch:  59000 quantization_loss:  0.0018045891774818301
p mean is: tensor(-1.2763, device='cuda:2')
Number of elements to keep: 150443
Threshold value: -1.1187421083450317
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
here
Number of elements to keep: 150443
Threshold value: -1.1187421083450317
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
1.1.1.weight         | nonzeros =    1829 /   12800             ( 14.29%) | total_pruned =   10971 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.2.weight           | nonzeros =       9 /      16             ( 56.25%) | total_pruned =       7 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =     754 /    6400             ( 11.78%) | total_pruned =    5646 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.5.weight           | nonzeros =      12 /      16             ( 75.00%) | total_pruned =       4 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =    1053 /   12800             (  8.23%) | total_pruned =   11747 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      19 /      32             ( 59.38%) | total_pruned =      13 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =    1221 /   25600             (  4.77%) | total_pruned =   24379 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =    1499 /   51200             (  2.93%) | total_pruned =   49701 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =    1852 /  102400             (  1.81%) | total_pruned =  100548 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =    2473 /  204800             (  1.21%) | total_pruned =  202327 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =    3429 /  409600             (  0.84%) | total_pruned =  406171 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =    5782 /  409600             (  1.41%) | total_pruned =  403818 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =    8115 /  409600             (  1.98%) | total_pruned =  401485 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =   17518 /  409600             (  4.28%) | total_pruned =  392082 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =   27404 /  409600             (  6.69%) | total_pruned =  382196 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   19331 /  147456             ( 13.11%) | total_pruned =  128125 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =   23429 /  147456             ( 15.89%) | total_pruned =  124027 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =   19438 /  147456             ( 13.18%) | total_pruned =  128018 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   10016 /   73728             ( 13.59%) | total_pruned =   63712 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =    2971 /   18432             ( 16.12%) | total_pruned =   15461 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      18 /      32             ( 56.25%) | total_pruned =      14 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    1192 /    4608             ( 25.87%) | total_pruned =    3416 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
4.weight             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      30 /      48             ( 62.50%) | total_pruned =      18 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       1 /       3             ( 33.33%) | total_pruned =       2 | shape = torch.Size([3])
alive: 150443, pruned : 2858424, total: 3008867, Compression rate :      20.00x  ( 95.00% pruned)
PSNR of output image is:  24.19777316468039
Experiment done
