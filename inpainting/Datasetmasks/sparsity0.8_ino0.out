(3, 512, 512)
(3, 512, 512)
Noisy PSNR is '11.746938206199552'
(3, 512, 512) (3, 512, 512) torch.Size([1, 32, 512, 512])
Output directory: data/inpainting/Dataset/mask/0/sparsity/0.5/det/0.8/1e-09
epoch:  0 quantization_loss:  0.047639600932598114
p mean is: tensor(-0.0002, device='cuda:0')
epoch:  1000 quantization_loss:  0.03531787171959877
p mean is: tensor(-0.0321, device='cuda:0')
epoch:  2000 quantization_loss:  0.03447955846786499
p mean is: tensor(-0.0598, device='cuda:0')
epoch:  3000 quantization_loss:  0.03350955247879028
p mean is: tensor(-0.0838, device='cuda:0')
epoch:  4000 quantization_loss:  0.03331523761153221
p mean is: tensor(-0.1052, device='cuda:0')
epoch:  5000 quantization_loss:  0.03309588134288788
p mean is: tensor(-0.1265, device='cuda:0')
epoch:  6000 quantization_loss:  0.032928355038166046
p mean is: tensor(-0.1493, device='cuda:0')
epoch:  7000 quantization_loss:  0.032951030880212784
p mean is: tensor(-0.1732, device='cuda:0')
epoch:  8000 quantization_loss:  0.03291790187358856
p mean is: tensor(-0.1987, device='cuda:0')
epoch:  9000 quantization_loss:  0.03310268372297287
p mean is: tensor(-0.2263, device='cuda:0')
epoch:  10000 quantization_loss:  0.032720934599637985
p mean is: tensor(-0.2558, device='cuda:0')
epoch:  11000 quantization_loss:  0.03268902003765106
p mean is: tensor(-0.2904, device='cuda:0')
epoch:  12000 quantization_loss:  0.03263908624649048
p mean is: tensor(-0.3329, device='cuda:0')
epoch:  13000 quantization_loss:  0.03283360227942467
p mean is: tensor(-0.3840, device='cuda:0')
epoch:  14000 quantization_loss:  0.03243935480713844
p mean is: tensor(-0.4408, device='cuda:0')
epoch:  15000 quantization_loss:  0.032338742166757584
p mean is: tensor(-0.5050, device='cuda:0')
epoch:  16000 quantization_loss:  0.0322042740881443
p mean is: tensor(-0.5766, device='cuda:0')
epoch:  17000 quantization_loss:  0.03212719038128853
p mean is: tensor(-0.6532, device='cuda:0')
epoch:  18000 quantization_loss:  0.032026004046201706
p mean is: tensor(-0.7306, device='cuda:0')
epoch:  19000 quantization_loss:  0.031961191445589066
p mean is: tensor(-0.8052, device='cuda:0')
epoch:  20000 quantization_loss:  0.03189430385828018
p mean is: tensor(-0.8742, device='cuda:0')
epoch:  21000 quantization_loss:  0.03161371499300003
p mean is: tensor(-0.9354, device='cuda:0')
epoch:  22000 quantization_loss:  0.03153759613633156
p mean is: tensor(-0.9878, device='cuda:0')
epoch:  23000 quantization_loss:  0.03145931288599968
p mean is: tensor(-1.0325, device='cuda:0')
epoch:  24000 quantization_loss:  0.03143298253417015
p mean is: tensor(-1.0709, device='cuda:0')
epoch:  25000 quantization_loss:  0.0311632938683033
p mean is: tensor(-1.1033, device='cuda:0')
epoch:  26000 quantization_loss:  0.03113195113837719
p mean is: tensor(-1.1304, device='cuda:0')
epoch:  27000 quantization_loss:  0.031064298003911972
p mean is: tensor(-1.1535, device='cuda:0')
epoch:  28000 quantization_loss:  0.03074488416314125
p mean is: tensor(-1.1734, device='cuda:0')
epoch:  29000 quantization_loss:  0.030802760273218155
p mean is: tensor(-1.1902, device='cuda:0')
epoch:  30000 quantization_loss:  0.030704613775014877
p mean is: tensor(-1.2047, device='cuda:0')
epoch:  31000 quantization_loss:  0.030670348554849625
p mean is: tensor(-1.2174, device='cuda:0')
epoch:  32000 quantization_loss:  0.030652597546577454
p mean is: tensor(-1.2285, device='cuda:0')
epoch:  33000 quantization_loss:  0.03061641938984394
p mean is: tensor(-1.2383, device='cuda:0')
epoch:  34000 quantization_loss:  0.030601127073168755
p mean is: tensor(-1.2468, device='cuda:0')
epoch:  35000 quantization_loss:  0.03069530799984932
p mean is: tensor(-1.2543, device='cuda:0')
epoch:  36000 quantization_loss:  0.03057880885899067
p mean is: tensor(-1.2610, device='cuda:0')
epoch:  37000 quantization_loss:  0.030567778274416924
p mean is: tensor(-1.2669, device='cuda:0')
epoch:  38000 quantization_loss:  0.030564630404114723
p mean is: tensor(-1.2721, device='cuda:0')
epoch:  39000 quantization_loss:  0.030553041025996208
p mean is: tensor(-1.2767, device='cuda:0')
epoch:  40000 quantization_loss:  0.03053506463766098
p mean is: tensor(-1.2808, device='cuda:0')
epoch:  41000 quantization_loss:  0.030525676906108856
p mean is: tensor(-1.2844, device='cuda:0')
epoch:  42000 quantization_loss:  0.030529621988534927
p mean is: tensor(-1.2877, device='cuda:0')
epoch:  43000 quantization_loss:  0.03051302395761013
p mean is: tensor(-1.2906, device='cuda:0')
epoch:  44000 quantization_loss:  0.030501259490847588
p mean is: tensor(-1.2933, device='cuda:0')
epoch:  45000 quantization_loss:  0.030496621504426003
p mean is: tensor(-1.2956, device='cuda:0')
epoch:  46000 quantization_loss:  0.030485114082694054
p mean is: tensor(-1.2978, device='cuda:0')
epoch:  47000 quantization_loss:  0.0304859708994627
p mean is: tensor(-1.2998, device='cuda:0')
epoch:  48000 quantization_loss:  0.030479075387120247
p mean is: tensor(-1.3016, device='cuda:0')
epoch:  49000 quantization_loss:  0.0304817333817482
p mean is: tensor(-1.3033, device='cuda:0')
epoch:  50000 quantization_loss:  0.030174724757671356
p mean is: tensor(-1.3048, device='cuda:0')
epoch:  51000 quantization_loss:  0.03016551025211811
p mean is: tensor(-1.3061, device='cuda:0')
epoch:  52000 quantization_loss:  0.030141562223434448
p mean is: tensor(-1.3074, device='cuda:0')
epoch:  53000 quantization_loss:  0.03013930656015873
p mean is: tensor(-1.3086, device='cuda:0')
epoch:  54000 quantization_loss:  0.030140304937958717
p mean is: tensor(-1.3099, device='cuda:0')
epoch:  55000 quantization_loss:  0.030140740796923637
p mean is: tensor(-1.3111, device='cuda:0')
epoch:  56000 quantization_loss:  0.0301193930208683
p mean is: tensor(-1.3123, device='cuda:0')
epoch:  57000 quantization_loss:  0.030122630298137665
p mean is: tensor(-1.3133, device='cuda:0')
epoch:  58000 quantization_loss:  0.0301199983805418
p mean is: tensor(-1.3144, device='cuda:0')
epoch:  59000 quantization_loss:  0.030110731720924377
p mean is: tensor(-1.3154, device='cuda:0')
Number of elements to keep: 2407093
Threshold value: -1.3191652297973633
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.7999998005893912
here
Number of elements to keep: 150443
Threshold value: -1.0158178806304932
Number of elements equal to threshold: 1
Number of elements to randomly select: 1
Actual sparsity achieved: 0.04999988367714492
1.1.1.weight         | nonzeros =    7151 /   12800             ( 55.87%) | total_pruned =    5649 | shape = torch.Size([16, 32, 5, 5])
1.1.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.2.weight           | nonzeros =      11 /      16             ( 68.75%) | total_pruned =       5 | shape = torch.Size([16])
1.2.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.4.1.weight         | nonzeros =    4316 /    6400             ( 67.44%) | total_pruned =    2084 | shape = torch.Size([16, 16, 5, 5])
1.4.1.bias           | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
1.5.weight           | nonzeros =       7 /      16             ( 43.75%) | total_pruned =       9 | shape = torch.Size([16])
1.5.bias             | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
1.7.1.1.1.weight     | nonzeros =    9173 /   12800             ( 71.66%) | total_pruned =    3627 | shape = torch.Size([32, 16, 5, 5])
1.7.1.1.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.2.weight       | nonzeros =      16 /      32             ( 50.00%) | total_pruned =      16 | shape = torch.Size([32])
1.7.1.2.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.4.1.weight     | nonzeros =   18819 /   25600             ( 73.51%) | total_pruned =    6781 | shape = torch.Size([32, 32, 5, 5])
1.7.1.4.1.bias       | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.1.5.weight       | nonzeros =      13 /      32             ( 40.62%) | total_pruned =      19 | shape = torch.Size([32])
1.7.1.5.bias         | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
1.7.1.7.1.1.1.weight | nonzeros =   38099 /   51200             ( 74.41%) | total_pruned =   13101 | shape = torch.Size([64, 32, 5, 5])
1.7.1.7.1.1.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.2.weight   | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
1.7.1.7.1.2.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.4.1.weight | nonzeros =   78970 /  102400             ( 77.12%) | total_pruned =   23430 | shape = torch.Size([64, 64, 5, 5])
1.7.1.7.1.4.1.bias   | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.1.5.weight   | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
1.7.1.7.1.5.bias     | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.1.7.1.7.1.1.1.weight | nonzeros =  164068 /  204800             ( 80.11%) | total_pruned =   40732 | shape = torch.Size([128, 64, 5, 5])
1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.weight | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.4.1.weight | nonzeros =  338766 /  409600             ( 82.71%) | total_pruned =   70834 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.weight | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  333441 /  409600             ( 81.41%) | total_pruned =   76159 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  318067 /  409600             ( 77.65%) | total_pruned =   91533 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.1.1.weight | nonzeros =  308956 /  409600             ( 75.43%) | total_pruned =  100644 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.1.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.4.1.weight | nonzeros =  322604 /  409600             ( 78.76%) | total_pruned =   86996 | shape = torch.Size([128, 128, 5, 5])
1.7.1.7.1.7.1.7.1.7.1.4.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.weight | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.1.5.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.weight | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  123461 /  147456             ( 83.73%) | total_pruned =   23995 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.weight | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.weight | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.2.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.3.1.weight | nonzeros =  128921 /  147456             ( 87.43%) | total_pruned =   18535 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.weight | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
1.7.1.7.1.7.1.7.4.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.2.weight | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
1.7.1.7.1.7.2.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.1.7.3.1.weight | nonzeros =  126736 /  147456             ( 85.95%) | total_pruned =   20720 | shape = torch.Size([128, 128, 3, 3])
1.7.1.7.1.7.3.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
1.7.1.7.1.7.4.weight | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
1.7.1.7.1.7.4.bias   | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.2.weight     | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
1.7.1.7.2.bias       | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
1.7.1.7.3.1.weight   | nonzeros =   62412 /   73728             ( 84.65%) | total_pruned =   11316 | shape = torch.Size([64, 128, 3, 3])
1.7.1.7.3.1.bias     | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
1.7.1.7.4.weight     | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
1.7.1.7.4.bias       | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.2.weight         | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
1.7.2.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
1.7.3.1.weight       | nonzeros =   15421 /   18432             ( 83.66%) | total_pruned =    3011 | shape = torch.Size([32, 64, 3, 3])
1.7.3.1.bias         | nonzeros =      32 /      32             (100.00%) | total_pruned =       0 | shape = torch.Size([32])
1.7.4.weight         | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
1.7.4.bias           | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
2.weight             | nonzeros =      11 /      32             ( 34.38%) | total_pruned =      21 | shape = torch.Size([32])
2.bias               | nonzeros =       0 /      32             (  0.00%) | total_pruned =      32 | shape = torch.Size([32])
3.1.weight           | nonzeros =    3150 /    4608             ( 68.36%) | total_pruned =    1458 | shape = torch.Size([16, 32, 3, 3])
3.1.bias             | nonzeros =      16 /      16             (100.00%) | total_pruned =       0 | shape = torch.Size([16])
4.weight             | nonzeros =      12 /      16             ( 75.00%) | total_pruned =       4 | shape = torch.Size([16])
4.bias               | nonzeros =       0 /      16             (  0.00%) | total_pruned =      16 | shape = torch.Size([16])
6.1.weight           | nonzeros =      16 /      48             ( 33.33%) | total_pruned =      32 | shape = torch.Size([3, 16, 1, 1])
6.1.bias             | nonzeros =       2 /       3             ( 66.67%) | total_pruned =       1 | shape = torch.Size([3])
alive: 2404997, pruned : 603870, total: 3008867, Compression rate :       1.25x  ( 20.07% pruned)
PSNR of output image is:  12.208393558395587
Experiment done
